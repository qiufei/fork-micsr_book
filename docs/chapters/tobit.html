<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Microeconometrics with R - 11&nbsp; Censored and truncated models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/count.html" rel="next">
<link href="../chapters/binomial.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="../site_libs/kePrint/kePrint.js"></script><link href="../site_libs/lightable/lightable.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Microeconometrics with R</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../OLS.html" class="sidebar-item-text sidebar-link">Ordinary least squares estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression_properties.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistical properties of the simple linear estimator</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/multiple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Multiple regression model</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/coefficients.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interpretation of the Coefficients</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../beyond_OLS.html" class="sidebar-item-text sidebar-link">Beyond the OLS estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/maximum_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Maximum likelihood estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/non_spherical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Non-spherical disturbances</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/endogeneity.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Endogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/treateff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Treatment effect</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/spatial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial econometrics</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../special_responses.html" class="sidebar-item-text sidebar-link">Special responses</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/binomial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/tobit.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/count.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Count data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/duration.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Duration models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/rum.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Discrete choice models</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-trunc_cens" id="toc-sec-trunc_cens" class="nav-link active" data-scroll-target="#sec-trunc_cens"><span class="toc-section-number">11.1</span>  Truncated response, truncated and censored samples</a>
  <ul class="collapse">
<li><a href="#corner-solution" id="toc-corner-solution" class="nav-link" data-scroll-target="#corner-solution">Corner solution</a></li>
  <li><a href="#data-censoring-and-truncation" id="toc-data-censoring-and-truncation" class="nav-link" data-scroll-target="#data-censoring-and-truncation">Data censoring and truncation</a></li>
  <li><a href="#sample-selection" id="toc-sample-selection" class="nav-link" data-scroll-target="#sample-selection">Sample selection</a></li>
  <li><a href="#truncated-and-censored-samples" id="toc-truncated-and-censored-samples" class="nav-link" data-scroll-target="#truncated-and-censored-samples">Truncated and censored samples</a></li>
  </ul>
</li>
  <li>
<a href="#sec-tobit1" id="toc-sec-tobit1" class="nav-link" data-scroll-target="#sec-tobit1"><span class="toc-section-number">11.2</span>  Tobit-1 model</a>
  <ul class="collapse">
<li><a href="#truncated-normal-distribution-truncated-and-censored-sample" id="toc-truncated-normal-distribution-truncated-and-censored-sample" class="nav-link" data-scroll-target="#truncated-normal-distribution-truncated-and-censored-sample">Truncated normal distribution, truncated and censored sample</a></li>
  <li><a href="#interpretation-of-the-coefficients" id="toc-interpretation-of-the-coefficients" class="nav-link" data-scroll-target="#interpretation-of-the-coefficients">Interpretation of the coefficients</a></li>
  </ul>
</li>
  <li>
<a href="#sec-tobit_estim" id="toc-sec-tobit_estim" class="nav-link" data-scroll-target="#sec-tobit_estim"><span class="toc-section-number">11.3</span>  Methods of estimation</a>
  <ul class="collapse">
<li><a href="#non-linear-least-squares" id="toc-non-linear-least-squares" class="nav-link" data-scroll-target="#non-linear-least-squares">Non-linear least squares</a></li>
  <li><a href="#probit-and-two-step-estimators" id="toc-probit-and-two-step-estimators" class="nav-link" data-scroll-target="#probit-and-two-step-estimators">Probit and two-step estimators</a></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">Maximum Likelihood estimation</a></li>
  <li><a href="#semi-parametric-estimators" id="toc-semi-parametric-estimators" class="nav-link" data-scroll-target="#semi-parametric-estimators">Semi-parametric estimators</a></li>
  </ul>
</li>
  <li>
<a href="#sec-tobit_estim_R" id="toc-sec-tobit_estim_R" class="nav-link" data-scroll-target="#sec-tobit_estim_R"><span class="toc-section-number">11.4</span>  Estimation of the tobit-1 model with R</a>
  <ul class="collapse">
<li><a href="#sec-charitable_estimation" id="toc-sec-charitable_estimation" class="nav-link" data-scroll-target="#sec-charitable_estimation">Left-truncated response</a></li>
  <li><a href="#right-truncated-response" id="toc-right-truncated-response" class="nav-link" data-scroll-target="#right-truncated-response">Right-truncated response</a></li>
  <li><a href="#two-sided-tobit-models" id="toc-two-sided-tobit-models" class="nav-link" data-scroll-target="#two-sided-tobit-models">Two-sided tobit models</a></li>
  </ul>
</li>
  <li>
<a href="#sec-tobit_eval" id="toc-sec-tobit_eval" class="nav-link" data-scroll-target="#sec-tobit_eval"><span class="toc-section-number">11.5</span>  Evaluation and tests</a>
  <ul class="collapse">
<li><a href="#conditional-moment-tests" id="toc-conditional-moment-tests" class="nav-link" data-scroll-target="#conditional-moment-tests">Conditional moment tests</a></li>
  <li><a href="#endogeneity" id="toc-endogeneity" class="nav-link" data-scroll-target="#endogeneity">Endogeneity</a></li>
  </ul>
</li>
  <li>
<a href="#sec-tobit2" id="toc-sec-tobit2" class="nav-link" data-scroll-target="#sec-tobit2"><span class="toc-section-number">11.6</span>  Tobit-2 model</a>
  <ul class="collapse">
<li><a href="#two-part-models" id="toc-two-part-models" class="nav-link" data-scroll-target="#two-part-models">Two-part models</a></li>
  <li><a href="#hurdle-models" id="toc-hurdle-models" class="nav-link" data-scroll-target="#hurdle-models">Hurdle models</a></li>
  <li><a href="#correlated-models" id="toc-correlated-models" class="nav-link" data-scroll-target="#correlated-models">Correlated models</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">Application</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-tobit" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><!-- precportfolio food trafficcitations + charitable dans tobit1 --><p>We’ll discuss in this chapter models for which the value of the response is continuous and observed only in a certain range. These variables are truncated for a certain value, which can be on the left side of the distribution (<span class="math inline">\(l\)</span>), on the right side (<span class="math inline">\(u\)</span>) or on both sides. Therefore, the distribution of such a variable is a mix of a discrete and a continuous distribution:</p>
<ul>
<li>the value of <span class="math inline">\(y\)</span> is continuous on the <span class="math inline">\(]l, u[\)</span> interval, and its distribution can be described by a density function <span class="math inline">\(f(y)\)</span>,</li>
<li>there is a mass of probability on <span class="math inline">\(l\)</span> or/and on <span class="math inline">\(u\)</span>, which is described by a probability <span class="math inline">\(P(y = l)\)</span> or/and <span class="math inline">\(P(y = u)\)</span>.</li>
</ul>
<p><a href="#sec-trunc_cens"><span>Section&nbsp;11.1</span></a> describes the situations where such responses occur. The Tobit model is presented in details in <a href="#sec-tobit1"><span>Section&nbsp;11.2</span></a>, the relevant estimation methods in <a href="#sec-tobit_estim"><span>Section&nbsp;11.3</span></a> and their implementation in <strong>R</strong> in <a href="#sec-tobit_estim_R"><span>Section&nbsp;11.4</span></a>. <a href="#sec-tobit_eval"><span>Section&nbsp;11.5</span></a> presents different tools useful to evaluate fitted models. Finally, <a href="#sec-tobit2"><span>Section&nbsp;11.6</span></a> presents the two-equations tobit model.</p>
<section id="sec-trunc_cens" class="level2" data-number="11.1"><h2 data-number="11.1" class="anchored" data-anchor-id="sec-trunc_cens">
<span class="header-section-number">11.1</span> Truncated response, truncated and censored samples</h2>
<p>Truncated responses are observed in different contexts in economics. The first is a corner solution, the second is a problem of missing data, also called censoring, and the last is a problem of selection, also called incidental truncation.</p>
<section id="corner-solution" class="level3"><h3 class="anchored" data-anchor-id="corner-solution">Corner solution</h3>
<p></p>
<p>Consider a consumer who can buy two goods, food (<span class="math inline">\(z\)</span>) and vacations (<span class="math inline">\(y\)</span>). Denoting <span class="math inline">\(q_z\)</span> and <span class="math inline">\(q_y\)</span> as the quantities of the two goods, assume that the preferences of the consumer can be represented by the following utility function:</p>
<p><span class="math display">\[
U(q_y,q_z) = (q_y + \mu) ^ \beta q_z ^ {1 - \beta}
\]</span></p>
<p>where <span class="math inline">\(0 &lt; \beta &lt; 1\)</span> and <span class="math inline">\(\mu &gt; 0\)</span>. The consumer seeks to maximize their utility subject to their budget constraint, which writes <span class="math inline">\(x=p_y q_y + p_z q_z\)</span>, where <span class="math inline">\(x\)</span> is the income and <span class="math inline">\(p_y\)</span> and <span class="math inline">\(p_z\)</span> are the unit prices of the two goods. For an interior solution, the consumer should equate the marginal rate of substitution to the price ratio:</p>
<p><span class="math display">\[
\frac{\beta}{1-\beta}\frac{q_z}{q_y + \mu} = \frac{p_y}{p_z}
\]</span></p>
<p>We therefore have <span class="math inline">\(p_z q_z = \frac{1 - \beta}{\beta} p_y(q_y + \mu)\)</span>. Replacing in the budget constraint and solving for <span class="math inline">\(q_z\)</span> and then for <span class="math inline">\(q_y\)</span>, we finally get the demand functions.</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
q_z &amp;=&amp; \displaystyle(1-\beta)\frac{x}{p_z} + (1-\beta)\frac{p_y}{p_z} \mu \\
q_y &amp;=&amp; \displaystyle\beta \frac{x}{p_y} - (1-\beta)\mu \\
\end{array}
\right.
\]</span></p>
<p>Note that the demand function for <span class="math inline">\(y\)</span> can return negative values, which of course is impossible. Therefore, the pseudo-demand function previously written are only suitable for an interior solution, i.e., when both goods are consumed. This is only the case for a sufficient level of income, namely <span class="math inline">\(\bar{x} = \frac{1 - \beta}{\beta} p_y \mu\)</span>. For a lower level of income, we have <span class="math inline">\(q_y = 0\)</span> and therefore <span class="math inline">\(q_z = x / p_z\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-cornersol" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="tobit_files/figure-html/fig-cornersol-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.1: Internal and corner solution</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>This situation is depicted on <a href="#fig-cornersol">Figure&nbsp;<span>11.1</span></a>. Points <span class="math inline">\(D\)</span> and <span class="math inline">\(E\)</span> correspond to interior solutions for large values of the income. On the contrary, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are corner solutions for low income households. We then have <span class="math inline">\(q_y=0\)</span> and the value of the marginal rate of substitution (the slope of the indifference curve) is lower than the price ratio. Point <span class="math inline">\(C\)</span> corresponds to the level of income that leads to a corner solution but for which the marginal rate of substitution equals the price ratio. The consumption of <span class="math inline">\(y\)</span> starts when the income is greater than this level. The expression simplifies by taking as the response the expense for the good, <span class="math inline">\(y = p_y q_y\)</span> and not the quantity. We then have: <span class="math inline">\(y = \beta x - (1 - \beta)p_y\mu\)</span> or, replacing <span class="math inline">\(p_y \mu\)</span> by its expression in terms of <span class="math inline">\(\bar{x}\)</span>:</p>
<p><span class="math display">\[
y = - \beta \bar{x} + \beta x = \alpha + \beta x
\]</span></p>
<p>In a linear regression context, the slope is therefore the marginal propensity to consume the specific good (for 1 more dollar of income, the expense increases by <span class="math inline">\(\beta\)</span> dollars) and the intercept is the opposite of <span class="math inline">\(\beta\)</span> times the minimum income <span class="math inline">\(\bar{x}\)</span> for which the consumption is positive.</p>
<p>The expense on good <span class="math inline">\(y\)</span> is an example of a truncated variable, more precisely a left-zero truncated variable. Note that, as stressed by <span class="citation" data-cites="WOOL:10">Wooldridge (<a href="#ref-WOOL:10" role="doc-biblioref">2010</a>)</span>, pp.517-520, 0 is a relevant value for the variable (this is not the case for the situation described in the next section), but all the values of 0 don’t have the same meaning. For example, at point <span class="math inline">\(B\)</span>, <span class="math inline">\(y\)</span> equal 0, but a small increase of the income would lead the household to start consuming the good. On the contrary, at point <span class="math inline">\(A\)</span>, <span class="math inline">\(y\)</span> also equals 0, but even with a large increase of income, the household would still consume only good <span class="math inline">\(z\)</span> and not good <span class="math inline">\(y\)</span>. </p>
</section><section id="data-censoring-and-truncation" class="level3"><h3 class="anchored" data-anchor-id="data-censoring-and-truncation">Data censoring and truncation</h3>
<p></p>
<p>Data censoring occurs when the value of the variable is reported only in a certain range <span class="math inline">\(]l,u[\)</span> and is set to <span class="math inline">\(l\)</span> or <span class="math inline">\(u\)</span> otherwise. For example, <span class="citation" data-cites="CROM:PALM:URBA:97">De Crombrugghe, Palm, and Urbain (<a href="#ref-CROM:PALM:URBA:97" role="doc-biblioref">1997</a>)</span> estimate the demand for food using household survey data in the Netherlands. For the upper 5 percentiles (13030 Dfl), the expenditure is not reported, but it is replaced by the average value (17670 Dfl). Therefore, the response is right-truncated with <span class="math inline">\(u =13030\)</span>. In this case, the data censoring process takes the <strong>top-coding</strong> form and <span class="math inline">\(13030\)</span> is not a relevant value of the covariate. Sometimes, the censoring process leads to a truncation sample, which means that only observations for which the response is in the continuous observed range are selected. A classic example is Hausman and Wise <span class="citation" data-cites="HAUS:WISE:76 HAUS:WISE:77">(<a href="#ref-HAUS:WISE:76" role="doc-biblioref">1976</a>, <a href="#ref-HAUS:WISE:77" role="doc-biblioref">1977</a>)</span> who used data from the New Jersey negative income tax experiment, for which families with income above 1.5 times the poverty level were excluded.</p>
</section><section id="sample-selection" class="level3"><h3 class="anchored" data-anchor-id="sample-selection">Sample selection</h3>
<p> The last data-generating process is the one of sample selection. It means that the observation of the response in a particular sample is not random because of a self-selection process. This kind of process was first analyzed by <span class="citation" data-cites="GRON:73">Gronau (<a href="#ref-GRON:73" role="doc-biblioref">1973</a>)</span> in the context of women participation in the labor force: the response is the wage offered to women, but it is only observed for women who participate in the labor market. Although it is clearly a different form of truncation compared to the case of a corner solution or data censoring, the models that deal with these kinds of responses are much alike; it therefore makes sense to consider these two cases in the same chapter. <!-- Data censoring often occurs when the response is a duration, for --> <!-- example an unemployment spell. If the interview starts in january 2020 --> <!-- and ends in december 2020 and that every individual reports mouthly --> <!-- their situation, 3 situations can be observed: --></p>
<!-- - the job is lost in march and another job is found in september, -->
<!--   therefore the unemployment spell is 7 month, -->
<!-- - the individual was unemployed when the survey started and found a -->
<!--   job in june: in this case, the response is left-censored and all we -->
<!--   can say about the unemployment spell (that ended) is that it is at -->
<!--   least equal to 6 month, -->
<!-- - the individual lost his job in september and is still unemployed at -->
<!--   the end of the survey. The unemployment spell is therefore ongoing -->
<!--   and will length at least 4 months. -->
</section><section id="truncated-and-censored-samples" class="level3"><h3 class="anchored" data-anchor-id="truncated-and-censored-samples">Truncated and censored samples</h3>
<p>Responses considered in this chapter are <strong>truncated variables</strong>, but the sample used can be either truncated or censored. For the demand for vacations:</p>
<ul>
<li>a <strong>censored sample</strong> consists of households for which the expenditure on vacations is positive and on household for which this expenditure is 0,</li>
<li>a <strong>truncated sample</strong> consists only of households for which the expenditure is strictly positive.</li>
</ul>
<p>Samples used in consumer expenditure surveys are censored. A representative sample of households is surveyed, and this includes households that don’t have any expenditure on vacations during the survey. On the contrary, samples that consist of individual surveyed in a travel agency or in an airport are truncated samples, i.e., sample for which the variable of interest (vacation expenditure) is strictly positive. Estimation of models using censored samples are called <strong>censored regression model</strong> or <strong>tobit</strong> models. The tobit name comes from James Tobin, who is the first economist who proposed this model in econometrics <span class="citation" data-cites="TOBI:58">(<a href="#ref-TOBI:58" role="doc-biblioref">Tobin 1958</a>)</span>, and it was proposed by <span class="citation" data-cites="GOLD:64">Goldberger (<a href="#ref-GOLD:64" role="doc-biblioref">1964</a>)</span> because of its similarity to the probit model. Estimation on truncated samples leads to the <strong>truncated regression model</strong> <span class="citation" data-cites="CRAG:71 HAUS:WISE:76 HAUS:WISE:77">(<a href="#ref-CRAG:71" role="doc-biblioref">Cragg 1971</a>; and <a href="#ref-HAUS:WISE:76" role="doc-biblioref">Hausman and Wise 1976</a>, <a href="#ref-HAUS:WISE:77" role="doc-biblioref">1977</a>)</span>.</p>
<p>In a classic paper, <span class="citation" data-cites="AMEM:84">Amemiya (<a href="#ref-AMEM:84" role="doc-biblioref">1984</a>)</span> surveyed different flavors of the tobit model and proposed a typology of five categories, tobit1, tobit2, …, tobit5. We’ll concentrate in this chapter on the first two categories:</p>
<ul>
<li>the <strong>tobit-1</strong> model is a model with one equation which explains jointly the probability that the value of the response is in the observable range and the value of the response if it is observed,</li>
<li>the <strong>tobit-2</strong> model, which is a bivariate model, with the first equation indicating whether the response is in the observable range or not, and the second one indicating the value of the response when it is observed.</li>
</ul></section></section><section id="sec-tobit1" class="level2" data-number="11.2"><h2 data-number="11.2" class="anchored" data-anchor-id="sec-tobit1">
<span class="header-section-number">11.2</span> Tobit-1 model</h2>
<p>We’ll denote by tobit-1 (or tobit, for short) a linear model of the usual form: <span class="math inline">\(y_n = \alpha + \beta ^ \top x_n + \epsilon_n = \gamma ^ \top z_n + \epsilon_n\)</span>, where <span class="math inline">\(y\)</span> is only observed in a certain range, say <span class="math inline">\(y \in ] l, u[\)</span>. In general, the tobit name is restricted to models estimated in a censored sample. We’ll treat in the same section the case where the estimation is performed in a truncated sample. In a semi-parametric setting, no hypotheses are made on the distribution of <span class="math inline">\(\epsilon_n\)</span>. On the contrary, a fully parametric model will specify the distribution of <span class="math inline">\(\epsilon\)</span>; for example, it will suppose that <span class="math inline">\(\epsilon_n \sim \mathcal{N} (0, \sigma_\epsilon^2)\)</span>, i.e., that the errors of the model are normal and homoskedastic. In the context of the linear regression model, violation of these assumptions is not too severe, as the estimator is still consistent. This is not the case for the model studied in this chapter, as wrong assumptions of homoskedasticity and normality will lead to biased and inconsistent estimators.</p>
<!-- Several examples may help to understand what kind of real situations -->
<!-- are included in this setting: -->
<!-- - @CROM:PALM:URBA:97 estimate the demand for food using households -->
<!--   survey data in the Netherlands. For the upper five percentiles -->
<!--   (13030 Dfl), the expenditure is not reported, but is replaced by the -->
<!--   average value (17670 Dfl). Therefore, we have $b = 13030$, -->
<!-- - @MINI:PAST:10 and @HOCH:03 estimate the share of risk-less assets, -->
<!--   which can be either an internal solution, or a corner solution with -->
<!--   the share equal to 0 or 1 ($a = 0$ and $b=1$). -->
<section id="truncated-normal-distribution-truncated-and-censored-sample" class="level3"><h3 class="anchored" data-anchor-id="truncated-normal-distribution-truncated-and-censored-sample">Truncated normal distribution, truncated and censored sample</h3>
<p> Early models assume that the (conditional) distribution of the response is normal. But the fact that the response is truncated implies that the distribution of <span class="math inline">\(y\)</span> is truncated normal. This distribution is represented in <a href="#fig-normal2Trunc">Figure&nbsp;<span>11.2</span></a>. Starting from a normal distribution <span class="math inline">\(\frac{1}{\sigma}e^{-\frac{1}{2}\left(\frac{y-\mu}{\sigma}\right)^2}\)</span>, we first compute the probability that <span class="math inline">\(l &lt; y &lt; u\)</span> and we divide the normal density by this probability, which is: <span class="math inline">\(\Phi\left(\frac{u-\mu}{\sigma}\right) - \Phi\left(\frac{l-\mu}{\sigma}\right)\)</span>. The density of <span class="math inline">\(y\)</span> is therefore:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-normal2Trunc" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/normal2Trunc.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.2: Truncated normal distribution</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><span class="math display">\[
f(y) = \frac{1}{\sigma}
\frac{\phi\left(\frac{y - \mu}{\sigma}\right)}{\Phi\left(\frac{u-\mu}{\sigma}\right) -
\Phi\left(\frac{l-\mu}{\sigma}\right)}
\]</span></p>
<p>so that <span class="math inline">\(\int_{l}^{u} f(y) dy = 1\)</span>. As <span class="math inline">\(y\)</span> is truncated, its expected value and its variance are not <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^ 2\)</span>. More precisely, left(-right) truncation will lead to an expected value greater(-lower) than <span class="math inline">\(\mu\)</span>. In <a href="#fig-normal2Trunc">Figure&nbsp;<span>11.2</span></a>, the expected value is greater than <span class="math inline">\(\mu\)</span> because the truncation is more severe on the left. Obviously, reducing the range of the values of <span class="math inline">\(y\)</span> implies a reduction of the variance, so that <span class="math inline">\(\mbox{V}(y) &lt; \sigma^2\)</span>. To compute the first two moments of this distribution, it’s easier to consider first a truncated standard normal deviate <span class="math inline">\(z\)</span>. The three following results will be used: <span class="math inline">\(\phi(z)' = - z \phi(z)\)</span>, <span class="math inline">\(\left[\Phi(z) - z \phi(z)\right]' = z ^ 2 \phi(z)\)</span> and <span class="math inline">\(\lim\limits_{z \to \pm \infty}z\phi(z)=0\)</span>.</p>
<p>For the left-truncated case, the expectation and the variance are:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
E(z | z &gt; l) &amp;=&amp; \displaystyle \frac{\displaystyle\int_l ^ {+\infty} z \phi(z) dz}{1 - \Phi(l)}=
\frac{\left[-\phi(z)\right]_l^{+\infty}}{1 - \Phi(l)} = \frac{\phi(l)}{1 - \Phi(l)} = \lambda_l \\
V(z | z &gt; l) &amp;=&amp; \displaystyle\frac{\displaystyle\int_l ^ {+\infty} z ^ 2 \phi(z) dz}{1 - \Phi(l)} - \lambda_l ^ 2=
\frac{\left[\Phi(v)-v\phi(v)\right]_{l}^{+\infty}}{1 - \Phi(l)} - \lambda_l ^ 2 = 1 - \lambda_l\left[\lambda_l - l\right] \\
\end{array}
\right.
\]</span></p>
<p>where <span class="math inline">\(\lambda_l\)</span> is called the <strong>inverse mills ratio</strong>. For a general normal variable <span class="math inline">\(y \sim \mathcal{N}(\mu, \sigma)\)</span>, denoting <span class="math inline">\(\tilde{l} = (l - \mu) / \sigma\)</span>, the expectation is:</p>
<p><span id="eq-exp_left_trunc"><span class="math display">\[
E(y | y &gt; l) = \displaystyle \frac{\displaystyle\int_l ^ {+\infty} y \phi\left(\frac{y - \mu}{\sigma}\right)/ \sigma dy}{1 - \Phi(\tilde{l})}
=
\displaystyle \frac{\displaystyle\int_{\tilde{l}} ^ {+\infty} (\mu + \sigma z) \phi(z) dz}{1 - \Phi(\tilde{l})}= \mu + \sigma \lambda_{\tilde{l}}
\tag{11.1}\]</span></span></p>
<p>and the variance is:</p>
<p><span id="eq-var_left_trunc"><span class="math display">\[
\begin{array}{rcl}
V(z | z &gt; l) &amp;=&amp; \displaystyle\frac{\displaystyle\int_l ^ {+\infty} \left(y - \mu - \sigma \lambda_{\tilde{l}}\right) ^ 2 \phi\left(\frac{y - \mu}{\sigma}\right)/\sigma dy}{1 - \Phi(\tilde{l})}\\
&amp;=&amp;
\displaystyle\frac{\displaystyle\int_{\tilde{l}} ^ {+\infty} \sigma ^ 2 (z - \lambda_{\tilde{l}}) ^ 2 \phi(z) dz}{1 - \Phi(\tilde{l})} = \sigma ^ 2\left[1 - \lambda_{\tilde{l}}(\lambda_{\tilde{l}}-\tilde{l})\right]
\end{array}
\tag{11.2}\]</span></span></p>
<p>Similarly, for the right-truncated case, denoting <span class="math inline">\(\tilde{u} = (u - \mu) / \sigma\)</span> and <span class="math inline">\(\lambda_{\tilde{u}}= - \phi(\tilde{u})/\Phi(\tilde{u})\)</span>, <span class="math inline">\(\mbox{E}(y \mid y &lt; u) = \mu + \sigma \lambda_{\tilde{u}}\)</span> and <span class="math inline">\(\mbox{V}(y \mid y &lt; u) = \sigma ^ 2\left[1 -\lambda_{\tilde{u}}(\lambda_{\tilde{u}}-\tilde{u})\right]\)</span>.</p>
<!-- We then have: -->
<!-- $$ -->
<!-- \mbox{E}(z) = \frac{\displaystyle\int_{l}^{u} z\phi(z) dz}{\Phi(u) - -->
<!-- \Phi(l)}=\frac{\left[ -\phi(z)\right]_{z_l}^{z_u}}{\Phi(u) - \Phi(l)} -->
<!-- =\frac{\phi(l) - \phi(u)}{\Phi(u) - \Phi(l)} -->
<!-- $$ -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \mbox{V}(z) &=& \frac{\int_{z_l}^{z_u} z ^ 2\phi(z) dz}{\Phi(z_u) -\Phi(z_l)}-E(z) ^ 2= -->
<!-- \frac{\left[\Phi(z) -z\phi(z)\right]_{z_l}^{z_u}}{\Phi(u) - \Phi(l)} - -->
<!-- E(z) ^ 2 \\ -->
<!-- &=&  -->
<!-- 1 - \frac{z_u \phi(z_u) - z_l \phi(z_l)}{\Phi(z_u) - \Phi(z_l)} - \frac{(\phi(z_u) - -->
<!-- \phi(z_l)) ^ 2}{(\Phi(z_u) - \Phi(z_l)) ^ 2} -->
<!-- \end{array} -->
<!-- $$ -->
<p>Consider now the special (and very common) case where the distribution of <span class="math inline">\(y\)</span> is normal left-truncated at <span class="math inline">\(l = 0\)</span>, with untruncated mean and variance equal to <span class="math inline">\(\mu_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n\)</span> and <span class="math inline">\(\sigma_\epsilon ^ 2\)</span>. Then, <span class="math inline">\(\tilde{l} = - \mu_n / \sigma\)</span> and the inverse mills ratio is:<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><span class="math display">\[
\lambda_{\tilde{0}} = \frac{\phi(-\mu_n/\sigma)}{1 - \Phi(-\mu_n/\sigma)} = \frac{\phi(\mu_n/\sigma)}{\Phi(\mu_n/\sigma)}
\]</span> Let <span class="math inline">\(r(x) = \frac{\phi(x)}{\Phi(x)}\)</span>; then <span class="math inline">\(\lambda_{\tilde{0}} = r(\mu_n / \sigma)\)</span>. The derivative of <span class="math inline">\(r\)</span> is: <span class="math inline">\(r'(x) = - r(x) \left[r(x) + x\right]\)</span>. <span class="math inline">\(r(x)\)</span> is represented in <a href="#fig-mills">Figure&nbsp;<span>11.3</span></a>. It is a decreasing function, with <span class="math inline">\(\displaystyle \lim_{x\rightarrow -\infty} r(x) + x= 0\)</span> and <span class="math inline">\(\displaystyle \lim_{x\rightarrow +\infty} r(x)= 0\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-mills" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/mills_ratio.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.3: Inverse Mills ratio</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The expectation and the variance of <span class="math inline">\(y\)</span> left-truncated at 0 can then be written, using <a href="#eq-exp_left_trunc">Equation&nbsp;<span>11.1</span></a> and <a href="#eq-var_left_trunc">Equation&nbsp;<span>11.2</span></a>:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
\mbox{E}(y \mid x_n, y &gt; 0) &amp;=&amp; \mu_n + \sigma r(\mu_n / \sigma)\\
\mbox{V}(y \mid x_n, y &gt; 0) &amp;=&amp; \sigma ^ 2 \left[1 + r'(\mu_n / \sigma)\right]\\
\end{array}
\right.
\]</span></p>
<!-- The derivative of $r$ is: -->
<!-- $$ -->
<!-- r'(x) = - r(x)\left[r(x) + x\right] -->
<!-- $$ -->
<!-- With these notations, the first two moments of the truncated normal -->
<!-- distribution are: -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \mbox{E}(z) &=& \left[r(z_l) - r(z_u)\right] -->
<!-- \frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} - r(z_u) \\ -->
<!-- \mbox{V}(z) &=&  1 + \left[z_l r(z_l) - z_u r(z_u)\right]  -->
<!-- \frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} -->
<!--  - z_u r(z_u) - \mbox{E}(z) ^ 2 -->
<!-- \end{array} -->
<!-- $$ -->
<!-- If $z$ is only left-truncated, $z_u \rightarrow +\infty$, -->
<!-- $r(z_u)\rightarrow 0$, $z_u \times r(z_u)\rightarrow 0$ and -->
<!-- $\frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} r(z_l) \rightarrow -->
<!-- \frac{\phi(z_l)}{1 - \Phi(z_l)} = \frac{\phi(z_l)}{\Phi(-z_l)} = -->
<!-- r(-z_l)$. The first two moments then reduce to: -->
<!-- $$ -->
<!-- \left\{ -->
<!-- \begin{array}{rcl} -->
<!-- \mbox{E}(z) &=&  r(-z_l) \\ -->
<!-- \mbox{V}(z) &=&  1 - r(-z_l)\left[r(-z_l) - z_l\right] = 1 + r'(-z_l) -->
<!-- \end{array} -->
<!-- \right. -->
<!-- $$ -->
<!-- If $z$ is only right-truncated\: -->
<!-- $$ -->
<!-- \left\{ -->
<!-- \begin{array}{rcl} -->
<!-- \mbox{E}(z) &=& - r(z_u) \\ -->
<!-- \mbox{V}(z) &=&  1 - r(z_u)\left[r(z_u) + z_u\right] = 1 + r'(z_u) -->
<!-- \end{array} -->
<!-- \right. -->
<!-- $$ -->
<!-- Consider now the linear model: $y=\alpha + \beta x + \epsilon$. For -->
<!-- the most common case where $y$ is zero-left truncated, $\epsilon$ is -->
<!-- left truncated at $-\beta x$ and we get, denoting $v = \beta x / \sigma$: -->
<!-- $$ -->
<!-- \left\{ -->
<!-- \begin{array}{rcl} -->
<!-- \mbox{E}(y\mid x) &=& \alpha + \beta x + \mbox{E}(\epsilon\mid x) = -->
<!-- \sigma_\epsilon r\left(\frac{\alpha + \beta  x}{\sigma}\right)\\ -->
<!-- \mbox{V}(y\mid x) &=& \sigma_\epsilon ^ 2 \left[1 + -->
<!-- r'\left(\frac{\alpha + \beta x}{\sigma}\right)\right] -->
<!-- \end{array} -->
<!-- \right. -->
<!-- $$ -->
<p>Therefore, truncation has two consequences for the linear regression model:</p>
<ul>
<li>the conditional variance depends on <span class="math inline">\(x\)</span> so that the errors of the model are heteroskedastic,</li>
<li>the conditional expectation of <span class="math inline">\(y\)</span> is no longer equal to <span class="math inline">\(\mu_n = \alpha+\beta ^ \top x_n\)</span>, but to <span class="math inline">\(\mu_n + \sigma r(\mu_n / \sigma)\)</span> or, stated differently, the errors of the model are correlated with the covariate as <span class="math inline">\(\mbox{E}(\epsilon \mid x) = \sigma r(\mu_n / \sigma)\)</span>.</li>
</ul>
<p>The first point implies that the OLS estimator is inefficient, the second one that it is biased and inconsistent. For the case where there is only one covariate and <span class="math inline">\(\beta &gt; 0\)</span>, this correlation is illustrated in <a href="#fig-normtrunc4">Figure&nbsp;<span>11.4</span></a> which presents the distribution of <span class="math inline">\(y\)</span> for different values of <span class="math inline">\(x\)</span>. The mode of the distribution is <span class="math inline">\(\alpha + \beta x\)</span> (and it would also be <span class="math inline">\(\mbox{E}(y\mid x)\)</span> if the response weren’t truncated). <span class="math inline">\(\mbox{E}(y\mid x)\)</span> is obtained by adding <span class="math inline">\(\mbox{E}(\epsilon\mid x)\)</span> to <span class="math inline">\(\alpha + \beta x\)</span> .</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-normtrunc4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/normTrunc4.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.4: Truncated normal distribution for <span class="math inline">\(y\)</span></figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As <span class="math inline">\(x\)</span> increases, <span class="math inline">\(\alpha + \beta x\)</span> increases, which reduces <span class="math inline">\(\mbox{P}(y &lt; 0)\)</span> and makes the truncated normal density closer to the untruncated one. As we can see in <a href="#fig-normtrunc4">Figure&nbsp;<span>11.4</span></a>, the distance between the mode of the distribution <span class="math inline">\(\alpha + \beta x\)</span> and <span class="math inline">\(\mbox{E}(y|x)\)</span>, which is <span class="math inline">\(\mbox{E}(\epsilon\mid x)\)</span> decreases with higher values of <span class="math inline">\(x\)</span>. This situation is illustrated, using simulated data on <a href="#fig-simulbias">Figure&nbsp;<span>11.5</span></a>. The plain line is defined by <span class="math inline">\(\alpha + \beta x\)</span>. The dotted line is the regression line for this sample. Its slope is slightly lower than <span class="math inline">\(\beta\)</span>, which illustrates the fact that the OLS estimator of the slope is downward biased (if <span class="math inline">\(\beta &gt; 0\)</span>, which is the case here). The dashed line depicts <span class="math inline">\(\mbox{E}(y\mid x, y &gt; 0)\)</span>.</p>
<p>For large values of <span class="math inline">\(x\)</span>, it is almost the same as the black line, which indicates that in this range of values of <span class="math inline">\(x\)</span>, <span class="math inline">\(\mbox{E}(y\mid x, y &gt; 0)\)</span> is almost equal to <span class="math inline">\(\alpha + \beta x\)</span>, which means than the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(\epsilon\)</span> almost vanishes. Conversely, for low values of <span class="math inline">\(x\)</span>, the gap between <span class="math inline">\(\mbox{E}(y\mid x, y &gt; 0)\)</span> and <span class="math inline">\(\alpha + \beta x\)</span> increases. This gap is <span class="math inline">\(\mbox{E}(\epsilon\mid x, y &gt; 0)\)</span>, it is positive and is particularly high for very low values of <span class="math inline">\(x\)</span>. As <span class="math inline">\(x\rightarrow -\infty\)</span>, <span class="math inline">\(\mbox{E}(y\mid x, y &gt; 0)\rightarrow 0\)</span> and therefore <span class="math inline">\(\mbox{E}(\epsilon\mid x, y &gt; 0)\rightarrow -(\alpha + \beta x)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-simulbias" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="tobit_files/figure-html/fig-simulbias-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.5: OLS bias in a truncated sample</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>By now, we have considered a truncated sample, which is a sample containing only observed values of <span class="math inline">\(y\)</span>. Consider now that the underlying variable is: <span class="math inline">\(y^*\mid x\sim \mathcal{N}(\mu, \sigma)\)</span> with the following rule of observation:</p>
<!-- \begin{equation} -->
<!-- \left\{ -->
<!-- \begin{array}{rclccc} -->
<!-- \tilde{y}&=&a &\mbox{ if }& y < a\\ -->
<!-- \tilde{y}&=&y  &\mbox{ if }& a \leq y \geq b\\ -->
<!-- \tilde{y}&=&b &\mbox{ if }& y > b\\ -->
<!-- \end{array} -->
<!-- \right. -->
<!-- \end{equation} -->
<!-- or, for the most common case where $y$ is zero-left truncated: -->
<p><span class="math display">\[\begin{equation}
\left\{
\begin{array}{rclccc}
y&amp;=&amp;0 &amp;\mbox{ if }&amp; y^* &lt; 0\\
y&amp;=&amp;y^*  &amp;\mbox{ if }&amp; y^* \geq 0\\
\end{array}
\right.
\end{equation}\]</span></p>
<p>The observed response <span class="math inline">\(y\)</span> is therefore either <span class="math inline">\(y^*\)</span> if positive, or 0 if <span class="math inline">\(y^*\leq 0\)</span>. In this case, the conditional expected value of <span class="math inline">\(y\)</span> can be computed as the weighted average of the expected value given that <span class="math inline">\(y\)</span> is greater or lower than 0, the first one being the expected value of <span class="math inline">\(y\)</span> left-truncated at 0 and the second one being 0. With <span class="math inline">\(\mu_n = \alpha + \beta x_n\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rcl}
\mbox{E}(y\mid x_n) &amp;=&amp; \left[1 - \Phi\left(\frac{\mu_n}{\sigma}\right)\right] \times 0 + \Phi\left(\frac{\mu_n}{\sigma}\right) \times \mbox{E}(y\mid x, y &gt; 0) \\
&amp;=&amp;
\mu_n \Phi\left(\frac{\mu_n}{\sigma}\right) +
\sigma \phi\left(\frac{\mu_n}{\sigma}\right)
\end{array}
\]</span></p>
<p>As for the previous case, the conditional expected value of <span class="math inline">\(y\)</span> is not <span class="math inline">\(\mu_n\)</span>, which implies that the OLS estimator is biased and inconsistent. Least squares estimation is illustrated, using simulated data, on <a href="#fig-simulbiascens">Figure&nbsp;<span>11.6</span></a>. The downward bias of the slope seems more severe than for the truncated sample because there are much more observations for very low values of <span class="math inline">\(x\)</span>, i.e., in the range of the values of <span class="math inline">\(x\)</span> where the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(\epsilon\)</span> is severe.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-simulbiascens" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="tobit_files/figure-html/fig-simulbiascens-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.6: OLS bias in a censored sample</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The asymptotic bias of the OLS estimator has been computed by <span class="citation" data-cites="GOLD:81">Goldberger (<a href="#ref-GOLD:81" role="doc-biblioref">1981</a>)</span> for a truncated sample and by <span class="citation" data-cites="GREE:81">Greene (<a href="#ref-GREE:81" role="doc-biblioref">1981</a>)</span> for a censored sample, with the hypothesis that <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> follow a jointly normal distribution. In both cases, we have, denoting <span class="math inline">\(\hat{\beta}\)</span> the OLS estimator: <span class="math inline">\(\mbox{plim}\; \hat{\beta} = \theta \beta\)</span>, with <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>. Therefore, the bias of the OLS estimator is an attenuation bias, which means that the OLS estimator converges in absolute value to a value lower than the true parameter. Moreover, for the censored sample case:</p>
<p><span id="eq-bias_ols_censored_sample"><span class="math display">\[
\mbox{plim}\;  \hat{\beta} = \Phi(\mu_y / \sigma) \beta
\tag{11.3}\]</span></span></p>
<p>Therefore, in this case, <span class="math inline">\(\theta\)</span> is the probability of observing a positive value of <span class="math inline">\(y\)</span>, which can be consistently estimated by the share of positive observations in the sample.</p>
<!-- ### Bias of the OLS estimator -->
<!-- We have seen in the previous section that OLS estimation, either with -->
<!-- a truncated or censored sample leads to a biased estimator. In this -->
<!-- section, we'll present the asymptotic bias, using the hypothesis that -->
<!-- $x$ is normally distributed^[The bias of the OLS estimator were first -->
<!-- computed by @GOLD:81 for the truncated sample and by -->
<!-- @GREE:81 for the censored sample.]. For sake of simplicity, -->
<!-- we'll consider the simple linear regression model, but the analysis -->
<!-- can be easily extended to the multiple linear regression model. -->
<!-- Estimating the model by OLS on the untruncated sample, we obtain: -->
<!-- $\hat{\beta}=\frac{\hat{\sigma}_{xy}}{\hat{\sigma_{x}^2}}$ which -->
<!-- converges to the "true" value, which is  -->
<!-- $\beta=\frac{\sigma_{xy}}{\sigma_{x}^2}=\rho\frac{\sigma_y}{\sigma_x}$. The -->
<!-- demonstration consists on computing the probability limit of the OLS -->
<!-- estimator for the truncated and for the censored sample and to express -->
<!-- the resulting value, $\beta^*=\frac{\sigma^*_{xy}}{\sigma_x^{*2}}$ for -->
<!-- the truncated sample and -->
<!-- $\tilde{\beta}=\frac{\tilde{\sigma_{xy}}}{\sigma_x^2}$ for the -->
<!-- censored sample as a function of $\beta$. -->
<!-- Suppose that $y$ and $x$ are drawn from a bivariate normal -->
<!-- distribution with a coefficient of correlation equal to $\rho$. -->
<!-- $$ -->
<!-- \left( \begin{array}{c} x \\ y \end{array} \right) \sim -->
<!-- N \left( \left( \begin{array}{c} \mu_x \\ \mu_y \end{array} \right) , -->
<!-- \left(  \begin{array}{cc} \sigma_x ^ 2 & \rho \sigma_x \sigma_y \\  -->
<!--                           \rho \sigma_x \sigma_y & \sigma_y ^ 2 -->
<!--                          \end{array} \right) -->
<!-- \right) -->
<!-- $$ -->
<!-- Using well-known results about the bivariate normal distribution, the -->
<!-- first two moments of the conditional distribution of $x$ are: -->
<!-- $$ -->
<!-- \mbox{E}(x\mid y) = \mu_x + \rho \frac{\sigma_x}{\sigma_y}(y - \mu_y) -->
<!-- $$ -->
<!-- $$ -->
<!-- \mbox{V}(x\mid y) = (1 - \rho ^ 2)\sigma_x ^ 2 -->
<!-- $$ -->
<!-- The unconditional expectation of $x$ is obtained as -->
<!-- $\mbox{E}_y\left[\mbox{E}(x\mid y)\right]=\mu_x$ and the unconditional -->
<!-- variance by using the variance decomposition formula: -->
<!-- $$ -->
<!-- \mbox{V}(x) = \mbox{V}_y\left[\mbox{E}(x\mid y)\right] + \mbox{E}_y\left[\mbox{V}(x\mid y)\right]=\sigma_x^2 -->
<!-- $$ -->
<!-- Now consider that $y$ is truncated. Denote: -->
<!-- $\sigma_y^{*2}=\theta \sigma_y ^ 2$. $\sigma_y^{*2}$ is the variance -->
<!-- of $y$ in the observable range. It is necessary lower than -->
<!-- $\sigma_y^2$, so that $0\leq \theta \leq 1$. -->
<!-- The conditional distribution of $x$ is unchanged, but the marginal -->
<!-- distribution of $y$ is. Therefore, to compute the unconditional -->
<!-- moments of $x$, the expectations are computed using the truncated -->
<!-- density function of $y$ and we'll denote $\mbox{E}_y^*$ and -->
<!-- $\mbox{V}_y^*$ the expected value and the variance operators that -->
<!-- use this density function. Denoting $\mu_y^*$ and $\sigma_y^{2*}$ the -->
<!-- mean and variance of $y$ in the observed range, we get: -->
<!-- $$ -->
<!-- \mu_x ^ * = E^*_y\left(\mbox{E}(x\mid y\right) = \mu_x + \rho -->
<!-- \frac{\sigma_x}{\sigma_y}(\mu_y ^ * - \mu_y) -->
<!-- $$ -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \sigma_x^{*2} &=&  -->
<!-- V^*_y\left(\mbox{E}(x\mid y\right) + E^*_y\left(\mbox{V}(x\mid -->
<!-- y\right)\\ -->
<!-- &=& -->
<!-- \rho ^ 2 \frac{\sigma_x ^ 2}{\sigma_y ^ 2} \sigma_y ^ {*2} + (1 - \rho -->
<!-- ^ 2) \sigma_x ^ 2 \\ -->
<!-- &=&  -->
<!-- \sigma_x ^ 2 \left(1 - \rho ^ 2 (1 - \theta)\right) -->
<!-- \end{array} -->
<!-- $$ -->
<!-- with $\theta=\frac{\sigma^{*2}_y}{\sigma^2_y}$. -->
<!-- Finally, to compute the covariance, we use the fact that the -->
<!-- covariance between $x$ and $y$ equals the covariance between -->
<!-- $\mbox{E}(x\mid y)$ and $y$: -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \sigma_{xy} ^ * &=&  \mbox{cov} ^ * \left(\mbox{E}(x\mid y), y\right) \\ -->
<!-- &=& \rho \frac{\sigma_x}{\sigma_y} \sigma_y ^{*2} \\ -->
<!-- &=& \rho \theta\sigma_x\sigma_y -->
<!-- \end{array} -->
<!-- $$ -->
<!-- The OLS estimator on a truncated sample $\beta^*$ is the ratio of the -->
<!-- population covariance and variance of $x$ on the observable range. -->
<!-- $$ -->
<!-- \beta ^ * = \frac{\sigma_{xy} ^ *}{\sigma_{x} ^ {*2}} = \beta -->
<!-- \frac{\theta}{1 - \rho ^ 2(1 - \theta)} = \lambda \beta -->
<!-- $$ -->
<!-- with $\lambda = \frac{\theta}{1 - \rho ^ 2(1 - \theta)} = -->
<!-- \frac{\theta}{\theta + (1-\theta)(1-\rho^2)}$. As $\rho$ and $\theta$ -->
<!-- are in the $[0,1]$ interval, so is $\lambda$. The probability limit of -->
<!-- the least squares estimator is therefore proportional to the real -->
<!-- value $\beta$. Moreover, this result applies to the multiple linear -->
<!-- model, for which the probability limits of the vector of estimated -->
<!-- slopes are proportional to the vector $\beta$. We are therefore in a -->
<!-- situation of an attenuation bias, which means that the absolute value -->
<!-- of all the estimated slopes are proportionally lower compared to the -->
<!-- true values.  -->
<!-- For the intercept, we get: -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \alpha ^ * - \alpha &=& (\mu_y ^ * - \mu_y) - \beta \lambda (\mu_x ^ * - -->
<!-- \mu_x) + \beta (1 - \lambda) \mu_x \\ -->
<!-- &=& (\mu_y ^ * - \mu_y)(1 - \lambda \rho ^ 2) + -->
<!-- (1 - \lambda) \rho \frac{\sigma_y}{\sigma_x} \mu_x -->
<!-- \end{array} -->
<!-- $$ -->
<!-- For the special case of a zero-left truncated response, denoting -->
<!-- $\nu_y = \frac{\mu_y}{\sigma_y}$, we have $\sigma_y^{*2} = -->
<!-- \sigma_y^2 \left[1 + r'(\nu_y)\right]$, so that $\theta = \left[1 + -->
<!-- r'(\nu_y)\right]$ and: -->
<!-- $$ -->
<!-- \lambda = \frac{1 + r'\left(\frac{\mu_y} -->
<!-- {\sigma_y}\right)}{1 + \rho ^ -->
<!-- 2 r'(\nu_y)} -->
<!-- $$ -->
<!-- $$ -->
<!-- \left\{ -->
<!-- \begin{array}{rcl} -->
<!-- \mu_y^* &=& \mu_y + \sigma_y r(\nu_y) \\ -->
<!-- \sigma_y^{*2} &=& \sigma_y^2 \left[1 + r'(\nu_y)\right] -->
<!-- \end{array} -->
<!-- \right. -->
<!-- $$ -->
<!-- $$ -->
<!-- \mu_x^* = \mu_x + \rho \sigma_x r(\nu_y) -->
<!-- $$ -->
<!-- $$ -->
<!-- \alpha ^ * - \alpha = (1 - \lambda \rho ^ 2) \sigma_y -->
<!-- r(\nu_y) -->
<!-- + -->
<!-- (1 - \lambda) \rho \frac{\sigma_y}{\sigma_x} \mu_x -->
<!-- $$ -->
<!-- For the zero-left censored sample case, we compute the uncentered -->
<!-- moments as a weight average of $0$ (with probability $1 - -->
<!-- \Phi(\nu_y)$) and of observable values of $y$ (with probability -->
<!-- $\Phi(\nu_y)$), which means that $\mbox{E}(\tilde{y}) = \Phi(\nu_y) -->
<!-- \mu_y ^ *$ and that $\mbox{E}(x\tilde{y})=\Phi(\nu_y)(\sigma_{xy}^* + -->
<!-- \mu_x^*\mu_y^*)$. The covariance between $x$ and $\tilde{y}$ is then: -->
<!-- $$ -->
<!-- \tilde{\sigma}_y ^ {2} = \mbox{E}(\tilde{y} ^ 2)  - \tilde{\mu}_y^{2} =  -->
<!-- \Phi(\nu_y) \mbox{E}(y ^ 2\mid y > 0) - -->
<!-- \tilde{\mu}_y ^ {2} =  -->
<!-- \Phi(\nu_y) \left(\sigma_y ^{*2} + \mu_y ^ {*2} \right) - \tilde{\mu}_y ^ {2} -->
<!-- $$ -->
<!-- $$ -->
<!-- \tilde{\sigma}_y ^ {2} = \sigma_y ^  2 -->
<!-- \Phi(\nu_y)  -->
<!-- \left[1 +  -->
<!-- \left( -->
<!-- \Phi(\nu_y) -->
<!-- r'(\nu_y) -->
<!-- - \eta__y\right) - -->
<!-- r'(\nu_y) -->
<!-- \right] -->
<!-- $$ -->
<!-- $$ -->
<!-- \begin{array}{rcl} -->
<!-- \tilde{\sigma}_{xy} &=& \mbox{E}(x\tilde{y}) - \mu_x\tilde{\mu}_y \\ -->
<!-- &=& \Phi(\nu_y) \left(\sigma_{xy} ^ * + \mu_x ^ * \mu_y ^ * \right) - -->
<!-- \mu_x\tilde{\mu}_y \\ -->
<!-- &=& \Phi(\nu_y) \rho \sigma_x \sigma_y -->
<!-- \end{array} -->
<!-- $$ -->
<!-- Dividing this covariance by $\sigma^2_x$, we finally obtain the -->
<!-- probability limit of the OLS estimator for the censored sample: -->
<!-- $$ -->
<!-- \tilde{\beta} = \Phi(\nu_y) \beta -->
<!-- $$ -->
<!-- Once again, the probability limit of the OLS estimator is proportional -->
<!-- to $\beta$. The remarkable result for the censored sample is that the -->
<!-- coefficient of proportionality is just the probability of drawing a -->
<!-- censored observation, which can be consistently estimated by the share -->
<!-- of censored observations in the sample.  -->
<!-- $$ -->
<!-- \tilde{\alpha} = \tilde{\mu}_y - \tilde{\beta} \mu_x = \Phi(\nu_y) (\mu_y + -->
<!-- \sigma_y r(\nu_y)) - \Phi \beta \mu_x = \Phi(\nu_y)(\alpha + \sigma_y r(\nu_y)) -->
<!-- $$ -->
</section><section id="interpretation-of-the-coefficients" class="level3"><h3 class="anchored" data-anchor-id="interpretation-of-the-coefficients">Interpretation of the coefficients</h3>
<p>This section concerns only the case of corner solution and not the case of data censoring (like top-coding). In both cases, the regression function: <span class="math inline">\(\mu_n = \alpha + \beta ^ \top x_n\)</span> returns the mean of the distribution of the untruncated distribution of <span class="math inline">\(y\)</span>. In the data censoring case, which is just a problem of missing values of the response, this is the relevant distribution to consider and therefore <span class="math inline">\(\beta_k\)</span> is the marginal effect of covariate <span class="math inline">\(x_k\)</span> that we have to consider. On the contrary, for corner solution models, the relevant distributions that we have to consider is on the one hand the probability of <span class="math inline">\(y &gt;0\)</span> and on the other hand the zero left-truncated distribution of <span class="math inline">\(y\)</span>. Therefore, <span class="math inline">\(\mu_n\)</span> is the mean of an untruncated latent variable, <span class="math inline">\(\beta_k\)</span> is the marginal effect of <span class="math inline">\(x_k\)</span> on this latent variable and none of these values are particularly meaningful. For a corner solution model, the effect of a change in <span class="math inline">\(x_k\)</span> is actually twofold:</p>
<ul>
<li>firstly, it changes the probability that the value of <span class="math inline">\(y\)</span> is positive: <span class="math inline">\(\mbox{P}(y &gt; 0 \mid x)\)</span>,</li>
<li>secondly, it changes the expected value of <span class="math inline">\(y\)</span> if it is positive: <span class="math inline">\(\mbox{E}(y\mid x, y &gt; 0)\)</span>.</li>
</ul>
<p>The probability that <span class="math inline">\(y\)</span> is positive and the conditional expectation for positive values of <span class="math inline">\(y\)</span> are, denoting as usual <span class="math inline">\(\mu_n = \alpha + \beta ^ \top x_n\)</span>:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
\mbox{P}(y_n &gt; 0\mid x_n) &amp;=&amp; \Phi\left(\frac{\mu_n}{\sigma}\right)\\
\mbox{E}(y_n\mid x_n, y_n &gt; 0) &amp;=&amp; \mu_n + \sigma
r\left(\frac{\mu_n}{\sigma}\right)
\end{array}
\right.
\]</span></p>
<p>and the unconditional expectation of <span class="math inline">\(y\)</span> is just the product of these two expressions:</p>
<p><span class="math display">\[
\mbox{E}(y_n\mid x_n) = \mbox{P}(y_n &gt; 0\mid x_n) \times \mbox{E}(y_n\mid x_n, y_n &gt; 0)
\]</span></p>
<p>Its derivative with respect to <span class="math inline">\(x_k\)</span> gives:</p>
<p><span class="math display">\[
\begin{array}{rclrcl}
\frac{\displaystyle\partial \mbox{E}(y_n\mid x_n)}{\displaystyle\partial x_{nk}} &amp;=&amp;
\frac{\displaystyle\partial\mbox{P}(y_n &gt; 0\mid x_n)}{\displaystyle\partial x_{nk}} &amp;\times&amp;
\mbox{E}(y_n\mid x_n, y_n &gt; 0)\\
&amp;+&amp; \mbox{P}(y_n &gt; 0\mid x_n) &amp;\times&amp; \frac{ \displaystyle\partial \mbox{E}(y_n\mid x_n, y_n &gt;
0)}{\displaystyle\partial x_{nk}}
\end{array}
\]</span></p>
<p>with:</p>
<p><span class="math display">\[
\left\{
\begin{array}{lcl}
\frac{\displaystyle\partial\mbox{P}(y_n &gt; 0\mid
x_n)}{\displaystyle\partial x_{nk}} &amp;=&amp; \frac{\beta_k}{\sigma} \phi\left(\frac{\mu_n}{\sigma}\right) \\
\frac{\displaystyle\partial \mbox{E}(y_n\mid x_n)}{\displaystyle\partial
x_{nk}} &amp;=&amp; \beta_k \left[1 + r'\left(\frac{\mu_n}{\sigma}\right) \right]
\end{array}
\right.
\]</span></p>
<p>The effect of a change of a covariate is represented in <a href="#fig-mfx">Figure&nbsp;<span>11.7</span></a> for the simple covariate case, with <span class="math inline">\(\beta &gt; 0\)</span>. When the value of <span class="math inline">\(x\)</span> increases from <span class="math inline">\(x_1\)</span> to <span class="math inline">\(x_2\)</span>, the untruncated normal density curve moves to the right, the mode increasing from <span class="math inline">\(\mu_1=\alpha+\beta x_1\)</span> to <span class="math inline">\(\mu_2=\alpha+\beta x_2\)</span>. The increase of the probability that <span class="math inline">\(y &gt; 0\)</span> is represented by the gray area, as it is the area between the two density curves from 0 to <span class="math inline">\(+\infty\)</span>, which reduces to the area between the two curves between <span class="math inline">\(\mu_1+\mu_2\)</span> and <span class="math inline">\(+\infty\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> This is the first source of change of <span class="math inline">\(\mbox{E}(y\mid x)\)</span> which, for a small variation of <span class="math inline">\(x\)</span> is equal to <span class="math inline">\(\Delta \Phi\left(\frac{\alpha + \beta x}{\sigma}\right) \times \mbox{E}(y\mid x, y &gt; 0)\)</span>. The second source of change is the increase of the conditional expectation of <span class="math inline">\(x\)</span>, which is multiplied by the probability that <span class="math inline">\(y\)</span> is observed: <span class="math inline">\(\Delta \mbox{E}(y\mid x, y &gt; 0) \times \Phi\left(\frac{\alpha + \beta x}{\sigma}\right)\)</span>. The first one can be considered as an increase of <span class="math inline">\(y\)</span> on the <strong>extensive margin</strong>, i.e., due to the fact that for more people, we observe <span class="math inline">\(y &gt; 0\)</span>. The second one is an increase of <span class="math inline">\(y\)</span> on the <strong>intensive margin</strong>, which means that people for which <span class="math inline">\(y\)</span> was already positive, the value of <span class="math inline">\(y\)</span> increases.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> The sum of these two components gives the marginal effect of a variation of <span class="math inline">\(x\)</span> on the unconditional expected value of <span class="math inline">\(y\)</span>, which is simply:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-mfx" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/mfx.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.7: Effect of a change of <span class="math inline">\(x\)</span></figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><span class="math display">\[
\frac{\partial \mbox{E}(y_n\mid x_n)}{\partial x_{nk}} =
\beta_k\Phi\left(\frac{\mu_n}{\sigma}\right)
\]</span> Note (<a href="#eq-bias_ols_censored_sample">Equation&nbsp;<span>11.3</span></a>) that it is exactly the probability limit of the OLS estimator.</p>
</section></section><section id="sec-tobit_estim" class="level2" data-number="11.3"><h2 data-number="11.3" class="anchored" data-anchor-id="sec-tobit_estim">
<span class="header-section-number">11.3</span> Methods of estimation</h2>
<p>Several consistent estimators are available for the truncated and the censored model. We’ll start by inefficient estimators (non-linear least squares, probit and two-step estimators). We’ll then present the maximum likelihood estimator which is asymptotically efficient if the conditional distribution of <span class="math inline">\(y\)</span> is normal and homoskedastic. We’ll finally develop the symmetrically trimmed least squares estimator, which is consistent even if the distribution of <span class="math inline">\(y\)</span> is not normal and heteroskedastic.</p>
<section id="non-linear-least-squares" class="level3"><h3 class="anchored" data-anchor-id="non-linear-least-squares">Non-linear least squares</h3>
<p> The conditional expected value of <span class="math inline">\(y\)</span>: <span class="math inline">\(\mbox{E}(y\mid x) = \gamma^\top z + \sigma r\left(\frac{\gamma^\top z}{\sigma}\right)\)</span> is non-linear in <span class="math inline">\(x\)</span>. Therefore, the parameters can be consistently estimated using non-linear least squares, by minimizing:</p>
<p><span class="math display">\[
\sum_{n=1} ^ N \left[y_n - \gamma^\top z_n - \sigma r\left(\frac{\gamma^\top
z_n}{\sigma}\right)\right] ^ 2
\]</span></p>
<p></p>
</section><section id="probit-and-two-step-estimators" class="level3"><h3 class="anchored" data-anchor-id="probit-and-two-step-estimators">Probit and two-step estimators</h3>
<p> The probability that <span class="math inline">\(y\)</span> is positive is <span class="math inline">\(\Phi\left(\frac{\gamma ^ \top z_n}{\sigma}\right)\)</span>, therefore, a probit model can be used to estimate the vector of coefficients <span class="math inline">\(\frac{\gamma}{\sigma}\)</span>. <span class="math inline">\(\sigma\)</span> is not identified, and each element of <span class="math inline">\(\gamma\)</span> is only estimated up to a <span class="math inline">\(1/\sigma\)</span> factor. To estimate the probit model, we first have to compute a binary response from the observed response which is equal to 1 if <span class="math inline">\(y &gt; 0\)</span> and 0 if <span class="math inline">\(y = 0\)</span>. We then obtain a vector of estimated coefficients <span class="math inline">\(\hat{\delta}\)</span> which are related to the structural coefficients of the model by the relation <span class="math inline">\(\delta = \frac{\gamma}{\sigma}\)</span>. Obviously, the probit estimation can only be performed for a censored sample, and not a truncated sample for which all the values of <span class="math inline">\(y\)</span> are positive. Remember that the expected value of <span class="math inline">\(y\)</span> is: <span class="math inline">\(\mbox{E}(y_n\mid x_n) = \gamma^\top z_n + \sigma r\left(\gamma^\top z_n/\sigma\right)\)</span>. If <span class="math inline">\(\gamma/\sigma\)</span> were known and denoting <span class="math inline">\(r_n = r(\gamma^\top z_n/\sigma)\)</span>, estimating the equation: <span class="math inline">\(y_n=\gamma ^\top z_n + \sigma r_n + \nu_n\)</span> by least squares would lead to consistent estimates of <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\sigma\)</span> as <span class="math inline">\(\mbox{E}(y_n\mid x_n, r_n) = \gamma^\top x_n + \sigma r_n\)</span> or <span class="math inline">\(\mbox{E}(\nu_n\mid x_n, r_n) = 0\)</span>. <span class="math inline">\(r_n\)</span> is obviously unknown, as it depends on the parameters we seek to estimate, but it can be consistently estimated, using the probit estimator, by <span class="math inline">\(\hat{r}_n = r\left(\hat{\delta}^\top z_n\right)\)</span>. This idea leads to the <strong>two-step estimator</strong> first proposed by <span class="citation" data-cites="HECK:76">Heckman (<a href="#ref-HECK:76" role="doc-biblioref">1976</a>)</span>:</p>
<ul>
<li>first estimate the coefficient of the probit model <span class="math inline">\(\hat{\delta}\)</span> and estimate <span class="math inline">\(r_n\)</span> by <span class="math inline">\(\hat{r}_n = r(\hat{\delta}^\top z_n)\)</span>,</li>
<li>then regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span> and <span class="math inline">\(\hat{r}\)</span> and estimate <span class="math inline">\(\hat{\gamma}\)</span> and <span class="math inline">\(\hat{\sigma}\)</span>.</li>
</ul>
<p>Denote <span class="math inline">\(W = (Z, \hat{r}) = (1, X, \hat{r})\)</span> the matrix of covariates for the second step and <span class="math inline">\(\lambda ^ \top = (\gamma ^ \top, \sigma)\)</span> the associated vector of parameters. The covariance matrix of the parameters reported by the OLS estimation is <span class="math inline">\(\hat{\sigma}_\epsilon ^ 2 (W^\top W) ^  {-1}\)</span>. It is inconsistent for two reasons:</p>
<ul>
<li>the errors of the model are heteroskedastic, their variance being <span class="math inline">\(\mbox{V}(\epsilon_n) = \sigma ^ 2 (1 + r'(\gamma^\top z_n / \sigma))\)</span>,</li>
<li>the supplementary covariate <span class="math inline">\(\hat{r}(\delta^ \top z_n)\)</span> differs from the true value of <span class="math inline">\(r(\delta ^ \top z_n)\)</span>, which inflates the variance of the estimators. A consistent estimate of the covariance matrix of the two-step estimator is<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>: </li>
</ul>
<p><span class="math display">\[
\hat{\sigma} ^ 2 (W ^ \top W) ^ {-1} W \left[\Sigma + (I - \Sigma) Z
\hat{\mbox{V}}_{\mbox{probit}} (I - \Sigma) Z ^ \top \right] W ^ \top (W ^
\top W) ^ {-1}
\]</span></p>
<p><span class="math inline">\(\Sigma\)</span> is a matrix that takes into account the heteroskedasticity, it is a diagonal matrix that contains either <span class="math inline">\(\hat{\sigma} ^ 2 (1 + r'(\hat{\delta}^\top z_n))\)</span> or, following the argument of <span class="citation" data-cites="WHIT:80">White (<a href="#ref-WHIT:80" role="doc-biblioref">1980</a>)</span>, the square of the residual <span class="math inline">\(y_n - \hat{\gamma} ^ \top z_n - \hat{\sigma} \hat{r}_n\)</span>. The second matrix, which uses the covariance matrix of the first stage probit regression, takes into account the fact that <span class="math inline">\(\hat{r}_n\)</span> is introduced in place of <span class="math inline">\(r_n\)</span>.</p>
<p> </p>
</section><section id="maximum-likelihood-estimation" class="level3"><h3 class="anchored" data-anchor-id="maximum-likelihood-estimation">Maximum Likelihood estimation</h3>
<p>Without loss of generality, we’ll assume that <span class="math inline">\(y=0\)</span> for observations from 1 to <span class="math inline">\(N_o\)</span> and <span class="math inline">\(y&gt;0\)</span> for those from <span class="math inline">\(N_o+1\)</span> to <span class="math inline">\(N\)</span> are not. Estimating the model on the truncated sample, we obtain the likelihood by multiplying the truncated density of <span class="math inline">\(y\)</span> for all the individuals from <span class="math inline">\(N_o+1\)</span> to <span class="math inline">\(N\)</span>:</p>
<p><span class="math display">\[
L^T(\gamma, \sigma \mid y, x) = \prod_{n = N_o + 1}^N
\frac{1}{\sigma \Phi\left(\frac{\gamma^\top
z_n}{\sigma}\right)}\phi\left(\frac{y_n - \gamma^ \top z_n}{\sigma}\right)
\]</span></p>
<p>or, taking the logarithm:</p>
<p><span class="math display">\[
\ln L^T(\gamma, \sigma\mid y, x) =
-\frac{N -N_o}{2}(\ln \sigma^2 + \ln 2\pi) -
\frac{1}{2\sigma ^ 2}\sum_{n = N_o + 1}^N (y_n -\gamma^\top z_n)^2 -
\sum_{n = N_o + 1} ^ N \ln \Phi\left(\frac{\gamma^\top z_n}{\sigma}\right)
\]</span> Note that, except for the last term, this is the log-likelihood of the normal gaussian model. For the censored sample, the individual contribution to the likelihood sample will depend on whether <span class="math inline">\(y=0\)</span> or not:</p>
<ul>
<li>if <span class="math inline">\(y = 0\)</span>, the contribution is the probability that <span class="math inline">\(y=0\)</span>, which is <span class="math inline">\(1 - \Phi\left(\frac{\gamma^ \top z}{\sigma}\right)\)</span>,</li>
<li>if <span class="math inline">\(y &gt; 0\)</span>, the contribution is the product of the probability that <span class="math inline">\(y &gt; 0\)</span> and the density of the truncated distribution of <span class="math inline">\(y\)</span>, which is: <span class="math inline">\(\Phi\left(\frac{\gamma^\top z}{\sigma}\right)\frac{1}{\sigma\Phi\left(\frac{\gamma^\top z}{\sigma}\right)} \phi\left(\frac{y - \gamma^ \top z}{\sigma}\right)\)</span>.</li>
</ul>
<p>The likelihood function is therefore:</p>
<p><span id="eq-tobit1_probit_plus_trunc"><span class="math display">\[
\begin{array}{rcl}
L^C(\gamma, \sigma  | y,x)&amp;=&amp;\prod_{n=1}^{N_o}
\left[1 - \Phi\left(\frac{\gamma^ \top z_n}{\sigma}\right)\right]
\prod_{n = N_o + 1}^{N}\Phi\left(\frac{\gamma^\top z_n}{\sigma}\right)\\
&amp;\times&amp;\prod_{n = N_o + 1}^{N}\frac{1}{\sigma\Phi\left(\frac{\gamma^\top
z_n}{\sigma}\right)}
\phi\left(\frac{y_n-\gamma^\top x_n}{\sigma}\right)
\end{array}
\tag{11.4}\]</span></span></p>
<p>which is simply the product of:</p>
<ul>
<li>the likelihood of a probit model which explains that <span class="math inline">\(y=0\)</span> or <span class="math inline">\(y &gt; 0\)</span> (the first line of <a href="#eq-tobit1_probit_plus_trunc">Equation&nbsp;<span>11.4</span></a>),</li>
<li>the likelihood of <span class="math inline">\(y\)</span> for the truncated sample (the second line of <a href="#eq-tobit1_probit_plus_trunc">Equation&nbsp;<span>11.4</span></a>).</li>
</ul>
<p>Denoting <span class="math inline">\(L^P\)</span> the likelihood of the probit model, we then have:</p>
<p><span class="math display">\[
L^C(\gamma, \sigma \mid y,x)=L^P(\gamma,\sigma\mid y, x) \times L^T(\gamma, \sigma \mid y, x)
\]</span></p>
<p>Taking logs and rearranging terms, we finally get:</p>
<p><span class="math display">\[
\begin{array}{rcl}
\ln L^C(\gamma, \sigma \mid y,x)&amp;=&amp;\sum_{n=1}^{N_o}
\ln \left[1 - \Phi\left(\frac{\gamma^ \top z_n}{\sigma}\right)\right]
-\frac{N - N_o}{2}\left(\ln \sigma ^ 2 + \ln 2 \pi\right)\\
&amp;-&amp;\frac{1}{2\sigma^ 2}\sum_{n = N_o + 1}^{N}\left(y_n-\gamma^\top
z_n\right)^2
\end{array}
\]</span></p>
<p>Denoting <span class="math inline">\(d_n = \mathbf{1}(y_n&gt;0)\)</span>, the first derivatives with <span class="math inline">\(\gamma\)</span> are, denoting: <span class="math inline">\(\mu_n = \gamma ^ \top z_n\)</span> and <span class="math inline">\(r_n = \frac{\phi(\mu_n / \sigma)}{1 - \Phi(\mu_n / \sigma)}\)</span>:</p>
<p><span class="math display">\[
\frac{\partial L^C}{\partial \gamma} = \frac{1}{\sigma ^ 2}\sum_{n= 1} ^ N\left(- (1 - d_n)\sigma r_n + d_n (y_n - \mu_n)\right)z_n = \frac{1}{\sigma ^ 2}\sum_{n= 1} ^ N \psi_n z_n
\]</span></p>
<p>For the maximum likelihood estimator, the vector of generalized residuals is then:<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> </p>
<p><span id="eq-gen_residuals_tobit"><span class="math display">\[
\psi_n = - (1 - d_n)\sigma r_n + d_n (y_n - \mu_n)
\tag{11.5}\]</span></span></p>
<p>and it is orthogonal to all the regressors. Note that, for positive values of <span class="math inline">\(y\)</span>, the generalized residual is just the standard residual. For null values of <span class="math inline">\(y\)</span>, which means negative values of <span class="math inline">\(y^*\)</span>, the generalized residual is: <span class="math inline">\(\mbox{E}(y_n^* - \mu_n \mid x, y_n ^*\leq 0) = - \sigma r_n\)</span>. As <span class="math inline">\(y_n^*\)</span> and therefore the residuals for null observations are unobserved; they are simply replaced by their expectations. The hessian is rather tricky, but its expression can be greatly simplified using a reparametrization, due to <span class="citation" data-cites="OLSE:78">Olsen (<a href="#ref-OLSE:78" role="doc-biblioref">1978</a>)</span>: <span class="math inline">\(\delta = \gamma / \sigma\)</span> and <span class="math inline">\(\theta = 1 / \sigma\)</span>. <span class="citation" data-cites="OLSE:78">Olsen (<a href="#ref-OLSE:78" role="doc-biblioref">1978</a>)</span> showed that the log-likelihood function of the censored model expressed in terms of <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\theta\)</span> is globally concave and therefore admits a unique optimum which is a maximum. </p>
</section><section id="semi-parametric-estimators" class="level3"><h3 class="anchored" data-anchor-id="semi-parametric-estimators">Semi-parametric estimators</h3>
<p> In a semi-parametric approach, only the regression function, i.e., <span class="math inline">\(\mbox{E}(y \mid x)= \mu_n = \alpha + \beta^\top x\)</span>, is parametrically specified, while the rest of the model (especially the conditional distribution of <span class="math inline">\(y\)</span>) is not. This approach is therefore much more generally applicable. Compared to the estimators presented in the previous two sections, which are only consistent if the conditional distribution of <span class="math inline">\(y\)</span> is normal and homoskedastic, the semi-parametric estimator presented in this section <span class="citation" data-cites="POWE:86">(<a href="#ref-POWE:86" role="doc-biblioref">Powell 1986</a>)</span> is consistent in a much broader context, as it requires only the symmetry of the conditional distribution of the response.</p>
<p>For the zero left-truncated response case, the OLS estimator is biased because the conditional distribution of <span class="math inline">\(y\)</span> is asymmetric, as the observations on the lower tail of the distribution (<span class="math inline">\(y &lt; 0\)</span>) are either missing (the case of a truncated sample) or set to 0 (the case of a censored sample). For the case of a truncated sample, trimming the observations for which <span class="math inline">\(y_n &gt; 2\mu_n\)</span>, i.e., observations that lie in the upper tail, would restore the symmetry, and OLS estimation on this trimmed sample would be consistent. This situation is depicted in <a href="#fig-symmetric">Figure&nbsp;<span>11.8</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-symmetric" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/symetric.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.8: Symmetrically trimmed truncated distribution</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The plain line represents the distribution of the untruncated response, the dashed line the corresponding distribution of the left zero-truncated response. This distribution is asymmetric, and the expected value of <span class="math inline">\(y\)</span> for <span class="math inline">\(x=x_n\)</span> is above <span class="math inline">\(\mu_n\)</span> because of the left-truncation. The dotted line represents the two-sided truncated distribution of <span class="math inline">\(y\)</span>, truncated at 0 on the left side and at <span class="math inline">\(2\mu_n\)</span> on the right side. As the untruncated distribution of <span class="math inline">\(y\)</span> is symmetric, so is the two-sided truncated distribution, for which the conditional expected value of <span class="math inline">\(y\)</span> is now equal to <span class="math inline">\(\mu_n\)</span>. Therefore, if we were able to remove from the sample all the observations for which <span class="math inline">\(y_n &gt; 2 \mu_n\)</span>, the OLS estimator on this trimmed sample would be consistent. Of course, the problem is that the right-truncation point is unknown for every observation, as it depends on <span class="math inline">\(\gamma\)</span> which is the parameter vector that we seek to estimate. The subset of observations that should be kept are such that <span class="math inline">\(0 &lt; y_n &lt; 2\gamma^\top z_n\)</span>, or <span class="math inline">\(-\gamma^\top z_n &lt; \epsilon_n &lt; \gamma^\top z_n\)</span>, the first inequality being always verified for a truncated sample. Note that this condition will remove all the observations for which <span class="math inline">\(\gamma^\top z_n &lt; 0\)</span>.</p>
<p>The first-order conditions to minimize the sum of squares of the residuals for the trimmed sample is then similar to the normal equations (<span class="math inline">\(\sum_{n=1}^N (y_n - \gamma ^ \top z_n) z_n = 0\)</span>) on the relevant subset of the sample:</p>
<p><span id="eq-foc_trimmed_trunc"><span class="math display">\[
\sum_{n = 1} ^ N \textbf{1}(y_n &lt; 2 \gamma^\top z_n) (y_n - \gamma ^
\top z_n)  z_n = 0
\tag{11.6}\]</span></span></p>
<p>Note that the left-hand side of this equation is a discontinuous function of <span class="math inline">\(\gamma\)</span>, as even a small change of <span class="math inline">\(\gamma\)</span> may, for some observations, turn the condition <span class="math inline">\(y_n &lt; 2 \gamma^\top z_n\)</span> from true to false (or the opposite). Moreover, note that <span class="math inline">\(\gamma=0\)</span> is a trivial solution as, in this case, <span class="math inline">\(\textbf{1}(y_n &lt; 2 \gamma^\top x_n)=0\;\forall n\)</span>. Therefore, it is safer to consider the estimator as the result of a minimization problem instead of solving the set of non-linear equations. By direct integration, we can check that minimizing the following function:</p>
<p><span class="math display">\[
R_T = \sum_{n=1}^N \left[y_n - \max\left(\frac{y_n}{2}, \gamma^\top
z_n\right)\right] ^ 2
\]</span></p>
<p>leads to <a href="#eq-foc_trimmed_trunc">Equation&nbsp;<span>11.6</span></a>. This <strong>symmetrically truncated least squares</strong> estimator easily extends to the case of censored samples. In this case, negative values of <span class="math inline">\(y\)</span> are unobserved, and the value of the response is set to 0. A symmetrically censored sample is obtained by setting the response, for observations whose the observed value of <span class="math inline">\(y\)</span> is greater than <span class="math inline">\(2\mu_n\)</span> to <span class="math inline">\(2\mu_n\)</span>. This means that as the response is zero left-censored, we also right-censor it, with a truncation value that is specific to the observation, and that depends on the set of unknown parameters <span class="math inline">\(\gamma\)</span> we seek to estimate. The resulting first-order condition to minimize the sum of squares of the “symmetrically censored sample” is:</p>
<p><span class="math display">\[
\sum_{n = 1} ^ N \textbf{1}(y_n &lt; 2 \gamma^\top z_n)
\left[\min\left(y_n, 2 \gamma ^ \top z_n\right) - \gamma ^ \top z_n\right]  z_n = 0
\]</span></p>
<p>which is the first-order conditions of the minimization of the following function:</p>
<p><span class="math display">\[
\begin{array}{rcl}
R_C &amp;=&amp; \sum_{n=1}^N \left[y_n - \max\left(\frac{y_n}{2}, \gamma^\top z_n\right)\right] ^ 2\\
&amp;+&amp; \sum_{n=1}^N \textbf{1}(y_n &lt; 2 \gamma^\top z_n)
\left[\left(\frac{y_n}{2}\right) ^ 2 - \max(0, \gamma ^ \top z_n) ^ 2\right]
\end{array}
\]</span> </p>
</section></section><section id="sec-tobit_estim_R" class="level2" data-number="11.4"><h2 data-number="11.4" class="anchored" data-anchor-id="sec-tobit_estim_R">
<span class="header-section-number">11.4</span> Estimation of the tobit-1 model with R</h2>
<p>The estimation of the tobit-1 model is available in functions of different packages: <code><a href="https://rdrr.io/pkg/AER/man/tobit.html">AER::tobit</a></code>, <code><a href="https://rdrr.io/pkg/censReg/man/censReg.html">censReg::censReg</a></code> and <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code>. All these functions use the usual formula-data interface to describe the model to be estimated and also a <code>left</code> and a <code>right</code> argument to indicate the truncation points. The default values of these last two arguments are 0 and <span class="math inline">\(+\infty\)</span>, which correspond to the most usual zero left-truncated case. The <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code> function allows to use either a censored or a truncated sample by setting the <code>sample</code> argument either to <code>"censored"</code> or <code>"truncated"</code>. The other two functions only allow the estimation of the censored regression model. The truncated regression model can also be estimated using the <code><a href="https://rdrr.io/pkg/truncreg/man/truncreg.html">truncreg::truncreg</a></code> function. <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code> also has the advantage of providing several different estimators, selected using the <code>method</code> argument: <code>"ml"</code> for maximum likelihood, <code>"lm"</code> for linear model, <code>"twostep"</code> for the two-step estimator, <code>"trimmed"</code> for the trimmed estimator and <code>"nls"</code> for the non-linear least squares estimator, the two other functions only providing the maximum likelihood estimator. We’ll present three examples of application, with respectively a left-truncated, a right-truncated and a two-sided truncated response.</p>
<section id="sec-charitable_estimation" class="level3"><h3 class="anchored" data-anchor-id="sec-charitable_estimation">Left-truncated response</h3>
<p>The <code>charitable</code> data set is used by <span class="citation" data-cites="WILH:08">Wilhelm (<a href="#ref-WILH:08" role="doc-biblioref">2008</a>)</span> and concerns charitable giving.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">charitable</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,384 × 7
  donation donparents education        religion income married south
     &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;            &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
1     335        5210 less_high_school other    21955.       0     0
2      75       13225 high_school      protest… 22104.       0     0
3    6150.       3375 some_college     catholic 50299.       0     0
# ℹ 2,381 more rows</code></pre>
</div>
</div>
<p>The response is called <code>donation</code>; it measures annual charitable giving in US dollars. This variable is left-censored for the value of 25, as this value corresponds to the item “less than $25 donation”. Therefore, for this value, we have households who didn’t make any charitable giving and some who made a small giving (from $1 to $25). The covariates used are the donations made by the parents (<code>donparents</code>), two factors indicating the educational level and religious beliefs (respectively <code>education</code> and <code>religion</code>), annual income (<code>income</code>) and two dummies for living in the south (<code>south</code>) and for married couples (<code>married</code>). <span class="citation" data-cites="WILH:08">Wilhelm (<a href="#ref-WILH:08" role="doc-biblioref">2008</a>)</span> considers the value of the donation in logs and subtracts from it <span class="math inline">\(\ln 25\)</span>, so that the response is 0 for households who gave no donation or a small donation. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">charitable</span> <span class="op">&lt;-</span> <span class="va">charitable</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>logdon <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">donation</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">25</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The model can either be estimated using <code>logdon</code> as the response and the default values of <code>left</code> or <code>right</code> or by using <code>log(donation)</code> as the response and setting <code>left</code> to <code>log(25)</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">char_form</span> <span class="op">&lt;-</span> <span class="va">logdon</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">donparents</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">income</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="va">education</span> <span class="op">+</span> <span class="va">religion</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">south</span></span>
<span><span class="va">ml_aer</span> <span class="op">&lt;-</span> <span class="fu">AER</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/AER/man/tobit.html">tobit</a></span><span class="op">(</span><span class="va">char_form</span>, data <span class="op">=</span> <span class="va">charitable</span><span class="op">)</span></span>
<span><span class="va">ml_creg</span> <span class="op">&lt;-</span> <span class="fu">censReg</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/censReg/man/censReg.html">censReg</a></span><span class="op">(</span><span class="va">char_form</span>, data <span class="op">=</span> <span class="va">charitable</span><span class="op">)</span></span>
<span><span class="va">ch_ml</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="va">char_form</span>, data <span class="op">=</span> <span class="va">charitable</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The three functions return identical results, except that they are parametrized differently: <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code> estimates <span class="math inline">\(\sigma\)</span> as the two other functions estimate <span class="math inline">\(\ln \sigma\)</span>. Using <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code>, we also estimate the two-step, the <strong>SCLS</strong> (symmetrically censored least squares) and the OLS estimators. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ch_twostep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">ch_ml</span>, method <span class="op">=</span> <span class="st">"twostep"</span><span class="op">)</span></span>
<span><span class="va">ch_scls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">ch_ml</span>, method <span class="op">=</span> <span class="st">"trimmed"</span><span class="op">)</span></span>
<span><span class="va">ch_ols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">ch_ml</span>, method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- nls only for zero-left truncated with truncated sample -->
<p>The results of the three models are presented in <a href="#tbl-models">Table&nbsp;<span>11.1</span></a>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> The last two columns of <a href="#tbl-models">Table&nbsp;<span>11.1</span></a> match the first two columns of table 3 of <span class="citation" data-cites="WILH:08">Wilhelm (<a href="#ref-WILH:08" role="doc-biblioref">2008</a>)</span>, page 577. Note that the OLS estimators are in general lower in absolute values than those of the three other estimators, which illustrates the fact that OLS estimators are biased toward zero when the response is censored. More precisely <a href="#eq-bias_ols_censored_sample">Equation&nbsp;<span>11.3</span></a> indicates that the OLS estimator converges to <span class="math inline">\(\Phi(\mu_y / \sigma) \beta\)</span>. <span class="math inline">\(\Phi(\mu_y / \sigma)\)</span> is the probability of <span class="math inline">\(y &gt; 0\)</span> (<span class="math inline">\(y\)</span> being in our example the log of the donation minus <span class="math inline">\(\ln 25\)</span>) and can be consistently estimated by the share of uncensored observations in our sample, which is about two-thirds. Therefore, the ratio of the OLS estimator and one of a consistent estimator, for example the ML estimator, should be approximately equal to two-thirds. This is actually the case for the first two covariates: <span class="math inline">\(0.135 / 0.2 = 0.672\)</span> and <span class="math inline">\(0.941 / 1.453 = 0.648\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-models" class="anchored">

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Table&nbsp;11.1:  Estimation of charitable giving models </caption>
 <thead><tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> OLS </th>
   <th style="text-align:center;"> &nbsp;2-steps </th>
   <th style="text-align:center;"> ML </th>
   <th style="text-align:center;"> SCLS </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:center;"> −10.071*** </td>
   <td style="text-align:center;"> −9.485*** </td>
   <td style="text-align:center;"> −17.618*** </td>
   <td style="text-align:center;"> −15.388*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.556) </td>
   <td style="text-align:center;"> (1.081) </td>
   <td style="text-align:center;"> (0.898) </td>
   <td style="text-align:center;"> (1.472) </td>
  </tr>
<tr>
<td style="text-align:left;"> log(donparents) </td>
   <td style="text-align:center;"> 0.135*** </td>
   <td style="text-align:center;"> 0.109*** </td>
   <td style="text-align:center;"> 0.200*** </td>
   <td style="text-align:center;"> 0.167*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.017) </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;"> (0.025) </td>
   <td style="text-align:center;"> (0.035) </td>
  </tr>
<tr>
<td style="text-align:left;"> log(income) </td>
   <td style="text-align:center;"> 0.941*** </td>
   <td style="text-align:center;"> 0.963*** </td>
   <td style="text-align:center;"> 1.453*** </td>
   <td style="text-align:center;"> 1.320*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.056) </td>
   <td style="text-align:center;"> (0.072) </td>
   <td style="text-align:center;"> (0.087) </td>
   <td style="text-align:center;"> (0.120) </td>
  </tr>
<tr>
<td style="text-align:left;"> married </td>
   <td style="text-align:center;"> 0.562*** </td>
   <td style="text-align:center;"> 0.614*** </td>
   <td style="text-align:center;"> 0.767*** </td>
   <td style="text-align:center;"> 0.702*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.079) </td>
   <td style="text-align:center;"> (0.062) </td>
   <td style="text-align:center;"> (0.117) </td>
   <td style="text-align:center;"> (0.169) </td>
  </tr>
<tr>
<td style="text-align:left;"> south </td>
   <td style="text-align:center;"> 0.111 </td>
   <td style="text-align:center;"> 0.128** </td>
   <td style="text-align:center;"> 0.113 </td>
   <td style="text-align:center;"> 0.064 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.071) </td>
   <td style="text-align:center;"> (0.043) </td>
   <td style="text-align:center;"> (0.105) </td>
   <td style="text-align:center;"> (0.130) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\sigma$ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.656* </td>
   <td style="text-align:center;"> 2.114*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.276) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.041) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 2384 </td>
   <td style="text-align:center;"> 2384 </td>
   <td style="text-align:center;"> 2384 </td>
   <td style="text-align:center;"> 2384 </td>
  </tr>
<tr>
<td style="text-align:left;"> AIC </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 8038.5 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> BIC </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 8119.4 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> Log.Lik. </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −4005.274 </td>
   <td style="text-align:center;">  </td>
  </tr>
</tbody>
</table>
</div>
</div>
</div>
</section><section id="right-truncated-response" class="level3"><h3 class="anchored" data-anchor-id="right-truncated-response">Right-truncated response</h3>
<p>The <code>food</code> data set is used by <span class="citation" data-cites="CROM:PALM:URBA:97">De Crombrugghe, Palm, and Urbain (<a href="#ref-CROM:PALM:URBA:97" role="doc-biblioref">1997</a>)</span> to estimate the demand for food in the Netherlands.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">food</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4,611 × 7
   year weights hsize  ageh income  food midage
  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1  1980   0.615     2     1  55900  5280      0
2  1980   1.52      1     1  10600  1700      0
3  1980   1.16      2     5  34800  6730      0
# ℹ 4,608 more rows</code></pre>
</div>
</div>
<p>Two surveys are available, for 1980 and 1988, we’ll use only the first one. Food expenses are top-coded for the top 5 percentiles, which corresponds to an expense of 13030 Dfl. The value reported for these observations is 17670 Dfl, which is the mean value of the expense for the top 5 percentile. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">food</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">year</span> <span class="op">==</span> <span class="fl">1980</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">summarise</span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">food</span> <span class="op">==</span> <span class="fl">17670</span><span class="op">)</span>,</span>
<span>              f <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">food</span> <span class="op">==</span> <span class="fl">17670</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
      n      f
  &lt;int&gt;  &lt;dbl&gt;
1   127 0.0453</code></pre>
</div>
</div>
<p>The percentage of censored observations is not exactly 5%, because some observations have been excluded due to missing values for some covariates. The response being expressed in logarithms, the right threshold is set to <code>log(13030)</code> and the left one to <code>- Inf</code> as the response is not left-truncated. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">food_tobit</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">food</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">income</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">hsize</span><span class="op">)</span> <span class="op">+</span> <span class="va">midage</span>,</span>
<span>                         data <span class="op">=</span> <span class="va">food</span>, subset <span class="op">=</span> <span class="va">year</span> <span class="op">==</span> <span class="fl">1980</span>,</span>
<span>                         left <span class="op">=</span> <span class="op">-</span><span class="cn">Inf</span>, right <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">13030</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">food_tobit</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error z-value Pr(&gt;|z|)
log(income)  0.34005    0.01856    18.3  &lt; 2e-16
log(hsize)   0.47304    0.01588    29.8  &lt; 2e-16
midage       0.09501    0.01462     6.5  8.1e-11
sigma        0.36716    0.00507    72.4  &lt; 2e-16</code></pre>
</div>
</div>
<p>The main coefficient of interest is the one associated with the <code>log(income)</code> covariate. Remember that in this data censoring case, the coefficient is the marginal effect, in the present context the income elasticity of food which is equal to 0.34.</p>
</section><section id="two-sided-tobit-models" class="level3"><h3 class="anchored" data-anchor-id="two-sided-tobit-models">Two-sided tobit models</h3>
<p> <span class="citation" data-cites="HOCH:03">Hochguertel (<a href="#ref-HOCH:03" role="doc-biblioref">2003</a>)</span> estimates the share of riskless assets, which can be either an internal solution, or a corner solution with the share equal to 0 or 1 (<span class="math inline">\(l = 0\)</span> and <span class="math inline">\(u=1\)</span>). Hochguertel therefore estimates a two-sided tobit model. The paper seeks to explain the low share of risky assets in portfolios of Dutch households. The data set is called <code>portfolio</code>. This data set is a panel of annual observations from 1993 to 1998. In his paper, <span class="citation" data-cites="HOCH:03">Hochguertel (<a href="#ref-HOCH:03" role="doc-biblioref">2003</a>)</span> used panel and cross-section estimators (the latter being obtained on the whole data set by pooling the six time-series). The response is <code>share</code>, and the two covariates of main interest are <code>uncert</code> and <code>expinc</code>.</p>
<ul>
<li>
<code>uncert</code> indicates the degree of uncertainty felt by the household; it is a factor with levels <code>low</code>, <code>moderate</code> and <code>high</code>,</li>
<li>
<code>expinc</code> indicates the prediction of the household concerning the evolution of their income in the next 5 years; it is a factor with levels <code>increase</code>, <code>constant</code> and <code>decrease</code>.</li>
</ul>
<p>We’ll use a simpler specification than the one used by the author, which contains a lot of covariates; we only add to the two covariates previously described the net worth, the age of household’s head and its square and a dummy for households whose head is a woman. We use the <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code> function and we set the <code>left</code> and the <code>right</code> arguments respectively to 0 and 1. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">portfolio</span> <span class="op">&lt;-</span> <span class="va">portfolio</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>agesq <span class="op">=</span> <span class="va">age</span> <span class="op">^</span> <span class="fl">2</span> <span class="op">/</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">prec_ml</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="va">share</span> <span class="op">~</span> <span class="va">uncert</span> <span class="op">+</span> <span class="va">expinc</span> <span class="op">+</span> <span class="va">networth</span> <span class="op">+</span> </span>
<span>                    <span class="va">age</span> <span class="op">+</span> <span class="va">agesq</span> <span class="op">+</span> <span class="va">female</span>,</span>
<span>                  left <span class="op">=</span> <span class="fl">0</span>, right <span class="op">=</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">portfolio</span><span class="op">)</span></span>
<span><span class="va">prec_ml</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Estimate Std. Error z-value Pr(&gt;|z|)
uncertmod   0.04410    0.01489    2.96  0.00307
uncerthigh  0.08155    0.01756    4.64  3.4e-06
expinccst   0.04059    0.01184    3.43  0.00061
expincdecr  0.04631    0.01582    2.93  0.00343
networth   -0.02940    0.00122  -24.19  &lt; 2e-16
age        -0.02848    0.00269  -10.58  &lt; 2e-16
agesq       0.03055    0.00257   11.88  &lt; 2e-16
female      0.14153    0.01447    9.78  &lt; 2e-16
sigma       0.45578    0.00423  107.64  &lt; 2e-16</code></pre>
</div>
</div>
<p>As expected, high uncertainty and pessimistic expectations about future income increase the share of riskless assets. Net worth has a negative effect on the share of riskless assets, and households headed by a woman have a higher share of riskless assets. Finally the effect of age is U-shaped. Actually, <span class="citation" data-cites="HOCH:03">Hochguertel (<a href="#ref-HOCH:03" role="doc-biblioref">2003</a>)</span> doesn’t estimate this model, as he suspected the presence of heteroskedascticity. Therefore, he estimates a model for which <span class="math inline">\(\sigma\)</span> is replaced by <span class="math inline">\(\sigma_n = e^{\delta^\top w_n}\)</span>, where <span class="math inline">\(w_n\)</span> are a set of covariates and <span class="math inline">\(\delta\)</span> a set of further parameters to be estimated. The <code><a href="https://rdrr.io/pkg/crch/man/crch.html">crch::crch</a></code> function <span class="citation" data-cites="MESS:MAYR:ZEIL:WILK:14">(<a href="#ref-MESS:MAYR:ZEIL:WILK:14" role="doc-biblioref">Messner et al. 2014</a>)</span> enables the estimation of such models. The model is described using a two-part formula, the second one containing the covariates that are used to estimate <span class="math inline">\(\sigma_n\)</span>. By default, a logistic link is used (<span class="math inline">\(\ln \sigma_n = \gamma ^ \top z_n\)</span>), but other links can be selected using the <code>link.scale</code> argument. Moreover, departure from normality can be taken into account using the <code>dist</code> argument by, for example, switching from a gaussian distribution (the default) to a Student or a logistic. For the skedasticity function, we use all the covariates used in the main equation except <code>uncert</code> and <code>expinc</code> which appear to be insignificant. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prec_ht</span> <span class="op">&lt;-</span> <span class="fu">crch</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/crch/man/crch.html">crch</a></span><span class="op">(</span><span class="va">share</span> <span class="op">~</span> <span class="va">uncert</span> <span class="op">+</span> <span class="va">expinc</span> <span class="op">+</span> <span class="va">networth</span> <span class="op">+</span></span>
<span>        <span class="va">age</span> <span class="op">+</span> <span class="va">agesq</span> <span class="op">+</span> <span class="va">female</span> <span class="op">|</span> <span class="va">networth</span> <span class="op">+</span></span>
<span>        <span class="va">age</span> <span class="op">+</span> <span class="va">agesq</span> <span class="op">+</span> <span class="va">female</span>, left <span class="op">=</span> <span class="fl">0</span>, right <span class="op">=</span> <span class="fl">1</span>,</span>
<span>        data <span class="op">=</span> <span class="va">portfolio</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">prec_ht</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
crch::crch(formula = share ~ uncert + expinc + networth + 
    age + agesq + female | networth + age + agesq + female, 
    data = portfolio, left = 0, right = 1)

Standardized residuals:
   Min     1Q Median     3Q    Max 
-2.112 -0.888 -0.258  0.407  2.776 

Coefficients (location model):
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  2.66330    0.08142   32.71  &lt; 2e-16 ***
uncertmod    0.03474    0.01385    2.51   0.0122 *  
uncerthigh   0.05365    0.01639    3.27   0.0011 ** 
expinccst    0.02645    0.01069    2.47   0.0133 *  
expincdecr   0.04223    0.01461    2.89   0.0038 ** 
networth    -0.14347    0.00435  -32.96  &lt; 2e-16 ***
age         -0.02202    0.00308   -7.15  8.6e-13 ***
agesq        0.02669    0.00303    8.80  &lt; 2e-16 ***
female       0.09196    0.01542    5.96  2.5e-09 ***

Coefficients (scale model with log link):
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  0.41494    0.12607    3.29   0.0010 ***
networth    -0.09291    0.00255  -36.37   &lt;2e-16 ***
age         -0.01575    0.00511   -3.08   0.0021 ** 
agesq        0.02267    0.00497    4.56    5e-06 ***
female       0.07027    0.02796    2.51   0.0120 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Distribution: gaussian
Log-likelihood: -5.96e+03 on 14 Df
Number of iterations in BFGS optimization: 29 </code></pre>
</div>
</div>
<p>Without conducting a formal test, it is clear that the heteroskedastic specification is supported by the data, the log-likelihood value of the second specification being much larger than the one of standard tobit model. The value of some coefficients are strikingly different. For example, the coefficient of <code>networth</code> is <span class="math inline">\(-0.029\)</span> for the tobit model, but <span class="math inline">\(-0.1435\)</span> for the heteroskedastic model, as this covariate also has a huge effect on the conditional variance of the response. </p>
</section></section><section id="sec-tobit_eval" class="level2" data-number="11.5"><h2 data-number="11.5" class="anchored" data-anchor-id="sec-tobit_eval">
<span class="header-section-number">11.5</span> Evaluation and tests</h2>
<section id="conditional-moment-tests" class="level3"><h3 class="anchored" data-anchor-id="conditional-moment-tests">Conditional moment tests</h3>
<p> The most popular method of estimation for the tobit-1 model is the fully parametric maximum likelihood method. Contrary to the OLS model, the estimator is only consistent if the GDP process is perfectly described by the likelihood function, i.e., if <span class="math inline">\(\epsilon_n \sim \mathcal{N}(0,\sigma)\)</span>. In particular, the consistency of the estimator rests on the hypothesis of normality and homoskedasticity. The conditional moment tests have been presented in <a href="maximum_likelihood.html#sec-ml_cond_moment_test"><span>Section&nbsp;5.3.2</span></a>, they use different powers of the residuals. We have seen in <a href="binomial.html#sec-cond_moment_binomial"><span>Section&nbsp;10.4.3.2</span></a> for the probit model how to compute these tests when the residuals are not observable: <span class="math inline">\(\epsilon_n ^ k\)</span> is then replaced by <span class="math inline">\(\mbox{E}(\epsilon_n ^ k \mid x_n)\)</span>. The computation of the conditional moment test for the tobit model is quite similar, except that the residuals are partially observed (when <span class="math inline">\(d_n=\mathbf{1}(y_n&gt;0) = 1\)</span>). Then, we’ll use <span class="math inline">\(\epsilon_n ^ k\)</span> if <span class="math inline">\(d_n=1\)</span> and <span class="math inline">\(\mbox{E}(\epsilon_n ^ k \mid x_n)\)</span> if <span class="math inline">\(d_n = 0\)</span>. From <a href="binomial.html#eq-moments_normal_trunc">Equation&nbsp;<span>10.12</span></a>, the moments of <span class="math inline">\(\epsilon \sim \mathcal{N}(0, \sigma_\epsilon)\)</span> right-truncated at <span class="math inline">\(-\mu_n\)</span> are, denoting <span class="math inline">\(r_n = \frac{\phi(\mu_n / \sigma_\epsilon)}{1-\Phi(\mu_n / \sigma_\epsilon)}\)</span>:</p>
<p><span class="math display">\[
\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) = (k - 1) \sigma_\epsilon ^ 2 m_{k-2} -\sigma_\epsilon (- \mu_n) ^ {k-1} r_n
\]</span> For example, <span class="math inline">\(E(\epsilon_n|x_n, y_n ^ * \leq 0) = -\sigma_\epsilon r_n\)</span>, which is the generalized residual for <span class="math inline">\(d_n = 0\)</span>, see <a href="#eq-gen_residuals_tobit">Equation&nbsp;<span>11.5</span></a>. Then a similar table as the one given in <a href="binomial.html#eq-table_moments_probit">Equation&nbsp;<span>10.13</span></a> can be written for the tobit model:</p>
<p><span id="eq-table_moments_tobit"><span class="math display">\[
\begin{array}{clcl}\hline
k &amp; \mbox{hypothesis} &amp; \mbox{E}(\epsilon_n ^ k \mid x_n \mid \epsilon_n \leq -\mu_n) &amp; \mbox{emp. moment} \\ \hline
1 &amp; \mbox{omit. variable} &amp; -\sigma r_n &amp;  \frac{1}{N}\sum_n \left[- (1 - d_n) r_n + d_n \epsilon_n)\right]w_n\\
2 &amp; \mbox{homosc.} &amp; \sigma ^ 2(1 + z_n r_n) &amp; \frac{1}{N}\sum_n \left[(1 - d_n)\sigma ^ 2 z_n r_n \right.\\
&amp; &amp; &amp; \left. + d_n (\epsilon_n ^ 2 - \sigma ^ 2)\right]w_n\\
3 &amp; \mbox{asymetry} &amp;  - \sigma ^ 3 r_n(2 + z_n ^ 2) r_n &amp;  \frac{1}{N}\sum_n \left[-(1 - d_n)\sigma ^ 3 r_n(2 + z ^ 2) \right. \\
&amp; &amp; &amp; + \left. d_n \epsilon_n ^ 3\right]w_n\\
4 &amp; \mbox{kurtosis} &amp; \mbox{E}(\epsilon_n^4 - 3\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \left[(1 - d_n)\sigma ^ 4 z_n r_n(3 + z_n ^ 3) \right.\\
&amp; &amp; &amp; + \left. d_n (\epsilon_n ^ 4 - 3\sigma ^ 2)\right]w_n \\\hline
\end{array}
\tag{11.7}\]</span></span></p>
<p>Conditional moment tests can be computed using the <code><a href="https://rdrr.io/pkg/micsr/man/cmtest.html">micsr::cmtest</a></code> function, which can take as input a model fitted by either <code><a href="https://rdrr.io/pkg/AER/man/tobit.html">AER::tobit</a></code>, <code><a href="https://rdrr.io/pkg/censReg/man/censReg.html">censReg::censReg</a></code> or <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code>. To test respectively the hypothesis of normality and of homoskedasticity, we use: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"normality"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 116.351, df: 2, pval = 0.000</span></span>
<span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"heterosc"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 103.592, df: 12, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Normality and heteroskedasticity are strongly rejected. The values are different from <span class="citation" data-cites="WILH:08">Wilhelm (<a href="#ref-WILH:08" role="doc-biblioref">2008</a>)</span>, as he used the “outer product of the gradient” form of the test. These versions of the test can be obtained by setting the <code>opg</code> argument to <code>TRUE</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"normality"</span>, opg <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 200.117, df: 2, pval = 0.000</span></span>
<span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"heterosc"</span>, opg <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 127.308, df: 12, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Non-normality can be further investigated by testing separately the fact that the skewness and kurtosis indicators are respectively different from 0 and 3. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"skewness"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## z = 10.393, pval = 0.000</span></span>
<span><span class="fu">cmtest</span><span class="op">(</span><span class="va">ch_ml</span>, test <span class="op">=</span> <span class="st">"kurtosis"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## z = 2.329, pval = 0.020</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The hypothesis that the conditional distribution of the response is mesokurtic is not rejected at the 1% level and the main problem seems to be the asymmetry of the distribution, even after taking the logarithm of the response. This can be illustrated (see <a href="#fig-histnorm">Figure&nbsp;<span>11.9</span></a>) by plotting the (unconditional) distribution of the response (for positive values) and adding to the histogram the normal density curve.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-histnorm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="tobit_files/figure-html/fig-histnorm-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;11.9: Empirical distribution of the response and normal approximation</figcaption><p></p>
</figure>
</div>
</div>
</div>
<!-- ### Hausman test -->

<!-- An alternative to the conditional moment tests to test the consistency of the maximum likelihood estimator (using tests of normality and of heteroskedasticity) is to use a Hausman test comparing the maximum likelihood estimator and the symetrically censored least square estimator. With the hypothesis of normal homoskedastic distribution, both estimators are consistent, but the ML estimator is more efficient. With the alternative hypothesis, only the SCLS estimator is consistent. For the `charitable` data set, we estimated both models in @sec-charitable_estimation. Using the `haustest` and excluding the intercept from the set of coefficients we get: -->
<!-- ```{r } -->
<!-- #| collapse: true -->
<!-- haustest(ml, scls, omit = "(Intercept)") %>% gaze -->
<!-- ``` -->
<p></p>
</section><section id="endogeneity" class="level3"><h3 class="anchored" data-anchor-id="endogeneity">Endogeneity</h3>
<p> We have seen in <a href="binomial.html#sec-endog_probit"><span>Section&nbsp;10.5</span></a> how endogeneity can be taken into account in a probit model. The analysis is almost the same for the probit model. The joint density of the distribution of the latent variable <span class="math inline">\(y^*\)</span> and the endogenous covariates <span class="math inline">\(w\)</span> is assumed to be normal and can be written as the product of the marginal density of <span class="math inline">\(w\)</span> (<a href="binomial.html#eq-marg_density_w">Equation&nbsp;<span>10.15</span></a>) and of the conditional density of <span class="math inline">\(y^*\)</span> (<a href="binomial.html#eq-cond_density_y_star">Equation&nbsp;<span>10.16</span></a>). For the tobit model, the former is exactly the same, but the latter is different because, for the probit model, only the sign of <span class="math inline">\(y ^ *\)</span> is observed. This is not the case for the tobit model, the value of the response being observed if <span class="math inline">\(y^*&gt;0\)</span>. Therefore, <a href="binomial.html#eq-cond_density_y_star">Equation&nbsp;<span>10.16</span></a> becomes:</p>
<p><span id="eq-cond_density_y_tobit"><span class="math display">\[
\begin{array}{rcl}
f(y_n \mid w_n) &amp;=&amp; (1 - d_n)\left[1 - \Phi\left(\frac{\gamma ^ \top z_n + \sigma_{\epsilon\nu}
^ \top \Sigma_\nu ^ {-1}(e_n - \Pi v_n)}{\sqrt{\sigma_\epsilon ^ 2 -
\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}}}\right)\right]\\
&amp;-&amp;\frac{1}{2}d_n\left[\ln 2 \pi + \ln (\sigma_\epsilon ^ 2-\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu})+\frac{y_n - \gamma ^ \top z_n - \sigma_{\epsilon\nu} ^ \top \Sigma ^ {-1}_\nu(e_n - \Pi w_n)}{(\sigma_\epsilon ^ 2-\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}))}\right]
\end{array}
\tag{11.8}\]</span></span></p>
<p>where, as usual, <span class="math inline">\(d_n = \mathbf{1}(y_n ^ * &gt; 0)\)</span>. Note that, as the value of the response is partly observed, <span class="math inline">\(\sigma_\epsilon\)</span> is identified, contrary to the probit case where it has been arbitrarily set to 1. As for the probit model, several estimators are available: the maximum likelihood, the two-step and the minimum <span class="math inline">\(\chi ^ 2\)</span> estimators. Moreover, the hypothesis of exogeneity can be performed by computing a Wald test on the two-step estimator.</p>
<p></p>
<p>In the protection for sale model of <span class="citation" data-cites="GROS:HELP:94">Grossman and Helpman (<a href="#ref-GROS:HELP:94" role="doc-biblioref">1994</a>)</span>, empirically tested by <span class="citation" data-cites="GOLD:MAGG:99">Goldberg and Maggi (<a href="#ref-GOLD:MAGG:99" role="doc-biblioref">1999</a>)</span>, trade protection is determined by capital owners’ lobbying. <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span> extend this model by introducing the potential effect of trade unions’ lobbying on trade protection. The response is non-tariff barriers coverage ratio <span class="math inline">\(\tau\)</span>, transformed as <span class="math inline">\(\frac{\tau}{1 + \tau}\)</span>. The two covariates of <span class="citation" data-cites="GROS:HELP:94">Grossman and Helpman (<a href="#ref-GROS:HELP:94" role="doc-biblioref">1994</a>)</span> are the inverse of the import penetration ratio<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> divided by the importation demand elasticity <span class="math inline">\(x_1\)</span> and this variable in interaction with a dummy for capital owners’ lobbying <span class="math inline">\(x_2\)</span>. The supplementary covariate in the model of <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span> <span class="math inline">\(x_3\)</span> takes into account trade union’s lobbying. The data set is called <code>trade_protection</code>. We first compute the response and the covariates using raw series:<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">trade_protection</span> <span class="op">&lt;-</span> <span class="va">trade_protection</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>y <span class="op">=</span> <span class="va">ntb</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">ntb</span><span class="op">)</span>,</span>
<span>         x1 <span class="op">=</span> <span class="va">vshipped</span> <span class="op">/</span> <span class="va">imports</span> <span class="op">/</span> <span class="va">elast</span>,</span>
<span>         x2 <span class="op">=</span> <span class="va">cap</span> <span class="op">*</span> <span class="va">x1</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">rename</span><span class="op">(</span>x3 <span class="op">=</span> <span class="va">labvar</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The theoretical model of <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span> results in the following structural equation:</p>
<p><span class="math display">\[
\frac{\tau}{1+\tau} = - \frac{\Theta}{\Theta + a} x_1 + \frac{1}{\Theta + a}x_2 + \frac{1}{\Theta + a} x_3
\]</span> Therefore, denoting <span class="math inline">\((\alpha, \beta_1, \beta_2, \beta_3)\)</span> the reduced form parameters, the model of <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span> implies that <span class="math inline">\(\alpha = 0\)</span> and that <span class="math inline">\(\beta_2 = \beta_3\)</span> as, in the model of <span class="citation" data-cites="GROS:HELP:94">Grossman and Helpman (<a href="#ref-GROS:HELP:94" role="doc-biblioref">1994</a>)</span> <span class="math inline">\(\alpha = \beta_3 = 0\)</span>. <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span> suspect that the three covariates may be endogenous and therefore use the model of <span class="citation" data-cites="SMIT:BLUN:86">Smith and Blundell (<a href="#ref-SMIT:BLUN:86" role="doc-biblioref">1986</a>)</span>. Three models are estimated:</p>
<ul>
<li>Grossman and Helpman’s model (GH), i.e., <span class="math inline">\(x_3\)</span> is omitted,</li>
<li>Matschke and Sherlund’s “full” model, that doesn’t impose that <span class="math inline">\(\beta_2 = \beta_3\)</span>,</li>
<li>Matschke and Sherlund’s “short” model, that imposes that <span class="math inline">\(\beta_2 = \beta_3\)</span>,</li>
</ul>
<p>The hypothesis that <span class="math inline">\(\alpha = 0\)</span> is not imposed in the three models. Numerous instruments are used, as described in <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span>, page 415 and are defined below as a one-sided formula:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inst</span> <span class="op">&lt;-</span> <span class="op">~</span> <span class="va">sic3</span> <span class="op">+</span> <span class="va">k_serv</span> <span class="op">+</span> <span class="va">inv</span> <span class="op">+</span> <span class="va">engsci</span> <span class="op">+</span> <span class="va">whitecol</span> <span class="op">+</span> <span class="va">skill</span> <span class="op">+</span> <span class="va">semskill</span> <span class="op">+</span> </span>
<span>  <span class="va">cropland</span> <span class="op">+</span> <span class="va">pasture</span> <span class="op">+</span> <span class="va">forest</span> <span class="op">+</span> <span class="va">coal</span> <span class="op">+</span> <span class="va">petro</span> <span class="op">+</span> <span class="va">minerals</span> <span class="op">+</span> <span class="va">scrconc</span> <span class="op">+</span> </span>
<span>  <span class="va">bcrconc</span> <span class="op">+</span> <span class="va">scrcomp</span> <span class="op">+</span> <span class="va">bcrcomp</span> <span class="op">+</span> <span class="va">meps</span> <span class="op">+</span> <span class="va">kstock</span> <span class="op">+</span> <span class="va">puni</span> <span class="op">+</span> <span class="va">geog2</span> <span class="op">+</span> <span class="va">tenure</span> <span class="op">+</span> </span>
<span>  <span class="va">klratio</span> <span class="op">+</span> <span class="va">bunion</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The formulas for the different models are, in terms of response and covariates only <code>y ~ x_1 + x_2</code> for the GH model, <code>y ~ x_1 + x_2 + x_3</code> for the full model and <code>y ~ x_1 + I(x_2 + x_3)</code> for the short model. To construct the relevant two-part formulas for the IV estimation, we use the <code><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula::as.Formula</a></code> function that enables to construct a two-part formula, using a standard formula and a one-sided formula. As an example: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span>, <span class="op">~</span> <span class="va">z1</span> <span class="op">+</span> <span class="va">z2</span> <span class="op">+</span> <span class="va">z3</span><span class="op">)</span></span>
<span><span class="co">## y ~ x1 + x2 | z1 + z2 + z3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then proceed to the estimation of the three models, using <code><a href="https://rdrr.io/pkg/micsr/man/tobit1.html">micsr::tobit1</a></code> with the <code>twostep</code> method, as in the original paper: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">GH</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span>, <span class="va">inst</span><span class="op">)</span>, </span>
<span>             <span class="va">trade_protection</span>, method <span class="op">=</span> <span class="st">"twostep"</span><span class="op">)</span> </span>
<span><span class="va">Short</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x2</span> <span class="op">+</span> <span class="va">x3</span><span class="op">)</span>, <span class="va">inst</span><span class="op">)</span>,</span>
<span>                 <span class="va">trade_protection</span>, method <span class="op">=</span> <span class="st">"twostep"</span><span class="op">)</span></span>
<span><span class="va">Full</span> <span class="op">&lt;-</span> <span class="fu">tobit1</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span> <span class="op">+</span> <span class="va">x3</span>, <span class="va">inst</span><span class="op">)</span>,</span>
<span>               <span class="va">trade_protection</span>, method <span class="op">=</span> <span class="st">"twostep"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-protection_for_sale" class="anchored">

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Table&nbsp;11.2:  Estimation results of the protection for sale model </caption>
 <thead><tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> GH </th>
   <th style="text-align:center;"> Full </th>
   <th style="text-align:center;"> Short </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:left;"> $\alpha$ </td>
   <td style="text-align:center;"> 0.0250 </td>
   <td style="text-align:center;"> 0.0109 </td>
   <td style="text-align:center;"> 0.0045 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.0226) </td>
   <td style="text-align:center;"> (0.0232) </td>
   <td style="text-align:center;"> (0.0219) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\beta_1$ </td>
   <td style="text-align:center;"> −0.0028* </td>
   <td style="text-align:center;"> −0.0024* </td>
   <td style="text-align:center;"> −0.0020** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.0011) </td>
   <td style="text-align:center;"> (0.0010) </td>
   <td style="text-align:center;"> (0.0007) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\beta_2$ </td>
   <td style="text-align:center;"> 0.0026* </td>
   <td style="text-align:center;"> 0.0032** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.0011) </td>
   <td style="text-align:center;"> (0.0011) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> $\beta_3$ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.0023 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.0014) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> $\beta_2 = \beta_3$ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.0031** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.0010) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\gamma_1$ </td>
   <td style="text-align:center;"> 0.0026+ </td>
   <td style="text-align:center;"> 0.0023 </td>
   <td style="text-align:center;"> 0.0029*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.0016) </td>
   <td style="text-align:center;"> (0.0015) </td>
   <td style="text-align:center;"> (0.0008) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\gamma_2$ </td>
   <td style="text-align:center;"> −0.0025 </td>
   <td style="text-align:center;"> −0.0042** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.0016) </td>
   <td style="text-align:center;"> (0.0016) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> $\gamma_3$ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.0048** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.0017) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> $\gamma_2 = \gamma_3$ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.0048*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.0014) </td>
  </tr>
<tr>
<td style="text-align:left;"> $\sigma$ </td>
   <td style="text-align:center;"> 0.2103*** </td>
   <td style="text-align:center;"> 0.2033*** </td>
   <td style="text-align:center;"> 0.2043*** </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.0172) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.0166) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.0167) </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 194 </td>
   <td style="text-align:center;"> 194 </td>
   <td style="text-align:center;"> 194 </td>
  </tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The results are presented in <a href="#tbl-protection_for_sale">Table&nbsp;<span>11.2</span></a>.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> As in the original article, we use the name of the coefficients and not the name of the terms, which are listed below: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Full</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] "(Intercept)" "x1"          "x2"          "x3"         </span></span>
<span><span class="co">## [5] "rho_x1"      "rho_x2"      "rho_x3"      "sigma"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For example, <code>x2</code> is replaced by <span class="math inline">\(\beta_2\)</span> and <code>rho_x2</code> by <span class="math inline">\(\gamma_2\)</span>. Tests of exogeneity for the three models give: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">endogtest</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span>, <span class="va">inst</span><span class="op">)</span>, </span>
<span>          <span class="va">trade_protection</span>, model <span class="op">=</span> <span class="st">"tobit"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 3.938, df: 2, pval = 0.140</span></span>
<span><span class="fu">endogtest</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x2</span> <span class="op">+</span> <span class="va">x3</span><span class="op">)</span>, <span class="va">inst</span><span class="op">)</span>, </span>
<span>          <span class="va">trade_protection</span>, model <span class="op">=</span> <span class="st">"tobit"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 13.957, df: 2, pval = 0.001</span></span>
<span><span class="fu">endogtest</span><span class="op">(</span><span class="fu">Formula</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">as.Formula</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span> <span class="op">+</span> <span class="va">x3</span>, <span class="va">inst</span><span class="op">)</span>, </span>
<span>          <span class="va">trade_protection</span>, model <span class="op">=</span> <span class="st">"tobit"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 12.773, df: 3, pval = 0.005</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The exogeneity hypothesis is not rejected for the GH model, but it is for the two versions of Matschke and Sherlund’s model. The GH model, which is a special case of the Full model is relevant if the hypotheses <span class="math inline">\(\beta_3 = \gamma_3 = 0\)</span> are not rejected. Performing a Wald test, we get: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">Full</span>, <span class="va">GH</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 8.441, df: 2, pval = 0.015</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and the hypothesis is therefore rejected at the 5% (but not at the 1%) level. Then, the hypothesis that <span class="math inline">\(\beta_2 = \beta_3\)</span> and <span class="math inline">\(\gamma_2 = \gamma_3\)</span> implied by Matschke and Sherlund’s model can be tested: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">Full</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x2 = x3"</span>, <span class="st">"rho_x2 = rho_x3"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 1.540, df: 2, pval = 0.463</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and is not rejected.</p>
</section></section><section id="sec-tobit2" class="level2" data-number="11.6"><h2 data-number="11.6" class="anchored" data-anchor-id="sec-tobit2">
<span class="header-section-number">11.6</span> Tobit-2 model</h2>
<p> <strong>Tobit-2</strong> models are bivariate models, the first equation being the <strong>selection equation</strong> and the second the <strong>outcome equation</strong>. The model can be written as follow:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y_1 ^ * &amp;=&amp; \alpha_1 + \beta_1^\top x_1 + \epsilon_1  = \mu_1 + \epsilon_1\\
y_2 ^ * &amp;=&amp; \alpha_1 + \beta_2^\top x_2 + \epsilon_2 = \mu_2 + \epsilon_2\\
\end{array}
\right.
\]</span></p>
<p>and the observation rule is:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y  &amp;=&amp; y_2^* \mbox{ if } y_1^* &gt; 0\\
y  &amp;=&amp; 0 \mbox{ if } y_1^* \leq 0\\
\end{array}
\right.
\]</span></p>
<p>Note that the tobit-2 model reduces to the tobit-1 model if <span class="math inline">\(x_1=x_2\)</span> and <span class="math inline">\(\beta_1=\beta_2\)</span>. In the outcome equation, <span class="math inline">\(y_2 ^ *\)</span> can be replaced by <span class="math inline">\(\ln y_2 ^*\)</span>, so that predicted values of <span class="math inline">\(y_2\)</span> are necessarily positive. The tobit-2 model is more general than the tobit-1 model, as it allows the economic mechanisms that explain the fact that the response is observed to be different from those that explain the value of the response. The seminal papers about the tobit-2 model are <span class="citation" data-cites="GRON:73">Gronau (<a href="#ref-GRON:73" role="doc-biblioref">1973</a>)</span> with his model of female labor supply, and Heckman <span class="citation" data-cites="HECK:76 HECK:79">(<a href="#ref-HECK:76" role="doc-biblioref">1976</a>, <a href="#ref-HECK:79" role="doc-biblioref">1979</a>)</span> who precisely described the statistical properties of this model and proposed a two-step estimator. Hurdle models, proposed by <span class="citation" data-cites="CRAG:71">Cragg (<a href="#ref-CRAG:71" role="doc-biblioref">1971</a>)</span>, can also be considered as tobit-2 models. These models describe the level of consumption of a good as a two-step process: first, the good should be selected (selection equation) and then the level of the consumption is set (outcome equation). The tobit-2 model is also widely used to measure the treatment effect of public programs. If the selection of individuals in a particular program is not purely random, the selection equation describes as a binomial model the process of getting hired in the program and the outcome equation measures the effectiveness of the program, e.g., the wage one year after leaving the program.</p>
<section id="two-part-models" class="level3"><h3 class="anchored" data-anchor-id="two-part-models">Two-part models</h3>
<p> With the assumption of uncorrelation between <span class="math inline">\(\epsilon_1\)</span> and <span class="math inline">\(\epsilon_2\)</span> (which means uncorrelation of the unobserved part of the two responses), the tobit-2 model is called the <strong>two-part</strong> model, and the two equations can be estimated independently, the first by any binomial model (very frequently but not necessarily a probit) with the response equal to 0/1 for positive/negative values of <span class="math inline">\(y_1^*\)</span> and the second by least squares (with either <span class="math inline">\(y_2\)</span> or <span class="math inline">\(\ln y_2\)</span> as the response). The main advantage of this model is that it can be estimated without further hypothesis about the conditional distribution of <span class="math inline">\(y_2\)</span> and can therefore be viewed as a semi-parametric estimator, which would be consistent in a wide variety of contexts (e.g., heteroskedasticity and non-normality). </p>
</section><section id="hurdle-models" class="level3"><h3 class="anchored" data-anchor-id="hurdle-models">Hurdle models</h3>
<p> Hurdle models, proposed by <span class="citation" data-cites="CRAG:71">Cragg (<a href="#ref-CRAG:71" role="doc-biblioref">1971</a>)</span>, share with the two-part models the fact that the errors of the two equations are uncorrelated. Cragg proposed three flavors of hurdle models:</p>
<ul>
<li>simple hurdle models with a log-normal or a truncated normal distribution for the outcome response,</li>
<li>double hurdle models with a normal distribution for the outcome response.</li>
</ul>
<p>The <strong>log-normal simple hurdle</strong> model is a two-part model for which the outcome equation consists of a linear regression of the logarithm of the outcome equation on the set of covariates <span class="math inline">\(x_2\)</span>, which is consistent even without the hypothesis of normality and homoskedasticity.</p>
<p>The <strong>truncated normal simple hurdle</strong> model shares with two-part models the fact that the two equations can be estimated independently, but the outcome equation is estimated by maximum likelihood and therefore the consistency of the estimator relies on the hypothesis of normality and homoskedasticity.</p>
<p>Finally, the <strong>normal double hurdle model</strong> is not per se a tobit-2 model because zero observations may appear not only because <span class="math inline">\(y_1^* &lt; 0\)</span>, but also because <span class="math inline">\(y_2^* &lt; 0\)</span>. If the response is the expenditure for a given good, it is positive only if the good is selected by the household (<span class="math inline">\(y_1^* &gt; 0\)</span>) and if the solution of the consumer problem is not a corner solution (<span class="math inline">\(y_2 ^ * &gt; 0\)</span>).</p>
<p>For this latter model, we have <span class="math inline">\(\mbox{P}(y_1 ^ * &gt; 0) = 1 - \Phi(-\mu_1) =\Phi(\mu_1)\)</span>, <span class="math inline">\(\mbox{P}(y_2 ^ * &gt; 0) = 1 - \Phi(-\mu_2/\sigma)=\Phi(\mu_2/\sigma)\)</span>, so that, given the hypothesis of independence of the two errors:</p>
<p><span class="math display">\[
\mbox{P}(y &gt; 0) = \Phi(\mu_1)\Phi(\mu_2/\sigma)
\]</span></p>
<p>The density of <span class="math inline">\(y\)</span> for positive values of <span class="math inline">\(y\)</span> is:</p>
<p><span class="math display">\[
f(y \mid x_2, y &gt; 0) = \frac{1}{\sigma}\frac{\phi\left(\frac{y -
\mu_2}{\sigma}\right)}{\Phi\left(\frac{y -
\mu_2}{\sigma}\right)}
\]</span></p>
<p>So that finally, the likelihood is:</p>
<p><span class="math display">\[
\begin{array}{rcl}
L^{2H}(\gamma_1, \gamma_2, \sigma | y, X)&amp;=&amp;\prod_{n=1}^{N_o}
\left[1 -
\Phi(\mu_{n1})
\Phi(\mu_{n2}/\sigma)
\right]
\prod_{n = N_o + 1}^{N}\Phi(\mu_{n2}/\sigma)
\Phi(\mu_{n1}) \\
&amp;\times&amp; \prod_{n = N_o + 1}^{N}\frac{1}{\sigma}\frac{\phi\left(\frac{y_n-\mu_{n2}}{\sigma}\right)}
{\Phi(\mu_{n2}/\sigma)}
\end{array}
\]</span></p>
<p>This expression is very similar to <a href="#eq-tobit1_probit_plus_trunc">Equation&nbsp;<span>11.4</span></a> which indicates that the likelihood for the tobit-1 model is the product of:</p>
<ul>
<li>the likelihood of a probit model which explains that <span class="math inline">\(y=0\)</span> or <span class="math inline">\(y &gt; 0\)</span>,</li>
<li>the likelihood of <span class="math inline">\(y\)</span> for the truncated sample.</li>
</ul>
<p>The second term is exactly the same, but the first one is different, as the probability of a positive value of <span class="math inline">\(y\)</span> is now <span class="math inline">\(\Phi(\mu_2/\sigma)\Phi(\mu_1)\)</span>. The likelihood can be simplified as:</p>
<p><span class="math display">\[
L^{2H}(\gamma_1, \gamma_2, \sigma | y,X)=\prod_{n=1}^{N_o}
\left[1 -
\Phi(\mu_{n1})
\Phi(\mu_{n2} / \sigma)
\right]
\prod_{n = N_o + 1}^{N}\frac{1}{\sigma}\Phi(\mu_{n1})
\phi\left(\frac{y_n-\mu_{2n}}{\sigma}\right)
\]</span></p>
<p>Hurdle models can be estimated using the <strong>mhurdle</strong> package <span class="citation" data-cites="CARL:CROI:23">(<a href="#ref-CARL:CROI:23" role="doc-biblioref">Carlevaro and Croissant 2023</a>)</span>. </p>
</section><section id="correlated-models" class="level3"><h3 class="anchored" data-anchor-id="correlated-models">Correlated models</h3>
<p> Finally, we consider the case where the errors of the two equations are correlated. In this case, the model should be fully parametrized and a natural way to do it is to suppose that <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2^*\)</span> (or <span class="math inline">\(\ln y_2 ^ *\)</span>) follow a bivariate normal distribution. The variance of <span class="math inline">\(y_1^*\)</span> is arbitrarily set to 1, as only the sign of <span class="math inline">\(y_1 ^ *\)</span> is observed. Therefore, we can write the system of two equations as:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y_1 ^ * &amp;=&amp; \gamma_1 ^ \top z_1 + \epsilon_1 = \mu_1 + u_1 \\
y_2 ^ * &amp;=&amp; \gamma_2 ^ \top z_2 + \epsilon_2 = \mu_2 + \sigma u_2
\end{array}
\right.
\]</span> where <span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span> are a couple of standard normal deviates. Then the joint distribution of the two latent variables is:</p>
<p><span class="math display">\[
\left( \begin{array}{c} y_1 ^ * \\ y_2 ^ * \end{array} \right) \sim
\mathcal{N} \left( \left( \begin{array}{c} \mu_1 \\ \mu_2 \end{array} \right) ,
\left(  \begin{array}{cc} 1 &amp; \rho \sigma \\
                          \rho \sigma &amp; \sigma ^ 2
                          \end{array} \right)
\right)
\]</span> Two properties of the bivariate normal distribution should be remembered. For a couple of standard normal deviates (<span class="math inline">\(u_1\)</span> and <span class="math inline">\(u_2\)</span>), the joint normal density can be written as the product of the marginal density of <span class="math inline">\(u_1\)</span> and the conditional density of <span class="math inline">\(u_2\)</span>:</p>
<p><span id="eq-bivariate_normal_dist"><span class="math display">\[
\phi_b(u_1, u_2, \rho) = \frac{1}{2\pi\sqrt{1-\rho ^  2}} e ^ {-\frac{1}{2}\left(\frac{u_1 ^ 2 + u_2 ^ 2 - 2 \rho u_1 u_2}{1 - \rho ^ 2}\right)}
= \phi(u_1)\frac{1}{\sqrt{1 - \rho ^ 2}}\phi\left(\frac{u_2 - \rho u_1}{\sqrt{1 - \rho ^ 2}}\right)
\tag{11.9}\]</span></span></p>
<p>Then, the expectation of <span class="math inline">\(u_2\)</span> for <span class="math inline">\(u_1\)</span> left-truncated at <span class="math inline">\(l\)</span> is:</p>
<p><span id="eq-exp_normal_inctrunc"><span class="math display">\[
\begin{array}{rcl}
\mbox{E}(u_2 \mid u_1 &gt; l) &amp;=&amp; \displaystyle\frac{\int_{l} ^ {+\infty}\int_{-\infty} ^ {+\infty}u_2\phi_b(u_1, u_2, \rho)du_1du_2}{\int_{l} ^ {+\infty}\int_{-\infty} ^ {+\infty}\phi_b(u_1, u_2, \rho)du_1du_2}\\
&amp;=&amp;\displaystyle\frac{\int_{l} ^ {+\infty}\left[\int_{-\infty} ^ {+\infty}u_2\phi\left(\frac{u_2 - \rho u_1}{\sqrt{1 - \rho ^ 2}}\right)du_2\right]\phi(u_1)du_1}{\sqrt{1 - \rho ^ 2}(1 - \Phi(l))} \\
&amp;=&amp;\displaystyle\frac{\int_{l} ^ {+\infty}\left[\int_{-\infty} ^ {+\infty}(v \sqrt{1 - \rho ^ 2} + \rho u_1)\phi(v)dv\right]\phi(u_1)du_1}{1 - \Phi(l)}\\
&amp;=&amp;\displaystyle\frac{\rho\int_{l} ^ {+\infty}\left[\int_{-\infty} ^ {+\infty} \phi(v)dv\right]u_1\phi(u_1)du_1}{1 - \Phi(l)}\\
&amp;=&amp; \rho \frac{\phi(l)}{1 - \Phi(l)}
\end{array}
\tag{11.10}\]</span></span></p>
<p><span class="math inline">\(y_2\)</span> is observed if <span class="math inline">\(y_1 ^ * &gt; 0\)</span> or, equivalently, if <span class="math inline">\(u_1 &gt; - \mu_1\)</span>. As <span class="math inline">\(u_1\)</span> follows a standard normal distribution, the probability that <span class="math inline">\(y_2\)</span> is observed is:</p>
<p><span id="eq-prob_y2_observed"><span class="math display">\[
\mbox{P}(y_1 ^ * &gt; 0) = \mbox{P}(u_1 ^ * &gt; -\mu_1)= 1 - \Phi(-\mu_1) = \Phi(\mu_1)
\tag{11.11}\]</span></span></p>
<p>Denote <span class="math inline">\(f(y_2)\)</span> the marginal distribution of <span class="math inline">\(y_2\)</span>: it is obtained by integrating out the joint distribution of <span class="math inline">\(y_1 ^ *\)</span> and <span class="math inline">\(y_2 ^ *\)</span> for all positive values of <span class="math inline">\(y_1 ^ *\)</span>. Using <a href="#eq-bivariate_normal_dist">Equation&nbsp;<span>11.9</span></a> and <a href="#eq-prob_y2_observed">Equation&nbsp;<span>11.11</span></a>:</p>
<p><span id="eq-density_y2_observed"><span class="math display">\[
\begin{array}{rcl}
f(y_2) &amp;=&amp; \frac{1}{\sigma}\frac{\int_{0} ^ {+\infty}\phi_b(y_1 ^ * - \mu_1, (y_2 - \mu_2) / \sigma))dy_1 ^ *}{\int_{0} ^ {+\infty}\phi(y_1 ^ * - \mu_1) dy_1 ^ *} \\
&amp;=&amp; \frac{1}{\sigma}\frac{\int_{-\mu_1} ^ {+\infty}\phi_b\left(u_1, (y_2 - \mu_2) / \sigma)\right)du_1}{1 - \Phi(-\gamma_1 ^ \top z_1)} \\
&amp;=&amp;\frac{\int_{-\mu_1} ^ {+\infty}\phi\left(\frac{u_1 - \rho(y_2 - \mu_2)/ \sigma}{\sqrt{1 - \rho ^ 2}}\right)\phi\left(\frac{y_2 - \mu_2}{\sigma}\right)} {\sigma\sqrt{1 - \rho ^ 2}\Phi(\mu_1)}\\
&amp;=&amp; \frac{\Phi\left(\frac{\mu_1 + \rho (y_2 - \mu_2)/\sigma}{\sqrt{1 - \rho ^ 2}}\right)}{\sigma\sqrt{1 - \rho ^ 2}\Phi(\mu_1)}\phi\left(\frac{y_2 - \mu_2}{\sigma}\right)
\end{array}
\tag{11.12}\]</span></span></p>
<p>The contribution of an observation to the likelihood is either <span class="math inline">\(P(y_1^* &lt; 0)\)</span> (one minus the probability given by <a href="#eq-prob_y2_observed">Equation&nbsp;<span>11.11</span></a>) if <span class="math inline">\(y_2\)</span> is not observed and <span class="math inline">\(P(y_1^* &gt; 0)\)</span> (<a href="#eq-prob_y2_observed">Equation&nbsp;<span>11.11</span></a>) times the density of <span class="math inline">\(y_2\)</span> (<a href="#eq-density_y2_observed">Equation&nbsp;<span>11.12</span></a>) if it is; which leads to the following likelihood function:</p>
<p><span class="math display">\[
L(\theta | y,X)=\prod_{n=1}^{N_o}
\left[1 -
\Phi(\mu_{n1})
\right]
\prod_{n = N_o + 1}^{N}
\frac{1}{\sigma\sqrt{1-\rho ^ 2}}
\Phi\left(\frac{\mu_{n1} +
    \rho\frac{y_n -
      \mu_{n2}}{\sigma}}{\sqrt{1-\rho^2}}\right)
\phi\left(\frac{y_{n}-\mu_{n2}}{\sigma}\right)
\]</span> Consider now the conditional expectation of <span class="math inline">\(y\)</span> if it is observed, i.e., if <span class="math inline">\(y_1 ^ * &gt; 0\)</span>:</p>
<p><span class="math display">\[
\mbox{E}(y\mid x_2, y &gt; 0) =
\mbox{E}(\mu_2 + \sigma_\epsilon u_2\mid x_2, u_1 ^ * &gt; -\mu_1)=
\mu_2 + \sigma_\epsilon\mbox{E}(u_2\mid u_1  &gt; -\mu_1)
\]</span> From <a href="#eq-exp_normal_inctrunc">Equation&nbsp;<span>11.10</span></a>, the last term is just <span class="math inline">\(\rho \frac{\phi(-\mu_1)}{1 - \Phi(-\mu_1)}\)</span>, so that:</p>
<p><span id="eq-cond_exp_heckit"><span class="math display">\[
\mbox{E}(y\mid x_2, x_1, y &gt; 0) = \mu_2 + \sigma \rho \frac{\phi(\mu_1)}{\Phi(\mu_1)}=
\gamma_2 ^ \top z_2 + \sigma \rho r(\mu_1)
\tag{11.13}\]</span></span></p>
<p>As for the tobit-1 model, the conditional expectation is not equal to <span class="math inline">\(\mu_2 = \gamma^\top z_2\)</span> because of the supplementary term <span class="math inline">\(\sigma\rho (\gamma_1^\top x_1)\)</span>. The linear estimator is therefore biased if the omitted variable if <span class="math inline">\(r(\gamma_1^\top z_1)\)</span> is correlated with <span class="math inline">\(x_2\)</span>, which is obviously the case if there are common covariates in <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. <a href="#eq-cond_exp_heckit">Equation&nbsp;<span>11.13</span></a> also directly leads to an alternative estimator. This is a two-step estimator, sometimes called the <strong>heckit</strong> estimator. It consists of first regressing <span class="math inline">\(\mathbf{1}(y_1^* &gt; 0)\)</span> on <span class="math inline">\(x_1\)</span> using a probit, and then estimating <span class="math inline">\(r(\gamma^\top z_1)\)</span> by <span class="math inline">\(r(\hat{\gamma}^\top z_1)\)</span>, <span class="math inline">\(\hat{\gamma}^\top z_1\)</span> being the linear predictor of the probit model. In a second step, regressing <span class="math inline">\(y_2\)</span> on <span class="math inline">\(x_2\)</span> and the supplementary covariate <span class="math inline">\(r(\hat{\gamma}_1^\top z_1)\)</span> leads to a consistent estimate of <span class="math inline">\(\gamma_2\)</span>. </p>
<p>As previously seen (<a href="#fig-mills">Figure&nbsp;<span>11.3</span></a>), <span class="math inline">\(r(z)\)</span> is almost linear in <span class="math inline">\(z\)</span> for a wide range of values of <span class="math inline">\(z\)</span>. Therefore, if <span class="math inline">\(x_1=x_2\)</span>, the coefficients of the second steps of the heckit estimator are only identified by the non-linearity of <span class="math inline">\(r\)</span>. The high correlation between <span class="math inline">\(x_2\)</span> and <span class="math inline">\(r(\hat{\gamma}^\top_1z_1)\)</span> will lead in this case to very imprecise estimates. It is therefore recommended to impose exclusion conditions, i.e., to exclude at least one covariate of the <span class="math inline">\(x_1\)</span> set for the second step of the estimator. This (or these) excluded covariates must be relevant for the selection equation, but not for the outcome equation. In practice, it is often difficult to provide theoretical bases to such exclusion conditions.</p>
<p>The relative merits of the two-part and the heckit models have been discussed in numerous articles, especially in the field of health economics. The arguments are presented in <span class="citation" data-cites="JONE:00">Jones (<a href="#ref-JONE:00" role="doc-biblioref">2000</a>)</span> and <span class="citation" data-cites="DOW:NORT:03">Dow and Norton (<a href="#ref-DOW:NORT:03" role="doc-biblioref">2003</a>)</span>. </p>
</section><section id="application" class="level3"><h3 class="anchored" data-anchor-id="application">Application</h3>
<p><span class="citation" data-cites="MAKO:STRA:09">Makowsky and Stratmann (<a href="#ref-MAKO:STRA:09" role="doc-biblioref">2009</a>)</span> analyze the behavior of policemen in terms of issuing speeding tickets, because of excessive speed. A policeman has to make two decisions:</p>
<ul>
<li>whether to give a ticket or not,</li>
<li>if a ticket is given, its amount should be set, with the recommendation of applying the following formula: $50 + (speed - (max speed allowed + 10))</li>
</ul>
<p>The authors make the hypotheses that a policeman’s behavior will depend on their institutional and political environment. First, there are two kinds of policemen, belonging to the municipality or to the state of Massachusetts. Municipality agents are headed by a chief who is nominated by the municipal authorities and can be fired at any time. One can suppose, that contrary to the state policemen, these local policemen will act in the interest of the local authorities, for which the fees policy has two aspects:</p>
<ul>
<li>fees are a source of income, which can be particularly important for municipalities with budget problems,</li>
<li>fees given to drivers from the municipality can make them unhappy and unwilling to vote for the current authorities, which is not an issue for drivers from other municipalities.</li>
</ul>
<p>The data set, called <code>traffic_citations</code> includes:</p>
<ul>
<li>two responses: <code>fine</code> which indicates whether a ticket has been given or not, and <code>amount</code> which is the amount of the fine when it has been issued,</li>
<li>covariates that describe local fiscal conditions: <code>prval</code> is the average property value in the municipality, which is the base of the main local tax, and <code>overloss</code> which indicates that an override referendum (which indicates that the municipality anticipates insufficient revenues) fails to pass,</li>
<li>characteristics of the offender: <code>ethn</code> indicates the ethnicity of the driver (<code>"other"</code>, <code>"hispanic"</code> or <code>"black"</code>), the sex is indicated by a dummy <code>female</code> and <code>res</code> indicates whether the driver lives in the municipality (<code>"loc"</code>), in another municipality of the state (<code>"oto"</code>) or in another State (<code>"ost"</code>), <code>courtdist</code> is the distance to the courts where the driver can appeal the citation, <code>mph</code> is the difference between the speed of the driver and the legal limit and <code>cdl</code> is a dummy for a commercial driver’s license.</li>
<li>characteristics of the policemen: <code>stpol</code> is a dummy for state officers and is therefore 0 for local policemen.</li>
</ul>
<p>We start by defining the selection and the outcome equations. The authors suppose that the probability of receiving a fine depends on the difference between the actual and the limit speed, the ethnicity, the sex and the age of the offender, the fact that the driver’s license is commercial and covariates describing local fiscal conditions and place of residence of the offender in interaction with the dummy for state officers. As the log of age is introduced in interaction with the <code>female</code> dummy, we divide the age by the sample mean so that the coefficient of <code>female</code> is the effect for the mean age. For the outcome equation, the set of covariates is the same except that the dummy for commercial driver’s license is removed: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">traffic_citations</span> <span class="op">&lt;-</span> <span class="va">traffic_citations</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>age <span class="op">=</span> <span class="va">age</span> <span class="op">/</span> <span class="fl">35</span><span class="op">)</span></span>
<span><span class="va">sel</span> <span class="op">&lt;-</span> <span class="va">fine</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">mph</span><span class="op">)</span> <span class="op">+</span> <span class="va">ethn</span> <span class="op">+</span> <span class="va">female</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="va">stpol</span> <span class="op">*</span> <span class="op">(</span><span class="va">res</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">prval</span><span class="op">)</span> <span class="op">+</span> <span class="va">oloss</span><span class="op">)</span> <span class="op">+</span> <span class="va">cdl</span></span>
<span><span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">sel</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">amount</span><span class="op">)</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">cdl</span><span class="op">)</span></span>
<span><span class="va">traffic_citations</span> <span class="op">&lt;-</span> <span class="va">traffic_citations</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>locpol <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">stpol</span><span class="op">)</span></span>
<span><span class="va">sel_c</span> <span class="op">&lt;-</span> <span class="va">fine</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">mph</span><span class="op">)</span> <span class="op">+</span> <span class="va">ethn</span> <span class="op">+</span> <span class="va">female</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="va">locpol</span> <span class="op">:</span> <span class="op">(</span><span class="va">res</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">prval</span><span class="op">)</span> <span class="op">+</span> <span class="va">oloss</span><span class="op">)</span> <span class="op">+</span> <span class="va">cdl</span> <span class="op">+</span> <span class="va">locpol</span></span>
<span><span class="va">out_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">sel_c</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">amount</span><span class="op">)</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">cdl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Therefore, the identification is performed using the hypothesis that <code>cdl</code> enters the selection equation, but not the outcome equation. The authors justify this hypothesis by the fact that a fine received by drivers with a commercial license may have important consequences for them, because the accumulation of points may lead to the suspension of their license and can cause the loss of their employment and affect their future income. Once the fine has been issued, there is no clear incentive for the officer to impose a lower fine <span class="citation" data-cites="MAKO:STRA:09">(<a href="#ref-MAKO:STRA:09" role="doc-biblioref">Makowsky and Stratmann 2009, 515–16</a>)</span>.</p>
<p>The hypothesis is that local policemen have an incentive to fine when their town experiences fiscal problems and when the offender is not a resident of the town. Therefore, the coefficients on <code>prval</code>, <code>overloss</code>, <code>locoto</code> and <code>locost</code> should be negative for the first one and positive for the other three. Interacting these covariates with the dummy for state officers, an opposite sign should be observed. We can then compute the heckit estimator. First, we estimate the selection equation using a probit and we estimate the inverse mills ratio: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">probit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">sel</span>, data <span class="op">=</span> <span class="va">traffic_citations</span>,</span>
<span>              family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">'probit'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">lp</span> <span class="op">&lt;-</span> <span class="va">probit</span><span class="op">$</span><span class="va">linear.predictor</span></span>
<span><span class="va">mls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">lp</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">lp</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then compute the second stage of the estimator by using OLS to fit the outcome equation, using the estimation of the inverse mills ratio as a supplementary covariate: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">out</span>, <span class="va">traffic_citations</span><span class="op">)</span></span>
<span><span class="va">heck</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lm</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">mls</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <strong>sampleSelection</strong> package <span class="citation" data-cites="TOOM:HENN:08">(<a href="#ref-TOOM:HENN:08" role="doc-biblioref">Toomet and Henningsen 2008</a>)</span> is devoted to the estimation of sample selection models. The <code><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">sampleSelection::selection</a></code> function performs the estimation of such models; two formulas should be provided for the selection and for the outcome equations. The method of estimation is indicated using the <code>method</code> argument which could be either <code>"2step"</code> and <code>"ml"</code> respectively for the two-step and the maximum likelihood estimator. The results are presented in <a href="#tbl-traffic_citations">Table&nbsp;<span>11.3</span></a>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sampleSelection.org">sampleSelection</a></span><span class="op">)</span></span>
<span><span class="va">tc_heck</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sampleSelection/man/selection.html">selection</a></span><span class="op">(</span><span class="va">sel</span>, <span class="va">out</span>, data <span class="op">=</span> <span class="va">traffic_citations</span>,</span>
<span>               method <span class="op">=</span> <span class="st">"2step"</span><span class="op">)</span></span>
<span><span class="va">tc_ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">tc_heck</span>, method <span class="op">=</span> <span class="st">"ml"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-traffic_citations" class="anchored">

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Table&nbsp;11.3:  Traffic citations </caption>
 <thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1"></th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">maximum likelihood</div></th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">heckit</div></th>
</tr>
<tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> selection </th>
   <th style="text-align:center;"> outcome </th>
   <th style="text-align:center;"> auxiliary </th>
   <th style="text-align:center;"> selection </th>
   <th style="text-align:center;"> outcome </th>
   <th style="text-align:center;"> auxiliary </th>
  </tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:center;"> −0.091 </td>
   <td style="text-align:center;"> 2.246*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.005 </td>
   <td style="text-align:center;"> 2.231*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.148) </td>
   <td style="text-align:center;"> (0.056) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.148) </td>
   <td style="text-align:center;"> (0.057) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> log(mph) </td>
   <td style="text-align:center;"> 1.654*** </td>
   <td style="text-align:center;"> 0.959*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 1.615*** </td>
   <td style="text-align:center;"> 1.005*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.019) </td>
   <td style="text-align:center;"> (0.008) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.019) </td>
   <td style="text-align:center;"> (0.015) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> ethnhispanic </td>
   <td style="text-align:center;"> 0.296*** </td>
   <td style="text-align:center;"> 0.035*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.291*** </td>
   <td style="text-align:center;"> 0.043*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.029) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.029) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> ethnblack </td>
   <td style="text-align:center;"> −0.006 </td>
   <td style="text-align:center;"> −0.022** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.009 </td>
   <td style="text-align:center;"> −0.022* </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.026) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.026) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> female </td>
   <td style="text-align:center;"> −0.193*** </td>
   <td style="text-align:center;"> −0.036*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.194*** </td>
   <td style="text-align:center;"> −0.042*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.011) </td>
   <td style="text-align:center;"> (0.004) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.011) </td>
   <td style="text-align:center;"> (0.005) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> log(age) </td>
   <td style="text-align:center;"> −0.412*** </td>
   <td style="text-align:center;"> −0.023*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.407*** </td>
   <td style="text-align:center;"> −0.035*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.018) </td>
   <td style="text-align:center;"> (0.006) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.018) </td>
   <td style="text-align:center;"> (0.007) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> stpol </td>
   <td style="text-align:center;"> −1.736*** </td>
   <td style="text-align:center;"> −0.119 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −1.548*** </td>
   <td style="text-align:center;"> −0.213* </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.294) </td>
   <td style="text-align:center;"> (0.087) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.295) </td>
   <td style="text-align:center;"> (0.092) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> resoto </td>
   <td style="text-align:center;"> 0.275*** </td>
   <td style="text-align:center;"> 0.037*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.276*** </td>
   <td style="text-align:center;"> 0.047*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;"> (0.006) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;"> (0.007) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> resost </td>
   <td style="text-align:center;"> 0.532*** </td>
   <td style="text-align:center;"> 0.121*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.533*** </td>
   <td style="text-align:center;"> 0.139*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.022) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.022) </td>
   <td style="text-align:center;"> (0.010) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> log(prval) </td>
   <td style="text-align:center;"> −0.436*** </td>
   <td style="text-align:center;"> −0.035*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.434*** </td>
   <td style="text-align:center;"> −0.050*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.012) </td>
   <td style="text-align:center;"> (0.005) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.012) </td>
   <td style="text-align:center;"> (0.007) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> oloss </td>
   <td style="text-align:center;"> 0.672*** </td>
   <td style="text-align:center;"> 0.077*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.670*** </td>
   <td style="text-align:center;"> 0.098*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.040) </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.040) </td>
   <td style="text-align:center;"> (0.015) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> cdl </td>
   <td style="text-align:center;"> −0.293*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.315*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.032) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.033) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> female × log(age) </td>
   <td style="text-align:center;"> 0.194*** </td>
   <td style="text-align:center;"> 0.016 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.188*** </td>
   <td style="text-align:center;"> 0.020+ </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.030) </td>
   <td style="text-align:center;"> (0.011) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.030) </td>
   <td style="text-align:center;"> (0.011) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> stpol × resoto </td>
   <td style="text-align:center;"> 0.021 </td>
   <td style="text-align:center;"> 0.034* </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.017 </td>
   <td style="text-align:center;"> 0.032* </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.046) </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.046) </td>
   <td style="text-align:center;"> (0.014) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> stpol × resost </td>
   <td style="text-align:center;"> 0.164** </td>
   <td style="text-align:center;"> 0.038* </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.166** </td>
   <td style="text-align:center;"> 0.036* </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.052) </td>
   <td style="text-align:center;"> (0.016) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.052) </td>
   <td style="text-align:center;"> (0.016) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> stpol × log(prval) </td>
   <td style="text-align:center;"> 0.252*** </td>
   <td style="text-align:center;"> 0.019* </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.235*** </td>
   <td style="text-align:center;"> 0.030*** </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.026) </td>
   <td style="text-align:center;"> (0.008) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.027) </td>
   <td style="text-align:center;"> (0.009) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> stpol × oloss </td>
   <td style="text-align:center;"> −0.325* </td>
   <td style="text-align:center;"> −0.054+ </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.346** </td>
   <td style="text-align:center;"> −0.072* </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.134) </td>
   <td style="text-align:center;"> (0.028) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.134) </td>
   <td style="text-align:center;"> (0.029) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> sigma </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.338*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.349 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.002) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> rho </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.360*** </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.506 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.019) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> invMillsRatio </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.177*** </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.017) </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 68357 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 68357 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> R2 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.445 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> R2 Adj. </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.445 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> AIC </td>
   <td style="text-align:center;"> 90598.4 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> BIC </td>
   <td style="text-align:center;"> 90918.0 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> RMSE </td>
   <td style="text-align:center;"> 0.34 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.33 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
  </tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Remember that for the probit, the marginal effect is the coefficient times the probability that a fine has been issued. As the mean value of <code>fine</code> is close to 0.5, we can multiply probit’s coefficients by 0.4 as an estimate of the marginal effect at the sample mean. Being a female reduces the probability of having a fine by about 8%. The probability is higher for Hispanic drivers (about 12%), there is not such effect for black drivers. State policemen are less severe than local policemen in terms of fine issuing, but when the fine is issuing; the amount is the same as the one set by local policemen. The coefficients of <code>log(prval)</code> and <code>oloss</code> have the expected sign and are highly significant. Moreover, as expected, the coefficients of these covariates in interaction with state policemen have the opposite sign and are significant. Out-of-town and out-of-state offenders have a higher probability to receive a fine and, if it is the case, the average amount is higher than the one for local offenders. The interaction term with the state policemen dummy is not significant for out-of-town offenders and is positive for out-of-state offenders. Finally, as expected, the probability of receiving a fine is lower for drivers with a commercial license. In the two-step model, the inverse mills ratio is positive and highly significant. The implied coefficient of correlation is 0.506 and the estimated value using ML is 0.360. Therefore, we can conclude that the unobserved parts of the selection and the outcome equations are positively correlated.</p>
<!-- - coefficients: the vector of coefficients -->
<!-- - model: the data frame used for the estimation -->
<!-- - gradient: a $N \times (K + 1)$ matrix of individual contributions to the gradient -->
<!-- - hessian: a $(K + 1) \times (K + 1)$ matrix -->
<!-- - info: a $(K + 1) \times (K + 1)$ matrix -->
<!-- - linear.predictors: the linear predictor: $\eta_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n$ -->
<!-- - logLik: the log-likelihood a numeric containing the value of the log-likelihood function for the proposed, the null and the saturated model -->
<!-- - fitted.values: the fitted values -->
<!-- - df.residual: the residual degrees of freedom -->
<!-- - est_method: the method of estimation -->
<!-- - formula: the formula used to describe the model -->
<!-- - npar: a named numeric containing the number of coefficients for the different subsets and the name of these subsets (there is a default attribute which can be problematic, especially for testing functions) -->
<!-- - value: the individual contribution to the objective function, a numeric of length $N$ -->
<!-- - tests: a numeric of length three giving the value of the test that all the coefficients of the covariates are 0 -->
<!-- - call: the matched call -->
<!-- - xlevels: the levels of the factors used in the estimation -->
<!-- - na.action: information returned model.frame on the handling of NAs -->
<!-- - **weights**: the specified weights -->
<!-- - **contrats**: the contrasts used -->
<!-- We have $y_2 = \gamma_2 ^ \top z_2 + \sigma z_2$ and $y_1 ^ * = \gamma_1 ^ \top z_1 + z_1$. Then, $y_2$ is observed if $z_1 > - \gamma_1 ^ \top z_1$ and, therefore -->
<!-- $$ -->
<!-- \mbox{E}(y_2 \mid x_1, x_2, z_1 > - \gamma_1 ^ \top z_1) = \gamma_2 ^ \top z_2 + \sigma \mbox{E}(z_2 \mid z_1 > - \gamma_1 ^ \top z_1) = \gamma_2 ^ \top z_2 + \sigma \rho \frac{\phi(- \gamma_1 ^ \top z_1)}{1 - \Phi(- \gamma_1 ^ \top z_1)} =  -->
<!-- \gamma_2 ^ \top z_2 + \sigma\rho \frac{\phi(\gamma_1 ^ \top z_1)}{\Phi(\gamma_1 ^ \top z_1)} -->
<!-- $$ -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-AMEM:84" class="csl-entry" role="doc-biblioentry">
Amemiya, Takeshi. 1984. <span>“Tobit Models: A Survey.”</span> <em>Journal of Econometrics</em> 24 (1): 3–61. <a href="https://doi.org/10.1016/0304-4076(84)90074-5">https://doi.org/10.1016/0304-4076(84)90074-5</a>.
</div>
<div id="ref-CARL:CROI:23" class="csl-entry" role="doc-biblioentry">
Carlevaro, Fabrizio, and Yves Croissant. 2023. <span>“Hurdle Regression Models: An Application to Consumer Behavior in the United States.”</span> In <em>Applied Econometrics Analysis Using Cross Section and Panel Data</em>, edited by Deep Mukherjee, 227–68. Contributions to Economics. Singapour: Springer.
</div>
<div id="ref-CRAG:71" class="csl-entry" role="doc-biblioentry">
Cragg, John G. 1971. <span>“Some Statistical Models for Limited Dependent Variables with Applications for the Demand for Durable Goods.”</span> <em>Econometrica</em> 39 (5): 829–44.
</div>
<div id="ref-CROM:PALM:URBA:97" class="csl-entry" role="doc-biblioentry">
De Crombrugghe, Denis, Franz C. Palm, and Jean-Pierre Urbain. 1997. <span>“Statistical Demand Functions for Food in the USA and the Netherlands.”</span> <em>Journal of Applied Econometrics</em> 12 (5): 615–45. <a href="https://doi.org/10.1002/(SICI)1099-1255(199709/10)12:5<615::AID-JAE455>3.0.CO;2-L">https://doi.org/10.1002/(SICI)1099-1255(199709/10)12:5&lt;615::AID-JAE455&gt;3.0.CO;2-L</a>.
</div>
<div id="ref-DOW:NORT:03" class="csl-entry" role="doc-biblioentry">
Dow, William H., and Edward C. Norton. 2003. <span>“Choosing Between and Interpreting the Heckit and Two-Part Models for Corner Solutions.”</span> <em>Health Services and Outcomes Research Methodology</em> 4 (1): 5–18.
</div>
<div id="ref-GOLD:MAGG:99" class="csl-entry" role="doc-biblioentry">
Goldberg, Pinelopi Koujianou, and Giovanni Maggi. 1999. <span>“Protection for Sale: An Empirical Investigation.”</span> <em>American Economic Review</em> 89 (5): 1135–55. <a href="https://doi.org/10.1257/aer.89.5.1135">https://doi.org/10.1257/aer.89.5.1135</a>.
</div>
<div id="ref-GOLD:64" class="csl-entry" role="doc-biblioentry">
Goldberger, A. S. 1964. <em>Econometric Theory</em>. Wiley, New-York.
</div>
<div id="ref-GOLD:81" class="csl-entry" role="doc-biblioentry">
———. 1981. <span>“Linear Regression After Regression.”</span> <em>Journal of Econometrics</em> 15: 357–66.
</div>
<div id="ref-GREE:81" class="csl-entry" role="doc-biblioentry">
Greene, William H. 1981. <span>“On the Asymptotic Bias of the Ordinary Least Squares Estimator of the Tobit Model.”</span> <em>Econometrica</em> 49: 505–13.
</div>
<div id="ref-GRON:73" class="csl-entry" role="doc-biblioentry">
Gronau, Reuben. 1973. <span>“The Effect of Children on the Housewife’s Value of Time.”</span> <em>Journal of Political Economy</em> 81 (2): S168–99. <a href="http://www.jstor.org/stable/1840419">http://www.jstor.org/stable/1840419</a>.
</div>
<div id="ref-GROS:HELP:94" class="csl-entry" role="doc-biblioentry">
Grossman, Gene M., and Elhanan Helpman. 1994. <span>“Protection for Sale.”</span> <em>The American Economic Review</em> 84 (4): 833–50. <a href="http://www.jstor.org/stable/2118033">http://www.jstor.org/stable/2118033</a>.
</div>
<div id="ref-HAUS:WISE:76" class="csl-entry" role="doc-biblioentry">
Hausman, Jerry, and David Wise. 1976. <span>“The Evaluation of Results from Truncated Samples: The New Jersey Income Maintenance Experiment,”</span> 421–45. <a href="https://EconPapers.repec.org/RePEc:nbr:nberch:10489">https://EconPapers.repec.org/RePEc:nbr:nberch:10489</a>.
</div>
<div id="ref-HAUS:WISE:77" class="csl-entry" role="doc-biblioentry">
———. 1977. <span>“<span class="nocase">Social Experimentation, Truncated Distributions, and Efficient Estimation</span>.”</span> <em>Econometrica</em> 45 (4): 919–38. <a href="https://ideas.repec.org/a/ecm/emetrp/v45y1977i4p919-38.html">https://ideas.repec.org/a/ecm/emetrp/v45y1977i4p919-38.html</a>.
</div>
<div id="ref-HECK:76" class="csl-entry" role="doc-biblioentry">
Heckman, James J. 1976. <span>“The Common Structure of Statistical Models of Truncation, Sample Selection and Limited Dependent Variables and a Simple Estimator for Such Models,”</span> 475–92. <a href="https://EconPapers.repec.org/RePEc:nbr:nberch:10491">https://EconPapers.repec.org/RePEc:nbr:nberch:10491</a>.
</div>
<div id="ref-HECK:79" class="csl-entry" role="doc-biblioentry">
———. 1979. <span>“Sample Selection Bias as a Specification Error.”</span> <em>Econometrica</em> 47 (1): 153–61. <a href="http://www.jstor.org/stable/1912352">http://www.jstor.org/stable/1912352</a>.
</div>
<div id="ref-HOCH:03" class="csl-entry" role="doc-biblioentry">
Hochguertel, Stefan. 2003. <span>“Precautionary Motives and Portfolio Decisions.”</span> <em>Journal of Applied Econometrics</em> 18 (1): 61–77. <a href="https://doi.org/10.1002/jae.658">https://doi.org/10.1002/jae.658</a>.
</div>
<div id="ref-JONE:00" class="csl-entry" role="doc-biblioentry">
Jones, Andrew. 2000. <span>“Health Econometrics.”</span> In <em>Handbook of Health Economics</em>, edited by A. J. Culyer and J. P. Newhouse, 1st ed., 1:265–344. Elsevier. <a href="https://EconPapers.repec.org/RePEc:eee:heachp:1-06">https://EconPapers.repec.org/RePEc:eee:heachp:1-06</a>.
</div>
<div id="ref-MAKO:STRA:09" class="csl-entry" role="doc-biblioentry">
Makowsky, Michael D., and Thomas Stratmann. 2009. <span>“Political Economy at Any Speed: What Determines Traffic Citations?”</span> <em>American Economic Review</em> 99 (1): 509–27. <a href="https://doi.org/10.1257/aer.99.1.509">https://doi.org/10.1257/aer.99.1.509</a>.
</div>
<div id="ref-MATS:SHER:06" class="csl-entry" role="doc-biblioentry">
Matschke, Xenia, and Shane M. Sherlund. 2006. <span>“Do Labor Issues Matter in the Determination of u.s. Trade Policy? An Empirical Reevaluation.”</span> <em>The American Economic Review</em> 96 (1): 405–21. <a href="http://www.jstor.org/stable/30034374">http://www.jstor.org/stable/30034374</a>.
</div>
<div id="ref-MCDO:MOFF:80" class="csl-entry" role="doc-biblioentry">
McDonald, John F, and Robert A Moffitt. 1980. <span>“<span class="nocase">The Uses of Tobit Analysis</span>.”</span> <em>The Review of Economics and Statistics</em> 62 (2): 318–21. <a href="https://ideas.repec.org/a/tpr/restat/v62y1980i2p318-21.html">https://ideas.repec.org/a/tpr/restat/v62y1980i2p318-21.html</a>.
</div>
<div id="ref-MESS:MAYR:ZEIL:WILK:14" class="csl-entry" role="doc-biblioentry">
Messner, Jakob W., Georg J. Mayr, Achim Zeileis, and Daniel S. Wilks. 2014. <span>“Heteroscedastic Extended Logistic Regression for Postprocessing of Ensemble Guidance.”</span> <em>Monthly Weather Review</em> 142 (1): 448–56. <a href="https://doi.org/10.1175/MWR-D-13-00271.1">https://doi.org/10.1175/MWR-D-13-00271.1</a>.
</div>
<div id="ref-OLSE:78" class="csl-entry" role="doc-biblioentry">
Olsen, Randall J. 1978. <span>“Note on the Uniqueness of the Maximum Likelihood Estimator for the Tobit Model.”</span> <em>Econometrica</em> 46 (5): 1211–15. <a href="https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:5:p:1211-15">https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:5:p:1211-15</a>.
</div>
<div id="ref-POWE:86" class="csl-entry" role="doc-biblioentry">
Powell, J. 1986. <span>“Symmetrically Trimed Least Squares Estimators for Tobit Models.”</span> <em>Econometrica</em> 54: 1435–60.
</div>
<div id="ref-SMIT:BLUN:86" class="csl-entry" role="doc-biblioentry">
Smith, Richard J., and Richard W. Blundell. 1986. <span>“An Exogeneity Test for a Simultaneous Equation Tobit Model with an Application to Labor Supply.”</span> <em>Econometrica</em> 54 (3): 679–85. <a href="http://www.jstor.org/stable/1911314">http://www.jstor.org/stable/1911314</a>.
</div>
<div id="ref-TOBI:58" class="csl-entry" role="doc-biblioentry">
Tobin, James. 1958. <span>“Estimation of Relationships for Limited Dependent Variables.”</span> <em>Econometrica</em> 26 (1): 24–36.
</div>
<div id="ref-TOOM:HENN:08" class="csl-entry" role="doc-biblioentry">
Toomet, Ott, and Arne Henningsen. 2008. <span>“Sample Selection Models in <span>R</span>: Package <span class="nocase">sampleSelection</span>.”</span> <em>Journal of Statistical Software</em> 27 (7). <a href="https://www.jstatsoft.org/v27/i07/">https://www.jstatsoft.org/v27/i07/</a>.
</div>
<div id="ref-WHIT:80" class="csl-entry" role="doc-biblioentry">
White, Halbert. 1980. <span>“A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity.”</span> <em>Econometrica</em> 48 (4): 817. <a href="https://doi.org/10.2307/1912934">https://doi.org/10.2307/1912934</a>.
</div>
<div id="ref-WILH:08" class="csl-entry" role="doc-biblioentry">
Wilhelm, Mark Ottoni. 2008. <span>“Practical Considerations for Choosing Between Tobit and SCLS or CLAD Estimators for Censored Regression Models with an Application to Charitable Giving.”</span> <em>Oxford Bulletin of Economics and Statistics</em> 70 (4): 559–82. <a href="https://doi.org/10.1111/j.1468-0084.2008.00506.x">https://doi.org/10.1111/j.1468-0084.2008.00506.x</a>.
</div>
<div id="ref-WOOL:10" class="csl-entry" role="doc-biblioentry">
Wooldridge, Jeffrey M. 2010. <em><span class="nocase">Econometric Analysis of Cross Section and Panel Data</span></em>. Vol. 1. MIT Press Books 0262232588. The MIT Press. <a href="https://ideas.repec.org/b/mtp/titles/0262232588.html">https://ideas.repec.org/b/mtp/titles/0262232588.html</a>.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>By symmetry of the normal distribution, <span class="math inline">\(\phi(-z) = \phi(z)\)</span> and <span class="math inline">\(1 - \Phi(z) = \Phi(-z)\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The area between 0 and the intersection point <span class="math inline">\(\frac{\mu_1+\mu_2}{2}\)</span> and the one between <span class="math inline">\(\frac{\mu_1+\mu_2}{2}\)</span> and <span class="math inline">\(\mu_1+\mu_2\)</span> are the same with the opposite sign.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This decomposition of marginal effects for tobit models was first proposed by <span class="citation" data-cites="MCDO:MOFF:80">McDonald and Moffitt (<a href="#ref-MCDO:MOFF:80" role="doc-biblioref">1980</a>)</span><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>See for example <span class="citation" data-cites="AMEM:84">Amemiya (<a href="#ref-AMEM:84" role="doc-biblioref">1984</a>)</span>, equation 28, page 13.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See <a href="binomial.html#sec-estimation_binomial"><span>Section&nbsp;10.4.1</span></a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>To save space, the coefficients of the levels of the <code>education</code> and <code>religion</code> covariates are omitted.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>The value of gross imports divided by the value of shipments.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>The third covariate is quite complicated to compute and is directly available in <code>trade_protection</code> as <code>labvar</code>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>See <span class="citation" data-cites="MATS:SHER:06">Matschke and Sherlund (<a href="#ref-MATS:SHER:06" role="doc-biblioref">2006</a>)</span>, table 3, page 417.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../chapters/binomial.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/count.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Count data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb31" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Censored and truncated models {#sec-tobit}</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- precportfolio food trafficcitations + charitable dans tobit1 --&gt;</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup_tobit</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"../_commonR.R"</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>We'll discuss in this chapter models for which the value of the</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>response is continuous and observed only in a certain range. These</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>variables are truncated for a certain value, which can be on the left</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>side of the distribution ($l$), on the right side ($u$) or on both</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>sides. Therefore, the distribution of such a variable is a mix of a</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>discrete and a continuous distribution:</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the value of $y$ is continuous on the $]l, u[$ interval, and its</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>  distribution can be described by a density function $f(y)$,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>there is a mass of probability on $l$ or/and on $u$, which is</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>  described by a probability $P(y = l)$ or/and $P(y = u)$.</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>@sec-trunc_cens describes the situations where such responses occur. The Tobit model is presented in details in @sec-tobit1, the relevant estimation methods in @sec-tobit_estim and their implementation in **R** in @sec-tobit_estim_R. @sec-tobit_eval presents different tools useful to evaluate fitted models. Finally, @sec-tobit2 presents the two-equations tobit model. </span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## Truncated response, truncated and censored samples {#sec-trunc_cens}</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>Truncated responses are observed in different contexts in</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>economics. The first is a corner solution, the second is a</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>problem of missing data, also called censoring, and the last is a</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>problem of selection, also called incidental truncation.</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="fu">### Corner solution</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{corner solution|(}</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>Consider a consumer who can buy two goods, food ($z$) and vacations</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>($y$). Denoting $q_z$ and $q_y$ as the quantities of the two goods, assume that the preferences of the consumer can be represented by the following utility function:</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>U(q_y,q_z) = (q_y + \mu) ^ \beta q_z ^ {1 - \beta}</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>where $0 &lt; \beta &lt; 1$ and $\mu &gt; 0$. The consumer seeks to maximize</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>their utility subject to their budget constraint, which writes $x=p_y q_y +</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>p_z q_z$, where $x$ is the income and $p_y$ and $p_z$ are the</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>unit prices of the two goods. For an interior solution, the consumer should equate the</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>marginal rate of substitution to the price ratio\:</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>\frac{\beta}{1-\beta}\frac{q_z}{q_y + \mu} = \frac{p_y}{p_z}</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>We therefore have $p_z q_z = \frac{1 - \beta}{\beta} p_y(q_y +</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>\mu)$. Replacing in the budget constraint and solving for $q_z$ and then</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>for $q_y$, we finally get the demand functions.</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>q_z &amp;=&amp; \displaystyle(1-\beta)\frac{x}{p_z} + (1-\beta)\frac{p_y}{p_z} \mu <span class="sc">\\</span></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>q_y &amp;=&amp; \displaystyle\beta \frac{x}{p_y} - (1-\beta)\mu <span class="sc">\\</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>Note that the demand function for $y$ can return negative values,</span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>which of course is impossible. Therefore, the pseudo-demand function</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>previously written are only suitable for an interior solution, i.e., when</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>both goods are consumed. This is only the case for a sufficient level</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>of income, namely $\bar{x} = \frac{1 - \beta}{\beta} p_y</span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>\mu$. For a lower level of income, we have $q_y = 0$ and therefore $q_z =</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>x / p_z$. </span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cornersol</span></span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Internal and corner solution"</span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"tidyverse"</span>)</span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ggplot2"</span>)</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"micsr"</span>)</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>Rs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.9</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>xs <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Rs <span class="sc">&gt;</span> <span class="dv">1</span>, <span class="fl">0.5</span> <span class="sc">*</span> (Rs <span class="sc">-</span> <span class="dv">1</span>), <span class="dv">0</span>)</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>ys <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Rs <span class="sc">&gt;</span> <span class="dv">1</span>, <span class="fl">0.5</span> <span class="sc">*</span> (Rs <span class="sc">+</span> <span class="dv">1</span>), Rs)</span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>pts <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> xs, <span class="at">y =</span> ys, <span class="at">label =</span> LETTERS[<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(Rs)])</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>ci <span class="ot">&lt;-</span> <span class="cf">function</span>(x, R) <span class="fu">ifelse</span>(R <span class="sc">&gt;</span> <span class="dv">1</span>, <span class="fl">0.5</span> <span class="sc">*</span> (R <span class="sc">+</span> <span class="dv">1</span>), <span class="fu">sqrt</span>(R)) <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> x)</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"orange"</span>, <span class="st">"purple"</span>, <span class="st">"purple"</span>)</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>)</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a><span class="co">#    ggrepel::geom_label_repel(data = pts, aes(x, y, label = label)) + </span></span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a><span class="co">#    theme_void()</span></span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> A <span class="sc">+</span> <span class="fu">geom_function</span>(<span class="at">fun =</span> ci, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">R =</span> Rs[i]),</span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>                           <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>)</span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> A <span class="sc">+</span> <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> Rs, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">0</span>, <span class="at">yend =</span> Rs))      </span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>A <span class="sc">+</span> ggrepel<span class="sc">::</span><span class="fu">geom_label_repel</span>(<span class="at">data =</span> pts, <span class="fu">aes</span>(x, y, <span class="at">label =</span> label))</span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>This situation is depicted on @fig-cornersol. Points $D$</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>and $E$ correspond to interior solutions for large values of the</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>income. On the contrary, $A$ and $B$ are corner solutions for low</span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>income households. We then have $q_y=0$ and the value of the marginal</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>rate of substitution (the slope of the indifference curve) is lower</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>than the price ratio. Point $C$ corresponds to the level of income</span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>that leads to a corner solution but for which the marginal rate of</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>substitution equals the price ratio. The consumption of $y$ starts</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>when the income is greater than this level.</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>The expression simplifies by taking as the response the expense for</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>the good, $y = p_y q_y$ and not the quantity. We then have: $y = \beta x - (1 -</span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>\beta)p_y\mu$ or, replacing $p_y \mu$ by its expression in terms of</span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a>$\bar{x}$\:</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>y = - \beta \bar{x} + \beta x = \alpha + \beta x</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a>In a linear regression context, the slope is therefore the marginal</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>propensity to consume the specific good (for 1 more dollar of income, the</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>expense increases by $\beta$ dollars) and the intercept is the opposite of</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>$\beta$ times the minimum income $\bar{x}$ for which the</span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>consumption is positive.</span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a>The expense on good $y$ is an example of a truncated variable,</span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>more precisely a left-zero truncated variable. Note that, as stressed</span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>by @WOOL:10\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wooldridge}, pp.517-520, 0 is a relevant value for the variable (this is not the case for the situation described in the next section), but all the values of 0 don't</span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>have the same meaning. For example, at point $B$, $y$ equal 0, but a small</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>increase of the income would lead the household to start consuming the</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>good. On the contrary, at point $A$, $y$ also equals 0, but even with</span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a>a large increase of income, the household would still consume only</span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a>good $z$ and not good $y$.</span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{corner solution|)}</span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data censoring and truncation</span></span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{censoring}</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a>Data censoring occurs when the value of the variable is reported only</span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a>in a certain range $]l,u[$ and is set to $l$ or $u$ otherwise. For</span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>example, @CROM:PALM:URBA:97\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{De Crombrugghe}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Palm}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Urbain} estimate the demand for food using household survey data in the Netherlands. For the upper 5</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a>percentiles (13030 Dfl), the expenditure is not reported, but it is</span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>replaced by the average value (17670 Dfl). Therefore, the response is</span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a>right-truncated with $u =13030$. In this case, the data censoring</span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>process takes the **top-coding** form and $13030$ is not a relevant value of the covariate.\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{top-coding}</span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a>Sometimes, the censoring process leads to a truncation sample, which</span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a>means that only observations for which the response is in the</span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a>continuous observed range are selected. A classic example is</span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a>Hausman and Wise <span class="co">[</span><span class="ot">-@HAUS:WISE:76; -@HAUS:WISE:77</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Hausman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wise} who used data from the New Jersey</span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a>negative income tax experiment, for which families with income above</span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a>1.5 times the poverty level were excluded.</span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sample selection</span></span>
<span id="cb31-156"><a href="#cb31-156" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{sample selection|(}</span>
<span id="cb31-157"><a href="#cb31-157" aria-hidden="true" tabindex="-1"></a>The last data-generating process is the one of sample selection. It</span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a>means that the observation of the response in a particular sample is</span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a>not random because of a self-selection process. This kind of process</span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a>was first analyzed by @GRON:73\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Gronau} in the context of women participation in the labor force: the response is the wage offered to women, but it is only observed for women who participate in the labor market.</span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a>Although it is clearly a different form of truncation compared to the</span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a>case of a corner solution or data censoring, the models that deal with</span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a>these kinds of responses are much alike; it therefore makes sense to</span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a>consider these two cases in the same chapter.</span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{sample selection|)}</span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Data censoring often occurs when the response is a duration, for --&gt;</span></span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- example an unemployment spell. If the interview starts in january 2020 --&gt;</span></span>
<span id="cb31-168"><a href="#cb31-168" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- and ends in december 2020 and that every individual reports mouthly --&gt;</span></span>
<span id="cb31-169"><a href="#cb31-169" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- their situation, 3 situations can be observed: --&gt;</span></span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - the job is lost in march and another job is found in september, --&gt;</span></span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   therefore the unemployment spell is 7 month, --&gt;</span></span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - the individual was unemployed when the survey started and found a --&gt;</span></span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   job in june: in this case, the response is left-censored and all we --&gt;</span></span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   can say about the unemployment spell (that ended) is that it is at --&gt;</span></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   least equal to 6 month, --&gt;</span></span>
<span id="cb31-177"><a href="#cb31-177" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - the individual lost his job in september and is still unemployed at --&gt;</span></span>
<span id="cb31-178"><a href="#cb31-178" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   the end of the survey. The unemployment spell is therefore ongoing --&gt;</span></span>
<span id="cb31-179"><a href="#cb31-179" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   and will length at least 4 months. --&gt;</span></span>
<span id="cb31-180"><a href="#cb31-180" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-181"><a href="#cb31-181" aria-hidden="true" tabindex="-1"></a><span class="fu">### Truncated and censored samples</span></span>
<span id="cb31-182"><a href="#cb31-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-183"><a href="#cb31-183" aria-hidden="true" tabindex="-1"></a>Responses considered in this chapter are **truncated variables**, but the</span>
<span id="cb31-184"><a href="#cb31-184" aria-hidden="true" tabindex="-1"></a>sample used can be either truncated or censored. For the demand for</span>
<span id="cb31-185"><a href="#cb31-185" aria-hidden="true" tabindex="-1"></a>vacations\:</span>
<span id="cb31-186"><a href="#cb31-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-187"><a href="#cb31-187" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a **censored sample** consists of households for which the expenditure on vacations is positive and on household for which this expenditure is 0,</span>
<span id="cb31-188"><a href="#cb31-188" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a **truncated sample** consists only of households for which the expenditure</span>
<span id="cb31-189"><a href="#cb31-189" aria-hidden="true" tabindex="-1"></a>  is strictly positive. </span>
<span id="cb31-190"><a href="#cb31-190" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-191"><a href="#cb31-191" aria-hidden="true" tabindex="-1"></a>Samples used in consumer expenditure surveys are censored. A</span>
<span id="cb31-192"><a href="#cb31-192" aria-hidden="true" tabindex="-1"></a>representative sample of households is surveyed, and this includes</span>
<span id="cb31-193"><a href="#cb31-193" aria-hidden="true" tabindex="-1"></a>households that don't have any expenditure on vacations during the survey.</span>
<span id="cb31-194"><a href="#cb31-194" aria-hidden="true" tabindex="-1"></a>On the contrary, samples that consist of individual surveyed in a</span>
<span id="cb31-195"><a href="#cb31-195" aria-hidden="true" tabindex="-1"></a>travel agency or in an airport are truncated samples, i.e., sample for</span>
<span id="cb31-196"><a href="#cb31-196" aria-hidden="true" tabindex="-1"></a>which the variable of interest (vacation expenditure) is strictly</span>
<span id="cb31-197"><a href="#cb31-197" aria-hidden="true" tabindex="-1"></a>positive. </span>
<span id="cb31-198"><a href="#cb31-198" aria-hidden="true" tabindex="-1"></a>Estimation of models using censored samples are called **censored</span>
<span id="cb31-199"><a href="#cb31-199" aria-hidden="true" tabindex="-1"></a>regression model** or **tobit** models. The tobit name comes from James</span>
<span id="cb31-200"><a href="#cb31-200" aria-hidden="true" tabindex="-1"></a>Tobin, who is the first economist who proposed this model in</span>
<span id="cb31-201"><a href="#cb31-201" aria-hidden="true" tabindex="-1"></a>econometrics <span class="co">[</span><span class="ot">@TOBI:58</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Tobin}, and it was proposed by @GOLD:64\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Goldberger} because of its similarity</span>
<span id="cb31-202"><a href="#cb31-202" aria-hidden="true" tabindex="-1"></a>to the probit model.</span>
<span id="cb31-203"><a href="#cb31-203" aria-hidden="true" tabindex="-1"></a>Estimation on truncated samples leads to the **truncated regression</span>
<span id="cb31-204"><a href="#cb31-204" aria-hidden="true" tabindex="-1"></a>model** <span class="co">[</span><span class="ot">@CRAG:71; and @HAUS:WISE:76;@HAUS:WISE:77</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Hausman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wise}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Cragg}.</span>
<span id="cb31-205"><a href="#cb31-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-206"><a href="#cb31-206" aria-hidden="true" tabindex="-1"></a>In a classic paper, @AMEM:84\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Amemiya} surveyed different flavors of the tobit model and proposed a typology of five categories, tobit1,</span>
<span id="cb31-207"><a href="#cb31-207" aria-hidden="true" tabindex="-1"></a>tobit2, ..., tobit5. We'll concentrate in this chapter on the first</span>
<span id="cb31-208"><a href="#cb31-208" aria-hidden="true" tabindex="-1"></a>two categories:</span>
<span id="cb31-209"><a href="#cb31-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-210"><a href="#cb31-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the **tobit-1** model is a model with one equation which</span>
<span id="cb31-211"><a href="#cb31-211" aria-hidden="true" tabindex="-1"></a>  explains jointly the probability that the value of the response is in the observable</span>
<span id="cb31-212"><a href="#cb31-212" aria-hidden="true" tabindex="-1"></a>  range and the value of the response if it is observed,</span>
<span id="cb31-213"><a href="#cb31-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the **tobit-2** model, which is a bivariate model, with the first equation indicating whether the response</span>
<span id="cb31-214"><a href="#cb31-214" aria-hidden="true" tabindex="-1"></a>  is in the observable range or not, and the second one indicating</span>
<span id="cb31-215"><a href="#cb31-215" aria-hidden="true" tabindex="-1"></a>  the value of the response when it is observed.</span>
<span id="cb31-216"><a href="#cb31-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-217"><a href="#cb31-217" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tobit-1 model {#sec-tobit1}</span></span>
<span id="cb31-218"><a href="#cb31-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-219"><a href="#cb31-219" aria-hidden="true" tabindex="-1"></a>We'll denote by tobit-1 (or tobit, for short)  a linear model of the usual form: $y_n = \alpha + \beta ^ \top x_n + \epsilon_n = \gamma ^ \top z_n + \epsilon_n$, where $y$ is only observed in a certain range, say $y \in ] l, u[$. In general, the tobit name is restricted to models estimated in a censored sample. We'll treat in the same section the case where the estimation is performed in a truncated sample.</span>
<span id="cb31-220"><a href="#cb31-220" aria-hidden="true" tabindex="-1"></a>In a semi-parametric setting, no hypotheses are made on the</span>
<span id="cb31-221"><a href="#cb31-221" aria-hidden="true" tabindex="-1"></a>distribution of $\epsilon_n$. On the contrary, a fully  parametric model</span>
<span id="cb31-222"><a href="#cb31-222" aria-hidden="true" tabindex="-1"></a>will specify the distribution of $\epsilon$; for example, it will</span>
<span id="cb31-223"><a href="#cb31-223" aria-hidden="true" tabindex="-1"></a>suppose that $\epsilon_n \sim \mathcal{N} (0, \sigma_\epsilon^2)$, i.e., that the errors of the</span>
<span id="cb31-224"><a href="#cb31-224" aria-hidden="true" tabindex="-1"></a>model are normal and homoskedastic. In the context of the linear</span>
<span id="cb31-225"><a href="#cb31-225" aria-hidden="true" tabindex="-1"></a>regression model, violation of these assumptions is not too severe,</span>
<span id="cb31-226"><a href="#cb31-226" aria-hidden="true" tabindex="-1"></a>as the estimator is still consistent. This is not the case for the</span>
<span id="cb31-227"><a href="#cb31-227" aria-hidden="true" tabindex="-1"></a>model studied in this chapter, as wrong assumptions of</span>
<span id="cb31-228"><a href="#cb31-228" aria-hidden="true" tabindex="-1"></a>homoskedasticity and normality will lead to biased and inconsistent</span>
<span id="cb31-229"><a href="#cb31-229" aria-hidden="true" tabindex="-1"></a>estimators.</span>
<span id="cb31-230"><a href="#cb31-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-231"><a href="#cb31-231" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Several examples may help to understand what kind of real situations --&gt;</span></span>
<span id="cb31-232"><a href="#cb31-232" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- are included in this setting: --&gt;</span></span>
<span id="cb31-233"><a href="#cb31-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-234"><a href="#cb31-234" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - @CROM:PALM:URBA:97 estimate the demand for food using households --&gt;</span></span>
<span id="cb31-235"><a href="#cb31-235" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   survey data in the Netherlands. For the upper five percentiles --&gt;</span></span>
<span id="cb31-236"><a href="#cb31-236" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   (13030 Dfl), the expenditure is not reported, but is replaced by the --&gt;</span></span>
<span id="cb31-237"><a href="#cb31-237" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   average value (17670 Dfl). Therefore, we have $b = 13030$, --&gt;</span></span>
<span id="cb31-238"><a href="#cb31-238" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - @MINI:PAST:10 and @HOCH:03 estimate the share of risk-less assets, --&gt;</span></span>
<span id="cb31-239"><a href="#cb31-239" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   which can be either an internal solution, or a corner solution with --&gt;</span></span>
<span id="cb31-240"><a href="#cb31-240" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   the share equal to 0 or 1 ($a = 0$ and $b=1$). --&gt;</span></span>
<span id="cb31-241"><a href="#cb31-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-242"><a href="#cb31-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-243"><a href="#cb31-243" aria-hidden="true" tabindex="-1"></a><span class="fu">### Truncated normal distribution, truncated and censored sample</span></span>
<span id="cb31-244"><a href="#cb31-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-245"><a href="#cb31-245" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{truncated normal distribution}</span>
<span id="cb31-246"><a href="#cb31-246" aria-hidden="true" tabindex="-1"></a>Early models assume that the (conditional) distribution of the response is </span>
<span id="cb31-247"><a href="#cb31-247" aria-hidden="true" tabindex="-1"></a>normal. But the fact that the response is truncated implies that the</span>
<span id="cb31-248"><a href="#cb31-248" aria-hidden="true" tabindex="-1"></a>distribution of $y$ is</span>
<span id="cb31-249"><a href="#cb31-249" aria-hidden="true" tabindex="-1"></a>truncated normal. This distribution is represented in</span>
<span id="cb31-250"><a href="#cb31-250" aria-hidden="true" tabindex="-1"></a>@fig-normal2Trunc.</span>
<span id="cb31-251"><a href="#cb31-251" aria-hidden="true" tabindex="-1"></a>Starting from a normal distribution</span>
<span id="cb31-252"><a href="#cb31-252" aria-hidden="true" tabindex="-1"></a>$\frac{1}{\sigma}e^{-\frac{1}{2}\left(\frac{y-\mu}{\sigma}\right)^2}$,</span>
<span id="cb31-253"><a href="#cb31-253" aria-hidden="true" tabindex="-1"></a>we first compute the probability that $l &lt; y &lt; u$ and we divide</span>
<span id="cb31-254"><a href="#cb31-254" aria-hidden="true" tabindex="-1"></a>the normal density by this probability, which is: </span>
<span id="cb31-255"><a href="#cb31-255" aria-hidden="true" tabindex="-1"></a>$\Phi\left(\frac{u-\mu}{\sigma}\right) - \Phi\left(\frac{l-\mu}{\sigma}\right)$.</span>
<span id="cb31-256"><a href="#cb31-256" aria-hidden="true" tabindex="-1"></a>The density of $y$ is therefore:</span>
<span id="cb31-257"><a href="#cb31-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-258"><a href="#cb31-258" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-259"><a href="#cb31-259" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-normal2Trunc</span></span>
<span id="cb31-260"><a href="#cb31-260" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Truncated normal distribution"</span></span>
<span id="cb31-261"><a href="#cb31-261" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-262"><a href="#cb31-262" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/normal2Trunc.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-263"><a href="#cb31-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-264"><a href="#cb31-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-265"><a href="#cb31-265" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-266"><a href="#cb31-266" aria-hidden="true" tabindex="-1"></a>f(y) = \frac{1}{\sigma}</span>
<span id="cb31-267"><a href="#cb31-267" aria-hidden="true" tabindex="-1"></a>\frac{\phi\left(\frac{y - \mu}{\sigma}\right)}{\Phi\left(\frac{u-\mu}{\sigma}\right) -</span>
<span id="cb31-268"><a href="#cb31-268" aria-hidden="true" tabindex="-1"></a>\Phi\left(\frac{l-\mu}{\sigma}\right)}</span>
<span id="cb31-269"><a href="#cb31-269" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-270"><a href="#cb31-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-271"><a href="#cb31-271" aria-hidden="true" tabindex="-1"></a>so that $\int_{l}^{u} f(y) dy = 1$.</span>
<span id="cb31-272"><a href="#cb31-272" aria-hidden="true" tabindex="-1"></a>As $y$ is truncated, its expected value and its variance are not</span>
<span id="cb31-273"><a href="#cb31-273" aria-hidden="true" tabindex="-1"></a>$\mu$ and $\sigma^ 2$. More precisely, left(-right) truncation will lead</span>
<span id="cb31-274"><a href="#cb31-274" aria-hidden="true" tabindex="-1"></a>to an expected value greater(-lower) than $\mu$. In</span>
<span id="cb31-275"><a href="#cb31-275" aria-hidden="true" tabindex="-1"></a>@fig-normal2Trunc, the expected value is greater than $\mu$</span>
<span id="cb31-276"><a href="#cb31-276" aria-hidden="true" tabindex="-1"></a>because the truncation is more severe on the left. Obviously,</span>
<span id="cb31-277"><a href="#cb31-277" aria-hidden="true" tabindex="-1"></a>reducing the range of the values of $y$ implies a reduction of the</span>
<span id="cb31-278"><a href="#cb31-278" aria-hidden="true" tabindex="-1"></a>variance, so that $\mbox{V}(y) &lt; \sigma^2$. </span>
<span id="cb31-279"><a href="#cb31-279" aria-hidden="true" tabindex="-1"></a>To compute the first two moments of this distribution, it's easier to consider</span>
<span id="cb31-280"><a href="#cb31-280" aria-hidden="true" tabindex="-1"></a>first a truncated standard normal deviate $z$. The three following results will be used: $\phi(z)' = - z \phi(z)$, $\left<span class="co">[</span><span class="ot">\Phi(z) - z \phi(z)\right</span><span class="co">]</span>' = z ^ 2 \phi(z)$ and $\lim\limits_{z \to \pm \infty}z\phi(z)=0$.</span>
<span id="cb31-281"><a href="#cb31-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-282"><a href="#cb31-282" aria-hidden="true" tabindex="-1"></a>For the left-truncated case, the expectation and the variance are:</span>
<span id="cb31-283"><a href="#cb31-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-284"><a href="#cb31-284" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-285"><a href="#cb31-285" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-286"><a href="#cb31-286" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-287"><a href="#cb31-287" aria-hidden="true" tabindex="-1"></a>E(z | z &gt; l) &amp;=&amp; \displaystyle \frac{\displaystyle\int_l ^ {+\infty} z \phi(z) dz}{1 - \Phi(l)}=</span>
<span id="cb31-288"><a href="#cb31-288" aria-hidden="true" tabindex="-1"></a>\frac{\left<span class="co">[</span><span class="ot">-\phi(z)\right</span><span class="co">]</span>_l^{+\infty}}{1 - \Phi(l)} = \frac{\phi(l)}{1 - \Phi(l)} = \lambda_l <span class="sc">\\</span></span>
<span id="cb31-289"><a href="#cb31-289" aria-hidden="true" tabindex="-1"></a>V(z | z &gt; l) &amp;=&amp; \displaystyle\frac{\displaystyle\int_l ^ {+\infty} z ^ 2 \phi(z) dz}{1 - \Phi(l)} - \lambda_l ^ 2=</span>
<span id="cb31-290"><a href="#cb31-290" aria-hidden="true" tabindex="-1"></a>\frac{\left<span class="co">[</span><span class="ot">\Phi(v)-v\phi(v)\right</span><span class="co">]</span>_{l}^{+\infty}}{1 - \Phi(l)} - \lambda_l ^ 2 = 1 - \lambda_l\left<span class="co">[</span><span class="ot">\lambda_l - l\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb31-291"><a href="#cb31-291" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-292"><a href="#cb31-292" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-293"><a href="#cb31-293" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-294"><a href="#cb31-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-295"><a href="#cb31-295" aria-hidden="true" tabindex="-1"></a>where $\lambda_l$ is called the **inverse mills ratio**. For a general normal variable $y \sim \mathcal{N}(\mu, \sigma)$, denoting $\tilde{l} = (l - \mu) / \sigma$, the expectation is:</span>
<span id="cb31-296"><a href="#cb31-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-297"><a href="#cb31-297" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-298"><a href="#cb31-298" aria-hidden="true" tabindex="-1"></a>E(y | y &gt; l) = \displaystyle \frac{\displaystyle\int_l ^ {+\infty} y \phi\left(\frac{y - \mu}{\sigma}\right)/ \sigma dy}{1 - \Phi(\tilde{l})}</span>
<span id="cb31-299"><a href="#cb31-299" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb31-300"><a href="#cb31-300" aria-hidden="true" tabindex="-1"></a>\displaystyle \frac{\displaystyle\int_{\tilde{l}} ^ {+\infty} (\mu + \sigma z) \phi(z) dz}{1 - \Phi(\tilde{l})}= \mu + \sigma \lambda_{\tilde{l}}</span>
<span id="cb31-301"><a href="#cb31-301" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp_left_trunc}</span>
<span id="cb31-302"><a href="#cb31-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-303"><a href="#cb31-303" aria-hidden="true" tabindex="-1"></a>and the variance is:</span>
<span id="cb31-304"><a href="#cb31-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-305"><a href="#cb31-305" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-306"><a href="#cb31-306" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-307"><a href="#cb31-307" aria-hidden="true" tabindex="-1"></a>V(z | z &gt; l) &amp;=&amp; \displaystyle\frac{\displaystyle\int_l ^ {+\infty} \left(y - \mu - \sigma \lambda_{\tilde{l}}\right) ^ 2 \phi\left(\frac{y - \mu}{\sigma}\right)/\sigma dy}{1 - \Phi(\tilde{l})}<span class="sc">\\</span></span>
<span id="cb31-308"><a href="#cb31-308" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;</span>
<span id="cb31-309"><a href="#cb31-309" aria-hidden="true" tabindex="-1"></a>\displaystyle\frac{\displaystyle\int_{\tilde{l}} ^ {+\infty} \sigma ^ 2 (z - \lambda_{\tilde{l}}) ^ 2 \phi(z) dz}{1 - \Phi(\tilde{l})} = \sigma ^ 2\left<span class="co">[</span><span class="ot">1 - \lambda_{\tilde{l}}(\lambda_{\tilde{l}}-\tilde{l})\right</span><span class="co">]</span></span>
<span id="cb31-310"><a href="#cb31-310" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-311"><a href="#cb31-311" aria-hidden="true" tabindex="-1"></a>$$ {#eq-var_left_trunc}</span>
<span id="cb31-312"><a href="#cb31-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-313"><a href="#cb31-313" aria-hidden="true" tabindex="-1"></a>Similarly, for the right-truncated case, denoting $\tilde{u} = (u - \mu) / \sigma$ and $\lambda_{\tilde{u}}= - \phi(\tilde{u})/\Phi(\tilde{u})$, </span>
<span id="cb31-314"><a href="#cb31-314" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y \mid y &lt; u) = \mu + \sigma \lambda_{\tilde{u}}$ and </span>
<span id="cb31-315"><a href="#cb31-315" aria-hidden="true" tabindex="-1"></a>$\mbox{V}(y \mid y &lt; u) = \sigma ^ 2\left<span class="co">[</span><span class="ot">1 -\lambda_{\tilde{u}}(\lambda_{\tilde{u}}-\tilde{u})\right</span><span class="co">]</span>$.</span>
<span id="cb31-316"><a href="#cb31-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-317"><a href="#cb31-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-318"><a href="#cb31-318" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- We then have: --&gt;</span></span>
<span id="cb31-319"><a href="#cb31-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-320"><a href="#cb31-320" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-321"><a href="#cb31-321" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(z) = \frac{\displaystyle\int_{l}^{u} z\phi(z) dz}{\Phi(u) - --&gt;</span></span>
<span id="cb31-322"><a href="#cb31-322" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(l)}=\frac{\left[ -\phi(z)\right]_{z_l}^{z_u}}{\Phi(u) - \Phi(l)} --&gt;</span></span>
<span id="cb31-323"><a href="#cb31-323" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- =\frac{\phi(l) - \phi(u)}{\Phi(u) - \Phi(l)} --&gt;</span></span>
<span id="cb31-324"><a href="#cb31-324" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-325"><a href="#cb31-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-326"><a href="#cb31-326" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-327"><a href="#cb31-327" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-328"><a href="#cb31-328" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(z) &amp;=&amp; \frac{\int_{z_l}^{z_u} z ^ 2\phi(z) dz}{\Phi(z_u) -\Phi(z_l)}-E(z) ^ 2= --&gt;</span></span>
<span id="cb31-329"><a href="#cb31-329" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\left[\Phi(z) -z\phi(z)\right]_{z_l}^{z_u}}{\Phi(u) - \Phi(l)} - --&gt;</span></span>
<span id="cb31-330"><a href="#cb31-330" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- E(z) ^ 2 \\ --&gt;</span></span>
<span id="cb31-331"><a href="#cb31-331" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp;  --&gt;</span></span>
<span id="cb31-332"><a href="#cb31-332" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 1 - \frac{z_u \phi(z_u) - z_l \phi(z_l)}{\Phi(z_u) - \Phi(z_l)} - \frac{(\phi(z_u) - --&gt;</span></span>
<span id="cb31-333"><a href="#cb31-333" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \phi(z_l)) ^ 2}{(\Phi(z_u) - \Phi(z_l)) ^ 2} --&gt;</span></span>
<span id="cb31-334"><a href="#cb31-334" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-335"><a href="#cb31-335" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-336"><a href="#cb31-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-337"><a href="#cb31-337" aria-hidden="true" tabindex="-1"></a>Consider now the special (and very common) case where the distribution of $y$ is normal left-truncated at $l = 0$, with untruncated mean and variance equal to $\mu_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n$ and $\sigma_\epsilon ^ 2$. Then, $\tilde{l} = - \mu_n / \sigma$ and the inverse mills ratio is:^<span class="co">[</span><span class="ot">By symmetry of the normal distribution, $\phi(-z) = \phi(z)$ and $1 - \Phi(z) = \Phi(-z)$.</span><span class="co">]</span></span>
<span id="cb31-338"><a href="#cb31-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-339"><a href="#cb31-339" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-340"><a href="#cb31-340" aria-hidden="true" tabindex="-1"></a>\lambda_{\tilde{0}} = \frac{\phi(-\mu_n/\sigma)}{1 - \Phi(-\mu_n/\sigma)} = \frac{\phi(\mu_n/\sigma)}{\Phi(\mu_n/\sigma)}</span>
<span id="cb31-341"><a href="#cb31-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-342"><a href="#cb31-342" aria-hidden="true" tabindex="-1"></a>Let $r(x) = \frac{\phi(x)}{\Phi(x)}$; then $\lambda_{\tilde{0}} = r(\mu_n / \sigma)$. The derivative of $r$ is: $r'(x) = - r(x) \left<span class="co">[</span><span class="ot">r(x) + x\right</span><span class="co">]</span>$. </span>
<span id="cb31-343"><a href="#cb31-343" aria-hidden="true" tabindex="-1"></a>$r(x)$ is represented in @fig-mills. It is a decreasing function, with $\displaystyle \lim_{x\rightarrow</span>
<span id="cb31-344"><a href="#cb31-344" aria-hidden="true" tabindex="-1"></a>-\infty} r(x) + x= 0$ and $\displaystyle \lim_{x\rightarrow +\infty} r(x)= 0$.</span>
<span id="cb31-345"><a href="#cb31-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-346"><a href="#cb31-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-347"><a href="#cb31-347" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mills</span></span>
<span id="cb31-348"><a href="#cb31-348" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Inverse Mills ratio"</span></span>
<span id="cb31-349"><a href="#cb31-349" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-350"><a href="#cb31-350" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/mills_ratio.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-351"><a href="#cb31-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-352"><a href="#cb31-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-353"><a href="#cb31-353" aria-hidden="true" tabindex="-1"></a>The expectation and the variance of $y$ left-truncated at 0 can then be written, using @eq-exp_left_trunc and @eq-var_left_trunc:</span>
<span id="cb31-354"><a href="#cb31-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-355"><a href="#cb31-355" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-356"><a href="#cb31-356" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-357"><a href="#cb31-357" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-358"><a href="#cb31-358" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y \mid x_n, y &gt; 0) &amp;=&amp; \mu_n + \sigma r(\mu_n / \sigma)<span class="sc">\\</span></span>
<span id="cb31-359"><a href="#cb31-359" aria-hidden="true" tabindex="-1"></a>\mbox{V}(y \mid x_n, y &gt; 0) &amp;=&amp; \sigma ^ 2 \left<span class="co">[</span><span class="ot">1 + r'(\mu_n / \sigma)\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb31-360"><a href="#cb31-360" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-361"><a href="#cb31-361" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-362"><a href="#cb31-362" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-363"><a href="#cb31-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-364"><a href="#cb31-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-365"><a href="#cb31-365" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The derivative of $r$ is: --&gt;</span></span>
<span id="cb31-366"><a href="#cb31-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-367"><a href="#cb31-367" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-368"><a href="#cb31-368" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r'(x) = - r(x)\left[r(x) + x\right] --&gt;</span></span>
<span id="cb31-369"><a href="#cb31-369" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-370"><a href="#cb31-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-371"><a href="#cb31-371" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- With these notations, the first two moments of the truncated normal --&gt;</span></span>
<span id="cb31-372"><a href="#cb31-372" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- distribution are: --&gt;</span></span>
<span id="cb31-373"><a href="#cb31-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-374"><a href="#cb31-374" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-375"><a href="#cb31-375" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-376"><a href="#cb31-376" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(z) &amp;=&amp; \left[r(z_l) - r(z_u)\right] --&gt;</span></span>
<span id="cb31-377"><a href="#cb31-377" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} - r(z_u) \\ --&gt;</span></span>
<span id="cb31-378"><a href="#cb31-378" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(z) &amp;=&amp;  1 + \left[z_l r(z_l) - z_u r(z_u)\right]  --&gt;</span></span>
<span id="cb31-379"><a href="#cb31-379" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} --&gt;</span></span>
<span id="cb31-380"><a href="#cb31-380" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--  - z_u r(z_u) - \mbox{E}(z) ^ 2 --&gt;</span></span>
<span id="cb31-381"><a href="#cb31-381" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-382"><a href="#cb31-382" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-383"><a href="#cb31-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-384"><a href="#cb31-384" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- If $z$ is only left-truncated, $z_u \rightarrow +\infty$, --&gt;</span></span>
<span id="cb31-385"><a href="#cb31-385" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $r(z_u)\rightarrow 0$, $z_u \times r(z_u)\rightarrow 0$ and --&gt;</span></span>
<span id="cb31-386"><a href="#cb31-386" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\frac{\Phi(z_l)}{\Phi(z_u) - \Phi(z_l)} r(z_l) \rightarrow --&gt;</span></span>
<span id="cb31-387"><a href="#cb31-387" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\phi(z_l)}{1 - \Phi(z_l)} = \frac{\phi(z_l)}{\Phi(-z_l)} = --&gt;</span></span>
<span id="cb31-388"><a href="#cb31-388" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r(-z_l)$. The first two moments then reduce to: --&gt;</span></span>
<span id="cb31-389"><a href="#cb31-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-390"><a href="#cb31-390" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-391"><a href="#cb31-391" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left\{ --&gt;</span></span>
<span id="cb31-392"><a href="#cb31-392" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-393"><a href="#cb31-393" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(z) &amp;=&amp;  r(-z_l) \\ --&gt;</span></span>
<span id="cb31-394"><a href="#cb31-394" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(z) &amp;=&amp;  1 - r(-z_l)\left[r(-z_l) - z_l\right] = 1 + r'(-z_l) --&gt;</span></span>
<span id="cb31-395"><a href="#cb31-395" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-396"><a href="#cb31-396" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right. --&gt;</span></span>
<span id="cb31-397"><a href="#cb31-397" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-398"><a href="#cb31-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-399"><a href="#cb31-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-400"><a href="#cb31-400" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- If $z$ is only right-truncated\: --&gt;</span></span>
<span id="cb31-401"><a href="#cb31-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-402"><a href="#cb31-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-403"><a href="#cb31-403" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-404"><a href="#cb31-404" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left\{ --&gt;</span></span>
<span id="cb31-405"><a href="#cb31-405" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-406"><a href="#cb31-406" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(z) &amp;=&amp; - r(z_u) \\ --&gt;</span></span>
<span id="cb31-407"><a href="#cb31-407" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(z) &amp;=&amp;  1 - r(z_u)\left[r(z_u) + z_u\right] = 1 + r'(z_u) --&gt;</span></span>
<span id="cb31-408"><a href="#cb31-408" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-409"><a href="#cb31-409" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right. --&gt;</span></span>
<span id="cb31-410"><a href="#cb31-410" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-411"><a href="#cb31-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-412"><a href="#cb31-412" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Consider now the linear model: $y=\alpha + \beta x + \epsilon$. For --&gt;</span></span>
<span id="cb31-413"><a href="#cb31-413" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- the most common case where $y$ is zero-left truncated, $\epsilon$ is --&gt;</span></span>
<span id="cb31-414"><a href="#cb31-414" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- left truncated at $-\beta x$ and we get, denoting $v = \beta x / \sigma$: --&gt;</span></span>
<span id="cb31-415"><a href="#cb31-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-416"><a href="#cb31-416" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-417"><a href="#cb31-417" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left\{ --&gt;</span></span>
<span id="cb31-418"><a href="#cb31-418" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-419"><a href="#cb31-419" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(y\mid x) &amp;=&amp; \alpha + \beta x + \mbox{E}(\epsilon\mid x) = --&gt;</span></span>
<span id="cb31-420"><a href="#cb31-420" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_\epsilon r\left(\frac{\alpha + \beta  x}{\sigma}\right)\\ --&gt;</span></span>
<span id="cb31-421"><a href="#cb31-421" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(y\mid x) &amp;=&amp; \sigma_\epsilon ^ 2 \left[1 + --&gt;</span></span>
<span id="cb31-422"><a href="#cb31-422" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r'\left(\frac{\alpha + \beta x}{\sigma}\right)\right] --&gt;</span></span>
<span id="cb31-423"><a href="#cb31-423" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-424"><a href="#cb31-424" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right. --&gt;</span></span>
<span id="cb31-425"><a href="#cb31-425" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-426"><a href="#cb31-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-427"><a href="#cb31-427" aria-hidden="true" tabindex="-1"></a>Therefore, truncation has two consequences for the linear regression</span>
<span id="cb31-428"><a href="#cb31-428" aria-hidden="true" tabindex="-1"></a>model:</span>
<span id="cb31-429"><a href="#cb31-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-430"><a href="#cb31-430" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the conditional variance depends on $x$ so that the errors of the</span>
<span id="cb31-431"><a href="#cb31-431" aria-hidden="true" tabindex="-1"></a>  model are heteroskedastic,\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heteroskedasticity}</span>
<span id="cb31-432"><a href="#cb31-432" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the conditional expectation of $y$ is no longer equal to</span>
<span id="cb31-433"><a href="#cb31-433" aria-hidden="true" tabindex="-1"></a>  $\mu_n = \alpha+\beta ^ \top x_n$, but to $\mu_n + \sigma r(\mu_n / \sigma)$ or, stated differently, the errors of the model are correlated with the covariate as $\mbox{E}(\epsilon \mid x) = \sigma r(\mu_n / \sigma)$.</span>
<span id="cb31-434"><a href="#cb31-434" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-435"><a href="#cb31-435" aria-hidden="true" tabindex="-1"></a>The first point implies that the OLS estimator is</span>
<span id="cb31-436"><a href="#cb31-436" aria-hidden="true" tabindex="-1"></a>inefficient, the second one that it is biased and inconsistent. For the case where there is only one covariate and $\beta &gt; 0$, this correlation is illustrated in @fig-normtrunc4</span>
<span id="cb31-437"><a href="#cb31-437" aria-hidden="true" tabindex="-1"></a>which presents the distribution of $y$ for different values of $x$. The</span>
<span id="cb31-438"><a href="#cb31-438" aria-hidden="true" tabindex="-1"></a>mode of the distribution is $\alpha + \beta x$ (and it would also be</span>
<span id="cb31-439"><a href="#cb31-439" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y\mid x)$ if the response weren't</span>
<span id="cb31-440"><a href="#cb31-440" aria-hidden="true" tabindex="-1"></a>truncated). $\mbox{E}(y\mid x)$ is obtained by adding</span>
<span id="cb31-441"><a href="#cb31-441" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(\epsilon\mid x)$ to $\alpha + \beta x$ .</span>
<span id="cb31-442"><a href="#cb31-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-443"><a href="#cb31-443" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-444"><a href="#cb31-444" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-normtrunc4</span></span>
<span id="cb31-445"><a href="#cb31-445" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Truncated normal distribution for $y$"</span></span>
<span id="cb31-446"><a href="#cb31-446" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-447"><a href="#cb31-447" aria-hidden="true" tabindex="-1"></a><span class="co">#| out.width: "100%"</span></span>
<span id="cb31-448"><a href="#cb31-448" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/normTrunc4.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-449"><a href="#cb31-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-450"><a href="#cb31-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-451"><a href="#cb31-451" aria-hidden="true" tabindex="-1"></a>As $x$ increases, $\alpha + \beta x$ increases, which reduces</span>
<span id="cb31-452"><a href="#cb31-452" aria-hidden="true" tabindex="-1"></a>$\mbox{P}(y &lt; 0)$ and makes the truncated normal density closer to the</span>
<span id="cb31-453"><a href="#cb31-453" aria-hidden="true" tabindex="-1"></a>untruncated one. As we can see in @fig-normtrunc4, the distance between the</span>
<span id="cb31-454"><a href="#cb31-454" aria-hidden="true" tabindex="-1"></a>mode of the distribution $\alpha + \beta x$ and $\mbox{E}(y|x)$, which is</span>
<span id="cb31-455"><a href="#cb31-455" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(\epsilon\mid x)$ decreases with higher values of $x$.</span>
<span id="cb31-456"><a href="#cb31-456" aria-hidden="true" tabindex="-1"></a>This situation is illustrated, using simulated data on</span>
<span id="cb31-457"><a href="#cb31-457" aria-hidden="true" tabindex="-1"></a>@fig-simulbias. The plain line is defined by $\alpha + \beta x$. The dotted</span>
<span id="cb31-458"><a href="#cb31-458" aria-hidden="true" tabindex="-1"></a>line is the regression line for this sample. Its slope is slightly</span>
<span id="cb31-459"><a href="#cb31-459" aria-hidden="true" tabindex="-1"></a>lower than $\beta$, which illustrates the fact that the OLS estimator</span>
<span id="cb31-460"><a href="#cb31-460" aria-hidden="true" tabindex="-1"></a>of the slope is downward biased (if $\beta &gt; 0$, which is the case</span>
<span id="cb31-461"><a href="#cb31-461" aria-hidden="true" tabindex="-1"></a>here). The dashed line depicts $\mbox{E}(y\mid x, y &gt; 0)$. </span>
<span id="cb31-462"><a href="#cb31-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-463"><a href="#cb31-463" aria-hidden="true" tabindex="-1"></a>For large values of $x$, it is almost the same as the black line, which indicates that in this range of values of $x$,</span>
<span id="cb31-464"><a href="#cb31-464" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y\mid x, y &gt; 0)$ is almost equal to $\alpha + \beta x$, which</span>
<span id="cb31-465"><a href="#cb31-465" aria-hidden="true" tabindex="-1"></a>means than the correlation between $x$ and $\epsilon$ almost</span>
<span id="cb31-466"><a href="#cb31-466" aria-hidden="true" tabindex="-1"></a>vanishes. Conversely, for low values of $x$, the gap between</span>
<span id="cb31-467"><a href="#cb31-467" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y\mid x, y &gt; 0)$ and $\alpha + \beta x$</span>
<span id="cb31-468"><a href="#cb31-468" aria-hidden="true" tabindex="-1"></a>increases. This gap is $\mbox{E}(\epsilon\mid x, y &gt; 0)$, it is</span>
<span id="cb31-469"><a href="#cb31-469" aria-hidden="true" tabindex="-1"></a>positive and is particularly high for very low values of $x$. As</span>
<span id="cb31-470"><a href="#cb31-470" aria-hidden="true" tabindex="-1"></a>$x\rightarrow -\infty$, $\mbox{E}(y\mid x, y &gt; 0)\rightarrow 0$</span>
<span id="cb31-471"><a href="#cb31-471" aria-hidden="true" tabindex="-1"></a>and therefore $\mbox{E}(\epsilon\mid x, y &gt; 0)\rightarrow -(\alpha + \beta x)$.</span>
<span id="cb31-472"><a href="#cb31-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-473"><a href="#cb31-473" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-474"><a href="#cb31-474" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simulbias</span></span>
<span id="cb31-475"><a href="#cb31-475" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-476"><a href="#cb31-476" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "OLS bias in a truncated sample"</span></span>
<span id="cb31-477"><a href="#cb31-477" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"tidyverse"</span>)</span>
<span id="cb31-478"><a href="#cb31-478" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb31-479"><a href="#cb31-479" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb31-480"><a href="#cb31-480" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb31-481"><a href="#cb31-481" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb31-482"><a href="#cb31-482" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fl">1E03</span></span>
<span id="cb31-483"><a href="#cb31-483" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(R, <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb31-484"><a href="#cb31-484" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(R, <span class="dv">0</span>, sigma)</span>
<span id="cb31-485"><a href="#cb31-485" aria-hidden="true" tabindex="-1"></a>ys <span class="ot">&lt;-</span> alpha <span class="sc">+</span> beta <span class="sc">*</span> x <span class="sc">+</span> eps</span>
<span id="cb31-486"><a href="#cb31-486" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">pmax</span>(ys, <span class="dv">0</span>)</span>
<span id="cb31-487"><a href="#cb31-487" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">ys =</span> ys, <span class="at">y =</span> y, <span class="at">x =</span> x)</span>
<span id="cb31-488"><a href="#cb31-488" aria-hidden="true" tabindex="-1"></a>Eytrunc <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb31-489"><a href="#cb31-489" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> (alpha <span class="sc">+</span> beta <span class="sc">*</span> x) <span class="sc">/</span> sigma</span>
<span id="cb31-490"><a href="#cb31-490" aria-hidden="true" tabindex="-1"></a>    (alpha <span class="sc">+</span> beta  <span class="sc">*</span> x) <span class="sc">+</span> sigma <span class="sc">*</span> <span class="fu">dnorm</span>(z) <span class="sc">/</span> <span class="fu">pnorm</span>(z)</span>
<span id="cb31-491"><a href="#cb31-491" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-492"><a href="#cb31-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-493"><a href="#cb31-493" aria-hidden="true" tabindex="-1"></a>Eycens <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb31-494"><a href="#cb31-494" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> (alpha <span class="sc">+</span> beta <span class="sc">*</span> x) <span class="sc">/</span> sigma</span>
<span id="cb31-495"><a href="#cb31-495" aria-hidden="true" tabindex="-1"></a>    (alpha <span class="sc">+</span> beta <span class="sc">*</span> x) <span class="sc">*</span> <span class="fu">pnorm</span>(z) <span class="sc">+</span> sigma <span class="sc">*</span> <span class="fu">dnorm</span>(z)</span>
<span id="cb31-496"><a href="#cb31-496" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-497"><a href="#cb31-497" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> <span class="fu">filter</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb31-498"><a href="#cb31-498" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) x <span class="sc">+</span> <span class="dv">1</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"true model"</span>)) <span class="sc">+</span> </span>
<span id="cb31-499"><a href="#cb31-499" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"ols regression"</span>), <span class="at">color=</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb31-500"><a href="#cb31-500" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> Eytrunc, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"conditional expectation"</span>)) <span class="sc">+</span></span>
<span id="cb31-501"><a href="#cb31-501" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_linetype_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb31-502"><a href="#cb31-502" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-503"><a href="#cb31-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-504"><a href="#cb31-504" aria-hidden="true" tabindex="-1"></a>By now, we have considered a truncated sample, which is a sample</span>
<span id="cb31-505"><a href="#cb31-505" aria-hidden="true" tabindex="-1"></a>containing only observed values of $y$. Consider now that the underlying variable is: $y^*\mid x\sim \mathcal{N}(\mu, \sigma)$ with the following rule of observation:</span>
<span id="cb31-506"><a href="#cb31-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-507"><a href="#cb31-507" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{equation} --&gt;</span></span>
<span id="cb31-508"><a href="#cb31-508" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left\{ --&gt;</span></span>
<span id="cb31-509"><a href="#cb31-509" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rclccc} --&gt;</span></span>
<span id="cb31-510"><a href="#cb31-510" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{y}&amp;=&amp;a &amp;\mbox{ if }&amp; y &lt; a\\ --&gt;</span></span>
<span id="cb31-511"><a href="#cb31-511" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{y}&amp;=&amp;y  &amp;\mbox{ if }&amp; a \leq y \geq b\\ --&gt;</span></span>
<span id="cb31-512"><a href="#cb31-512" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{y}&amp;=&amp;b &amp;\mbox{ if }&amp; y &gt; b\\ --&gt;</span></span>
<span id="cb31-513"><a href="#cb31-513" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-514"><a href="#cb31-514" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right. --&gt;</span></span>
<span id="cb31-515"><a href="#cb31-515" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{equation} --&gt;</span></span>
<span id="cb31-516"><a href="#cb31-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-517"><a href="#cb31-517" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- or, for the most common case where $y$ is zero-left truncated: --&gt;</span></span>
<span id="cb31-518"><a href="#cb31-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-519"><a href="#cb31-519" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb31-520"><a href="#cb31-520" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-521"><a href="#cb31-521" aria-hidden="true" tabindex="-1"></a>\begin{array}{rclccc}</span>
<span id="cb31-522"><a href="#cb31-522" aria-hidden="true" tabindex="-1"></a>y&amp;=&amp;0 &amp;\mbox{ if }&amp; y^* &lt; 0<span class="sc">\\</span></span>
<span id="cb31-523"><a href="#cb31-523" aria-hidden="true" tabindex="-1"></a>y&amp;=&amp;y^*  &amp;\mbox{ if }&amp; y^* \geq 0<span class="sc">\\</span></span>
<span id="cb31-524"><a href="#cb31-524" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-525"><a href="#cb31-525" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-526"><a href="#cb31-526" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb31-527"><a href="#cb31-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-528"><a href="#cb31-528" aria-hidden="true" tabindex="-1"></a>The observed response $y$ is therefore either $y^*$ if positive, or 0 if $y^*\leq 0$.</span>
<span id="cb31-529"><a href="#cb31-529" aria-hidden="true" tabindex="-1"></a>In this case, the conditional expected value of $y$ can be</span>
<span id="cb31-530"><a href="#cb31-530" aria-hidden="true" tabindex="-1"></a>computed as the weighted average of the expected value given that $y$</span>
<span id="cb31-531"><a href="#cb31-531" aria-hidden="true" tabindex="-1"></a>is greater or lower than 0, the first one being the expected value of</span>
<span id="cb31-532"><a href="#cb31-532" aria-hidden="true" tabindex="-1"></a>$y$ left-truncated at 0 and the second one being 0. With $\mu_n = \alpha + \beta x_n$:</span>
<span id="cb31-533"><a href="#cb31-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-534"><a href="#cb31-534" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-535"><a href="#cb31-535" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-536"><a href="#cb31-536" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y\mid x_n) &amp;=&amp; \left<span class="co">[</span><span class="ot">1 - \Phi\left(\frac{\mu_n}{\sigma}\right)\right</span><span class="co">]</span> \times 0 + \Phi\left(\frac{\mu_n}{\sigma}\right) \times \mbox{E}(y\mid x, y &gt; 0) <span class="sc">\\</span></span>
<span id="cb31-537"><a href="#cb31-537" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; </span>
<span id="cb31-538"><a href="#cb31-538" aria-hidden="true" tabindex="-1"></a>\mu_n \Phi\left(\frac{\mu_n}{\sigma}\right) + </span>
<span id="cb31-539"><a href="#cb31-539" aria-hidden="true" tabindex="-1"></a>\sigma \phi\left(\frac{\mu_n}{\sigma}\right)</span>
<span id="cb31-540"><a href="#cb31-540" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-541"><a href="#cb31-541" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-542"><a href="#cb31-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-543"><a href="#cb31-543" aria-hidden="true" tabindex="-1"></a>As for the previous case, the conditional expected value of</span>
<span id="cb31-544"><a href="#cb31-544" aria-hidden="true" tabindex="-1"></a>$y$ is not $\mu_n$, which implies that the OLS estimator</span>
<span id="cb31-545"><a href="#cb31-545" aria-hidden="true" tabindex="-1"></a>is biased and inconsistent.\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{bias!truncated response}</span>
<span id="cb31-546"><a href="#cb31-546" aria-hidden="true" tabindex="-1"></a>Least squares estimation is illustrated, using simulated data, on</span>
<span id="cb31-547"><a href="#cb31-547" aria-hidden="true" tabindex="-1"></a>@fig-simulbiascens. The downward bias of the slope seems more severe than for the</span>
<span id="cb31-548"><a href="#cb31-548" aria-hidden="true" tabindex="-1"></a>truncated sample because there are much more observations for very low</span>
<span id="cb31-549"><a href="#cb31-549" aria-hidden="true" tabindex="-1"></a>values of $x$, i.e., in the range of the values of $x$ where the</span>
<span id="cb31-550"><a href="#cb31-550" aria-hidden="true" tabindex="-1"></a>correlation between $x$ and $\epsilon$ is severe.</span>
<span id="cb31-551"><a href="#cb31-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-552"><a href="#cb31-552" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-553"><a href="#cb31-553" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simulbiascens</span></span>
<span id="cb31-554"><a href="#cb31-554" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-555"><a href="#cb31-555" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "OLS bias in a censored sample"</span></span>
<span id="cb31-556"><a href="#cb31-556" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, y)) <span class="sc">+</span> <span class="fu">geom_jitter</span>(<span class="at">size =</span> <span class="fl">0.1</span>, <span class="at">width =</span> <span class="dv">0</span>, <span class="at">height =</span> .<span class="dv">02</span>) <span class="sc">+</span></span>
<span id="cb31-557"><a href="#cb31-557" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) x <span class="sc">+</span> <span class="dv">1</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"true model"</span>)) <span class="sc">+</span> </span>
<span id="cb31-558"><a href="#cb31-558" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"lm regression"</span>), <span class="at">color=</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb31-559"><a href="#cb31-559" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> Eytrunc, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"conditional expectation"</span>)) <span class="sc">+</span></span>
<span id="cb31-560"><a href="#cb31-560" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_linetype_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb31-561"><a href="#cb31-561" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-562"><a href="#cb31-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-563"><a href="#cb31-563" aria-hidden="true" tabindex="-1"></a>The asymptotic bias of the OLS estimator has been computed by @GOLD:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Goldberger} for a truncated sample and by</span>
<span id="cb31-564"><a href="#cb31-564" aria-hidden="true" tabindex="-1"></a>@GREE:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Greene} for a censored sample, with the hypothesis that $y$ and $x$ follow a jointly normal distribution. In both cases, we have, denoting $\hat{\beta}$ the OLS estimator: $\mbox{plim}\;  \hat{\beta} = \theta \beta$, with $0 &lt; \theta &lt; 1$. Therefore, the bias of the OLS estimator is an attenuation bias, which means that the OLS estimator converges in absolute value to a value lower than the true parameter. Moreover, for the censored sample case: </span>
<span id="cb31-565"><a href="#cb31-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-566"><a href="#cb31-566" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-567"><a href="#cb31-567" aria-hidden="true" tabindex="-1"></a>\mbox{plim}\;  \hat{\beta} = \Phi(\mu_y / \sigma) \beta</span>
<span id="cb31-568"><a href="#cb31-568" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bias_ols_censored_sample}</span>
<span id="cb31-569"><a href="#cb31-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-570"><a href="#cb31-570" aria-hidden="true" tabindex="-1"></a>Therefore, in this case, $\theta$ is the probability of observing a positive value of $y$, which can be consistently estimated by the share of positive observations in the sample.</span>
<span id="cb31-571"><a href="#cb31-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-572"><a href="#cb31-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-573"><a href="#cb31-573" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Bias of the OLS estimator --&gt;</span></span>
<span id="cb31-574"><a href="#cb31-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-575"><a href="#cb31-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-576"><a href="#cb31-576" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- We have seen in the previous section that OLS estimation, either with --&gt;</span></span>
<span id="cb31-577"><a href="#cb31-577" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- a truncated or censored sample leads to a biased estimator. In this --&gt;</span></span>
<span id="cb31-578"><a href="#cb31-578" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- section, we'll present the asymptotic bias, using the hypothesis that --&gt;</span></span>
<span id="cb31-579"><a href="#cb31-579" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $x$ is normally distributed^[The bias of the OLS estimator were first --&gt;</span></span>
<span id="cb31-580"><a href="#cb31-580" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- computed by @GOLD:81 for the truncated sample and by --&gt;</span></span>
<span id="cb31-581"><a href="#cb31-581" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- @GREE:81 for the censored sample.]. For sake of simplicity, --&gt;</span></span>
<span id="cb31-582"><a href="#cb31-582" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- we'll consider the simple linear regression model, but the analysis --&gt;</span></span>
<span id="cb31-583"><a href="#cb31-583" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- can be easily extended to the multiple linear regression model. --&gt;</span></span>
<span id="cb31-584"><a href="#cb31-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-585"><a href="#cb31-585" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Estimating the model by OLS on the untruncated sample, we obtain: --&gt;</span></span>
<span id="cb31-586"><a href="#cb31-586" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\hat{\beta}=\frac{\hat{\sigma}_{xy}}{\hat{\sigma_{x}^2}}$ which --&gt;</span></span>
<span id="cb31-587"><a href="#cb31-587" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- converges to the "true" value, which is  --&gt;</span></span>
<span id="cb31-588"><a href="#cb31-588" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\beta=\frac{\sigma_{xy}}{\sigma_{x}^2}=\rho\frac{\sigma_y}{\sigma_x}$. The --&gt;</span></span>
<span id="cb31-589"><a href="#cb31-589" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- demonstration consists on computing the probability limit of the OLS --&gt;</span></span>
<span id="cb31-590"><a href="#cb31-590" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- estimator for the truncated and for the censored sample and to express --&gt;</span></span>
<span id="cb31-591"><a href="#cb31-591" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- the resulting value, $\beta^*=\frac{\sigma^*_{xy}}{\sigma_x^{*2}}$ for --&gt;</span></span>
<span id="cb31-592"><a href="#cb31-592" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- the truncated sample and --&gt;</span></span>
<span id="cb31-593"><a href="#cb31-593" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\tilde{\beta}=\frac{\tilde{\sigma_{xy</span><span class="re">}}}</span><span class="co">{\sigma_x^2}$ for the --&gt;</span></span>
<span id="cb31-594"><a href="#cb31-594" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- censored sample as a function of $\beta$. --&gt;</span></span>
<span id="cb31-595"><a href="#cb31-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-596"><a href="#cb31-596" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Suppose that $y$ and $x$ are drawn from a bivariate normal --&gt;</span></span>
<span id="cb31-597"><a href="#cb31-597" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- distribution with a coefficient of correlation equal to $\rho$. --&gt;</span></span>
<span id="cb31-598"><a href="#cb31-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-599"><a href="#cb31-599" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-600"><a href="#cb31-600" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left( \begin{array}{c} x \\ y \end{array} \right) \sim --&gt;</span></span>
<span id="cb31-601"><a href="#cb31-601" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- N \left( \left( \begin{array}{c} \mu_x \\ \mu_y \end{array} \right) , --&gt;</span></span>
<span id="cb31-602"><a href="#cb31-602" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left(  \begin{array}{cc} \sigma_x ^ 2 &amp; \rho \sigma_x \sigma_y \\  --&gt;</span></span>
<span id="cb31-603"><a href="#cb31-603" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                           \rho \sigma_x \sigma_y &amp; \sigma_y ^ 2 --&gt;</span></span>
<span id="cb31-604"><a href="#cb31-604" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                          \end{array} \right) --&gt;</span></span>
<span id="cb31-605"><a href="#cb31-605" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right) --&gt;</span></span>
<span id="cb31-606"><a href="#cb31-606" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-607"><a href="#cb31-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-608"><a href="#cb31-608" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Using well-known results about the bivariate normal distribution, the --&gt;</span></span>
<span id="cb31-609"><a href="#cb31-609" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- first two moments of the conditional distribution of $x$ are: --&gt;</span></span>
<span id="cb31-610"><a href="#cb31-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-611"><a href="#cb31-611" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-612"><a href="#cb31-612" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(x\mid y) = \mu_x + \rho \frac{\sigma_x}{\sigma_y}(y - \mu_y) --&gt;</span></span>
<span id="cb31-613"><a href="#cb31-613" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-614"><a href="#cb31-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-615"><a href="#cb31-615" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-616"><a href="#cb31-616" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(x\mid y) = (1 - \rho ^ 2)\sigma_x ^ 2 --&gt;</span></span>
<span id="cb31-617"><a href="#cb31-617" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-618"><a href="#cb31-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-619"><a href="#cb31-619" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The unconditional expectation of $x$ is obtained as --&gt;</span></span>
<span id="cb31-620"><a href="#cb31-620" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\mbox{E}_y\left[\mbox{E}(x\mid y)\right]=\mu_x$ and the unconditional --&gt;</span></span>
<span id="cb31-621"><a href="#cb31-621" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- variance by using the variance decomposition formula: --&gt;</span></span>
<span id="cb31-622"><a href="#cb31-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-623"><a href="#cb31-623" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-624"><a href="#cb31-624" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{V}(x) = \mbox{V}_y\left[\mbox{E}(x\mid y)\right] + \mbox{E}_y\left[\mbox{V}(x\mid y)\right]=\sigma_x^2 --&gt;</span></span>
<span id="cb31-625"><a href="#cb31-625" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-626"><a href="#cb31-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-627"><a href="#cb31-627" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Now consider that $y$ is truncated. Denote: --&gt;</span></span>
<span id="cb31-628"><a href="#cb31-628" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\sigma_y^{*2}=\theta \sigma_y ^ 2$. $\sigma_y^{*2}$ is the variance --&gt;</span></span>
<span id="cb31-629"><a href="#cb31-629" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- of $y$ in the observable range. It is necessary lower than --&gt;</span></span>
<span id="cb31-630"><a href="#cb31-630" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\sigma_y^2$, so that $0\leq \theta \leq 1$. --&gt;</span></span>
<span id="cb31-631"><a href="#cb31-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-632"><a href="#cb31-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-633"><a href="#cb31-633" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The conditional distribution of $x$ is unchanged, but the marginal --&gt;</span></span>
<span id="cb31-634"><a href="#cb31-634" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- distribution of $y$ is. Therefore, to compute the unconditional --&gt;</span></span>
<span id="cb31-635"><a href="#cb31-635" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- moments of $x$, the expectations are computed using the truncated --&gt;</span></span>
<span id="cb31-636"><a href="#cb31-636" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- density function of $y$ and we'll denote $\mbox{E}_y^*$ and --&gt;</span></span>
<span id="cb31-637"><a href="#cb31-637" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\mbox{V}_y^*$ the expected value and the variance operators that --&gt;</span></span>
<span id="cb31-638"><a href="#cb31-638" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- use this density function. Denoting $\mu_y^*$ and $\sigma_y^{2*}$ the --&gt;</span></span>
<span id="cb31-639"><a href="#cb31-639" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- mean and variance of $y$ in the observed range, we get: --&gt;</span></span>
<span id="cb31-640"><a href="#cb31-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-641"><a href="#cb31-641" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-642"><a href="#cb31-642" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_x ^ * = E^*_y\left(\mbox{E}(x\mid y\right) = \mu_x + \rho --&gt;</span></span>
<span id="cb31-643"><a href="#cb31-643" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\sigma_x}{\sigma_y}(\mu_y ^ * - \mu_y) --&gt;</span></span>
<span id="cb31-644"><a href="#cb31-644" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-645"><a href="#cb31-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-646"><a href="#cb31-646" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-647"><a href="#cb31-647" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-648"><a href="#cb31-648" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_x^{*2} &amp;=&amp;  --&gt;</span></span>
<span id="cb31-649"><a href="#cb31-649" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- V^*_y\left(\mbox{E}(x\mid y\right) + E^*_y\left(\mbox{V}(x\mid --&gt;</span></span>
<span id="cb31-650"><a href="#cb31-650" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- y\right)\\ --&gt;</span></span>
<span id="cb31-651"><a href="#cb31-651" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; --&gt;</span></span>
<span id="cb31-652"><a href="#cb31-652" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \rho ^ 2 \frac{\sigma_x ^ 2}{\sigma_y ^ 2} \sigma_y ^ {*2} + (1 - \rho --&gt;</span></span>
<span id="cb31-653"><a href="#cb31-653" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ^ 2) \sigma_x ^ 2 \\ --&gt;</span></span>
<span id="cb31-654"><a href="#cb31-654" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp;  --&gt;</span></span>
<span id="cb31-655"><a href="#cb31-655" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_x ^ 2 \left(1 - \rho ^ 2 (1 - \theta)\right) --&gt;</span></span>
<span id="cb31-656"><a href="#cb31-656" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-657"><a href="#cb31-657" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-658"><a href="#cb31-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-659"><a href="#cb31-659" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- with $\theta=\frac{\sigma^{*2}_y}{\sigma^2_y}$. --&gt;</span></span>
<span id="cb31-660"><a href="#cb31-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-661"><a href="#cb31-661" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Finally, to compute the covariance, we use the fact that the --&gt;</span></span>
<span id="cb31-662"><a href="#cb31-662" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- covariance between $x$ and $y$ equals the covariance between --&gt;</span></span>
<span id="cb31-663"><a href="#cb31-663" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\mbox{E}(x\mid y)$ and $y$: --&gt;</span></span>
<span id="cb31-664"><a href="#cb31-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-665"><a href="#cb31-665" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-666"><a href="#cb31-666" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-667"><a href="#cb31-667" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_{xy} ^ * &amp;=&amp;  \mbox{cov} ^ * \left(\mbox{E}(x\mid y), y\right) \\ --&gt;</span></span>
<span id="cb31-668"><a href="#cb31-668" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; \rho \frac{\sigma_x}{\sigma_y} \sigma_y ^{*2} \\ --&gt;</span></span>
<span id="cb31-669"><a href="#cb31-669" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; \rho \theta\sigma_x\sigma_y --&gt;</span></span>
<span id="cb31-670"><a href="#cb31-670" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-671"><a href="#cb31-671" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-672"><a href="#cb31-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-673"><a href="#cb31-673" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The OLS estimator on a truncated sample $\beta^*$ is the ratio of the --&gt;</span></span>
<span id="cb31-674"><a href="#cb31-674" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- population covariance and variance of $x$ on the observable range. --&gt;</span></span>
<span id="cb31-675"><a href="#cb31-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-676"><a href="#cb31-676" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-677"><a href="#cb31-677" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \beta ^ * = \frac{\sigma_{xy} ^ *}{\sigma_{x} ^ {*2}} = \beta --&gt;</span></span>
<span id="cb31-678"><a href="#cb31-678" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\theta}{1 - \rho ^ 2(1 - \theta)} = \lambda \beta --&gt;</span></span>
<span id="cb31-679"><a href="#cb31-679" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-680"><a href="#cb31-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-681"><a href="#cb31-681" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- with $\lambda = \frac{\theta}{1 - \rho ^ 2(1 - \theta)} = --&gt;</span></span>
<span id="cb31-682"><a href="#cb31-682" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \frac{\theta}{\theta + (1-\theta)(1-\rho^2)}$. As $\rho$ and $\theta$ --&gt;</span></span>
<span id="cb31-683"><a href="#cb31-683" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- are in the $[0,1]$ interval, so is $\lambda$. The probability limit of --&gt;</span></span>
<span id="cb31-684"><a href="#cb31-684" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- the least squares estimator is therefore proportional to the real --&gt;</span></span>
<span id="cb31-685"><a href="#cb31-685" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- value $\beta$. Moreover, this result applies to the multiple linear --&gt;</span></span>
<span id="cb31-686"><a href="#cb31-686" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- model, for which the probability limits of the vector of estimated --&gt;</span></span>
<span id="cb31-687"><a href="#cb31-687" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- slopes are proportional to the vector $\beta$. We are therefore in a --&gt;</span></span>
<span id="cb31-688"><a href="#cb31-688" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- situation of an attenuation bias, which means that the absolute value --&gt;</span></span>
<span id="cb31-689"><a href="#cb31-689" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- of all the estimated slopes are proportionally lower compared to the --&gt;</span></span>
<span id="cb31-690"><a href="#cb31-690" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- true values.  --&gt;</span></span>
<span id="cb31-691"><a href="#cb31-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-692"><a href="#cb31-692" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- For the intercept, we get: --&gt;</span></span>
<span id="cb31-693"><a href="#cb31-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-694"><a href="#cb31-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-695"><a href="#cb31-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-696"><a href="#cb31-696" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-697"><a href="#cb31-697" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-698"><a href="#cb31-698" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \alpha ^ * - \alpha &amp;=&amp; (\mu_y ^ * - \mu_y) - \beta \lambda (\mu_x ^ * - --&gt;</span></span>
<span id="cb31-699"><a href="#cb31-699" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_x) + \beta (1 - \lambda) \mu_x \\ --&gt;</span></span>
<span id="cb31-700"><a href="#cb31-700" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; (\mu_y ^ * - \mu_y)(1 - \lambda \rho ^ 2) + --&gt;</span></span>
<span id="cb31-701"><a href="#cb31-701" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- (1 - \lambda) \rho \frac{\sigma_y}{\sigma_x} \mu_x --&gt;</span></span>
<span id="cb31-702"><a href="#cb31-702" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-703"><a href="#cb31-703" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-704"><a href="#cb31-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-705"><a href="#cb31-705" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- For the special case of a zero-left truncated response, denoting --&gt;</span></span>
<span id="cb31-706"><a href="#cb31-706" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\nu_y = \frac{\mu_y}{\sigma_y}$, we have $\sigma_y^{*2} = --&gt;</span></span>
<span id="cb31-707"><a href="#cb31-707" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_y^2 \left[1 + r'(\nu_y)\right]$, so that $\theta = \left[1 + --&gt;</span></span>
<span id="cb31-708"><a href="#cb31-708" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r'(\nu_y)\right]$ and: --&gt;</span></span>
<span id="cb31-709"><a href="#cb31-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-710"><a href="#cb31-710" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-711"><a href="#cb31-711" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \lambda = \frac{1 + r'\left(\frac{\mu_y} --&gt;</span></span>
<span id="cb31-712"><a href="#cb31-712" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- {\sigma_y}\right)}{1 + \rho ^ --&gt;</span></span>
<span id="cb31-713"><a href="#cb31-713" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 2 r'(\nu_y)} --&gt;</span></span>
<span id="cb31-714"><a href="#cb31-714" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-715"><a href="#cb31-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-716"><a href="#cb31-716" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-717"><a href="#cb31-717" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left\{ --&gt;</span></span>
<span id="cb31-718"><a href="#cb31-718" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-719"><a href="#cb31-719" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_y^* &amp;=&amp; \mu_y + \sigma_y r(\nu_y) \\ --&gt;</span></span>
<span id="cb31-720"><a href="#cb31-720" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_y^{*2} &amp;=&amp; \sigma_y^2 \left[1 + r'(\nu_y)\right] --&gt;</span></span>
<span id="cb31-721"><a href="#cb31-721" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-722"><a href="#cb31-722" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right. --&gt;</span></span>
<span id="cb31-723"><a href="#cb31-723" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-724"><a href="#cb31-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-725"><a href="#cb31-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-726"><a href="#cb31-726" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-727"><a href="#cb31-727" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_x^* = \mu_x + \rho \sigma_x r(\nu_y) --&gt;</span></span>
<span id="cb31-728"><a href="#cb31-728" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-729"><a href="#cb31-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-730"><a href="#cb31-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-731"><a href="#cb31-731" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-732"><a href="#cb31-732" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \alpha ^ * - \alpha = (1 - \lambda \rho ^ 2) \sigma_y --&gt;</span></span>
<span id="cb31-733"><a href="#cb31-733" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r(\nu_y) --&gt;</span></span>
<span id="cb31-734"><a href="#cb31-734" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- + --&gt;</span></span>
<span id="cb31-735"><a href="#cb31-735" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- (1 - \lambda) \rho \frac{\sigma_y}{\sigma_x} \mu_x --&gt;</span></span>
<span id="cb31-736"><a href="#cb31-736" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-737"><a href="#cb31-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-738"><a href="#cb31-738" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- For the zero-left censored sample case, we compute the uncentered --&gt;</span></span>
<span id="cb31-739"><a href="#cb31-739" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- moments as a weight average of $0$ (with probability $1 - --&gt;</span></span>
<span id="cb31-740"><a href="#cb31-740" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(\nu_y)$) and of observable values of $y$ (with probability --&gt;</span></span>
<span id="cb31-741"><a href="#cb31-741" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $\Phi(\nu_y)$), which means that $\mbox{E}(\tilde{y}) = \Phi(\nu_y) --&gt;</span></span>
<span id="cb31-742"><a href="#cb31-742" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_y ^ *$ and that $\mbox{E}(x\tilde{y})=\Phi(\nu_y)(\sigma_{xy}^* + --&gt;</span></span>
<span id="cb31-743"><a href="#cb31-743" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_x^*\mu_y^*)$. The covariance between $x$ and $\tilde{y}$ is then: --&gt;</span></span>
<span id="cb31-744"><a href="#cb31-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-745"><a href="#cb31-745" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-746"><a href="#cb31-746" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\sigma}_y ^ {2} = \mbox{E}(\tilde{y} ^ 2)  - \tilde{\mu}_y^{2} =  --&gt;</span></span>
<span id="cb31-747"><a href="#cb31-747" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(\nu_y) \mbox{E}(y ^ 2\mid y &gt; 0) - --&gt;</span></span>
<span id="cb31-748"><a href="#cb31-748" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\mu}_y ^ {2} =  --&gt;</span></span>
<span id="cb31-749"><a href="#cb31-749" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(\nu_y) \left(\sigma_y ^{*2} + \mu_y ^ {*2} \right) - \tilde{\mu}_y ^ {2} --&gt;</span></span>
<span id="cb31-750"><a href="#cb31-750" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-751"><a href="#cb31-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-752"><a href="#cb31-752" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-753"><a href="#cb31-753" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\sigma}_y ^ {2} = \sigma_y ^  2 --&gt;</span></span>
<span id="cb31-754"><a href="#cb31-754" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(\nu_y)  --&gt;</span></span>
<span id="cb31-755"><a href="#cb31-755" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left[1 +  --&gt;</span></span>
<span id="cb31-756"><a href="#cb31-756" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \left( --&gt;</span></span>
<span id="cb31-757"><a href="#cb31-757" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi(\nu_y) --&gt;</span></span>
<span id="cb31-758"><a href="#cb31-758" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r'(\nu_y) --&gt;</span></span>
<span id="cb31-759"><a href="#cb31-759" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - \eta__y\right) - --&gt;</span></span>
<span id="cb31-760"><a href="#cb31-760" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- r'(\nu_y) --&gt;</span></span>
<span id="cb31-761"><a href="#cb31-761" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \right] --&gt;</span></span>
<span id="cb31-762"><a href="#cb31-762" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-763"><a href="#cb31-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-764"><a href="#cb31-764" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-765"><a href="#cb31-765" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{rcl} --&gt;</span></span>
<span id="cb31-766"><a href="#cb31-766" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\sigma}_{xy} &amp;=&amp; \mbox{E}(x\tilde{y}) - \mu_x\tilde{\mu}_y \\ --&gt;</span></span>
<span id="cb31-767"><a href="#cb31-767" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; \Phi(\nu_y) \left(\sigma_{xy} ^ * + \mu_x ^ * \mu_y ^ * \right) - --&gt;</span></span>
<span id="cb31-768"><a href="#cb31-768" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mu_x\tilde{\mu}_y \\ --&gt;</span></span>
<span id="cb31-769"><a href="#cb31-769" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &amp;=&amp; \Phi(\nu_y) \rho \sigma_x \sigma_y --&gt;</span></span>
<span id="cb31-770"><a href="#cb31-770" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb31-771"><a href="#cb31-771" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-772"><a href="#cb31-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-773"><a href="#cb31-773" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Dividing this covariance by $\sigma^2_x$, we finally obtain the --&gt;</span></span>
<span id="cb31-774"><a href="#cb31-774" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- probability limit of the OLS estimator for the censored sample: --&gt;</span></span>
<span id="cb31-775"><a href="#cb31-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-776"><a href="#cb31-776" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-777"><a href="#cb31-777" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\beta} = \Phi(\nu_y) \beta --&gt;</span></span>
<span id="cb31-778"><a href="#cb31-778" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-779"><a href="#cb31-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-780"><a href="#cb31-780" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Once again, the probability limit of the OLS estimator is proportional --&gt;</span></span>
<span id="cb31-781"><a href="#cb31-781" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- to $\beta$. The remarkable result for the censored sample is that the --&gt;</span></span>
<span id="cb31-782"><a href="#cb31-782" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- coefficient of proportionality is just the probability of drawing a --&gt;</span></span>
<span id="cb31-783"><a href="#cb31-783" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- censored observation, which can be consistently estimated by the share --&gt;</span></span>
<span id="cb31-784"><a href="#cb31-784" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- of censored observations in the sample.  --&gt;</span></span>
<span id="cb31-785"><a href="#cb31-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-786"><a href="#cb31-786" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-787"><a href="#cb31-787" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \tilde{\alpha} = \tilde{\mu}_y - \tilde{\beta} \mu_x = \Phi(\nu_y) (\mu_y + --&gt;</span></span>
<span id="cb31-788"><a href="#cb31-788" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma_y r(\nu_y)) - \Phi \beta \mu_x = \Phi(\nu_y)(\alpha + \sigma_y r(\nu_y)) --&gt;</span></span>
<span id="cb31-789"><a href="#cb31-789" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-790"><a href="#cb31-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-791"><a href="#cb31-791" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of the coefficients</span></span>
<span id="cb31-792"><a href="#cb31-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-793"><a href="#cb31-793" aria-hidden="true" tabindex="-1"></a>This section concerns only the case of corner solution and not the case of data censoring (like top-coding). In both cases, the regression function: $\mu_n = \alpha + \beta ^ \top x_n$ returns the mean of the distribution of the untruncated distribution of $y$. In the data censoring case, which is just a problem of missing values of the response, this is the relevant distribution to consider and therefore $\beta_k$ is the marginal effect of covariate $x_k$ that we have to consider. On the contrary, for corner solution models, the relevant distributions that we have to consider is on the one hand the probability of $y &gt;0$ and on the other hand the zero left-truncated distribution of $y$. Therefore, $\mu_n$ is the mean of an untruncated latent variable, $\beta_k$ is the marginal effect of $x_k$ on this latent variable and none of these values are particularly meaningful. </span>
<span id="cb31-794"><a href="#cb31-794" aria-hidden="true" tabindex="-1"></a>For a corner solution model, the effect of a change in $x_k$ is actually twofold:</span>
<span id="cb31-795"><a href="#cb31-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-796"><a href="#cb31-796" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>firstly, it changes the probability that the value of $y$ is positive: $\mbox{P}(y &gt; 0 \mid x)$,</span>
<span id="cb31-797"><a href="#cb31-797" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>secondly, it changes the expected value of $y$ if it is positive: $\mbox{E}(y\mid x, y &gt; 0)$.</span>
<span id="cb31-798"><a href="#cb31-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-799"><a href="#cb31-799" aria-hidden="true" tabindex="-1"></a>The probability that $y$ is positive and the conditional expectation for positive values of $y$ are, denoting as usual $\mu_n = \alpha + \beta ^ \top x_n$:</span>
<span id="cb31-800"><a href="#cb31-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-801"><a href="#cb31-801" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-802"><a href="#cb31-802" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-803"><a href="#cb31-803" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-804"><a href="#cb31-804" aria-hidden="true" tabindex="-1"></a>\mbox{P}(y_n &gt; 0\mid x_n) &amp;=&amp; \Phi\left(\frac{\mu_n}{\sigma}\right)<span class="sc">\\</span></span>
<span id="cb31-805"><a href="#cb31-805" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y_n\mid x_n, y_n &gt; 0) &amp;=&amp; \mu_n + \sigma</span>
<span id="cb31-806"><a href="#cb31-806" aria-hidden="true" tabindex="-1"></a>r\left(\frac{\mu_n}{\sigma}\right)</span>
<span id="cb31-807"><a href="#cb31-807" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-808"><a href="#cb31-808" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-809"><a href="#cb31-809" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-810"><a href="#cb31-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-811"><a href="#cb31-811" aria-hidden="true" tabindex="-1"></a>and the unconditional expectation of $y$ is just the product of these</span>
<span id="cb31-812"><a href="#cb31-812" aria-hidden="true" tabindex="-1"></a>two expressions:</span>
<span id="cb31-813"><a href="#cb31-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-814"><a href="#cb31-814" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-815"><a href="#cb31-815" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y_n\mid x_n) = \mbox{P}(y_n &gt; 0\mid x_n) \times \mbox{E}(y_n\mid x_n, y_n &gt; 0)</span>
<span id="cb31-816"><a href="#cb31-816" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-817"><a href="#cb31-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-818"><a href="#cb31-818" aria-hidden="true" tabindex="-1"></a>Its derivative with respect to $x_k$ gives:</span>
<span id="cb31-819"><a href="#cb31-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-820"><a href="#cb31-820" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-821"><a href="#cb31-821" aria-hidden="true" tabindex="-1"></a>\begin{array}{rclrcl}</span>
<span id="cb31-822"><a href="#cb31-822" aria-hidden="true" tabindex="-1"></a>\frac{\displaystyle\partial \mbox{E}(y_n\mid x_n)}{\displaystyle\partial x_{nk}} &amp;=&amp; </span>
<span id="cb31-823"><a href="#cb31-823" aria-hidden="true" tabindex="-1"></a>\frac{\displaystyle\partial\mbox{P}(y_n &gt; 0\mid x_n)}{\displaystyle\partial x_{nk}} &amp;\times&amp;</span>
<span id="cb31-824"><a href="#cb31-824" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y_n\mid x_n, y_n &gt; 0)<span class="sc">\\</span> </span>
<span id="cb31-825"><a href="#cb31-825" aria-hidden="true" tabindex="-1"></a>&amp;+&amp; \mbox{P}(y_n &gt; 0\mid x_n) &amp;\times&amp; \frac{ \displaystyle\partial \mbox{E}(y_n\mid x_n, y_n &gt;</span>
<span id="cb31-826"><a href="#cb31-826" aria-hidden="true" tabindex="-1"></a>0)}{\displaystyle\partial x_{nk}}</span>
<span id="cb31-827"><a href="#cb31-827" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-828"><a href="#cb31-828" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-829"><a href="#cb31-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-830"><a href="#cb31-830" aria-hidden="true" tabindex="-1"></a>with:</span>
<span id="cb31-831"><a href="#cb31-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-832"><a href="#cb31-832" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-833"><a href="#cb31-833" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-834"><a href="#cb31-834" aria-hidden="true" tabindex="-1"></a>\begin{array}{lcl}</span>
<span id="cb31-835"><a href="#cb31-835" aria-hidden="true" tabindex="-1"></a>\frac{\displaystyle\partial\mbox{P}(y_n &gt; 0\mid</span>
<span id="cb31-836"><a href="#cb31-836" aria-hidden="true" tabindex="-1"></a>x_n)}{\displaystyle\partial x_{nk}} &amp;=&amp; \frac{\beta_k}{\sigma} \phi\left(\frac{\mu_n}{\sigma}\right) <span class="sc">\\</span></span>
<span id="cb31-837"><a href="#cb31-837" aria-hidden="true" tabindex="-1"></a>\frac{\displaystyle\partial \mbox{E}(y_n\mid x_n)}{\displaystyle\partial</span>
<span id="cb31-838"><a href="#cb31-838" aria-hidden="true" tabindex="-1"></a>x_{nk}} &amp;=&amp; \beta_k \left<span class="co">[</span><span class="ot">1 + r'\left(\frac{\mu_n}{\sigma}\right) \right</span><span class="co">]</span></span>
<span id="cb31-839"><a href="#cb31-839" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-840"><a href="#cb31-840" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-841"><a href="#cb31-841" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-842"><a href="#cb31-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-843"><a href="#cb31-843" aria-hidden="true" tabindex="-1"></a>The effect of a change of a covariate is represented in</span>
<span id="cb31-844"><a href="#cb31-844" aria-hidden="true" tabindex="-1"></a>@fig-mfx for the simple covariate case, with $\beta &gt; 0$.</span>
<span id="cb31-845"><a href="#cb31-845" aria-hidden="true" tabindex="-1"></a>When the value of $x$ increases from $x_1$ to $x_2$, the untruncated</span>
<span id="cb31-846"><a href="#cb31-846" aria-hidden="true" tabindex="-1"></a>normal density curve moves to the right, the mode increasing from</span>
<span id="cb31-847"><a href="#cb31-847" aria-hidden="true" tabindex="-1"></a>$\mu_1=\alpha+\beta x_1$ to $\mu_2=\alpha+\beta x_2$. The increase of the probability that $y &gt; 0$</span>
<span id="cb31-848"><a href="#cb31-848" aria-hidden="true" tabindex="-1"></a>is represented by the gray area, as it is the area between the two</span>
<span id="cb31-849"><a href="#cb31-849" aria-hidden="true" tabindex="-1"></a>density curves from 0 to $+\infty$, which reduces to the area between</span>
<span id="cb31-850"><a href="#cb31-850" aria-hidden="true" tabindex="-1"></a>the two curves between $\mu_1+\mu_2$ and $+\infty$.^[The area</span>
<span id="cb31-851"><a href="#cb31-851" aria-hidden="true" tabindex="-1"></a>between 0 and the intersection point $\frac{\mu_1+\mu_2}{2}$ and the</span>
<span id="cb31-852"><a href="#cb31-852" aria-hidden="true" tabindex="-1"></a>one between $\frac{\mu_1+\mu_2}{2}$ and $\mu_1+\mu_2$ are the same</span>
<span id="cb31-853"><a href="#cb31-853" aria-hidden="true" tabindex="-1"></a>with the opposite sign.]</span>
<span id="cb31-854"><a href="#cb31-854" aria-hidden="true" tabindex="-1"></a>This is the first source of change of $\mbox{E}(y\mid x)$ which, for a</span>
<span id="cb31-855"><a href="#cb31-855" aria-hidden="true" tabindex="-1"></a>small variation of $x$ is equal to $\Delta \Phi\left(\frac{\alpha + \beta</span>
<span id="cb31-856"><a href="#cb31-856" aria-hidden="true" tabindex="-1"></a>x}{\sigma}\right) \times \mbox{E}(y\mid x, y &gt; 0)$.</span>
<span id="cb31-857"><a href="#cb31-857" aria-hidden="true" tabindex="-1"></a>The second source of change is the increase of the conditional</span>
<span id="cb31-858"><a href="#cb31-858" aria-hidden="true" tabindex="-1"></a>expectation of $x$, which is multiplied by the probability that $y$ is</span>
<span id="cb31-859"><a href="#cb31-859" aria-hidden="true" tabindex="-1"></a>observed: $\Delta \mbox{E}(y\mid x, y &gt; 0) \times \Phi\left(\frac{\alpha +</span>
<span id="cb31-860"><a href="#cb31-860" aria-hidden="true" tabindex="-1"></a>\beta x}{\sigma}\right)$.</span>
<span id="cb31-861"><a href="#cb31-861" aria-hidden="true" tabindex="-1"></a>The first one can be considered as an increase of $y$ on the **extensive</span>
<span id="cb31-862"><a href="#cb31-862" aria-hidden="true" tabindex="-1"></a>margin**, i.e., due to the fact that for more people, we observe $y &gt;</span>
<span id="cb31-863"><a href="#cb31-863" aria-hidden="true" tabindex="-1"></a>0$. The second one is an increase of $y$ on the **intensive margin**,</span>
<span id="cb31-864"><a href="#cb31-864" aria-hidden="true" tabindex="-1"></a>which means that people for which $y$ was already positive, the</span>
<span id="cb31-865"><a href="#cb31-865" aria-hidden="true" tabindex="-1"></a>value of $y$ increases.^[This decomposition of marginal effects for</span>
<span id="cb31-866"><a href="#cb31-866" aria-hidden="true" tabindex="-1"></a>tobit models was first proposed by @MCDO:MOFF:80\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McDonald}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Moffitt}]</span>
<span id="cb31-867"><a href="#cb31-867" aria-hidden="true" tabindex="-1"></a>The sum of these two components gives the marginal effect of a</span>
<span id="cb31-868"><a href="#cb31-868" aria-hidden="true" tabindex="-1"></a>variation of $x$ on the unconditional expected value of $y$, which is</span>
<span id="cb31-869"><a href="#cb31-869" aria-hidden="true" tabindex="-1"></a>simply:</span>
<span id="cb31-870"><a href="#cb31-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-871"><a href="#cb31-871" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-872"><a href="#cb31-872" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mfx</span></span>
<span id="cb31-873"><a href="#cb31-873" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Effect of a change of $x$"</span></span>
<span id="cb31-874"><a href="#cb31-874" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb31-875"><a href="#cb31-875" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/mfx.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-876"><a href="#cb31-876" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-877"><a href="#cb31-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-878"><a href="#cb31-878" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-879"><a href="#cb31-879" aria-hidden="true" tabindex="-1"></a>\frac{\partial \mbox{E}(y_n\mid x_n)}{\partial x_{nk}} = </span>
<span id="cb31-880"><a href="#cb31-880" aria-hidden="true" tabindex="-1"></a>\beta_k\Phi\left(\frac{\mu_n}{\sigma}\right)</span>
<span id="cb31-881"><a href="#cb31-881" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-882"><a href="#cb31-882" aria-hidden="true" tabindex="-1"></a>Note (@eq-bias_ols_censored_sample) that it is exactly the probability limit of the OLS estimator.</span>
<span id="cb31-883"><a href="#cb31-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-884"><a href="#cb31-884" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methods of estimation {#sec-tobit_estim}</span></span>
<span id="cb31-885"><a href="#cb31-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-886"><a href="#cb31-886" aria-hidden="true" tabindex="-1"></a>Several consistent estimators are available for the truncated and the</span>
<span id="cb31-887"><a href="#cb31-887" aria-hidden="true" tabindex="-1"></a>censored model. We'll start by inefficient estimators (non-linear</span>
<span id="cb31-888"><a href="#cb31-888" aria-hidden="true" tabindex="-1"></a>least squares, probit and two-step estimators). We'll then present</span>
<span id="cb31-889"><a href="#cb31-889" aria-hidden="true" tabindex="-1"></a>the maximum likelihood estimator which is asymptotically efficient if</span>
<span id="cb31-890"><a href="#cb31-890" aria-hidden="true" tabindex="-1"></a>the conditional distribution of $y$ is normal and homoskedastic. We'll</span>
<span id="cb31-891"><a href="#cb31-891" aria-hidden="true" tabindex="-1"></a>finally develop the symmetrically trimmed least squares estimator,</span>
<span id="cb31-892"><a href="#cb31-892" aria-hidden="true" tabindex="-1"></a>which is consistent even if the distribution of $y$ is not normal and</span>
<span id="cb31-893"><a href="#cb31-893" aria-hidden="true" tabindex="-1"></a>heteroskedastic.</span>
<span id="cb31-894"><a href="#cb31-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-895"><a href="#cb31-895" aria-hidden="true" tabindex="-1"></a><span class="fu">### Non-linear least squares</span></span>
<span id="cb31-896"><a href="#cb31-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-897"><a href="#cb31-897" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{non-linear least squares|(}</span>
<span id="cb31-898"><a href="#cb31-898" aria-hidden="true" tabindex="-1"></a>The conditional expected value of $y$:</span>
<span id="cb31-899"><a href="#cb31-899" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y\mid x) = \gamma^\top z + \sigma r\left(\frac{\gamma^\top z}{\sigma}\right)$ is non-linear in $x$. Therefore, the parameters can be consistently</span>
<span id="cb31-900"><a href="#cb31-900" aria-hidden="true" tabindex="-1"></a>estimated using non-linear least squares, by minimizing:</span>
<span id="cb31-901"><a href="#cb31-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-902"><a href="#cb31-902" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-903"><a href="#cb31-903" aria-hidden="true" tabindex="-1"></a>\sum_{n=1} ^ N \left[y_n - \gamma^\top z_n - \sigma r\left(\frac{\gamma^\top</span>
<span id="cb31-904"><a href="#cb31-904" aria-hidden="true" tabindex="-1"></a>z_n}{\sigma}\right)\right] ^ 2</span>
<span id="cb31-905"><a href="#cb31-905" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-906"><a href="#cb31-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-907"><a href="#cb31-907" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{non-linear least squares|(}</span>
<span id="cb31-908"><a href="#cb31-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-909"><a href="#cb31-909" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probit and two-step estimators</span></span>
<span id="cb31-910"><a href="#cb31-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-911"><a href="#cb31-911" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{probit}</span>
<span id="cb31-912"><a href="#cb31-912" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-1!two-step estimator|(}</span>
<span id="cb31-913"><a href="#cb31-913" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!tobit-1|(}</span>
<span id="cb31-914"><a href="#cb31-914" aria-hidden="true" tabindex="-1"></a>The probability that $y$ is positive is $\Phi\left(\frac{\gamma ^ \top</span>
<span id="cb31-915"><a href="#cb31-915" aria-hidden="true" tabindex="-1"></a>z_n}{\sigma}\right)$, therefore, a probit model can be used to estimate the</span>
<span id="cb31-916"><a href="#cb31-916" aria-hidden="true" tabindex="-1"></a>vector of coefficients $\frac{\gamma}{\sigma}$. $\sigma$ is not identified, and each element of </span>
<span id="cb31-917"><a href="#cb31-917" aria-hidden="true" tabindex="-1"></a>$\gamma$ is only estimated up to a $1/\sigma$ factor.</span>
<span id="cb31-918"><a href="#cb31-918" aria-hidden="true" tabindex="-1"></a>To estimate the probit model, we first have to compute a binary</span>
<span id="cb31-919"><a href="#cb31-919" aria-hidden="true" tabindex="-1"></a>response from the observed response which is equal to 1 if $y &gt; 0$ and</span>
<span id="cb31-920"><a href="#cb31-920" aria-hidden="true" tabindex="-1"></a>0 if $y = 0$. We then obtain a vector of estimated coefficients</span>
<span id="cb31-921"><a href="#cb31-921" aria-hidden="true" tabindex="-1"></a>$\hat{\delta}$ which are related to the structural coefficients of the</span>
<span id="cb31-922"><a href="#cb31-922" aria-hidden="true" tabindex="-1"></a>model by the relation $\delta = \frac{\gamma}{\sigma}$. Obviously, the</span>
<span id="cb31-923"><a href="#cb31-923" aria-hidden="true" tabindex="-1"></a>probit estimation can only be performed for a censored sample, and</span>
<span id="cb31-924"><a href="#cb31-924" aria-hidden="true" tabindex="-1"></a>not a truncated sample for which all the values of $y$ are</span>
<span id="cb31-925"><a href="#cb31-925" aria-hidden="true" tabindex="-1"></a>positive.</span>
<span id="cb31-926"><a href="#cb31-926" aria-hidden="true" tabindex="-1"></a>Remember that the expected value of $y$ is: $\mbox{E}(y_n\mid x_n) = \gamma^\top z_n + \sigma r\left(\gamma^\top z_n/\sigma\right)$.</span>
<span id="cb31-927"><a href="#cb31-927" aria-hidden="true" tabindex="-1"></a>If $\gamma/\sigma$ were known and denoting $r_n =</span>
<span id="cb31-928"><a href="#cb31-928" aria-hidden="true" tabindex="-1"></a>r(\gamma^\top z_n/\sigma)$, estimating the equation: $y_n=\gamma ^\top z_n + \sigma r_n + \nu_n$</span>
<span id="cb31-929"><a href="#cb31-929" aria-hidden="true" tabindex="-1"></a>by least squares would lead to consistent estimates of $\gamma$ and</span>
<span id="cb31-930"><a href="#cb31-930" aria-hidden="true" tabindex="-1"></a>$\sigma$ as $\mbox{E}(y_n\mid x_n, r_n) = \gamma^\top x_n + \sigma r_n$</span>
<span id="cb31-931"><a href="#cb31-931" aria-hidden="true" tabindex="-1"></a>or $\mbox{E}(\nu_n\mid x_n, r_n) = 0$. $r_n$ is obviously unknown, as</span>
<span id="cb31-932"><a href="#cb31-932" aria-hidden="true" tabindex="-1"></a>it depends on the parameters we seek to estimate, but it can be</span>
<span id="cb31-933"><a href="#cb31-933" aria-hidden="true" tabindex="-1"></a>consistently estimated, using the probit estimator, by $\hat{r}_n =</span>
<span id="cb31-934"><a href="#cb31-934" aria-hidden="true" tabindex="-1"></a>r\left(\hat{\delta}^\top z_n\right)$. This idea leads to the</span>
<span id="cb31-935"><a href="#cb31-935" aria-hidden="true" tabindex="-1"></a>**two-step estimator** first proposed by @HECK:76\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Heckman}:</span>
<span id="cb31-936"><a href="#cb31-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-937"><a href="#cb31-937" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>first estimate the coefficient of the probit model $\hat{\delta}$</span>
<span id="cb31-938"><a href="#cb31-938" aria-hidden="true" tabindex="-1"></a>  and estimate $r_n$ by $\hat{r}_n = r(\hat{\delta}^\top z_n)$,</span>
<span id="cb31-939"><a href="#cb31-939" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>then regress $y$ on $x$ and $\hat{r}$ and estimate $\hat{\gamma}$ and</span>
<span id="cb31-940"><a href="#cb31-940" aria-hidden="true" tabindex="-1"></a>  $\hat{\sigma}$.</span>
<span id="cb31-941"><a href="#cb31-941" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-942"><a href="#cb31-942" aria-hidden="true" tabindex="-1"></a>Denote $W = (Z, \hat{r}) = (1, X, \hat{r})$ the matrix of covariates for the second</span>
<span id="cb31-943"><a href="#cb31-943" aria-hidden="true" tabindex="-1"></a>  step and $\lambda ^ \top = (\gamma ^ \top, \sigma)$ the associated</span>
<span id="cb31-944"><a href="#cb31-944" aria-hidden="true" tabindex="-1"></a>  vector of parameters. The covariance matrix of the parameters</span>
<span id="cb31-945"><a href="#cb31-945" aria-hidden="true" tabindex="-1"></a>  reported by the OLS estimation is $\hat{\sigma}_\epsilon ^ 2 (W^\top W) ^</span>
<span id="cb31-946"><a href="#cb31-946" aria-hidden="true" tabindex="-1"></a>  {-1}$. It is inconsistent for two reasons:</span>
<span id="cb31-947"><a href="#cb31-947" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-948"><a href="#cb31-948" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the errors of the model are heteroskedastic,</span>
<span id="cb31-949"><a href="#cb31-949" aria-hidden="true" tabindex="-1"></a>  their variance being $\mbox{V}(\epsilon_n) = \sigma ^ 2 (1 +</span>
<span id="cb31-950"><a href="#cb31-950" aria-hidden="true" tabindex="-1"></a>  r'(\gamma^\top z_n / \sigma))$,</span>
<span id="cb31-951"><a href="#cb31-951" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the supplementary covariate $\hat{r}(\delta^ \top z_n)$ differs from the true value of $r(\delta ^ \top z_n)$, which inflates the variance of the estimators.</span>
<span id="cb31-952"><a href="#cb31-952" aria-hidden="true" tabindex="-1"></a>A consistent estimate of the covariance matrix of the two-step</span>
<span id="cb31-953"><a href="#cb31-953" aria-hidden="true" tabindex="-1"></a>estimator is^<span class="co">[</span><span class="ot">See for example @AMEM:84\index[author]{Amemiya}, equation 28, page 13.</span><span class="co">]</span>:</span>
<span id="cb31-954"><a href="#cb31-954" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{covariance matrix!two-step estimator}</span>
<span id="cb31-955"><a href="#cb31-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-956"><a href="#cb31-956" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-957"><a href="#cb31-957" aria-hidden="true" tabindex="-1"></a>\hat{\sigma} ^ 2 (W ^ \top W) ^ {-1} W \left[\Sigma + (I - \Sigma) Z</span>
<span id="cb31-958"><a href="#cb31-958" aria-hidden="true" tabindex="-1"></a>\hat{\mbox{V}}_{\mbox{probit}} (I - \Sigma) Z ^ \top \right] W ^ \top (W ^</span>
<span id="cb31-959"><a href="#cb31-959" aria-hidden="true" tabindex="-1"></a>\top W) ^ {-1}</span>
<span id="cb31-960"><a href="#cb31-960" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-961"><a href="#cb31-961" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-962"><a href="#cb31-962" aria-hidden="true" tabindex="-1"></a>$\Sigma$ is a matrix that takes into account the</span>
<span id="cb31-963"><a href="#cb31-963" aria-hidden="true" tabindex="-1"></a>heteroskedasticity, it is a diagonal matrix that contains either</span>
<span id="cb31-964"><a href="#cb31-964" aria-hidden="true" tabindex="-1"></a>$\hat{\sigma} ^ 2 (1 + r'(\hat{\delta}^\top z_n))$ </span>
<span id="cb31-965"><a href="#cb31-965" aria-hidden="true" tabindex="-1"></a>or, following the argument of @WHIT:80\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{White}, the square of the residual $y_n - \hat{\gamma} ^ \top z_n -  \hat{\sigma} \hat{r}_n$.</span>
<span id="cb31-966"><a href="#cb31-966" aria-hidden="true" tabindex="-1"></a>The second matrix, which uses the covariance matrix of the first stage probit regression, takes into account the fact that $\hat{r}_n$ is introduced in place of $r_n$.</span>
<span id="cb31-967"><a href="#cb31-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-968"><a href="#cb31-968" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-1!two-step estimator|)}</span>
<span id="cb31-969"><a href="#cb31-969" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!tobit-1|)}</span>
<span id="cb31-970"><a href="#cb31-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-971"><a href="#cb31-971" aria-hidden="true" tabindex="-1"></a><span class="fu">###  Maximum Likelihood estimation</span></span>
<span id="cb31-972"><a href="#cb31-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-973"><a href="#cb31-973" aria-hidden="true" tabindex="-1"></a>Without loss of generality, we'll assume that $y=0$ for observations from 1 to</span>
<span id="cb31-974"><a href="#cb31-974" aria-hidden="true" tabindex="-1"></a>$N_o$ and $y&gt;0$ for those from $N_o+1$ to $N$ are not. Estimating</span>
<span id="cb31-975"><a href="#cb31-975" aria-hidden="true" tabindex="-1"></a>the model on the truncated sample, we obtain the likelihood by</span>
<span id="cb31-976"><a href="#cb31-976" aria-hidden="true" tabindex="-1"></a>multiplying the truncated density of $y$ for all the individuals from</span>
<span id="cb31-977"><a href="#cb31-977" aria-hidden="true" tabindex="-1"></a>$N_o+1$ to $N$:</span>
<span id="cb31-978"><a href="#cb31-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-979"><a href="#cb31-979" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-980"><a href="#cb31-980" aria-hidden="true" tabindex="-1"></a>L^T(\gamma, \sigma \mid y, x) = \prod_{n = N_o + 1}^N</span>
<span id="cb31-981"><a href="#cb31-981" aria-hidden="true" tabindex="-1"></a>\frac{1}{\sigma \Phi\left(\frac{\gamma^\top</span>
<span id="cb31-982"><a href="#cb31-982" aria-hidden="true" tabindex="-1"></a>z_n}{\sigma}\right)}\phi\left(\frac{y_n - \gamma^ \top z_n}{\sigma}\right)</span>
<span id="cb31-983"><a href="#cb31-983" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-984"><a href="#cb31-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-985"><a href="#cb31-985" aria-hidden="true" tabindex="-1"></a>or, taking the logarithm:</span>
<span id="cb31-986"><a href="#cb31-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-987"><a href="#cb31-987" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-988"><a href="#cb31-988" aria-hidden="true" tabindex="-1"></a>\ln L^T(\gamma, \sigma\mid y, x) = </span>
<span id="cb31-989"><a href="#cb31-989" aria-hidden="true" tabindex="-1"></a>-\frac{N -N_o}{2}(\ln \sigma^2 + \ln 2\pi) - </span>
<span id="cb31-990"><a href="#cb31-990" aria-hidden="true" tabindex="-1"></a>\frac{1}{2\sigma ^ 2}\sum_{n = N_o + 1}^N (y_n -\gamma^\top z_n)^2 - </span>
<span id="cb31-991"><a href="#cb31-991" aria-hidden="true" tabindex="-1"></a>\sum_{n = N_o + 1} ^ N \ln \Phi\left(\frac{\gamma^\top z_n}{\sigma}\right)</span>
<span id="cb31-992"><a href="#cb31-992" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-993"><a href="#cb31-993" aria-hidden="true" tabindex="-1"></a>Note that, except for the last term, this is the log-likelihood of the normal gaussian model. </span>
<span id="cb31-994"><a href="#cb31-994" aria-hidden="true" tabindex="-1"></a>For the censored sample, the individual contribution to the likelihood</span>
<span id="cb31-995"><a href="#cb31-995" aria-hidden="true" tabindex="-1"></a>sample will depend on whether $y=0$ or not:</span>
<span id="cb31-996"><a href="#cb31-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-997"><a href="#cb31-997" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if $y = 0$, the contribution is the probability that $y=0$, which is </span>
<span id="cb31-998"><a href="#cb31-998" aria-hidden="true" tabindex="-1"></a>  $1 - \Phi\left(\frac{\gamma^ \top z}{\sigma}\right)$,</span>
<span id="cb31-999"><a href="#cb31-999" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if $y &gt; 0$, the contribution is the product of the probability that $y &gt; 0$ and</span>
<span id="cb31-1000"><a href="#cb31-1000" aria-hidden="true" tabindex="-1"></a>  the density of the truncated distribution of $y$, which is:</span>
<span id="cb31-1001"><a href="#cb31-1001" aria-hidden="true" tabindex="-1"></a>  $\Phi\left(\frac{\gamma^\top</span>
<span id="cb31-1002"><a href="#cb31-1002" aria-hidden="true" tabindex="-1"></a>  z}{\sigma}\right)\frac{1}{\sigma\Phi\left(\frac{\gamma^\top</span>
<span id="cb31-1003"><a href="#cb31-1003" aria-hidden="true" tabindex="-1"></a>  z}{\sigma}\right)} \phi\left(\frac{y - \gamma^ \top</span>
<span id="cb31-1004"><a href="#cb31-1004" aria-hidden="true" tabindex="-1"></a>  z}{\sigma}\right)$.</span>
<span id="cb31-1005"><a href="#cb31-1005" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-1006"><a href="#cb31-1006" aria-hidden="true" tabindex="-1"></a>The likelihood function is therefore:</span>
<span id="cb31-1007"><a href="#cb31-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1008"><a href="#cb31-1008" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1009"><a href="#cb31-1009" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1010"><a href="#cb31-1010" aria-hidden="true" tabindex="-1"></a>L^C(\gamma, \sigma  | y,x)&amp;=&amp;\prod_{n=1}^{N_o}</span>
<span id="cb31-1011"><a href="#cb31-1011" aria-hidden="true" tabindex="-1"></a>\left<span class="co">[</span><span class="ot">1 - \Phi\left(\frac{\gamma^ \top z_n}{\sigma}\right)\right</span><span class="co">]</span></span>
<span id="cb31-1012"><a href="#cb31-1012" aria-hidden="true" tabindex="-1"></a>\prod_{n = N_o + 1}^{N}\Phi\left(\frac{\gamma^\top z_n}{\sigma}\right)<span class="sc">\\</span></span>
<span id="cb31-1013"><a href="#cb31-1013" aria-hidden="true" tabindex="-1"></a>&amp;\times&amp;\prod_{n = N_o + 1}^{N}\frac{1}{\sigma\Phi\left(\frac{\gamma^\top</span>
<span id="cb31-1014"><a href="#cb31-1014" aria-hidden="true" tabindex="-1"></a>z_n}{\sigma}\right)}</span>
<span id="cb31-1015"><a href="#cb31-1015" aria-hidden="true" tabindex="-1"></a>\phi\left(\frac{y_n-\gamma^\top x_n}{\sigma}\right)</span>
<span id="cb31-1016"><a href="#cb31-1016" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1017"><a href="#cb31-1017" aria-hidden="true" tabindex="-1"></a>$$ {#eq-tobit1_probit_plus_trunc}</span>
<span id="cb31-1018"><a href="#cb31-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1019"><a href="#cb31-1019" aria-hidden="true" tabindex="-1"></a>which is simply the product of:</span>
<span id="cb31-1020"><a href="#cb31-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1021"><a href="#cb31-1021" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the likelihood of a probit model which explains that $y=0$ or $y &gt;</span>
<span id="cb31-1022"><a href="#cb31-1022" aria-hidden="true" tabindex="-1"></a>  0$ (the first line of @eq-tobit1_probit_plus_trunc),</span>
<span id="cb31-1023"><a href="#cb31-1023" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the likelihood of $y$ for the truncated sample (the second line of @eq-tobit1_probit_plus_trunc). </span>
<span id="cb31-1024"><a href="#cb31-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1025"><a href="#cb31-1025" aria-hidden="true" tabindex="-1"></a>Denoting $L^P$ the likelihood of the probit model, we then have:</span>
<span id="cb31-1026"><a href="#cb31-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1027"><a href="#cb31-1027" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1028"><a href="#cb31-1028" aria-hidden="true" tabindex="-1"></a>L^C(\gamma, \sigma \mid y,x)=L^P(\gamma,\sigma\mid y, x) \times L^T(\gamma, \sigma \mid y, x)</span>
<span id="cb31-1029"><a href="#cb31-1029" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1030"><a href="#cb31-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1031"><a href="#cb31-1031" aria-hidden="true" tabindex="-1"></a>Taking logs and rearranging terms, we finally get:</span>
<span id="cb31-1032"><a href="#cb31-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1033"><a href="#cb31-1033" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1034"><a href="#cb31-1034" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1035"><a href="#cb31-1035" aria-hidden="true" tabindex="-1"></a>\ln L^C(\gamma, \sigma \mid y,x)&amp;=&amp;\sum_{n=1}^{N_o}</span>
<span id="cb31-1036"><a href="#cb31-1036" aria-hidden="true" tabindex="-1"></a>\ln \left<span class="co">[</span><span class="ot">1 - \Phi\left(\frac{\gamma^ \top z_n}{\sigma}\right)\right</span><span class="co">]</span></span>
<span id="cb31-1037"><a href="#cb31-1037" aria-hidden="true" tabindex="-1"></a>-\frac{N - N_o}{2}\left(\ln \sigma ^ 2 + \ln 2 \pi\right)<span class="sc">\\</span></span>
<span id="cb31-1038"><a href="#cb31-1038" aria-hidden="true" tabindex="-1"></a>&amp;-&amp;\frac{1}{2\sigma^ 2}\sum_{n = N_o + 1}^{N}\left(y_n-\gamma^\top</span>
<span id="cb31-1039"><a href="#cb31-1039" aria-hidden="true" tabindex="-1"></a>z_n\right)^2</span>
<span id="cb31-1040"><a href="#cb31-1040" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1041"><a href="#cb31-1041" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1042"><a href="#cb31-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1043"><a href="#cb31-1043" aria-hidden="true" tabindex="-1"></a>Denoting $d_n = \mathbf{1}(y_n&gt;0)$, the first derivatives with $\gamma$ are, denoting: $\mu_n = \gamma ^ \top z_n$ and $r_n = \frac{\phi(\mu_n / \sigma)}{1 - \Phi(\mu_n / \sigma)}$:</span>
<span id="cb31-1044"><a href="#cb31-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1045"><a href="#cb31-1045" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1046"><a href="#cb31-1046" aria-hidden="true" tabindex="-1"></a>\frac{\partial L^C}{\partial \gamma} = \frac{1}{\sigma ^ 2}\sum_{n= 1} ^ N\left(- (1 - d_n)\sigma r_n + d_n (y_n - \mu_n)\right)z_n = \frac{1}{\sigma ^ 2}\sum_{n= 1} ^ N \psi_n z_n</span>
<span id="cb31-1047"><a href="#cb31-1047" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1048"><a href="#cb31-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1049"><a href="#cb31-1049" aria-hidden="true" tabindex="-1"></a>For the maximum likelihood estimator, the vector of generalized residuals is then:^<span class="co">[</span><span class="ot">See @sec-estimation_binomial.</span><span class="co">]</span></span>
<span id="cb31-1050"><a href="#cb31-1050" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized!censored regression model|(}</span>
<span id="cb31-1051"><a href="#cb31-1051" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized residuals!censored regression model|(}</span>
<span id="cb31-1052"><a href="#cb31-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1053"><a href="#cb31-1053" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1054"><a href="#cb31-1054" aria-hidden="true" tabindex="-1"></a>\psi_n = - (1 - d_n)\sigma r_n + d_n (y_n - \mu_n)</span>
<span id="cb31-1055"><a href="#cb31-1055" aria-hidden="true" tabindex="-1"></a>$$ {#eq-gen_residuals_tobit}</span>
<span id="cb31-1056"><a href="#cb31-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1057"><a href="#cb31-1057" aria-hidden="true" tabindex="-1"></a>and it is orthogonal to all the regressors. Note that, for positive values of $y$, the generalized residual is just the standard residual. For null values of $y$, which means negative values of $y^*$, the generalized residual is: $\mbox{E}(y_n^* - \mu_n \mid x, y_n ^*\leq 0) = - \sigma r_n$. As $y_n^*$ and therefore the residuals for null observations are unobserved; they are simply replaced by their expectations.</span>
<span id="cb31-1058"><a href="#cb31-1058" aria-hidden="true" tabindex="-1"></a>The hessian is rather tricky, but its</span>
<span id="cb31-1059"><a href="#cb31-1059" aria-hidden="true" tabindex="-1"></a>expression can be greatly simplified using a reparametrization, due</span>
<span id="cb31-1060"><a href="#cb31-1060" aria-hidden="true" tabindex="-1"></a>to @OLSE:78\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Olsen}: $\delta = \gamma / \sigma$ and $\theta = 1 / \sigma$.</span>
<span id="cb31-1061"><a href="#cb31-1061" aria-hidden="true" tabindex="-1"></a>@OLSE:78\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Olsen} showed that the log-likelihood function of the censored model</span>
<span id="cb31-1062"><a href="#cb31-1062" aria-hidden="true" tabindex="-1"></a>expressed in terms of $\delta$ and $\theta$ is globally concave and</span>
<span id="cb31-1063"><a href="#cb31-1063" aria-hidden="true" tabindex="-1"></a>therefore admits a unique optimum which is a maximum. </span>
<span id="cb31-1064"><a href="#cb31-1064" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized!censored regression model|)}</span>
<span id="cb31-1065"><a href="#cb31-1065" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized residuals!censored regression model|)}</span>
<span id="cb31-1066"><a href="#cb31-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1067"><a href="#cb31-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1068"><a href="#cb31-1068" aria-hidden="true" tabindex="-1"></a><span class="fu">### Semi-parametric estimators</span></span>
<span id="cb31-1069"><a href="#cb31-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1070"><a href="#cb31-1070" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{semi-parametric estimator!tobit-1|(}</span>
<span id="cb31-1071"><a href="#cb31-1071" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-1!semi-parametric estimator|(}</span>
<span id="cb31-1072"><a href="#cb31-1072" aria-hidden="true" tabindex="-1"></a>In a semi-parametric approach, only the regression function, i.e., </span>
<span id="cb31-1073"><a href="#cb31-1073" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(y \mid x)= \mu_n = \alpha + \beta^\top x$, is parametrically specified, while the rest of the</span>
<span id="cb31-1074"><a href="#cb31-1074" aria-hidden="true" tabindex="-1"></a>model (especially the conditional distribution of $y$) is not. This</span>
<span id="cb31-1075"><a href="#cb31-1075" aria-hidden="true" tabindex="-1"></a>approach is therefore much more generally applicable. Compared to the</span>
<span id="cb31-1076"><a href="#cb31-1076" aria-hidden="true" tabindex="-1"></a>estimators presented in the previous two sections, which are only</span>
<span id="cb31-1077"><a href="#cb31-1077" aria-hidden="true" tabindex="-1"></a>consistent if the conditional distribution of $y$ is normal and</span>
<span id="cb31-1078"><a href="#cb31-1078" aria-hidden="true" tabindex="-1"></a>homoskedastic, the semi-parametric estimator presented in this section <span class="co">[</span><span class="ot">@POWE:86</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Powell}</span>
<span id="cb31-1079"><a href="#cb31-1079" aria-hidden="true" tabindex="-1"></a>is consistent in a much broader context, as it requires only the</span>
<span id="cb31-1080"><a href="#cb31-1080" aria-hidden="true" tabindex="-1"></a>symmetry of the conditional distribution of the response.</span>
<span id="cb31-1081"><a href="#cb31-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1082"><a href="#cb31-1082" aria-hidden="true" tabindex="-1"></a>For the zero left-truncated response case, the OLS estimator is biased because the conditional distribution</span>
<span id="cb31-1083"><a href="#cb31-1083" aria-hidden="true" tabindex="-1"></a>of $y$ is asymmetric, as the observations on the lower tail of the</span>
<span id="cb31-1084"><a href="#cb31-1084" aria-hidden="true" tabindex="-1"></a>distribution ($y &lt; 0$) are either missing (the case of a truncated</span>
<span id="cb31-1085"><a href="#cb31-1085" aria-hidden="true" tabindex="-1"></a>sample) or set to 0 (the case of a censored sample). For the case of a</span>
<span id="cb31-1086"><a href="#cb31-1086" aria-hidden="true" tabindex="-1"></a>truncated sample, trimming the observations for which </span>
<span id="cb31-1087"><a href="#cb31-1087" aria-hidden="true" tabindex="-1"></a>$y_n &gt; 2\mu_n$, i.e., observations that lie in the upper tail, would restore</span>
<span id="cb31-1088"><a href="#cb31-1088" aria-hidden="true" tabindex="-1"></a>the symmetry, and OLS estimation on this trimmed sample would be</span>
<span id="cb31-1089"><a href="#cb31-1089" aria-hidden="true" tabindex="-1"></a>consistent. This situation is depicted in @fig-symmetric.</span>
<span id="cb31-1090"><a href="#cb31-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1091"><a href="#cb31-1091" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1092"><a href="#cb31-1092" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-symmetric</span></span>
<span id="cb31-1093"><a href="#cb31-1093" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Symmetrically trimmed truncated distribution"</span></span>
<span id="cb31-1094"><a href="#cb31-1094" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb31-1095"><a href="#cb31-1095" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/symetric.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-1096"><a href="#cb31-1096" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1097"><a href="#cb31-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1098"><a href="#cb31-1098" aria-hidden="true" tabindex="-1"></a>The plain line represents the distribution of the untruncated</span>
<span id="cb31-1099"><a href="#cb31-1099" aria-hidden="true" tabindex="-1"></a>response, the dashed line the corresponding distribution of the</span>
<span id="cb31-1100"><a href="#cb31-1100" aria-hidden="true" tabindex="-1"></a>left zero-truncated response. This distribution is asymmetric, and the</span>
<span id="cb31-1101"><a href="#cb31-1101" aria-hidden="true" tabindex="-1"></a>expected value of $y$ for $x=x_n$ is above $\mu_n$</span>
<span id="cb31-1102"><a href="#cb31-1102" aria-hidden="true" tabindex="-1"></a>because of the left-truncation. The dotted line represents the</span>
<span id="cb31-1103"><a href="#cb31-1103" aria-hidden="true" tabindex="-1"></a>two-sided truncated distribution of $y$, truncated at 0 on the left side</span>
<span id="cb31-1104"><a href="#cb31-1104" aria-hidden="true" tabindex="-1"></a>and at $2\mu_n$ on the right side. As the untruncated distribution</span>
<span id="cb31-1105"><a href="#cb31-1105" aria-hidden="true" tabindex="-1"></a>of $y$ is symmetric, so is the two-sided truncated distribution, for</span>
<span id="cb31-1106"><a href="#cb31-1106" aria-hidden="true" tabindex="-1"></a>which the conditional expected value of $y$ is now equal to</span>
<span id="cb31-1107"><a href="#cb31-1107" aria-hidden="true" tabindex="-1"></a>$\mu_n$. Therefore, if we were able to remove from the sample</span>
<span id="cb31-1108"><a href="#cb31-1108" aria-hidden="true" tabindex="-1"></a>all the observations for which $y_n &gt; 2 \mu_n$, the OLS estimator</span>
<span id="cb31-1109"><a href="#cb31-1109" aria-hidden="true" tabindex="-1"></a>on this trimmed sample would be consistent. Of course, the problem is</span>
<span id="cb31-1110"><a href="#cb31-1110" aria-hidden="true" tabindex="-1"></a>that the right-truncation point is unknown for every observation, as</span>
<span id="cb31-1111"><a href="#cb31-1111" aria-hidden="true" tabindex="-1"></a>it depends on $\gamma$ which is the parameter vector that we seek to</span>
<span id="cb31-1112"><a href="#cb31-1112" aria-hidden="true" tabindex="-1"></a>estimate. The subset of observations that should be kept are such that $0 &lt; y_n &lt; 2\gamma^\top z_n$, or $-\gamma^\top z_n &lt; \epsilon_n &lt; \gamma^\top z_n$, the first inequality being always verified for a truncated sample. Note that this condition will remove all the</span>
<span id="cb31-1113"><a href="#cb31-1113" aria-hidden="true" tabindex="-1"></a>observations for which $\gamma^\top z_n &lt; 0$.</span>
<span id="cb31-1114"><a href="#cb31-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1115"><a href="#cb31-1115" aria-hidden="true" tabindex="-1"></a>The first-order conditions to minimize the sum of squares</span>
<span id="cb31-1116"><a href="#cb31-1116" aria-hidden="true" tabindex="-1"></a>of the residuals for the trimmed sample is then similar to the normal</span>
<span id="cb31-1117"><a href="#cb31-1117" aria-hidden="true" tabindex="-1"></a>equations ($\sum_{n=1}^N (y_n - \gamma ^ \top z_n) z_n = 0$) on the relevant</span>
<span id="cb31-1118"><a href="#cb31-1118" aria-hidden="true" tabindex="-1"></a>subset of the sample:</span>
<span id="cb31-1119"><a href="#cb31-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1120"><a href="#cb31-1120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1121"><a href="#cb31-1121" aria-hidden="true" tabindex="-1"></a>\sum_{n = 1} ^ N \textbf{1}(y_n &lt; 2 \gamma^\top z_n) (y_n - \gamma ^</span>
<span id="cb31-1122"><a href="#cb31-1122" aria-hidden="true" tabindex="-1"></a>\top z_n)  z_n = 0</span>
<span id="cb31-1123"><a href="#cb31-1123" aria-hidden="true" tabindex="-1"></a>$$ {#eq-foc_trimmed_trunc}</span>
<span id="cb31-1124"><a href="#cb31-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1125"><a href="#cb31-1125" aria-hidden="true" tabindex="-1"></a>Note that the left-hand side of this equation is a discontinuous</span>
<span id="cb31-1126"><a href="#cb31-1126" aria-hidden="true" tabindex="-1"></a>function of $\gamma$, as even a small change of $\gamma$ may, for some</span>
<span id="cb31-1127"><a href="#cb31-1127" aria-hidden="true" tabindex="-1"></a>observations, turn the condition $y_n &lt; 2 \gamma^\top z_n$ from true</span>
<span id="cb31-1128"><a href="#cb31-1128" aria-hidden="true" tabindex="-1"></a>to false (or the opposite). Moreover, note that $\gamma=0$ is a trivial</span>
<span id="cb31-1129"><a href="#cb31-1129" aria-hidden="true" tabindex="-1"></a>solution as, in this case, $\textbf{1}(y_n &lt; 2 \gamma^\top</span>
<span id="cb31-1130"><a href="#cb31-1130" aria-hidden="true" tabindex="-1"></a>x_n)=0\;\forall n$. Therefore, it is safer to consider the estimator</span>
<span id="cb31-1131"><a href="#cb31-1131" aria-hidden="true" tabindex="-1"></a>as the result of a minimization problem instead of solving the set of</span>
<span id="cb31-1132"><a href="#cb31-1132" aria-hidden="true" tabindex="-1"></a>non-linear equations. By direct integration, we can check that minimizing</span>
<span id="cb31-1133"><a href="#cb31-1133" aria-hidden="true" tabindex="-1"></a>the following function:</span>
<span id="cb31-1134"><a href="#cb31-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1135"><a href="#cb31-1135" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1136"><a href="#cb31-1136" aria-hidden="true" tabindex="-1"></a>R_T = \sum_{n=1}^N \left[y_n - \max\left(\frac{y_n}{2}, \gamma^\top</span>
<span id="cb31-1137"><a href="#cb31-1137" aria-hidden="true" tabindex="-1"></a>z_n\right)\right] ^ 2</span>
<span id="cb31-1138"><a href="#cb31-1138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1139"><a href="#cb31-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1140"><a href="#cb31-1140" aria-hidden="true" tabindex="-1"></a>leads to @eq-foc_trimmed_trunc.</span>
<span id="cb31-1141"><a href="#cb31-1141" aria-hidden="true" tabindex="-1"></a>This **symmetrically truncated least squares** estimator easily extends to the case of</span>
<span id="cb31-1142"><a href="#cb31-1142" aria-hidden="true" tabindex="-1"></a>censored samples. In this case, negative values of $y$ are unobserved,</span>
<span id="cb31-1143"><a href="#cb31-1143" aria-hidden="true" tabindex="-1"></a>and the value of the response is set to 0. A symmetrically censored</span>
<span id="cb31-1144"><a href="#cb31-1144" aria-hidden="true" tabindex="-1"></a>sample is obtained by setting the response, for observations whose</span>
<span id="cb31-1145"><a href="#cb31-1145" aria-hidden="true" tabindex="-1"></a>the observed value of $y$ is greater than $2\mu_n$ to</span>
<span id="cb31-1146"><a href="#cb31-1146" aria-hidden="true" tabindex="-1"></a>$2\mu_n$. This means that as the response is zero left-censored, we also right-censor it, with a truncation value that is</span>
<span id="cb31-1147"><a href="#cb31-1147" aria-hidden="true" tabindex="-1"></a>specific to the observation, and that depends on the set of unknown</span>
<span id="cb31-1148"><a href="#cb31-1148" aria-hidden="true" tabindex="-1"></a>parameters $\gamma$ we seek to estimate. The resulting first-order</span>
<span id="cb31-1149"><a href="#cb31-1149" aria-hidden="true" tabindex="-1"></a>condition to minimize the sum of squares of the "symmetrically</span>
<span id="cb31-1150"><a href="#cb31-1150" aria-hidden="true" tabindex="-1"></a>censored sample" is:</span>
<span id="cb31-1151"><a href="#cb31-1151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1152"><a href="#cb31-1152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1153"><a href="#cb31-1153" aria-hidden="true" tabindex="-1"></a>\sum_{n = 1} ^ N \textbf{1}(y_n &lt; 2 \gamma^\top z_n)</span>
<span id="cb31-1154"><a href="#cb31-1154" aria-hidden="true" tabindex="-1"></a>\left<span class="co">[</span><span class="ot">\min\left(y_n, 2 \gamma ^ \top z_n\right) - \gamma ^ \top z_n\right</span><span class="co">]</span>  z_n = 0</span>
<span id="cb31-1155"><a href="#cb31-1155" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1156"><a href="#cb31-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1157"><a href="#cb31-1157" aria-hidden="true" tabindex="-1"></a>which is the first-order conditions of the minimization of the following function:</span>
<span id="cb31-1158"><a href="#cb31-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1159"><a href="#cb31-1159" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1160"><a href="#cb31-1160" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1161"><a href="#cb31-1161" aria-hidden="true" tabindex="-1"></a>R_C &amp;=&amp; \sum_{n=1}^N \left<span class="co">[</span><span class="ot">y_n - \max\left(\frac{y_n}{2}, \gamma^\top z_n\right)\right</span><span class="co">]</span> ^ 2<span class="sc">\\</span></span>
<span id="cb31-1162"><a href="#cb31-1162" aria-hidden="true" tabindex="-1"></a>&amp;+&amp; \sum_{n=1}^N \textbf{1}(y_n &lt; 2 \gamma^\top z_n)</span>
<span id="cb31-1163"><a href="#cb31-1163" aria-hidden="true" tabindex="-1"></a>\left<span class="co">[</span><span class="ot">\left(\frac{y_n}{2}\right) ^ 2 - \max(0, \gamma ^ \top z_n) ^ 2\right</span><span class="co">]</span></span>
<span id="cb31-1164"><a href="#cb31-1164" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1165"><a href="#cb31-1165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1166"><a href="#cb31-1166" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{semi-parametric estimator!tobit-1|)}</span>
<span id="cb31-1167"><a href="#cb31-1167" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-1!semi-parametric estimator|)}</span>
<span id="cb31-1168"><a href="#cb31-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1169"><a href="#cb31-1169" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimation of the tobit-1 model with R {#sec-tobit_estim_R}</span></span>
<span id="cb31-1170"><a href="#cb31-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1171"><a href="#cb31-1171" aria-hidden="true" tabindex="-1"></a>The estimation of the tobit-1 model is available in functions of different packages: <span class="in">`AER::tobit`</span>, <span class="in">`censReg::censReg`</span> and <span class="in">`micsr::tobit1`</span>. All these functions use the usual formula-data interface to describe the model to be estimated and also a <span class="in">`left`</span> and a <span class="in">`right`</span> argument to indicate the truncation points. The default values of these last two arguments are 0 and $+\infty$, which correspond to the most usual zero left-truncated case. The   <span class="in">`micsr::tobit1`</span> function allows to use either a censored or a truncated sample by setting the <span class="in">`sample`</span> argument either to <span class="in">`"censored"`</span> or <span class="in">`"truncated"`</span>. The other two functions only allow the estimation of the censored regression model. The truncated regression model can also be estimated using the <span class="in">`truncreg::truncreg`</span> function. <span class="in">`micsr::tobit1`</span> also has the advantage of providing several different estimators, selected using the <span class="in">`method`</span> argument: <span class="in">`"ml"`</span> for maximum likelihood, <span class="in">`"lm"`</span> for linear model, <span class="in">`"twostep"`</span> for the two-step estimator, <span class="in">`"trimmed"`</span> for the trimmed estimator and <span class="in">`"nls"`</span> for the non-linear least squares estimator, the two other functions only providing the maximum likelihood estimator. We'll present three examples of application, with respectively a left-truncated, a right-truncated and a two-sided truncated response.</span>
<span id="cb31-1172"><a href="#cb31-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1173"><a href="#cb31-1173" aria-hidden="true" tabindex="-1"></a><span class="fu">### Left-truncated response {#sec-charitable_estimation}</span></span>
<span id="cb31-1174"><a href="#cb31-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1175"><a href="#cb31-1175" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{charitable}{micsr}</span>
<span id="cb31-1176"><a href="#cb31-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1177"><a href="#cb31-1177" aria-hidden="true" tabindex="-1"></a>The <span class="in">`charitable`</span> data set is used by @WILH:08\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wilhelm} and concerns charitable giving. </span>
<span id="cb31-1178"><a href="#cb31-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1179"><a href="#cb31-1179" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1180"><a href="#cb31-1180" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: charitable_head</span></span>
<span id="cb31-1181"><a href="#cb31-1181" aria-hidden="true" tabindex="-1"></a>charitable <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">3</span>)</span>
<span id="cb31-1182"><a href="#cb31-1182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1183"><a href="#cb31-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1184"><a href="#cb31-1184" aria-hidden="true" tabindex="-1"></a>The response is called <span class="in">`donation`</span>; it measures annual charitable</span>
<span id="cb31-1185"><a href="#cb31-1185" aria-hidden="true" tabindex="-1"></a>giving in US dollars. This variable is left-censored for the value of 25, as</span>
<span id="cb31-1186"><a href="#cb31-1186" aria-hidden="true" tabindex="-1"></a>this value corresponds to the item "less than $25 donation". Therefore, for this value, we have households who didn't make any charitable giving and some who made a small giving (from $1 to $25). The covariates used are the donations made by the parents (<span class="in">`donparents`</span>), two factors indicating the educational level and</span>
<span id="cb31-1187"><a href="#cb31-1187" aria-hidden="true" tabindex="-1"></a>religious beliefs (respectively <span class="in">`education`</span> and <span class="in">`religion`</span>), annual</span>
<span id="cb31-1188"><a href="#cb31-1188" aria-hidden="true" tabindex="-1"></a>income (<span class="in">`income`</span>) and two dummies for living in the south (<span class="in">`south`</span>)</span>
<span id="cb31-1189"><a href="#cb31-1189" aria-hidden="true" tabindex="-1"></a>and for married couples (<span class="in">`married`</span>). </span>
<span id="cb31-1190"><a href="#cb31-1190" aria-hidden="true" tabindex="-1"></a>@WILH:08\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wilhelm} considers the value of the donation in logs and subtracts from it $\ln 25$, so that the response is 0 for households who gave no donation or</span>
<span id="cb31-1191"><a href="#cb31-1191" aria-hidden="true" tabindex="-1"></a>a small donation.</span>
<span id="cb31-1192"><a href="#cb31-1192" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}</span>
<span id="cb31-1193"><a href="#cb31-1193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1194"><a href="#cb31-1194" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1195"><a href="#cb31-1195" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: charitable_logdon</span></span>
<span id="cb31-1196"><a href="#cb31-1196" aria-hidden="true" tabindex="-1"></a>charitable <span class="ot">&lt;-</span> charitable <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">logdon =</span> <span class="fu">log</span>(donation) <span class="sc">-</span> <span class="fu">log</span>(<span class="dv">25</span>))</span>
<span id="cb31-1197"><a href="#cb31-1197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1198"><a href="#cb31-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1199"><a href="#cb31-1199" aria-hidden="true" tabindex="-1"></a>The model can either be estimated using <span class="in">`logdon`</span> as the response and the default values of <span class="in">`left`</span> or <span class="in">`right`</span> or by using <span class="in">`log(donation)`</span> as the response and setting <span class="in">`left`</span> to <span class="in">`log(25)`</span>.</span>
<span id="cb31-1200"><a href="#cb31-1200" aria-hidden="true" tabindex="-1"></a>\idxfun{tobit}{AER}\idxfun{censReg}{censReg}\idxfun{tobit1}{micsr}</span>
<span id="cb31-1201"><a href="#cb31-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1202"><a href="#cb31-1202" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1203"><a href="#cb31-1203" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: charitable_estimation_libraries</span></span>
<span id="cb31-1204"><a href="#cb31-1204" aria-hidden="true" tabindex="-1"></a>char_form <span class="ot">&lt;-</span> logdon <span class="sc">~</span> <span class="fu">log</span>(donparents) <span class="sc">+</span> <span class="fu">log</span>(income) <span class="sc">+</span></span>
<span id="cb31-1205"><a href="#cb31-1205" aria-hidden="true" tabindex="-1"></a>    education <span class="sc">+</span> religion <span class="sc">+</span> married <span class="sc">+</span> south</span>
<span id="cb31-1206"><a href="#cb31-1206" aria-hidden="true" tabindex="-1"></a>ml_aer <span class="ot">&lt;-</span> AER<span class="sc">::</span><span class="fu">tobit</span>(char_form, <span class="at">data =</span> charitable)</span>
<span id="cb31-1207"><a href="#cb31-1207" aria-hidden="true" tabindex="-1"></a>ml_creg <span class="ot">&lt;-</span> censReg<span class="sc">::</span><span class="fu">censReg</span>(char_form, <span class="at">data =</span> charitable)</span>
<span id="cb31-1208"><a href="#cb31-1208" aria-hidden="true" tabindex="-1"></a>ch_ml <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(char_form, <span class="at">data =</span> charitable)</span>
<span id="cb31-1209"><a href="#cb31-1209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1210"><a href="#cb31-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1211"><a href="#cb31-1211" aria-hidden="true" tabindex="-1"></a>The three functions return identical results, except that they are parametrized differently: <span class="in">`micsr::tobit1`</span> estimates $\sigma$ as the two other functions estimate $\ln \sigma$.</span>
<span id="cb31-1212"><a href="#cb31-1212" aria-hidden="true" tabindex="-1"></a>Using <span class="in">`micsr::tobit1`</span>, we also estimate the two-step, </span>
<span id="cb31-1213"><a href="#cb31-1213" aria-hidden="true" tabindex="-1"></a>the **SCLS** (symmetrically censored least squares) and the OLS estimators.</span>
<span id="cb31-1214"><a href="#cb31-1214" aria-hidden="true" tabindex="-1"></a>\idxfun{update}{stats}</span>
<span id="cb31-1215"><a href="#cb31-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1216"><a href="#cb31-1216" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1217"><a href="#cb31-1217" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: charitable_models</span></span>
<span id="cb31-1218"><a href="#cb31-1218" aria-hidden="true" tabindex="-1"></a>ch_twostep <span class="ot">&lt;-</span> <span class="fu">update</span>(ch_ml, <span class="at">method =</span> <span class="st">"twostep"</span>)</span>
<span id="cb31-1219"><a href="#cb31-1219" aria-hidden="true" tabindex="-1"></a>ch_scls <span class="ot">&lt;-</span> <span class="fu">update</span>(ch_ml, <span class="at">method =</span> <span class="st">"trimmed"</span>)</span>
<span id="cb31-1220"><a href="#cb31-1220" aria-hidden="true" tabindex="-1"></a>ch_ols <span class="ot">&lt;-</span> <span class="fu">update</span>(ch_ml, <span class="at">method =</span> <span class="st">"lm"</span>)</span>
<span id="cb31-1221"><a href="#cb31-1221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1222"><a href="#cb31-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1223"><a href="#cb31-1223" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- nls only for zero-left truncated with truncated sample --&gt;</span></span>
<span id="cb31-1224"><a href="#cb31-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1225"><a href="#cb31-1225" aria-hidden="true" tabindex="-1"></a>The results of the three models are presented in </span>
<span id="cb31-1226"><a href="#cb31-1226" aria-hidden="true" tabindex="-1"></a>@tbl-models.^<span class="co">[</span><span class="ot">To save space, the coefficients of the levels of the `education` and `religion` covariates are omitted.</span><span class="co">]</span> The last two columns of @tbl-models match  the</span>
<span id="cb31-1227"><a href="#cb31-1227" aria-hidden="true" tabindex="-1"></a>first two columns of table 3 of @WILH:08\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wilhelm}, page 577. Note that the OLS</span>
<span id="cb31-1228"><a href="#cb31-1228" aria-hidden="true" tabindex="-1"></a>estimators are in general lower in absolute values than those of the three</span>
<span id="cb31-1229"><a href="#cb31-1229" aria-hidden="true" tabindex="-1"></a>other estimators, which illustrates the fact that OLS estimators are</span>
<span id="cb31-1230"><a href="#cb31-1230" aria-hidden="true" tabindex="-1"></a>biased toward zero when the response is censored. More precisely @eq-bias_ols_censored_sample indicates that the OLS estimator converges to $\Phi(\mu_y / \sigma) \beta$. $\Phi(\mu_y / \sigma)$ is the probability of $y &gt; 0$ ($y$ being in our example the log of the donation minus $\ln 25$) and can be consistently estimated by the share of uncensored observations in our sample, which is about two-thirds. Therefore, the ratio of the OLS estimator and one of a consistent estimator, for example the ML estimator, should be approximately equal to two-thirds. This is actually the case for the first two covariates: </span>
<span id="cb31-1231"><a href="#cb31-1231" aria-hidden="true" tabindex="-1"></a>$<span class="in">`r round(coef(ch_ols)[2], 3)`</span> / <span class="in">`r round(coef(ch_ml)[2], 3)`</span> = <span class="in">`r round(coef(ch_ols)[2] / coef(ch_ml)[2], 3)`</span>$ and </span>
<span id="cb31-1232"><a href="#cb31-1232" aria-hidden="true" tabindex="-1"></a>$<span class="in">`r round(coef(ch_ols)[3], 3)`</span> / <span class="in">`r round(coef(ch_ml)[3], 3)`</span> = <span class="in">`r round(coef(ch_ols)[3] / coef(ch_ml)[3], 3)`</span>$.</span>
<span id="cb31-1233"><a href="#cb31-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1234"><a href="#cb31-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1235"><a href="#cb31-1235" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-models</span></span>
<span id="cb31-1236"><a href="#cb31-1236" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: 'asis'</span></span>
<span id="cb31-1237"><a href="#cb31-1237" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-1238"><a href="#cb31-1238" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Estimation of charitable giving models"</span></span>
<span id="cb31-1239"><a href="#cb31-1239" aria-hidden="true" tabindex="-1"></a>modelsummary<span class="sc">::</span><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="st">"OLS"</span> <span class="ot">=</span> ch_ols, <span class="st">"2-steps"</span> <span class="ot">=</span> ch_twostep, </span>
<span id="cb31-1240"><a href="#cb31-1240" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"ML"</span> <span class="ot">=</span> ch_ml, <span class="st">"SCLS"</span> <span class="ot">=</span> ch_scls), </span>
<span id="cb31-1241"><a href="#cb31-1241" aria-hidden="true" tabindex="-1"></a>                       <span class="at">coef_omit =</span> <span class="st">"(education|religion)"</span>, <span class="at">estimate =</span> <span class="st">"{estimate}{stars}"</span>,</span>
<span id="cb31-1242"><a href="#cb31-1242" aria-hidden="true" tabindex="-1"></a>                       <span class="at">coef_rename =</span> <span class="fu">c</span>(<span class="st">"sigma"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">sigma$"</span>), <span class="at">escape =</span> <span class="cn">FALSE</span>,</span>
<span id="cb31-1243"><a href="#cb31-1243" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output =</span> <span class="st">"kableExtra"</span>)</span>
<span id="cb31-1244"><a href="#cb31-1244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1245"><a href="#cb31-1245" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{charitable}{micsr}</span>
<span id="cb31-1246"><a href="#cb31-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1247"><a href="#cb31-1247" aria-hidden="true" tabindex="-1"></a><span class="fu">### Right-truncated response</span></span>
<span id="cb31-1248"><a href="#cb31-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1249"><a href="#cb31-1249" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{food}{micsr}</span>
<span id="cb31-1250"><a href="#cb31-1250" aria-hidden="true" tabindex="-1"></a>The <span class="in">`food`</span> data set is used by @CROM:PALM:URBA:97 to estimate the demand for food in the Netherlands.</span>
<span id="cb31-1251"><a href="#cb31-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1252"><a href="#cb31-1252" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1253"><a href="#cb31-1253" aria-hidden="true" tabindex="-1"></a>food <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">3</span>)</span>
<span id="cb31-1254"><a href="#cb31-1254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1255"><a href="#cb31-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1256"><a href="#cb31-1256" aria-hidden="true" tabindex="-1"></a>Two surveys are available, for 1980 and 1988, we'll use only the first one. Food expenses are top-coded for the top 5 percentiles, which corresponds to an expense of 13030 Dfl. The value reported for these observations is 17670 Dfl, which is the mean value of the expense for the top 5 percentile. </span>
<span id="cb31-1257"><a href="#cb31-1257" aria-hidden="true" tabindex="-1"></a>\idxfun{filter}{dplyr}\idxfun{summarise}{dplyr}</span>
<span id="cb31-1258"><a href="#cb31-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1259"><a href="#cb31-1259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1260"><a href="#cb31-1260" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: food_summarise</span></span>
<span id="cb31-1261"><a href="#cb31-1261" aria-hidden="true" tabindex="-1"></a>food <span class="sc">%&gt;%</span> <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">1980</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-1262"><a href="#cb31-1262" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">sum</span>(food <span class="sc">==</span> <span class="dv">17670</span>),</span>
<span id="cb31-1263"><a href="#cb31-1263" aria-hidden="true" tabindex="-1"></a>              <span class="at">f =</span> <span class="fu">mean</span>(food <span class="sc">==</span> <span class="dv">17670</span>))</span>
<span id="cb31-1264"><a href="#cb31-1264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1265"><a href="#cb31-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1266"><a href="#cb31-1266" aria-hidden="true" tabindex="-1"></a>The percentage of censored observations is not exactly 5%, because some observations have been excluded due to missing values for some covariates. The response being expressed in logarithms, the right threshold is set to <span class="in">`log(13030)`</span> and the left</span>
<span id="cb31-1267"><a href="#cb31-1267" aria-hidden="true" tabindex="-1"></a>one to <span class="in">`- Inf`</span> as the response is not left-truncated.</span>
<span id="cb31-1268"><a href="#cb31-1268" aria-hidden="true" tabindex="-1"></a>\idxfun{tobit1}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1269"><a href="#cb31-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1270"><a href="#cb31-1270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1271"><a href="#cb31-1271" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: food_tobit1</span></span>
<span id="cb31-1272"><a href="#cb31-1272" aria-hidden="true" tabindex="-1"></a>food_tobit <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(<span class="fu">log</span>(food) <span class="sc">~</span> <span class="fu">log</span>(income) <span class="sc">+</span> <span class="fu">log</span>(hsize) <span class="sc">+</span> midage,</span>
<span id="cb31-1273"><a href="#cb31-1273" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> food, <span class="at">subset =</span> year <span class="sc">==</span> <span class="dv">1980</span>,</span>
<span id="cb31-1274"><a href="#cb31-1274" aria-hidden="true" tabindex="-1"></a>                         <span class="at">left =</span> <span class="sc">-</span><span class="cn">Inf</span>, <span class="at">right =</span> <span class="fu">log</span>(<span class="dv">13030</span>))</span>
<span id="cb31-1275"><a href="#cb31-1275" aria-hidden="true" tabindex="-1"></a>food_tobit <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1276"><a href="#cb31-1276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1277"><a href="#cb31-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1278"><a href="#cb31-1278" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{food}{micsr}</span>
<span id="cb31-1279"><a href="#cb31-1279" aria-hidden="true" tabindex="-1"></a>The main coefficient of interest is the one associated with the</span>
<span id="cb31-1280"><a href="#cb31-1280" aria-hidden="true" tabindex="-1"></a><span class="in">`log(income)`</span> covariate. Remember that in this data censoring case, the coefficient is the marginal effect, in the present context the income elasticity of food which is equal to <span class="in">`r round(coef(food_tobit)[2], 2)`</span>.</span>
<span id="cb31-1281"><a href="#cb31-1281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1282"><a href="#cb31-1282" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two-sided tobit models</span></span>
<span id="cb31-1283"><a href="#cb31-1283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1284"><a href="#cb31-1284" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{censored regression model!two-sided}</span>
<span id="cb31-1285"><a href="#cb31-1285" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{portfolio}{micsr}</span>
<span id="cb31-1286"><a href="#cb31-1286" aria-hidden="true" tabindex="-1"></a>@HOCH:03 estimates the share of riskless assets, which can be either</span>
<span id="cb31-1287"><a href="#cb31-1287" aria-hidden="true" tabindex="-1"></a>  an internal solution, or a corner solution with the share equal to 0</span>
<span id="cb31-1288"><a href="#cb31-1288" aria-hidden="true" tabindex="-1"></a>  or 1 ($l = 0$ and $u=1$). Hochguertel therefore estimates a two-sided tobit</span>
<span id="cb31-1289"><a href="#cb31-1289" aria-hidden="true" tabindex="-1"></a>  model. The paper seeks to explain the low share of risky assets in</span>
<span id="cb31-1290"><a href="#cb31-1290" aria-hidden="true" tabindex="-1"></a>  portfolios of Dutch households.  The data set is called <span class="in">`portfolio`</span>.</span>
<span id="cb31-1291"><a href="#cb31-1291" aria-hidden="true" tabindex="-1"></a>This data set is a panel of annual observations from 1993 to 1998. In</span>
<span id="cb31-1292"><a href="#cb31-1292" aria-hidden="true" tabindex="-1"></a>    his paper, @HOCH:03 used panel and cross-section estimators (the</span>
<span id="cb31-1293"><a href="#cb31-1293" aria-hidden="true" tabindex="-1"></a>    latter being obtained on the whole data set by pooling the six</span>
<span id="cb31-1294"><a href="#cb31-1294" aria-hidden="true" tabindex="-1"></a>    time-series). The response is <span class="in">`share`</span>, and the two covariates of main interest</span>
<span id="cb31-1295"><a href="#cb31-1295" aria-hidden="true" tabindex="-1"></a>    are <span class="in">`uncert`</span> and <span class="in">`expinc`</span>.</span>
<span id="cb31-1296"><a href="#cb31-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1297"><a href="#cb31-1297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`uncert`</span> indicates the degree of uncertainty felt by the household;</span>
<span id="cb31-1298"><a href="#cb31-1298" aria-hidden="true" tabindex="-1"></a>  it is a factor with levels <span class="in">`low`</span>, <span class="in">`moderate`</span> and <span class="in">`high`</span>,</span>
<span id="cb31-1299"><a href="#cb31-1299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`expinc`</span> indicates the prediction of the household concerning the</span>
<span id="cb31-1300"><a href="#cb31-1300" aria-hidden="true" tabindex="-1"></a>  evolution of their income in the next 5 years; it is a factor with</span>
<span id="cb31-1301"><a href="#cb31-1301" aria-hidden="true" tabindex="-1"></a>  levels <span class="in">`increase`</span>, <span class="in">`constant`</span> and <span class="in">`decrease`</span>. </span>
<span id="cb31-1302"><a href="#cb31-1302" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-1303"><a href="#cb31-1303" aria-hidden="true" tabindex="-1"></a>We'll use a simpler specification than the one used by the author, which contains a lot of</span>
<span id="cb31-1304"><a href="#cb31-1304" aria-hidden="true" tabindex="-1"></a>covariates; we only add to the two covariates previously described</span>
<span id="cb31-1305"><a href="#cb31-1305" aria-hidden="true" tabindex="-1"></a>the net worth, the age of household's head and its square and a dummy</span>
<span id="cb31-1306"><a href="#cb31-1306" aria-hidden="true" tabindex="-1"></a>for households whose head is a woman. We use the <span class="in">`micsr::tobit1`</span></span>
<span id="cb31-1307"><a href="#cb31-1307" aria-hidden="true" tabindex="-1"></a>function and we set the <span class="in">`left`</span> and the <span class="in">`right`</span> arguments respectively</span>
<span id="cb31-1308"><a href="#cb31-1308" aria-hidden="true" tabindex="-1"></a>to 0 and 1.</span>
<span id="cb31-1309"><a href="#cb31-1309" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{tobit1}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1310"><a href="#cb31-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1311"><a href="#cb31-1311" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1312"><a href="#cb31-1312" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: portfolio:tobit1</span></span>
<span id="cb31-1313"><a href="#cb31-1313" aria-hidden="true" tabindex="-1"></a>portfolio <span class="ot">&lt;-</span> portfolio <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">agesq =</span> age <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> <span class="dv">100</span>)</span>
<span id="cb31-1314"><a href="#cb31-1314" aria-hidden="true" tabindex="-1"></a>prec_ml <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(share <span class="sc">~</span> uncert <span class="sc">+</span> expinc <span class="sc">+</span> networth <span class="sc">+</span> </span>
<span id="cb31-1315"><a href="#cb31-1315" aria-hidden="true" tabindex="-1"></a>                    age <span class="sc">+</span> agesq <span class="sc">+</span> female,</span>
<span id="cb31-1316"><a href="#cb31-1316" aria-hidden="true" tabindex="-1"></a>                  <span class="at">left =</span> <span class="dv">0</span>, <span class="at">right =</span> <span class="dv">1</span>, <span class="at">data =</span> portfolio)</span>
<span id="cb31-1317"><a href="#cb31-1317" aria-hidden="true" tabindex="-1"></a>prec_ml <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1318"><a href="#cb31-1318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1319"><a href="#cb31-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1320"><a href="#cb31-1320" aria-hidden="true" tabindex="-1"></a>As expected, high uncertainty and pessimistic expectations about future</span>
<span id="cb31-1321"><a href="#cb31-1321" aria-hidden="true" tabindex="-1"></a>income increase the share of riskless assets. Net worth has a negative effect on the share of riskless assets, and households headed by a woman have a higher share of riskless assets. Finally</span>
<span id="cb31-1322"><a href="#cb31-1322" aria-hidden="true" tabindex="-1"></a>the effect of age is U-shaped.</span>
<span id="cb31-1323"><a href="#cb31-1323" aria-hidden="true" tabindex="-1"></a>Actually, @HOCH:03 doesn't estimate this model, as he suspected the</span>
<span id="cb31-1324"><a href="#cb31-1324" aria-hidden="true" tabindex="-1"></a>presence of heteroskedascticity. Therefore, he estimates a model for</span>
<span id="cb31-1325"><a href="#cb31-1325" aria-hidden="true" tabindex="-1"></a>which $\sigma$ is replaced by $\sigma_n = e^{\delta^\top w_n}$,</span>
<span id="cb31-1326"><a href="#cb31-1326" aria-hidden="true" tabindex="-1"></a>where $w_n$ are a set of covariates and $\delta$ a set of further</span>
<span id="cb31-1327"><a href="#cb31-1327" aria-hidden="true" tabindex="-1"></a>parameters to be estimated. The <span class="in">`crch::crch`</span> function <span class="co">[</span><span class="ot">@MESS:MAYR:ZEIL:WILK:14</span><span class="co">]</span></span>
<span id="cb31-1328"><a href="#cb31-1328" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Messner}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Mayr}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Zeileis}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wilks}enables the estimation of</span>
<span id="cb31-1329"><a href="#cb31-1329" aria-hidden="true" tabindex="-1"></a>such models. The model is described using a two-part formula, the</span>
<span id="cb31-1330"><a href="#cb31-1330" aria-hidden="true" tabindex="-1"></a>second one containing the covariates that are used to estimate</span>
<span id="cb31-1331"><a href="#cb31-1331" aria-hidden="true" tabindex="-1"></a>$\sigma_n$. By default, a logistic link is used ($\ln \sigma_n =</span>
<span id="cb31-1332"><a href="#cb31-1332" aria-hidden="true" tabindex="-1"></a>\gamma ^ \top z_n$), but other links can be selected using the</span>
<span id="cb31-1333"><a href="#cb31-1333" aria-hidden="true" tabindex="-1"></a><span class="in">`link.scale`</span> argument. Moreover, departure from normality can be taken</span>
<span id="cb31-1334"><a href="#cb31-1334" aria-hidden="true" tabindex="-1"></a>into account using the <span class="in">`dist`</span> argument by, for example, switching</span>
<span id="cb31-1335"><a href="#cb31-1335" aria-hidden="true" tabindex="-1"></a>from a gaussian distribution (the default) to a Student or a</span>
<span id="cb31-1336"><a href="#cb31-1336" aria-hidden="true" tabindex="-1"></a>logistic. For the skedasticity function, we use all the covariates</span>
<span id="cb31-1337"><a href="#cb31-1337" aria-hidden="true" tabindex="-1"></a>used in the main equation except <span class="in">`uncert`</span> and <span class="in">`expinc`</span> which appear to</span>
<span id="cb31-1338"><a href="#cb31-1338" aria-hidden="true" tabindex="-1"></a>be insignificant. </span>
<span id="cb31-1339"><a href="#cb31-1339" aria-hidden="true" tabindex="-1"></a>\idxfun{crch}{crch}</span>
<span id="cb31-1340"><a href="#cb31-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1341"><a href="#cb31-1341" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1342"><a href="#cb31-1342" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: crch</span></span>
<span id="cb31-1343"><a href="#cb31-1343" aria-hidden="true" tabindex="-1"></a>prec_ht <span class="ot">&lt;-</span> crch<span class="sc">::</span><span class="fu">crch</span>(share <span class="sc">~</span> uncert <span class="sc">+</span> expinc <span class="sc">+</span> networth <span class="sc">+</span></span>
<span id="cb31-1344"><a href="#cb31-1344" aria-hidden="true" tabindex="-1"></a>        age <span class="sc">+</span> agesq <span class="sc">+</span> female <span class="sc">|</span> networth <span class="sc">+</span></span>
<span id="cb31-1345"><a href="#cb31-1345" aria-hidden="true" tabindex="-1"></a>        age <span class="sc">+</span> agesq <span class="sc">+</span> female, <span class="at">left =</span> <span class="dv">0</span>, <span class="at">right =</span> <span class="dv">1</span>,</span>
<span id="cb31-1346"><a href="#cb31-1346" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> portfolio)</span>
<span id="cb31-1347"><a href="#cb31-1347" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(prec_ht)</span>
<span id="cb31-1348"><a href="#cb31-1348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1349"><a href="#cb31-1349" aria-hidden="true" tabindex="-1"></a>\idxfun{tobit1}{micsr}</span>
<span id="cb31-1350"><a href="#cb31-1350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1353"><a href="#cb31-1353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1354"><a href="#cb31-1354" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tobit1_heter</span></span>
<span id="cb31-1355"><a href="#cb31-1355" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb31-1356"><a href="#cb31-1356" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb31-1357"><a href="#cb31-1357" aria-hidden="true" tabindex="-1"></a>prec_ht2 <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(share <span class="sc">~</span> uncert <span class="sc">+</span> expinc <span class="sc">+</span> networth <span class="sc">+</span></span>
<span id="cb31-1358"><a href="#cb31-1358" aria-hidden="true" tabindex="-1"></a>        age <span class="sc">+</span> agesq <span class="sc">+</span> female <span class="sc">|</span> networth <span class="sc">+</span></span>
<span id="cb31-1359"><a href="#cb31-1359" aria-hidden="true" tabindex="-1"></a>        age <span class="sc">+</span> agesq <span class="sc">+</span> female, <span class="at">left =</span> <span class="dv">0</span>, <span class="at">right =</span> <span class="dv">1</span>,</span>
<span id="cb31-1360"><a href="#cb31-1360" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> portfolio, <span class="at">scedas =</span> <span class="st">"exp"</span>)</span>
<span id="cb31-1361"><a href="#cb31-1361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1362"><a href="#cb31-1362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1363"><a href="#cb31-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1364"><a href="#cb31-1364" aria-hidden="true" tabindex="-1"></a>Without conducting a formal test, it is clear that the heteroskedastic</span>
<span id="cb31-1365"><a href="#cb31-1365" aria-hidden="true" tabindex="-1"></a>specification is supported by the data, the log-likelihood value of</span>
<span id="cb31-1366"><a href="#cb31-1366" aria-hidden="true" tabindex="-1"></a>the second specification being much larger than the one of standard</span>
<span id="cb31-1367"><a href="#cb31-1367" aria-hidden="true" tabindex="-1"></a>tobit model. The value of some coefficients are strikingly</span>
<span id="cb31-1368"><a href="#cb31-1368" aria-hidden="true" tabindex="-1"></a>different. For example, the coefficient of <span class="in">`networth`</span> is</span>
<span id="cb31-1369"><a href="#cb31-1369" aria-hidden="true" tabindex="-1"></a>$<span class="in">`r round(coef(prec_ml)["networth"], 3)`</span>$ for the tobit model, but</span>
<span id="cb31-1370"><a href="#cb31-1370" aria-hidden="true" tabindex="-1"></a>$<span class="in">`r coef(prec_ht)["networth"]`</span>$ for the heteroskedastic model, as this</span>
<span id="cb31-1371"><a href="#cb31-1371" aria-hidden="true" tabindex="-1"></a>covariate also has a huge effect on the conditional variance of the</span>
<span id="cb31-1372"><a href="#cb31-1372" aria-hidden="true" tabindex="-1"></a>response. </span>
<span id="cb31-1373"><a href="#cb31-1373" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{portfolio}{micsr}</span>
<span id="cb31-1374"><a href="#cb31-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1375"><a href="#cb31-1375" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation and tests {#sec-tobit_eval}</span></span>
<span id="cb31-1376"><a href="#cb31-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1377"><a href="#cb31-1377" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditional moment tests</span></span>
<span id="cb31-1378"><a href="#cb31-1378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1379"><a href="#cb31-1379" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{conditional moment test!tobit1|(}</span>
<span id="cb31-1380"><a href="#cb31-1380" aria-hidden="true" tabindex="-1"></a>The most popular method of estimation for the tobit-1 model is the</span>
<span id="cb31-1381"><a href="#cb31-1381" aria-hidden="true" tabindex="-1"></a>fully parametric maximum likelihood method. Contrary to the OLS model,</span>
<span id="cb31-1382"><a href="#cb31-1382" aria-hidden="true" tabindex="-1"></a>the estimator is only consistent if the GDP process is perfectly</span>
<span id="cb31-1383"><a href="#cb31-1383" aria-hidden="true" tabindex="-1"></a>described by the likelihood function, i.e., if $\epsilon_n \sim \mathcal{N}(0,\sigma)$. In particular, the consistency of the estimator rests on the hypothesis of normality and homoskedasticity.</span>
<span id="cb31-1384"><a href="#cb31-1384" aria-hidden="true" tabindex="-1"></a>The conditional moment tests have been presented in @sec-ml_cond_moment_test, they use different powers of the residuals. We have seen in  @sec-cond_moment_binomial for the probit model how to compute these tests when the residuals are not observable: $\epsilon_n ^ k$ is then replaced by $\mbox{E}(\epsilon_n ^ k \mid x_n)$. The computation of the conditional moment test for the tobit model is quite similar, except that the residuals are partially observed (when $d_n=\mathbf{1}(y_n&gt;0) = 1$). Then, we'll use $\epsilon_n ^ k$ if $d_n=1$ and $\mbox{E}(\epsilon_n ^ k \mid x_n)$ if $d_n = 0$. From @eq-moments_normal_trunc, the moments of $\epsilon \sim \mathcal{N}(0, \sigma_\epsilon)$ right-truncated at $-\mu_n$ are, denoting $r_n = \frac{\phi(\mu_n / \sigma_\epsilon)}{1-\Phi(\mu_n / \sigma_\epsilon)}$:</span>
<span id="cb31-1385"><a href="#cb31-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1386"><a href="#cb31-1386" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1387"><a href="#cb31-1387" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) = (k - 1) \sigma_\epsilon ^ 2 m_{k-2} -\sigma_\epsilon (- \mu_n) ^ {k-1} r_n</span>
<span id="cb31-1388"><a href="#cb31-1388" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1389"><a href="#cb31-1389" aria-hidden="true" tabindex="-1"></a>For example, $E(\epsilon_n|x_n, y_n ^ * \leq 0) = -\sigma_\epsilon r_n$, which is the generalized residual for $d_n = 0$, see @eq-gen_residuals_tobit.</span>
<span id="cb31-1390"><a href="#cb31-1390" aria-hidden="true" tabindex="-1"></a>Then a similar table as the one given in @eq-table_moments_probit can be written for the tobit model:</span>
<span id="cb31-1391"><a href="#cb31-1391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1392"><a href="#cb31-1392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1393"><a href="#cb31-1393" aria-hidden="true" tabindex="-1"></a>\begin{array}{clcl}\hline</span>
<span id="cb31-1394"><a href="#cb31-1394" aria-hidden="true" tabindex="-1"></a>k &amp; \mbox{hypothesis} &amp; \mbox{E}(\epsilon_n ^ k \mid x_n \mid \epsilon_n \leq -\mu_n) &amp; \mbox{emp. moment} <span class="sc">\\</span> \hline</span>
<span id="cb31-1395"><a href="#cb31-1395" aria-hidden="true" tabindex="-1"></a>1 &amp; \mbox{omit. variable} &amp; -\sigma r_n &amp;  \frac{1}{N}\sum_n \left<span class="co">[</span><span class="ot">- (1 - d_n) r_n + d_n \epsilon_n)\right</span><span class="co">]</span>w_n<span class="sc">\\</span></span>
<span id="cb31-1396"><a href="#cb31-1396" aria-hidden="true" tabindex="-1"></a>2 &amp; \mbox{homosc.} &amp; \sigma ^ 2(1 + z_n r_n) &amp; \frac{1}{N}\sum_n \left[(1 - d_n)\sigma ^ 2 z_n r_n \right.<span class="sc">\\</span></span>
<span id="cb31-1397"><a href="#cb31-1397" aria-hidden="true" tabindex="-1"></a>&amp; &amp; &amp; \left. + d_n (\epsilon_n ^ 2 - \sigma ^ 2)\right]w_n<span class="sc">\\</span></span>
<span id="cb31-1398"><a href="#cb31-1398" aria-hidden="true" tabindex="-1"></a>3 &amp; \mbox{asymetry} &amp;  - \sigma ^ 3 r_n(2 + z_n ^ 2) r_n &amp;  \frac{1}{N}\sum_n \left[-(1 - d_n)\sigma ^ 3 r_n(2 + z ^ 2) \right. <span class="sc">\\</span></span>
<span id="cb31-1399"><a href="#cb31-1399" aria-hidden="true" tabindex="-1"></a>&amp; &amp; &amp; + \left. d_n \epsilon_n ^ 3\right]w_n<span class="sc">\\</span></span>
<span id="cb31-1400"><a href="#cb31-1400" aria-hidden="true" tabindex="-1"></a>4 &amp; \mbox{kurtosis} &amp; \mbox{E}(\epsilon_n^4 - 3\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \left[(1 - d_n)\sigma ^ 4 z_n r_n(3 + z_n ^ 3) \right.<span class="sc">\\</span></span>
<span id="cb31-1401"><a href="#cb31-1401" aria-hidden="true" tabindex="-1"></a>&amp; &amp; &amp; + \left. d_n (\epsilon_n ^ 4 - 3\sigma ^ 2)\right]w_n <span class="sc">\\</span>\hline</span>
<span id="cb31-1402"><a href="#cb31-1402" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1403"><a href="#cb31-1403" aria-hidden="true" tabindex="-1"></a>$$ {#eq-table_moments_tobit}</span>
<span id="cb31-1404"><a href="#cb31-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1405"><a href="#cb31-1405" aria-hidden="true" tabindex="-1"></a>Conditional moment tests can be computed using</span>
<span id="cb31-1406"><a href="#cb31-1406" aria-hidden="true" tabindex="-1"></a>the <span class="in">`micsr::cmtest`</span> function, which can take as input a model fitted by</span>
<span id="cb31-1407"><a href="#cb31-1407" aria-hidden="true" tabindex="-1"></a>either <span class="in">`AER::tobit`</span>, <span class="in">`censReg::censReg`</span> or <span class="in">`micsr::tobit1`</span>. To test respectively the hypothesis of normality and of homoskedasticity, we use:</span>
<span id="cb31-1408"><a href="#cb31-1408" aria-hidden="true" tabindex="-1"></a>\idxfun{cmtest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1409"><a href="#cb31-1409" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{charitable}{micsr}</span>
<span id="cb31-1410"><a href="#cb31-1410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1411"><a href="#cb31-1411" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1412"><a href="#cb31-1412" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cmtest_tobit_default</span></span>
<span id="cb31-1413"><a href="#cb31-1413" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1414"><a href="#cb31-1414" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"normality"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1415"><a href="#cb31-1415" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"heterosc"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1416"><a href="#cb31-1416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1417"><a href="#cb31-1417" aria-hidden="true" tabindex="-1"></a>\idxfun{cmtest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1418"><a href="#cb31-1418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1419"><a href="#cb31-1419" aria-hidden="true" tabindex="-1"></a><span class="in">```{r include = FALSE}</span></span>
<span id="cb31-1420"><a href="#cb31-1420" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1421"><a href="#cb31-1421" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cmtest_aer_censreg</span></span>
<span id="cb31-1422"><a href="#cb31-1422" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ml_aer) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1423"><a href="#cb31-1423" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ml_creg) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1424"><a href="#cb31-1424" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1425"><a href="#cb31-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1426"><a href="#cb31-1426" aria-hidden="true" tabindex="-1"></a>Normality and heteroskedasticity are strongly rejected. The values are</span>
<span id="cb31-1427"><a href="#cb31-1427" aria-hidden="true" tabindex="-1"></a>different from @WILH:08\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wilhelm}, as he used the "outer product of the gradient" form of the test. These versions of the test can be obtained by</span>
<span id="cb31-1428"><a href="#cb31-1428" aria-hidden="true" tabindex="-1"></a>setting the <span class="in">`opg`</span> argument to <span class="in">`TRUE`</span>.</span>
<span id="cb31-1429"><a href="#cb31-1429" aria-hidden="true" tabindex="-1"></a>\idxfun{cmtest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1430"><a href="#cb31-1430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1431"><a href="#cb31-1431" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1432"><a href="#cb31-1432" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1433"><a href="#cb31-1433" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cmtest_tobit_opg</span></span>
<span id="cb31-1434"><a href="#cb31-1434" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"normality"</span>, <span class="at">opg =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1435"><a href="#cb31-1435" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"heterosc"</span>, <span class="at">opg =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1436"><a href="#cb31-1436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1437"><a href="#cb31-1437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1438"><a href="#cb31-1438" aria-hidden="true" tabindex="-1"></a>Non-normality can be further investigated by testing separately</span>
<span id="cb31-1439"><a href="#cb31-1439" aria-hidden="true" tabindex="-1"></a>the fact that the skewness and kurtosis indicators are respectively</span>
<span id="cb31-1440"><a href="#cb31-1440" aria-hidden="true" tabindex="-1"></a>different from 0 and 3.</span>
<span id="cb31-1441"><a href="#cb31-1441" aria-hidden="true" tabindex="-1"></a>\idxfun{cmtest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb31-1442"><a href="#cb31-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1443"><a href="#cb31-1443" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1444"><a href="#cb31-1444" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: cmtest_tobit_skew_kurt</span></span>
<span id="cb31-1445"><a href="#cb31-1445" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1446"><a href="#cb31-1446" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"skewness"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1447"><a href="#cb31-1447" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(ch_ml, <span class="at">test =</span> <span class="st">"kurtosis"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1448"><a href="#cb31-1448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1449"><a href="#cb31-1449" aria-hidden="true" tabindex="-1"></a>The hypothesis that the conditional distribution of the response is</span>
<span id="cb31-1450"><a href="#cb31-1450" aria-hidden="true" tabindex="-1"></a>mesokurtic is not rejected at the 1% level and the main problem seems</span>
<span id="cb31-1451"><a href="#cb31-1451" aria-hidden="true" tabindex="-1"></a>to be the asymmetry of the distribution, even after taking the</span>
<span id="cb31-1452"><a href="#cb31-1452" aria-hidden="true" tabindex="-1"></a>logarithm of the response. </span>
<span id="cb31-1453"><a href="#cb31-1453" aria-hidden="true" tabindex="-1"></a>This can be illustrated (see @fig-histnorm) by plotting the</span>
<span id="cb31-1454"><a href="#cb31-1454" aria-hidden="true" tabindex="-1"></a>(unconditional) distribution of the response (for positive values) and</span>
<span id="cb31-1455"><a href="#cb31-1455" aria-hidden="true" tabindex="-1"></a>adding to the histogram the normal density curve.</span>
<span id="cb31-1456"><a href="#cb31-1456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1457"><a href="#cb31-1457" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb31-1458"><a href="#cb31-1458" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-histnorm</span></span>
<span id="cb31-1459"><a href="#cb31-1459" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-1460"><a href="#cb31-1460" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Empirical distribution of the response and normal approximation"</span></span>
<span id="cb31-1461"><a href="#cb31-1461" aria-hidden="true" tabindex="-1"></a>moments <span class="ot">&lt;-</span> charitable <span class="sc">%&gt;%</span> <span class="fu">filter</span>(logdon <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">mu =</span> <span class="fu">mean</span>(logdon), <span class="at">sigma =</span> <span class="fu">sd</span>(logdon))</span>
<span id="cb31-1462"><a href="#cb31-1462" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">filter</span>(charitable, logdon <span class="sc">&gt;</span> <span class="dv">0</span>), <span class="fu">aes</span>(logdon)) <span class="sc">+</span></span>
<span id="cb31-1463"><a href="#cb31-1463" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"white"</span>, <span class="at">bins =</span> <span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb31-1464"><a href="#cb31-1464" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> moments<span class="sc">$</span>mu, <span class="at">sd =</span> moments<span class="sc">$</span>sigma)) <span class="sc">+</span></span>
<span id="cb31-1465"><a href="#cb31-1465" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"log of charitable giving"</span>, <span class="at">y =</span> <span class="cn">NULL</span>)</span>
<span id="cb31-1466"><a href="#cb31-1466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1467"><a href="#cb31-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1468"><a href="#cb31-1468" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{charitable}{micsr}</span>
<span id="cb31-1469"><a href="#cb31-1469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1470"><a href="#cb31-1470" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Hausman test --&gt;</span></span>
<span id="cb31-1471"><a href="#cb31-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1472"><a href="#cb31-1472" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- An alternative to the conditional moment tests to test the consistency of the maximum likelihood estimator (using tests of normality and of heteroskedasticity) is to use a Hausman test comparing the maximum likelihood estimator and the symetrically censored least square estimator. With the hypothesis of normal homoskedastic distribution, both estimators are consistent, but the ML estimator is more efficient. With the alternative hypothesis, only the SCLS estimator is consistent. For the `charitable` data set, we estimated both models in @sec-charitable_estimation. Using the `haustest` and excluding the intercept from the set of coefficients we get: --&gt;</span></span>
<span id="cb31-1473"><a href="#cb31-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1474"><a href="#cb31-1474" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r } --&gt;</span></span>
<span id="cb31-1475"><a href="#cb31-1475" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #| collapse: true --&gt;</span></span>
<span id="cb31-1476"><a href="#cb31-1476" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- haustest(ml, scls, omit = "(Intercept)") %&gt;% gaze --&gt;</span></span>
<span id="cb31-1477"><a href="#cb31-1477" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb31-1478"><a href="#cb31-1478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1479"><a href="#cb31-1479" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{conditional moment test!tobit1|)}</span>
<span id="cb31-1480"><a href="#cb31-1480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1481"><a href="#cb31-1481" aria-hidden="true" tabindex="-1"></a><span class="fu">### Endogeneity</span></span>
<span id="cb31-1482"><a href="#cb31-1482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1483"><a href="#cb31-1483" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{endogeneity!tobit1}</span>
<span id="cb31-1484"><a href="#cb31-1484" aria-hidden="true" tabindex="-1"></a>We have seen in @sec-endog_probit how endogeneity can be taken into account in a probit model. The analysis is almost the same for the probit model. The joint density of the distribution of the latent variable $y^*$ and the endogenous covariates $w$ is assumed to be normal and can be written as the product of the marginal density of $w$ (@eq-marg_density_w) and of the conditional density of $y^*$ (@eq-cond_density_y_star). For the tobit model, the former is exactly the same, but the latter is different because, for the probit model, only the sign of $y ^ *$ is observed. This is not the case for the tobit model, the value of the response being observed if $y^*&gt;0$. Therefore, @eq-cond_density_y_star becomes:</span>
<span id="cb31-1485"><a href="#cb31-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1486"><a href="#cb31-1486" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1487"><a href="#cb31-1487" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1488"><a href="#cb31-1488" aria-hidden="true" tabindex="-1"></a>f(y_n \mid w_n) &amp;=&amp; (1 - d_n)\left[1 - \Phi\left(\frac{\gamma ^ \top z_n + \sigma_{\epsilon\nu}</span>
<span id="cb31-1489"><a href="#cb31-1489" aria-hidden="true" tabindex="-1"></a>^ \top \Sigma_\nu ^ {-1}(e_n - \Pi v_n)}{\sqrt{\sigma_\epsilon ^ 2 -</span>
<span id="cb31-1490"><a href="#cb31-1490" aria-hidden="true" tabindex="-1"></a>\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}}}\right)\right]<span class="sc">\\</span></span>
<span id="cb31-1491"><a href="#cb31-1491" aria-hidden="true" tabindex="-1"></a>&amp;-&amp;\frac{1}{2}d_n\left<span class="co">[</span><span class="ot">\ln 2 \pi + \ln (\sigma_\epsilon ^ 2-\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu})+\frac{y_n - \gamma ^ \top z_n - \sigma_{\epsilon\nu} ^ \top \Sigma ^ {-1}_\nu(e_n - \Pi w_n)}{(\sigma_\epsilon ^ 2-\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}))}\right</span><span class="co">]</span></span>
<span id="cb31-1492"><a href="#cb31-1492" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1493"><a href="#cb31-1493" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_density_y_tobit}</span>
<span id="cb31-1494"><a href="#cb31-1494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1495"><a href="#cb31-1495" aria-hidden="true" tabindex="-1"></a>where, as usual, $d_n = \mathbf{1}(y_n ^ * &gt; 0)$. Note that, as the value of the response is partly observed, $\sigma_\epsilon$ is identified, contrary to the probit case where it has been arbitrarily set to 1. As for the probit model, several estimators are available: the maximum likelihood, the two-step and the minimum $\chi ^ 2$ estimators. Moreover, the hypothesis of exogeneity can be performed by computing a Wald test on the two-step estimator.</span>
<span id="cb31-1496"><a href="#cb31-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1497"><a href="#cb31-1497" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{endogeneity!tobit1}</span>
<span id="cb31-1498"><a href="#cb31-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1499"><a href="#cb31-1499" aria-hidden="true" tabindex="-1"></a>In the protection for sale model of @GROS:HELP:94\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Grossman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Helpman}, empirically tested by @GOLD:MAGG:99\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Goldberg}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Maggi}, trade protection is determined by capital owners' lobbying. @MATS:SHER:06\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} extend this model by introducing the potential effect of trade unions' lobbying on trade protection. The response is non-tariff barriers coverage ratio $\tau$, transformed as $\frac{\tau}{1 + \tau}$. The two covariates of @GROS:HELP:94\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Grossman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Helpman} are the inverse of the import penetration ratio^<span class="co">[</span><span class="ot">The value of gross imports divided by the value of shipments.</span><span class="co">]</span> divided by the importation demand elasticity $x_1$ and this variable in interaction with a dummy for capital owners' lobbying $x_2$. The supplementary covariate in the model of @MATS:SHER:06\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} $x_3$ takes into account trade union's lobbying. The data set is called <span class="in">`trade_protection`</span>. We first compute the response and the covariates using raw series:^<span class="co">[</span><span class="ot">The third covariate is quite complicated to compute and is directly available  in `trade_protection` as `labvar`.</span><span class="co">]</span></span>
<span id="cb31-1500"><a href="#cb31-1500" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{rename}{dplyr}</span>
<span id="cb31-1501"><a href="#cb31-1501" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{trade<span class="sc">\_</span>protection}{micsr}</span>
<span id="cb31-1502"><a href="#cb31-1502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1505"><a href="#cb31-1505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1506"><a href="#cb31-1506" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_variables</span></span>
<span id="cb31-1507"><a href="#cb31-1507" aria-hidden="true" tabindex="-1"></a>trade_protection <span class="ot">&lt;-</span> trade_protection <span class="sc">%&gt;%</span> </span>
<span id="cb31-1508"><a href="#cb31-1508" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> ntb <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> ntb),</span>
<span id="cb31-1509"><a href="#cb31-1509" aria-hidden="true" tabindex="-1"></a>         <span class="at">x1 =</span> vshipped <span class="sc">/</span> imports <span class="sc">/</span> elast,</span>
<span id="cb31-1510"><a href="#cb31-1510" aria-hidden="true" tabindex="-1"></a>         <span class="at">x2 =</span> cap <span class="sc">*</span> x1) <span class="sc">%&gt;%</span> </span>
<span id="cb31-1511"><a href="#cb31-1511" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">x3 =</span> labvar)</span>
<span id="cb31-1512"><a href="#cb31-1512" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1513"><a href="#cb31-1513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1514"><a href="#cb31-1514" aria-hidden="true" tabindex="-1"></a>The theoretical model of @MATS:SHER:06\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} results in the following structural equation:</span>
<span id="cb31-1515"><a href="#cb31-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1516"><a href="#cb31-1516" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1517"><a href="#cb31-1517" aria-hidden="true" tabindex="-1"></a>\frac{\tau}{1+\tau} = - \frac{\Theta}{\Theta + a} x_1 + \frac{1}{\Theta + a}x_2 + \frac{1}{\Theta + a} x_3</span>
<span id="cb31-1518"><a href="#cb31-1518" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1519"><a href="#cb31-1519" aria-hidden="true" tabindex="-1"></a>Therefore, denoting $(\alpha, \beta_1, \beta_2, \beta_3)$ the reduced form parameters, the model of @MATS:SHER:06\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} implies that $\alpha = 0$ and that $\beta_2 = \beta_3$ as, in the model of  @GROS:HELP:94\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Grossman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Helpman} $\alpha = \beta_3 = 0$. @MATS:SHER:06 suspect that the three covariates may be endogenous and therefore use the model of @SMIT:BLUN:86. Three models are estimated: </span>
<span id="cb31-1520"><a href="#cb31-1520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1521"><a href="#cb31-1521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Grossman and Helpman's model \index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Grossman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Helpman} (GH), i.e., $x_3$ is omitted,</span>
<span id="cb31-1522"><a href="#cb31-1522" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Matschke and Sherlund's "full" model, \index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} that doesn't impose that $\beta_2 = \beta_3$,</span>
<span id="cb31-1523"><a href="#cb31-1523" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Matschke and Sherlund's "short" model, \index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} that imposes that $\beta_2 = \beta_3$,</span>
<span id="cb31-1524"><a href="#cb31-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1525"><a href="#cb31-1525" aria-hidden="true" tabindex="-1"></a>The hypothesis that $\alpha = 0$ is not imposed in the three models.</span>
<span id="cb31-1526"><a href="#cb31-1526" aria-hidden="true" tabindex="-1"></a>Numerous instruments are used, as described in @MATS:SHER:06\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke}, page 415 and are defined below as a one-sided formula:</span>
<span id="cb31-1527"><a href="#cb31-1527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1530"><a href="#cb31-1530" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1531"><a href="#cb31-1531" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_instruments</span></span>
<span id="cb31-1532"><a href="#cb31-1532" aria-hidden="true" tabindex="-1"></a>inst <span class="ot">&lt;-</span> <span class="er">~</span> sic3 <span class="sc">+</span> k_serv <span class="sc">+</span> inv <span class="sc">+</span> engsci <span class="sc">+</span> whitecol <span class="sc">+</span> skill <span class="sc">+</span> semskill <span class="sc">+</span> </span>
<span id="cb31-1533"><a href="#cb31-1533" aria-hidden="true" tabindex="-1"></a>  cropland <span class="sc">+</span> pasture <span class="sc">+</span> forest <span class="sc">+</span> coal <span class="sc">+</span> petro <span class="sc">+</span> minerals <span class="sc">+</span> scrconc <span class="sc">+</span> </span>
<span id="cb31-1534"><a href="#cb31-1534" aria-hidden="true" tabindex="-1"></a>  bcrconc <span class="sc">+</span> scrcomp <span class="sc">+</span> bcrcomp <span class="sc">+</span> meps <span class="sc">+</span> kstock <span class="sc">+</span> puni <span class="sc">+</span> geog2 <span class="sc">+</span> tenure <span class="sc">+</span> </span>
<span id="cb31-1535"><a href="#cb31-1535" aria-hidden="true" tabindex="-1"></a>  klratio <span class="sc">+</span> bunion</span>
<span id="cb31-1536"><a href="#cb31-1536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1537"><a href="#cb31-1537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1538"><a href="#cb31-1538" aria-hidden="true" tabindex="-1"></a>The formulas for the different models are, in terms of response and covariates only <span class="in">`y ~ x_1 + x_2`</span> for the GH model, <span class="in">`y ~ x_1 + x_2 + x_3`</span> for the full model and <span class="in">`y ~ x_1 + I(x_2 + x_3)`</span> for the short model. To construct the relevant two-part formulas for the IV estimation, we use the <span class="in">`Formula::as.Formula`</span> function that enables to construct a two-part formula, using a standard formula and a one-sided formula. As an example:</span>
<span id="cb31-1539"><a href="#cb31-1539" aria-hidden="true" tabindex="-1"></a>\idxfun{as.Formula}{Formula}</span>
<span id="cb31-1540"><a href="#cb31-1540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1543"><a href="#cb31-1543" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1544"><a href="#cb31-1544" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: as_formula</span></span>
<span id="cb31-1545"><a href="#cb31-1545" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1546"><a href="#cb31-1546" aria-hidden="true" tabindex="-1"></a>Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="sc">~</span> z1 <span class="sc">+</span> z2 <span class="sc">+</span> z3)</span>
<span id="cb31-1547"><a href="#cb31-1547" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1548"><a href="#cb31-1548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1549"><a href="#cb31-1549" aria-hidden="true" tabindex="-1"></a>We then proceed to the estimation of the three models, using <span class="in">`micsr::tobit1`</span> with the <span class="in">`twostep`</span> method, as in the original paper:</span>
<span id="cb31-1550"><a href="#cb31-1550" aria-hidden="true" tabindex="-1"></a>\idxfun{as.Formula}{Formula}\idxfun{tobit1}{micsr}</span>
<span id="cb31-1551"><a href="#cb31-1551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1554"><a href="#cb31-1554" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1555"><a href="#cb31-1555" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_estimation</span></span>
<span id="cb31-1556"><a href="#cb31-1556" aria-hidden="true" tabindex="-1"></a>GH <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, inst), </span>
<span id="cb31-1557"><a href="#cb31-1557" aria-hidden="true" tabindex="-1"></a>             trade_protection, <span class="at">method =</span> <span class="st">"twostep"</span>) </span>
<span id="cb31-1558"><a href="#cb31-1558" aria-hidden="true" tabindex="-1"></a>Short <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> <span class="fu">I</span>(x2 <span class="sc">+</span> x3), inst),</span>
<span id="cb31-1559"><a href="#cb31-1559" aria-hidden="true" tabindex="-1"></a>                 trade_protection, <span class="at">method =</span> <span class="st">"twostep"</span>)</span>
<span id="cb31-1560"><a href="#cb31-1560" aria-hidden="true" tabindex="-1"></a>Full <span class="ot">&lt;-</span> <span class="fu">tobit1</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, inst),</span>
<span id="cb31-1561"><a href="#cb31-1561" aria-hidden="true" tabindex="-1"></a>               trade_protection, <span class="at">method =</span> <span class="st">"twostep"</span>)</span>
<span id="cb31-1562"><a href="#cb31-1562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1563"><a href="#cb31-1563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1566"><a href="#cb31-1566" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1567"><a href="#cb31-1567" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-1568"><a href="#cb31-1568" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Estimation results of the protection for sale model"</span></span>
<span id="cb31-1569"><a href="#cb31-1569" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-protection_for_sale</span></span>
<span id="cb31-1570"><a href="#cb31-1570" aria-hidden="true" tabindex="-1"></a>modelsummary<span class="sc">::</span><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="at">GH =</span> GH, <span class="at">Full =</span> Full, <span class="at">Short =</span> Short), </span>
<span id="cb31-1571"><a href="#cb31-1571" aria-hidden="true" tabindex="-1"></a>                       <span class="at">fmt =</span> <span class="dv">4</span>, <span class="at">estimate =</span> <span class="st">"{estimate}{stars}"</span>,</span>
<span id="cb31-1572"><a href="#cb31-1572" aria-hidden="true" tabindex="-1"></a>                       <span class="at">coef_map =</span> <span class="fu">c</span>(<span class="st">"(Intercept)"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">alpha$"</span>,</span>
<span id="cb31-1573"><a href="#cb31-1573" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"x1"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">beta_1$"</span>, <span class="st">"x2"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">beta_2$"</span>, </span>
<span id="cb31-1574"><a href="#cb31-1574" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"x3"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">beta_3$"</span>, </span>
<span id="cb31-1575"><a href="#cb31-1575" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"I(x2 + x3)"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">beta_2 = </span><span class="sc">\\</span><span class="st">beta_3$"</span>,</span>
<span id="cb31-1576"><a href="#cb31-1576" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"rho_x1"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">gamma_1$"</span>, <span class="st">"rho_x2"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">gamma_2$"</span>,</span>
<span id="cb31-1577"><a href="#cb31-1577" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"rho_x3"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">gamma_3$"</span>,</span>
<span id="cb31-1578"><a href="#cb31-1578" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"rho_I(x2 + x3)"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">gamma_2 = </span><span class="sc">\\</span><span class="st">gamma_3$"</span>,</span>
<span id="cb31-1579"><a href="#cb31-1579" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"sigma"</span> <span class="ot">=</span> <span class="st">"$</span><span class="sc">\\</span><span class="st">sigma$"</span>),</span>
<span id="cb31-1580"><a href="#cb31-1580" aria-hidden="true" tabindex="-1"></a>                       <span class="at">escape =</span> <span class="cn">FALSE</span>, <span class="at">output =</span> <span class="st">"kableExtra"</span>)</span>
<span id="cb31-1581"><a href="#cb31-1581" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1582"><a href="#cb31-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1583"><a href="#cb31-1583" aria-hidden="true" tabindex="-1"></a>The results are presented in @tbl-protection_for_sale.^<span class="co">[</span><span class="ot">See @MATS:SHER:06\index[author]{Sherlund}\index[author]{Matschke}, table 3, page 417.</span><span class="co">]</span> As in the original article, we use the name of the coefficients and not the name of the terms, which are listed below:</span>
<span id="cb31-1584"><a href="#cb31-1584" aria-hidden="true" tabindex="-1"></a>\idxfun{names}{base}\idxfun{coef}{stats}</span>
<span id="cb31-1585"><a href="#cb31-1585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1588"><a href="#cb31-1588" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1589"><a href="#cb31-1589" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_names</span></span>
<span id="cb31-1590"><a href="#cb31-1590" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1591"><a href="#cb31-1591" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">coef</span>(Full))</span>
<span id="cb31-1592"><a href="#cb31-1592" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1593"><a href="#cb31-1593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1594"><a href="#cb31-1594" aria-hidden="true" tabindex="-1"></a>For example, <span class="in">`x2`</span> is replaced by $\beta_2$ and <span class="in">`rho_x2`</span> by $\gamma_2$. Tests of exogeneity for the three models give:</span>
<span id="cb31-1595"><a href="#cb31-1595" aria-hidden="true" tabindex="-1"></a>\idxfun{endogtest}{micsr}\idxfun{as.Formula}{Formula}</span>
<span id="cb31-1596"><a href="#cb31-1596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1599"><a href="#cb31-1599" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1600"><a href="#cb31-1600" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_tests</span></span>
<span id="cb31-1601"><a href="#cb31-1601" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1602"><a href="#cb31-1602" aria-hidden="true" tabindex="-1"></a><span class="fu">endogtest</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, inst), </span>
<span id="cb31-1603"><a href="#cb31-1603" aria-hidden="true" tabindex="-1"></a>          trade_protection, <span class="at">model =</span> <span class="st">"tobit"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1604"><a href="#cb31-1604" aria-hidden="true" tabindex="-1"></a><span class="fu">endogtest</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> <span class="fu">I</span>(x2 <span class="sc">+</span> x3), inst), </span>
<span id="cb31-1605"><a href="#cb31-1605" aria-hidden="true" tabindex="-1"></a>          trade_protection, <span class="at">model =</span> <span class="st">"tobit"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1606"><a href="#cb31-1606" aria-hidden="true" tabindex="-1"></a><span class="fu">endogtest</span>(Formula<span class="sc">::</span><span class="fu">as.Formula</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, inst), </span>
<span id="cb31-1607"><a href="#cb31-1607" aria-hidden="true" tabindex="-1"></a>          trade_protection, <span class="at">model =</span> <span class="st">"tobit"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1608"><a href="#cb31-1608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1609"><a href="#cb31-1609" aria-hidden="true" tabindex="-1"></a>The exogeneity hypothesis is not rejected for the GH model, but it is for the two versions of Matschke and Sherlund's model. \index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} The GH model, which is a special case of the Full model is relevant if the hypotheses $\beta_3 = \gamma_3 = 0$ are not rejected. Performing a Wald test, we get:</span>
<span id="cb31-1610"><a href="#cb31-1610" aria-hidden="true" tabindex="-1"></a>\idxfun{waldtest}{lmtest}\idxfun{gaze}{micsr}</span>
<span id="cb31-1611"><a href="#cb31-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1614"><a href="#cb31-1614" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1615"><a href="#cb31-1615" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1616"><a href="#cb31-1616" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_wald1</span></span>
<span id="cb31-1617"><a href="#cb31-1617" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">waldtest</span>(Full, GH) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1618"><a href="#cb31-1618" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1619"><a href="#cb31-1619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1620"><a href="#cb31-1620" aria-hidden="true" tabindex="-1"></a>and the hypothesis is therefore rejected at the 5% (but not at the 1%) level. Then, the hypothesis that $\beta_2 = \beta_3$ and $\gamma_2 = \gamma_3$ implied by</span>
<span id="cb31-1621"><a href="#cb31-1621" aria-hidden="true" tabindex="-1"></a>Matschke and Sherlund's\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Sherlund}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Matschke} model can be tested:</span>
<span id="cb31-1622"><a href="#cb31-1622" aria-hidden="true" tabindex="-1"></a>\idxfun{linearHypothesis}{car}\idxfun{gaze}{micsr}</span>
<span id="cb31-1623"><a href="#cb31-1623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1626"><a href="#cb31-1626" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1627"><a href="#cb31-1627" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trade_protection_wald2</span></span>
<span id="cb31-1628"><a href="#cb31-1628" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb31-1629"><a href="#cb31-1629" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(Full, <span class="fu">c</span>(<span class="st">"x2 = x3"</span>, <span class="st">"rho_x2 = rho_x3"</span>)) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb31-1630"><a href="#cb31-1630" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1631"><a href="#cb31-1631" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{trade<span class="sc">\_</span>protection}{micsr}</span>
<span id="cb31-1632"><a href="#cb31-1632" aria-hidden="true" tabindex="-1"></a>and is not rejected.</span>
<span id="cb31-1633"><a href="#cb31-1633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1634"><a href="#cb31-1634" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tobit-2 model {#sec-tobit2}</span></span>
<span id="cb31-1635"><a href="#cb31-1635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1636"><a href="#cb31-1636" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-2|(}</span>
<span id="cb31-1637"><a href="#cb31-1637" aria-hidden="true" tabindex="-1"></a>**Tobit-2** models are bivariate models, the first equation being the</span>
<span id="cb31-1638"><a href="#cb31-1638" aria-hidden="true" tabindex="-1"></a>**selection equation** and the second the **outcome equation**. The model</span>
<span id="cb31-1639"><a href="#cb31-1639" aria-hidden="true" tabindex="-1"></a>can be written as follow:</span>
<span id="cb31-1640"><a href="#cb31-1640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1641"><a href="#cb31-1641" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1642"><a href="#cb31-1642" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-1643"><a href="#cb31-1643" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1644"><a href="#cb31-1644" aria-hidden="true" tabindex="-1"></a>y_1 ^ * &amp;=&amp; \alpha_1 + \beta_1^\top x_1 + \epsilon_1  = \mu_1 + \epsilon_1<span class="sc">\\</span></span>
<span id="cb31-1645"><a href="#cb31-1645" aria-hidden="true" tabindex="-1"></a>y_2 ^ * &amp;=&amp; \alpha_1 + \beta_2^\top x_2 + \epsilon_2 = \mu_2 + \epsilon_2<span class="sc">\\</span></span>
<span id="cb31-1646"><a href="#cb31-1646" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1647"><a href="#cb31-1647" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-1648"><a href="#cb31-1648" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1649"><a href="#cb31-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1650"><a href="#cb31-1650" aria-hidden="true" tabindex="-1"></a>and the observation rule is:</span>
<span id="cb31-1651"><a href="#cb31-1651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1652"><a href="#cb31-1652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1653"><a href="#cb31-1653" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-1654"><a href="#cb31-1654" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1655"><a href="#cb31-1655" aria-hidden="true" tabindex="-1"></a>y  &amp;=&amp; y_2^* \mbox{ if } y_1^* &gt; 0<span class="sc">\\</span></span>
<span id="cb31-1656"><a href="#cb31-1656" aria-hidden="true" tabindex="-1"></a>y  &amp;=&amp; 0 \mbox{ if } y_1^* \leq 0<span class="sc">\\</span></span>
<span id="cb31-1657"><a href="#cb31-1657" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1658"><a href="#cb31-1658" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-1659"><a href="#cb31-1659" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1660"><a href="#cb31-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1661"><a href="#cb31-1661" aria-hidden="true" tabindex="-1"></a>Note that the tobit-2 model reduces to the tobit-1 model if $x_1=x_2$</span>
<span id="cb31-1662"><a href="#cb31-1662" aria-hidden="true" tabindex="-1"></a>and $\beta_1=\beta_2$. In the outcome equation, $y_2 ^ *$ can be</span>
<span id="cb31-1663"><a href="#cb31-1663" aria-hidden="true" tabindex="-1"></a>replaced by $\ln y_2 ^*$, so that predicted values of $y_2$ are</span>
<span id="cb31-1664"><a href="#cb31-1664" aria-hidden="true" tabindex="-1"></a>necessarily positive. </span>
<span id="cb31-1665"><a href="#cb31-1665" aria-hidden="true" tabindex="-1"></a>The tobit-2 model is more general than the tobit-1 model, as it allows the</span>
<span id="cb31-1666"><a href="#cb31-1666" aria-hidden="true" tabindex="-1"></a>economic mechanisms that explain the fact that the response is</span>
<span id="cb31-1667"><a href="#cb31-1667" aria-hidden="true" tabindex="-1"></a>observed to be different from those that explain the value of the</span>
<span id="cb31-1668"><a href="#cb31-1668" aria-hidden="true" tabindex="-1"></a>response.</span>
<span id="cb31-1669"><a href="#cb31-1669" aria-hidden="true" tabindex="-1"></a>The seminal papers about the tobit-2 model are @GRON:73\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Gronau} with his model of female labor supply, and Heckman <span class="co">[</span><span class="ot">-@HECK:76; -@HECK:79</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Heckman} who precisely described the</span>
<span id="cb31-1670"><a href="#cb31-1670" aria-hidden="true" tabindex="-1"></a>statistical properties of this model and proposed a two-step</span>
<span id="cb31-1671"><a href="#cb31-1671" aria-hidden="true" tabindex="-1"></a>estimator.</span>
<span id="cb31-1672"><a href="#cb31-1672" aria-hidden="true" tabindex="-1"></a>Hurdle models, proposed by @CRAG:71,\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Cragg} can also be considered as tobit-2</span>
<span id="cb31-1673"><a href="#cb31-1673" aria-hidden="true" tabindex="-1"></a>models. These models describe the level of consumption of a good as a</span>
<span id="cb31-1674"><a href="#cb31-1674" aria-hidden="true" tabindex="-1"></a>two-step process: first, the good should be selected (selection</span>
<span id="cb31-1675"><a href="#cb31-1675" aria-hidden="true" tabindex="-1"></a>equation) and then the level of the consumption is set (outcome</span>
<span id="cb31-1676"><a href="#cb31-1676" aria-hidden="true" tabindex="-1"></a>equation). </span>
<span id="cb31-1677"><a href="#cb31-1677" aria-hidden="true" tabindex="-1"></a>The tobit-2 model is also widely used to measure the treatment effect</span>
<span id="cb31-1678"><a href="#cb31-1678" aria-hidden="true" tabindex="-1"></a>of public programs. If the selection of individuals in a particular</span>
<span id="cb31-1679"><a href="#cb31-1679" aria-hidden="true" tabindex="-1"></a>program is not purely random, the selection equation describes as a</span>
<span id="cb31-1680"><a href="#cb31-1680" aria-hidden="true" tabindex="-1"></a>binomial model the process of getting hired in the program and the</span>
<span id="cb31-1681"><a href="#cb31-1681" aria-hidden="true" tabindex="-1"></a>outcome equation measures the effectiveness of the program, e.g., </span>
<span id="cb31-1682"><a href="#cb31-1682" aria-hidden="true" tabindex="-1"></a>the wage one year after leaving the program.</span>
<span id="cb31-1683"><a href="#cb31-1683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1684"><a href="#cb31-1684" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two-part models</span></span>
<span id="cb31-1685"><a href="#cb31-1685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1686"><a href="#cb31-1686" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-part models|(}</span>
<span id="cb31-1687"><a href="#cb31-1687" aria-hidden="true" tabindex="-1"></a>With the assumption of uncorrelation between $\epsilon_1$ and</span>
<span id="cb31-1688"><a href="#cb31-1688" aria-hidden="true" tabindex="-1"></a>$\epsilon_2$ (which means uncorrelation of the unobserved part of the</span>
<span id="cb31-1689"><a href="#cb31-1689" aria-hidden="true" tabindex="-1"></a>two responses), the tobit-2 model is called the **two-part** model, and the</span>
<span id="cb31-1690"><a href="#cb31-1690" aria-hidden="true" tabindex="-1"></a>two equations can be estimated independently, the first by any</span>
<span id="cb31-1691"><a href="#cb31-1691" aria-hidden="true" tabindex="-1"></a>binomial model (very frequently but not necessarily a probit) with the</span>
<span id="cb31-1692"><a href="#cb31-1692" aria-hidden="true" tabindex="-1"></a>response equal to 0/1 for positive/negative values of $y_1^*$ and the</span>
<span id="cb31-1693"><a href="#cb31-1693" aria-hidden="true" tabindex="-1"></a>second by least squares (with either $y_2$ or $\ln y_2$ as the</span>
<span id="cb31-1694"><a href="#cb31-1694" aria-hidden="true" tabindex="-1"></a>response). The main advantage of this model is that it can be</span>
<span id="cb31-1695"><a href="#cb31-1695" aria-hidden="true" tabindex="-1"></a>estimated without further hypothesis about the conditional</span>
<span id="cb31-1696"><a href="#cb31-1696" aria-hidden="true" tabindex="-1"></a>distribution of $y_2$ and can therefore be viewed as a semi-parametric</span>
<span id="cb31-1697"><a href="#cb31-1697" aria-hidden="true" tabindex="-1"></a>estimator, which would be consistent in a wide variety of contexts (e.g., </span>
<span id="cb31-1698"><a href="#cb31-1698" aria-hidden="true" tabindex="-1"></a>heteroskedasticity and non-normality).</span>
<span id="cb31-1699"><a href="#cb31-1699" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-part models|(}</span>
<span id="cb31-1700"><a href="#cb31-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1701"><a href="#cb31-1701" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hurdle models</span></span>
<span id="cb31-1702"><a href="#cb31-1702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1703"><a href="#cb31-1703" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{hurdle model!censored regression model|(}</span>
<span id="cb31-1704"><a href="#cb31-1704" aria-hidden="true" tabindex="-1"></a>Hurdle models, proposed by @CRAG:71,\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Cragg} share with the two-part models the fact that the errors of the two equations are uncorrelated. Cragg</span>
<span id="cb31-1705"><a href="#cb31-1705" aria-hidden="true" tabindex="-1"></a>proposed three flavors of hurdle models: </span>
<span id="cb31-1706"><a href="#cb31-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1707"><a href="#cb31-1707" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>simple hurdle models with a log-normal or a truncated normal</span>
<span id="cb31-1708"><a href="#cb31-1708" aria-hidden="true" tabindex="-1"></a>distribution for the outcome response,</span>
<span id="cb31-1709"><a href="#cb31-1709" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>double hurdle models with a normal distribution for the outcome</span>
<span id="cb31-1710"><a href="#cb31-1710" aria-hidden="true" tabindex="-1"></a>  response.</span>
<span id="cb31-1711"><a href="#cb31-1711" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-1712"><a href="#cb31-1712" aria-hidden="true" tabindex="-1"></a>The **log-normal simple hurdle** model is a two-part model for</span>
<span id="cb31-1713"><a href="#cb31-1713" aria-hidden="true" tabindex="-1"></a>which the outcome equation consists of a linear regression of the</span>
<span id="cb31-1714"><a href="#cb31-1714" aria-hidden="true" tabindex="-1"></a>logarithm of the outcome equation on the set of covariates $x_2$,</span>
<span id="cb31-1715"><a href="#cb31-1715" aria-hidden="true" tabindex="-1"></a>which is consistent even without the hypothesis of normality and homoskedasticity.</span>
<span id="cb31-1716"><a href="#cb31-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1717"><a href="#cb31-1717" aria-hidden="true" tabindex="-1"></a>The **truncated normal simple hurdle** model shares with</span>
<span id="cb31-1718"><a href="#cb31-1718" aria-hidden="true" tabindex="-1"></a>two-part models the fact that the two equations can be estimated</span>
<span id="cb31-1719"><a href="#cb31-1719" aria-hidden="true" tabindex="-1"></a>independently, but the outcome equation is estimated by maximum</span>
<span id="cb31-1720"><a href="#cb31-1720" aria-hidden="true" tabindex="-1"></a>likelihood and therefore the consistency of the estimator relies on the hypothesis of normality and homoskedasticity.</span>
<span id="cb31-1721"><a href="#cb31-1721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1722"><a href="#cb31-1722" aria-hidden="true" tabindex="-1"></a>Finally, the **normal double hurdle model** is not per se a</span>
<span id="cb31-1723"><a href="#cb31-1723" aria-hidden="true" tabindex="-1"></a>tobit-2 model because zero observations may appear not only because</span>
<span id="cb31-1724"><a href="#cb31-1724" aria-hidden="true" tabindex="-1"></a>$y_1^* &lt; 0$, but also because $y_2^* &lt; 0$. If the response is the expenditure for a given good, it is positive only if the good is selected by the household ($y_1^* &gt; 0$) and if the solution of the consumer problem is not a corner solution ($y_2 ^ * &gt; 0$). </span>
<span id="cb31-1725"><a href="#cb31-1725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1726"><a href="#cb31-1726" aria-hidden="true" tabindex="-1"></a>For this latter model, we have $\mbox{P}(y_1 ^ * &gt; 0) = 1 - \Phi(-\mu_1) =\Phi(\mu_1)$, </span>
<span id="cb31-1727"><a href="#cb31-1727" aria-hidden="true" tabindex="-1"></a>$\mbox{P}(y_2 ^ * &gt; 0) = 1 - \Phi(-\mu_2/\sigma)=\Phi(\mu_2/\sigma)$,</span>
<span id="cb31-1728"><a href="#cb31-1728" aria-hidden="true" tabindex="-1"></a>so that, given the hypothesis of independence of the two errors:</span>
<span id="cb31-1729"><a href="#cb31-1729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1730"><a href="#cb31-1730" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1731"><a href="#cb31-1731" aria-hidden="true" tabindex="-1"></a>\mbox{P}(y &gt; 0) = \Phi(\mu_1)\Phi(\mu_2/\sigma)</span>
<span id="cb31-1732"><a href="#cb31-1732" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1733"><a href="#cb31-1733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1734"><a href="#cb31-1734" aria-hidden="true" tabindex="-1"></a>The density of $y$ for positive values of $y$ is:</span>
<span id="cb31-1735"><a href="#cb31-1735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1736"><a href="#cb31-1736" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1737"><a href="#cb31-1737" aria-hidden="true" tabindex="-1"></a>f(y \mid x_2, y &gt; 0) = \frac{1}{\sigma}\frac{\phi\left(\frac{y -</span>
<span id="cb31-1738"><a href="#cb31-1738" aria-hidden="true" tabindex="-1"></a>\mu_2}{\sigma}\right)}{\Phi\left(\frac{y -</span>
<span id="cb31-1739"><a href="#cb31-1739" aria-hidden="true" tabindex="-1"></a>\mu_2}{\sigma}\right)}</span>
<span id="cb31-1740"><a href="#cb31-1740" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1741"><a href="#cb31-1741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1742"><a href="#cb31-1742" aria-hidden="true" tabindex="-1"></a>So that finally, the likelihood is:</span>
<span id="cb31-1743"><a href="#cb31-1743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1744"><a href="#cb31-1744" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1745"><a href="#cb31-1745" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1746"><a href="#cb31-1746" aria-hidden="true" tabindex="-1"></a>L^{2H}(\gamma_1, \gamma_2, \sigma | y, X)&amp;=&amp;\prod_{n=1}^{N_o}</span>
<span id="cb31-1747"><a href="#cb31-1747" aria-hidden="true" tabindex="-1"></a>\left[1 - </span>
<span id="cb31-1748"><a href="#cb31-1748" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n1})</span>
<span id="cb31-1749"><a href="#cb31-1749" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n2}/\sigma)</span>
<span id="cb31-1750"><a href="#cb31-1750" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb31-1751"><a href="#cb31-1751" aria-hidden="true" tabindex="-1"></a>\prod_{n = N_o + 1}^{N}\Phi(\mu_{n2}/\sigma)</span>
<span id="cb31-1752"><a href="#cb31-1752" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n1}) <span class="sc">\\</span></span>
<span id="cb31-1753"><a href="#cb31-1753" aria-hidden="true" tabindex="-1"></a>&amp;\times&amp; \prod_{n = N_o + 1}^{N}\frac{1}{\sigma}\frac{\phi\left(\frac{y_n-\mu_{n2}}{\sigma}\right)}</span>
<span id="cb31-1754"><a href="#cb31-1754" aria-hidden="true" tabindex="-1"></a>{\Phi(\mu_{n2}/\sigma)}</span>
<span id="cb31-1755"><a href="#cb31-1755" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1756"><a href="#cb31-1756" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1757"><a href="#cb31-1757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1758"><a href="#cb31-1758" aria-hidden="true" tabindex="-1"></a>This expression is very similar to @eq-tobit1_probit_plus_trunc which indicates that the likelihood for the tobit-1 model is the product of:</span>
<span id="cb31-1759"><a href="#cb31-1759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1760"><a href="#cb31-1760" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the likelihood of a probit model which explains that $y=0$ or $y &gt;  0$,</span>
<span id="cb31-1761"><a href="#cb31-1761" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the likelihood of $y$ for the truncated sample. </span>
<span id="cb31-1762"><a href="#cb31-1762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1763"><a href="#cb31-1763" aria-hidden="true" tabindex="-1"></a>The second term is exactly the same, but the first one is different, as the probability of a positive value of $y$ is now $\Phi(\mu_2/\sigma)\Phi(\mu_1)$.</span>
<span id="cb31-1764"><a href="#cb31-1764" aria-hidden="true" tabindex="-1"></a>The likelihood can be simplified as:</span>
<span id="cb31-1765"><a href="#cb31-1765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1766"><a href="#cb31-1766" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1767"><a href="#cb31-1767" aria-hidden="true" tabindex="-1"></a>L^{2H}(\gamma_1, \gamma_2, \sigma | y,X)=\prod_{n=1}^{N_o}</span>
<span id="cb31-1768"><a href="#cb31-1768" aria-hidden="true" tabindex="-1"></a>\left[1 - </span>
<span id="cb31-1769"><a href="#cb31-1769" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n1})</span>
<span id="cb31-1770"><a href="#cb31-1770" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n2} / \sigma)</span>
<span id="cb31-1771"><a href="#cb31-1771" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb31-1772"><a href="#cb31-1772" aria-hidden="true" tabindex="-1"></a>\prod_{n = N_o + 1}^{N}\frac{1}{\sigma}\Phi(\mu_{n1})</span>
<span id="cb31-1773"><a href="#cb31-1773" aria-hidden="true" tabindex="-1"></a>\phi\left(\frac{y_n-\mu_{2n}}{\sigma}\right)</span>
<span id="cb31-1774"><a href="#cb31-1774" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1775"><a href="#cb31-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1776"><a href="#cb31-1776" aria-hidden="true" tabindex="-1"></a>Hurdle models can be estimated using the **mhurdle** package <span class="co">[</span><span class="ot">@CARL:CROI:23</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Carlevaro}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Croissant}.</span>
<span id="cb31-1777"><a href="#cb31-1777" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{hurdle model!censored regression model|)}</span>
<span id="cb31-1778"><a href="#cb31-1778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1779"><a href="#cb31-1779" aria-hidden="true" tabindex="-1"></a><span class="fu">### Correlated models</span></span>
<span id="cb31-1780"><a href="#cb31-1780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1781"><a href="#cb31-1781" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heckit model|(}</span>
<span id="cb31-1782"><a href="#cb31-1782" aria-hidden="true" tabindex="-1"></a>Finally, we consider the case where the errors of the two equations are</span>
<span id="cb31-1783"><a href="#cb31-1783" aria-hidden="true" tabindex="-1"></a>correlated. In this case, the model should be fully parametrized and</span>
<span id="cb31-1784"><a href="#cb31-1784" aria-hidden="true" tabindex="-1"></a>a natural way to do it is to suppose that $y_1^*$ and $y_2^*$ (or $\ln y_2 ^ *$) follow a bivariate normal distribution. The variance of $y_1^*$ is arbitrarily set to 1, as only the sign of $y_1 ^ *$ is observed. Therefore, we can write the system of two equations as:</span>
<span id="cb31-1785"><a href="#cb31-1785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1786"><a href="#cb31-1786" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1787"><a href="#cb31-1787" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb31-1788"><a href="#cb31-1788" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1789"><a href="#cb31-1789" aria-hidden="true" tabindex="-1"></a>y_1 ^ * &amp;=&amp; \gamma_1 ^ \top z_1 + \epsilon_1 = \mu_1 + u_1 <span class="sc">\\</span></span>
<span id="cb31-1790"><a href="#cb31-1790" aria-hidden="true" tabindex="-1"></a>y_2 ^ * &amp;=&amp; \gamma_2 ^ \top z_2 + \epsilon_2 = \mu_2 + \sigma u_2</span>
<span id="cb31-1791"><a href="#cb31-1791" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1792"><a href="#cb31-1792" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb31-1793"><a href="#cb31-1793" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1794"><a href="#cb31-1794" aria-hidden="true" tabindex="-1"></a>where $u_1$ and $u_2$ are a couple of standard normal deviates. Then the joint distribution of the two latent variables is:</span>
<span id="cb31-1795"><a href="#cb31-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1796"><a href="#cb31-1796" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1797"><a href="#cb31-1797" aria-hidden="true" tabindex="-1"></a>\left( \begin{array}{c} y_1 ^ * <span class="sc">\\</span> y_2 ^ * \end{array} \right) \sim</span>
<span id="cb31-1798"><a href="#cb31-1798" aria-hidden="true" tabindex="-1"></a>\mathcal{N} \left( \left( \begin{array}{c} \mu_1 <span class="sc">\\</span> \mu_2 \end{array} \right) ,</span>
<span id="cb31-1799"><a href="#cb31-1799" aria-hidden="true" tabindex="-1"></a>\left(  \begin{array}{cc} 1 &amp; \rho \sigma <span class="sc">\\</span> </span>
<span id="cb31-1800"><a href="#cb31-1800" aria-hidden="true" tabindex="-1"></a>                          \rho \sigma &amp; \sigma ^ 2</span>
<span id="cb31-1801"><a href="#cb31-1801" aria-hidden="true" tabindex="-1"></a>                          \end{array} \right)</span>
<span id="cb31-1802"><a href="#cb31-1802" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb31-1803"><a href="#cb31-1803" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1804"><a href="#cb31-1804" aria-hidden="true" tabindex="-1"></a>Two properties of the bivariate normal distribution should be remembered. For a couple of standard normal deviates ($u_1$ and $u_2$), the joint normal density can be written as the product of the marginal density of $u_1$ and the conditional density of $u_2$:</span>
<span id="cb31-1805"><a href="#cb31-1805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1806"><a href="#cb31-1806" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1807"><a href="#cb31-1807" aria-hidden="true" tabindex="-1"></a>\phi_b(u_1, u_2, \rho) = \frac{1}{2\pi\sqrt{1-\rho ^  2}} e ^ {-\frac{1}{2}\left(\frac{u_1 ^ 2 + u_2 ^ 2 - 2 \rho u_1 u_2}{1 - \rho ^ 2}\right)}</span>
<span id="cb31-1808"><a href="#cb31-1808" aria-hidden="true" tabindex="-1"></a>= \phi(u_1)\frac{1}{\sqrt{1 - \rho ^ 2}}\phi\left(\frac{u_2 - \rho u_1}{\sqrt{1 - \rho ^ 2}}\right)</span>
<span id="cb31-1809"><a href="#cb31-1809" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bivariate_normal_dist}</span>
<span id="cb31-1810"><a href="#cb31-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1811"><a href="#cb31-1811" aria-hidden="true" tabindex="-1"></a>Then, the expectation of $u_2$ for $u_1$ left-truncated at $l$ is:</span>
<span id="cb31-1812"><a href="#cb31-1812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1813"><a href="#cb31-1813" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1814"><a href="#cb31-1814" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1815"><a href="#cb31-1815" aria-hidden="true" tabindex="-1"></a>\mbox{E}(u_2 \mid u_1 &gt; l) &amp;=&amp; \displaystyle\frac{\int_{l} ^ {+\infty}\int_{-\infty} ^ {+\infty}u_2\phi_b(u_1, u_2, \rho)du_1du_2}{\int_{l} ^ {+\infty}\int_{-\infty} ^ {+\infty}\phi_b(u_1, u_2, \rho)du_1du_2}<span class="sc">\\</span></span>
<span id="cb31-1816"><a href="#cb31-1816" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;\displaystyle\frac{\int_{l} ^ {+\infty}\left<span class="co">[</span><span class="ot">\int_{-\infty} ^ {+\infty}u_2\phi\left(\frac{u_2 - \rho u_1}{\sqrt{1 - \rho ^ 2}}\right)du_2\right</span><span class="co">]</span>\phi(u_1)du_1}{\sqrt{1 - \rho ^ 2}(1 - \Phi(l))} <span class="sc">\\</span></span>
<span id="cb31-1817"><a href="#cb31-1817" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;\displaystyle\frac{\int_{l} ^ {+\infty}\left<span class="co">[</span><span class="ot">\int_{-\infty} ^ {+\infty}(v \sqrt{1 - \rho ^ 2} + \rho u_1)\phi(v)dv\right</span><span class="co">]</span>\phi(u_1)du_1}{1 - \Phi(l)}<span class="sc">\\</span></span>
<span id="cb31-1818"><a href="#cb31-1818" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;\displaystyle\frac{\rho\int_{l} ^ {+\infty}\left<span class="co">[</span><span class="ot">\int_{-\infty} ^ {+\infty} \phi(v)dv\right</span><span class="co">]</span>u_1\phi(u_1)du_1}{1 - \Phi(l)}<span class="sc">\\</span></span>
<span id="cb31-1819"><a href="#cb31-1819" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \rho \frac{\phi(l)}{1 - \Phi(l)}</span>
<span id="cb31-1820"><a href="#cb31-1820" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1821"><a href="#cb31-1821" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp_normal_inctrunc}</span>
<span id="cb31-1822"><a href="#cb31-1822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1823"><a href="#cb31-1823" aria-hidden="true" tabindex="-1"></a>$y_2$ is observed if $y_1 ^ * &gt; 0$ or, equivalently, if $u_1 &gt; - \mu_1$. As $u_1$ follows a standard normal distribution, the probability that $y_2$ is observed is:</span>
<span id="cb31-1824"><a href="#cb31-1824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1825"><a href="#cb31-1825" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1826"><a href="#cb31-1826" aria-hidden="true" tabindex="-1"></a>\mbox{P}(y_1 ^ * &gt; 0) = \mbox{P}(u_1 ^ * &gt; -\mu_1)= 1 - \Phi(-\mu_1) = \Phi(\mu_1)</span>
<span id="cb31-1827"><a href="#cb31-1827" aria-hidden="true" tabindex="-1"></a>$$ {#eq-prob_y2_observed}</span>
<span id="cb31-1828"><a href="#cb31-1828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1829"><a href="#cb31-1829" aria-hidden="true" tabindex="-1"></a>Denote $f(y_2)$ the marginal distribution of $y_2$: it is obtained by integrating out the joint distribution of $y_1 ^ *$ and $y_2 ^ *$ for all positive values of $y_1 ^ *$. Using @eq-bivariate_normal_dist and @eq-prob_y2_observed:</span>
<span id="cb31-1830"><a href="#cb31-1830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1831"><a href="#cb31-1831" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1832"><a href="#cb31-1832" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb31-1833"><a href="#cb31-1833" aria-hidden="true" tabindex="-1"></a>f(y_2) &amp;=&amp; \frac{1}{\sigma}\frac{\int_{0} ^ {+\infty}\phi_b(y_1 ^ * - \mu_1, (y_2 - \mu_2) / \sigma))dy_1 ^ *}{\int_{0} ^ {+\infty}\phi(y_1 ^ * - \mu_1) dy_1 ^ *} <span class="sc">\\</span></span>
<span id="cb31-1834"><a href="#cb31-1834" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \frac{1}{\sigma}\frac{\int_{-\mu_1} ^ {+\infty}\phi_b\left(u_1, (y_2 - \mu_2) / \sigma)\right)du_1}{1 - \Phi(-\gamma_1 ^ \top z_1)} <span class="sc">\\</span></span>
<span id="cb31-1835"><a href="#cb31-1835" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;\frac{\int_{-\mu_1} ^ {+\infty}\phi\left(\frac{u_1 - \rho(y_2 - \mu_2)/ \sigma}{\sqrt{1 - \rho ^ 2}}\right)\phi\left(\frac{y_2 - \mu_2}{\sigma}\right)} {\sigma\sqrt{1 - \rho ^ 2}\Phi(\mu_1)}<span class="sc">\\</span></span>
<span id="cb31-1836"><a href="#cb31-1836" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \frac{\Phi\left(\frac{\mu_1 + \rho (y_2 - \mu_2)/\sigma}{\sqrt{1 - \rho ^ 2}}\right)}{\sigma\sqrt{1 - \rho ^ 2}\Phi(\mu_1)}\phi\left(\frac{y_2 - \mu_2}{\sigma}\right)</span>
<span id="cb31-1837"><a href="#cb31-1837" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb31-1838"><a href="#cb31-1838" aria-hidden="true" tabindex="-1"></a>$$ {#eq-density_y2_observed}</span>
<span id="cb31-1839"><a href="#cb31-1839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1840"><a href="#cb31-1840" aria-hidden="true" tabindex="-1"></a>The contribution of an observation to the likelihood is either</span>
<span id="cb31-1841"><a href="#cb31-1841" aria-hidden="true" tabindex="-1"></a>$P(y_1^* &lt; 0)$ (one minus the probability given by @eq-prob_y2_observed) if $y_2$ is not observed and $P(y_1^* &gt; 0)$ (@eq-prob_y2_observed) times the density of $y_2$ (@eq-density_y2_observed) if it is; which leads to the following likelihood</span>
<span id="cb31-1842"><a href="#cb31-1842" aria-hidden="true" tabindex="-1"></a>function:</span>
<span id="cb31-1843"><a href="#cb31-1843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1844"><a href="#cb31-1844" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1845"><a href="#cb31-1845" aria-hidden="true" tabindex="-1"></a>L(\theta | y,X)=\prod_{n=1}^{N_o}</span>
<span id="cb31-1846"><a href="#cb31-1846" aria-hidden="true" tabindex="-1"></a>\left[1 - </span>
<span id="cb31-1847"><a href="#cb31-1847" aria-hidden="true" tabindex="-1"></a>\Phi(\mu_{n1})</span>
<span id="cb31-1848"><a href="#cb31-1848" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb31-1849"><a href="#cb31-1849" aria-hidden="true" tabindex="-1"></a>\prod_{n = N_o + 1}^{N}</span>
<span id="cb31-1850"><a href="#cb31-1850" aria-hidden="true" tabindex="-1"></a>\frac{1}{\sigma\sqrt{1-\rho ^ 2}}</span>
<span id="cb31-1851"><a href="#cb31-1851" aria-hidden="true" tabindex="-1"></a>\Phi\left(\frac{\mu_{n1} +</span>
<span id="cb31-1852"><a href="#cb31-1852" aria-hidden="true" tabindex="-1"></a>    \rho\frac{y_n -</span>
<span id="cb31-1853"><a href="#cb31-1853" aria-hidden="true" tabindex="-1"></a>      \mu_{n2}}{\sigma}}{\sqrt{1-\rho^2}}\right)</span>
<span id="cb31-1854"><a href="#cb31-1854" aria-hidden="true" tabindex="-1"></a>\phi\left(\frac{y_{n}-\mu_{n2}}{\sigma}\right)</span>
<span id="cb31-1855"><a href="#cb31-1855" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1856"><a href="#cb31-1856" aria-hidden="true" tabindex="-1"></a>Consider now the conditional expectation of $y$ if it is observed, i.e., if $y_1 ^ *  &gt; 0$:</span>
<span id="cb31-1857"><a href="#cb31-1857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1858"><a href="#cb31-1858" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1859"><a href="#cb31-1859" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y\mid x_2, y &gt; 0) = </span>
<span id="cb31-1860"><a href="#cb31-1860" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\mu_2 + \sigma_\epsilon u_2\mid x_2, u_1 ^ * &gt; -\mu_1)=</span>
<span id="cb31-1861"><a href="#cb31-1861" aria-hidden="true" tabindex="-1"></a>\mu_2 + \sigma_\epsilon\mbox{E}(u_2\mid u_1  &gt; -\mu_1)</span>
<span id="cb31-1862"><a href="#cb31-1862" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1863"><a href="#cb31-1863" aria-hidden="true" tabindex="-1"></a>From @eq-exp_normal_inctrunc, the last term is just $\rho \frac{\phi(-\mu_1)}{1 - \Phi(-\mu_1)}$, so that:</span>
<span id="cb31-1864"><a href="#cb31-1864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1865"><a href="#cb31-1865" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb31-1866"><a href="#cb31-1866" aria-hidden="true" tabindex="-1"></a>\mbox{E}(y\mid x_2, x_1, y &gt; 0) = \mu_2 + \sigma \rho \frac{\phi(\mu_1)}{\Phi(\mu_1)}=</span>
<span id="cb31-1867"><a href="#cb31-1867" aria-hidden="true" tabindex="-1"></a> \gamma_2 ^ \top z_2 + \sigma \rho r(\mu_1)</span>
<span id="cb31-1868"><a href="#cb31-1868" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_exp_heckit}</span>
<span id="cb31-1869"><a href="#cb31-1869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1870"><a href="#cb31-1870" aria-hidden="true" tabindex="-1"></a>As for the tobit-1 model, the conditional expectation is not equal to</span>
<span id="cb31-1871"><a href="#cb31-1871" aria-hidden="true" tabindex="-1"></a>$\mu_2 = \gamma^\top z_2$ because of the supplementary term $\sigma\rho</span>
<span id="cb31-1872"><a href="#cb31-1872" aria-hidden="true" tabindex="-1"></a>(\gamma_1^\top x_1)$. The linear estimator is therefore biased if </span>
<span id="cb31-1873"><a href="#cb31-1873" aria-hidden="true" tabindex="-1"></a>the omitted variable if $r(\gamma_1^\top z_1)$ is correlated</span>
<span id="cb31-1874"><a href="#cb31-1874" aria-hidden="true" tabindex="-1"></a>with $x_2$, which is obviously the case if there are common covariates</span>
<span id="cb31-1875"><a href="#cb31-1875" aria-hidden="true" tabindex="-1"></a>in $x_1$ and $x_2$. @eq-cond_exp_heckit also directly leads to an</span>
<span id="cb31-1876"><a href="#cb31-1876" aria-hidden="true" tabindex="-1"></a>alternative estimator. This </span>
<span id="cb31-1877"><a href="#cb31-1877" aria-hidden="true" tabindex="-1"></a>is a two-step estimator, sometimes called the **heckit** estimator. It</span>
<span id="cb31-1878"><a href="#cb31-1878" aria-hidden="true" tabindex="-1"></a>consists of first regressing $\mathbf{1}(y_1^* &gt; 0)$ on $x_1$ using a probit, and then estimating $r(\gamma^\top z_1)$ by $r(\hat{\gamma}^\top z_1)$, $\hat{\gamma}^\top z_1$ being the linear</span>
<span id="cb31-1879"><a href="#cb31-1879" aria-hidden="true" tabindex="-1"></a>predictor of the probit model. In a second step, regressing $y_2$ on</span>
<span id="cb31-1880"><a href="#cb31-1880" aria-hidden="true" tabindex="-1"></a>$x_2$ and the supplementary covariate $r(\hat{\gamma}_1^\top z_1)$</span>
<span id="cb31-1881"><a href="#cb31-1881" aria-hidden="true" tabindex="-1"></a>leads to a consistent estimate of $\gamma_2$.</span>
<span id="cb31-1882"><a href="#cb31-1882" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!selection models}</span>
<span id="cb31-1883"><a href="#cb31-1883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1884"><a href="#cb31-1884" aria-hidden="true" tabindex="-1"></a>As previously seen (@fig-mills), $r(z)$ is almost linear</span>
<span id="cb31-1885"><a href="#cb31-1885" aria-hidden="true" tabindex="-1"></a>in $z$ for a wide range of values of $z$. Therefore, if $x_1=x_2$, the</span>
<span id="cb31-1886"><a href="#cb31-1886" aria-hidden="true" tabindex="-1"></a>coefficients of the second steps of the heckit estimator are only</span>
<span id="cb31-1887"><a href="#cb31-1887" aria-hidden="true" tabindex="-1"></a>identified by the non-linearity of $r$. The high correlation between</span>
<span id="cb31-1888"><a href="#cb31-1888" aria-hidden="true" tabindex="-1"></a>$x_2$ and $r(\hat{\gamma}^\top_1z_1)$ will lead in this case to very</span>
<span id="cb31-1889"><a href="#cb31-1889" aria-hidden="true" tabindex="-1"></a>imprecise estimates. It is therefore recommended to impose exclusion</span>
<span id="cb31-1890"><a href="#cb31-1890" aria-hidden="true" tabindex="-1"></a>conditions, i.e., to exclude at least one covariate of the $x_1$ set for</span>
<span id="cb31-1891"><a href="#cb31-1891" aria-hidden="true" tabindex="-1"></a>the second step of the estimator. This (or these) excluded covariates</span>
<span id="cb31-1892"><a href="#cb31-1892" aria-hidden="true" tabindex="-1"></a>must be relevant for the selection equation, but not for the outcome</span>
<span id="cb31-1893"><a href="#cb31-1893" aria-hidden="true" tabindex="-1"></a>equation. In practice, it is often  difficult to provide theoretical</span>
<span id="cb31-1894"><a href="#cb31-1894" aria-hidden="true" tabindex="-1"></a>bases to such exclusion conditions. </span>
<span id="cb31-1895"><a href="#cb31-1895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1896"><a href="#cb31-1896" aria-hidden="true" tabindex="-1"></a>The relative merits of the two-part and the heckit models have been discussed in numerous articles, especially in the field of health economics. The arguments are presented in @JONE:00\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Jones} and @DOW:NORT:03\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Dow}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Norton}.</span>
<span id="cb31-1897"><a href="#cb31-1897" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator}</span>
<span id="cb31-1898"><a href="#cb31-1898" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heckit model|)}</span>
<span id="cb31-1899"><a href="#cb31-1899" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{tobit-2|)}</span>
<span id="cb31-1900"><a href="#cb31-1900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1901"><a href="#cb31-1901" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application</span></span>
<span id="cb31-1902"><a href="#cb31-1902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1903"><a href="#cb31-1903" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{traffic<span class="sc">\_</span>citations}{micsr.data}</span>
<span id="cb31-1904"><a href="#cb31-1904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1905"><a href="#cb31-1905" aria-hidden="true" tabindex="-1"></a>@MAKO:STRA:09\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Makowsky}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Stratmann} analyze the behavior of policemen in terms of issuing speeding tickets, because of excessive speed. A policeman has to make two decisions:</span>
<span id="cb31-1906"><a href="#cb31-1906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1907"><a href="#cb31-1907" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>whether to give a ticket or not,</span>
<span id="cb31-1908"><a href="#cb31-1908" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if a ticket is given, its amount should be set, with the</span>
<span id="cb31-1909"><a href="#cb31-1909" aria-hidden="true" tabindex="-1"></a>  recommendation of applying the following formula: </span>
<span id="cb31-1910"><a href="#cb31-1910" aria-hidden="true" tabindex="-1"></a>  $50 + (speed - (max speed allowed + 10))</span>
<span id="cb31-1911"><a href="#cb31-1911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1912"><a href="#cb31-1912" aria-hidden="true" tabindex="-1"></a>The authors make the hypotheses that a policeman's behavior will depend</span>
<span id="cb31-1913"><a href="#cb31-1913" aria-hidden="true" tabindex="-1"></a>on their institutional and political environment. First, there are two</span>
<span id="cb31-1914"><a href="#cb31-1914" aria-hidden="true" tabindex="-1"></a>kinds of policemen, belonging to the municipality or to the state of</span>
<span id="cb31-1915"><a href="#cb31-1915" aria-hidden="true" tabindex="-1"></a>Massachusetts. Municipality agents are headed by a chief who is</span>
<span id="cb31-1916"><a href="#cb31-1916" aria-hidden="true" tabindex="-1"></a>nominated by the municipal authorities and can be fired at any</span>
<span id="cb31-1917"><a href="#cb31-1917" aria-hidden="true" tabindex="-1"></a>time. One can suppose, that contrary to the state policemen, these</span>
<span id="cb31-1918"><a href="#cb31-1918" aria-hidden="true" tabindex="-1"></a>local policemen will act in the interest of the local</span>
<span id="cb31-1919"><a href="#cb31-1919" aria-hidden="true" tabindex="-1"></a>authorities, for which the fees policy has two aspects:</span>
<span id="cb31-1920"><a href="#cb31-1920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1921"><a href="#cb31-1921" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>fees are a source of income, which can be particularly</span>
<span id="cb31-1922"><a href="#cb31-1922" aria-hidden="true" tabindex="-1"></a>  important for municipalities with budget problems,</span>
<span id="cb31-1923"><a href="#cb31-1923" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>fees given to drivers from the municipality can make them</span>
<span id="cb31-1924"><a href="#cb31-1924" aria-hidden="true" tabindex="-1"></a>  unhappy and unwilling to vote for the current authorities, which is</span>
<span id="cb31-1925"><a href="#cb31-1925" aria-hidden="true" tabindex="-1"></a>  not an issue for drivers from other municipalities.</span>
<span id="cb31-1926"><a href="#cb31-1926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1927"><a href="#cb31-1927" aria-hidden="true" tabindex="-1"></a>The data set, called <span class="in">`traffic_citations`</span> includes:</span>
<span id="cb31-1928"><a href="#cb31-1928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1929"><a href="#cb31-1929" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>two responses: <span class="in">`fine`</span> which indicates whether a ticket has been given</span>
<span id="cb31-1930"><a href="#cb31-1930" aria-hidden="true" tabindex="-1"></a>or not, and <span class="in">`amount`</span> which is the amount of the fine when it has been</span>
<span id="cb31-1931"><a href="#cb31-1931" aria-hidden="true" tabindex="-1"></a>issued,</span>
<span id="cb31-1932"><a href="#cb31-1932" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>covariates that describe local fiscal conditions: <span class="in">`prval`</span> is the</span>
<span id="cb31-1933"><a href="#cb31-1933" aria-hidden="true" tabindex="-1"></a>  average property value in the municipality, which is the base of the</span>
<span id="cb31-1934"><a href="#cb31-1934" aria-hidden="true" tabindex="-1"></a>  main local tax, and <span class="in">`overloss`</span> which indicates that an override</span>
<span id="cb31-1935"><a href="#cb31-1935" aria-hidden="true" tabindex="-1"></a>  referendum (which indicates that the municipality anticipates</span>
<span id="cb31-1936"><a href="#cb31-1936" aria-hidden="true" tabindex="-1"></a>  insufficient revenues) fails to pass,</span>
<span id="cb31-1937"><a href="#cb31-1937" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>characteristics of the offender: <span class="in">`ethn`</span> indicates the ethnicity of the driver (<span class="in">`"other"`</span>, <span class="in">`"hispanic"`</span> or <span class="in">`"black"`</span>), the sex is indicated by a dummy <span class="in">`female`</span> and <span class="in">`res`</span> indicates whether the driver lives in the municipality (<span class="in">`"loc"`</span>), in another municipality of the state</span>
<span id="cb31-1938"><a href="#cb31-1938" aria-hidden="true" tabindex="-1"></a>(<span class="in">`"oto"`</span>) or in another State (<span class="in">`"ost"`</span>), <span class="in">`courtdist`</span> is the</span>
<span id="cb31-1939"><a href="#cb31-1939" aria-hidden="true" tabindex="-1"></a>distance to the courts where the driver can appeal the citation,</span>
<span id="cb31-1940"><a href="#cb31-1940" aria-hidden="true" tabindex="-1"></a><span class="in">`mph`</span> is the difference between the speed of the driver and the</span>
<span id="cb31-1941"><a href="#cb31-1941" aria-hidden="true" tabindex="-1"></a>legal limit and <span class="in">`cdl`</span> is a dummy for a commercial driver's license.</span>
<span id="cb31-1942"><a href="#cb31-1942" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>characteristics of the policemen: <span class="in">`stpol`</span> is a dummy for state officers and is therefore 0 for local policemen.</span>
<span id="cb31-1943"><a href="#cb31-1943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1944"><a href="#cb31-1944" aria-hidden="true" tabindex="-1"></a>We start by defining the selection and the outcome equations. The authors suppose that the probability of receiving a fine depends on the difference between the actual and the limit speed, the ethnicity, the sex and the age of the offender, the fact that the driver's license is commercial and covariates describing local fiscal conditions and place of residence of the offender in interaction with the dummy for state officers. As the log of age is introduced in interaction with the <span class="in">`female`</span> dummy, we divide the age by the sample mean so that the coefficient of <span class="in">`female`</span> is the effect for the mean age. For the outcome equation, the set of covariates is the same except that the dummy for commercial driver's license is removed:</span>
<span id="cb31-1945"><a href="#cb31-1945" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{update}{stats}</span>
<span id="cb31-1946"><a href="#cb31-1946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1949"><a href="#cb31-1949" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1950"><a href="#cb31-1950" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: traffic_citations_eqs</span></span>
<span id="cb31-1951"><a href="#cb31-1951" aria-hidden="true" tabindex="-1"></a>traffic_citations <span class="ot">&lt;-</span> traffic_citations <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">age =</span> age <span class="sc">/</span> <span class="dv">35</span>)</span>
<span id="cb31-1952"><a href="#cb31-1952" aria-hidden="true" tabindex="-1"></a>sel <span class="ot">&lt;-</span> fine <span class="sc">~</span> <span class="fu">log</span>(mph) <span class="sc">+</span> ethn <span class="sc">+</span> female <span class="sc">*</span> <span class="fu">log</span>(age) <span class="sc">+</span></span>
<span id="cb31-1953"><a href="#cb31-1953" aria-hidden="true" tabindex="-1"></a>    stpol <span class="sc">*</span> (res <span class="sc">+</span> <span class="fu">log</span>(prval) <span class="sc">+</span> oloss) <span class="sc">+</span> cdl</span>
<span id="cb31-1954"><a href="#cb31-1954" aria-hidden="true" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">update</span>(sel, <span class="fu">log</span>(amount) <span class="sc">~</span> . <span class="sc">-</span> cdl)</span>
<span id="cb31-1955"><a href="#cb31-1955" aria-hidden="true" tabindex="-1"></a>traffic_citations <span class="ot">&lt;-</span> traffic_citations <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">locpol =</span> <span class="dv">1</span> <span class="sc">-</span> stpol)</span>
<span id="cb31-1956"><a href="#cb31-1956" aria-hidden="true" tabindex="-1"></a>sel_c <span class="ot">&lt;-</span> fine <span class="sc">~</span> <span class="fu">log</span>(mph) <span class="sc">+</span> ethn <span class="sc">+</span> female <span class="sc">*</span> <span class="fu">log</span>(age) <span class="sc">+</span></span>
<span id="cb31-1957"><a href="#cb31-1957" aria-hidden="true" tabindex="-1"></a>    locpol <span class="sc">:</span> (res <span class="sc">+</span> <span class="fu">log</span>(prval) <span class="sc">+</span> oloss) <span class="sc">+</span> cdl <span class="sc">+</span> locpol</span>
<span id="cb31-1958"><a href="#cb31-1958" aria-hidden="true" tabindex="-1"></a>out_c <span class="ot">&lt;-</span> <span class="fu">update</span>(sel_c, <span class="fu">log</span>(amount) <span class="sc">~</span> . <span class="sc">-</span> cdl)</span>
<span id="cb31-1959"><a href="#cb31-1959" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1960"><a href="#cb31-1960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1961"><a href="#cb31-1961" aria-hidden="true" tabindex="-1"></a>Therefore, the identification is performed using the hypothesis that <span class="in">`cdl`</span> enters the selection equation, but not the outcome equation. The authors justify this hypothesis by the fact that a fine received by drivers with a commercial license may have important consequences for them, because the accumulation of points may lead to the suspension of their license and can cause the loss of their employment and affect their future income. Once the fine has been issued, there is no clear incentive for the officer to impose a lower fine <span class="co">[</span><span class="ot">@MAKO:STRA:09, page 515-516</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Makowsky}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Stratmann}.</span>
<span id="cb31-1962"><a href="#cb31-1962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1963"><a href="#cb31-1963" aria-hidden="true" tabindex="-1"></a>The hypothesis is that local policemen have an incentive to fine when their town experiences fiscal problems and when the offender is not a resident of the town. Therefore, the coefficients on <span class="in">`prval`</span>, <span class="in">`overloss`</span>, <span class="in">`locoto`</span> and <span class="in">`locost`</span> should be negative for the first one and positive for the other three. Interacting these covariates with the dummy for state officers, an opposite sign should be observed. </span>
<span id="cb31-1964"><a href="#cb31-1964" aria-hidden="true" tabindex="-1"></a>We can then compute the heckit estimator. First, we estimate the selection equation using a probit and we estimate the inverse mills ratio:</span>
<span id="cb31-1965"><a href="#cb31-1965" aria-hidden="true" tabindex="-1"></a>\idxfun{glm}{stats}\idxfun{dnorm}{stats}\idxfun{pnorm}{stats}</span>
<span id="cb31-1966"><a href="#cb31-1966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1969"><a href="#cb31-1969" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1970"><a href="#cb31-1970" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: traffic_citations_heckit_manual1</span></span>
<span id="cb31-1971"><a href="#cb31-1971" aria-hidden="true" tabindex="-1"></a>probit <span class="ot">&lt;-</span> <span class="fu">glm</span>(sel, <span class="at">data =</span> traffic_citations,</span>
<span id="cb31-1972"><a href="#cb31-1972" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">'probit'</span>))</span>
<span id="cb31-1973"><a href="#cb31-1973" aria-hidden="true" tabindex="-1"></a>lp <span class="ot">&lt;-</span> probit<span class="sc">$</span>linear.predictor</span>
<span id="cb31-1974"><a href="#cb31-1974" aria-hidden="true" tabindex="-1"></a>mls <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(lp) <span class="sc">/</span> <span class="fu">pnorm</span>(lp)</span>
<span id="cb31-1975"><a href="#cb31-1975" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1976"><a href="#cb31-1976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1977"><a href="#cb31-1977" aria-hidden="true" tabindex="-1"></a>We then compute the second stage of the estimator by using OLS to fit the outcome equation, using the estimation of the inverse mills ratio as a supplementary covariate:</span>
<span id="cb31-1978"><a href="#cb31-1978" aria-hidden="true" tabindex="-1"></a>\idxfun{lm}{stats}\idxfun{update}{stats}</span>
<span id="cb31-1979"><a href="#cb31-1979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1982"><a href="#cb31-1982" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1983"><a href="#cb31-1983" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: traffic_citations_heckit_manual2</span></span>
<span id="cb31-1984"><a href="#cb31-1984" aria-hidden="true" tabindex="-1"></a>lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(out, traffic_citations)</span>
<span id="cb31-1985"><a href="#cb31-1985" aria-hidden="true" tabindex="-1"></a>heck <span class="ot">&lt;-</span> <span class="fu">update</span>(lm, . <span class="sc">~</span> . <span class="sc">+</span> mls)</span>
<span id="cb31-1986"><a href="#cb31-1986" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-1987"><a href="#cb31-1987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1988"><a href="#cb31-1988" aria-hidden="true" tabindex="-1"></a>The **sampleSelection** package <span class="co">[</span><span class="ot">@TOOM:HENN:08</span><span class="co">]</span> is devoted to the estimation of sample selection models.</span>
<span id="cb31-1989"><a href="#cb31-1989" aria-hidden="true" tabindex="-1"></a>The <span class="in">`sampleSelection::selection`</span> function performs the estimation of such models; two formulas should be provided for the selection and for the outcome equations. The method of estimation is indicated using the <span class="in">`method`</span> argument which could be either <span class="in">`"2step"`</span> and <span class="in">`"ml"`</span> respectively for the two-step and the maximum likelihood estimator. The results are presented in @tbl-traffic_citations.</span>
<span id="cb31-1990"><a href="#cb31-1990" aria-hidden="true" tabindex="-1"></a>\idxfun{selection}{sampleSelection}\idxfun{update}{stats}</span>
<span id="cb31-1991"><a href="#cb31-1991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-1994"><a href="#cb31-1994" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-1995"><a href="#cb31-1995" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: traffic_citations_sampleSelection</span></span>
<span id="cb31-1996"><a href="#cb31-1996" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sampleSelection)</span>
<span id="cb31-1997"><a href="#cb31-1997" aria-hidden="true" tabindex="-1"></a>tc_heck <span class="ot">&lt;-</span> <span class="fu">selection</span>(sel, out, <span class="at">data =</span> traffic_citations,</span>
<span id="cb31-1998"><a href="#cb31-1998" aria-hidden="true" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">"2step"</span>)</span>
<span id="cb31-1999"><a href="#cb31-1999" aria-hidden="true" tabindex="-1"></a>tc_ml <span class="ot">&lt;-</span> <span class="fu">update</span>(tc_heck, <span class="at">method =</span> <span class="st">"ml"</span>)</span>
<span id="cb31-2000"><a href="#cb31-2000" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-2001"><a href="#cb31-2001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2004"><a href="#cb31-2004" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-2005"><a href="#cb31-2005" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb31-2006"><a href="#cb31-2006" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-traffic_citations</span></span>
<span id="cb31-2007"><a href="#cb31-2007" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Traffic citations"</span></span>
<span id="cb31-2008"><a href="#cb31-2008" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelsummary)</span>
<span id="cb31-2009"><a href="#cb31-2009" aria-hidden="true" tabindex="-1"></a><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="st">"maximum likelihood"</span> <span class="ot">=</span> tc_ml, <span class="at">heckit =</span> tc_heck), <span class="at">shape =</span> <span class="sc">~</span> component,</span>
<span id="cb31-2010"><a href="#cb31-2010" aria-hidden="true" tabindex="-1"></a>         <span class="at">estimate =</span> <span class="st">"{estimate}{stars}"</span>, <span class="at">output =</span> <span class="st">"kableExtra"</span>, <span class="at">stars =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-2011"><a href="#cb31-2011" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-2012"><a href="#cb31-2012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2013"><a href="#cb31-2013" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{traffic<span class="sc">\_</span>citations}{micsr.data}</span>
<span id="cb31-2014"><a href="#cb31-2014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2015"><a href="#cb31-2015" aria-hidden="true" tabindex="-1"></a>Remember that for the probit, the marginal effect is the coefficient times the probability that a fine has been issued. As the mean value of <span class="in">`fine`</span> is close to 0.5, we can multiply probit's coefficients by 0.4 as an estimate of the marginal effect at the sample mean. Being a female reduces the probability of having a fine by about 8%. The probability is higher for Hispanic drivers (about 12%), there is not such effect for black drivers. State policemen are less severe than local policemen in terms of fine issuing, but when the fine is issuing; the amount is the same as the one set by local policemen. The coefficients of <span class="in">`log(prval)`</span> and <span class="in">`oloss`</span> have the expected sign and are highly significant. Moreover, as expected, the coefficients of these covariates in interaction with state policemen have the opposite sign and are significant. Out-of-town and out-of-state offenders have a higher probability to receive a fine and, if it is the case, the average amount is higher than the one for local offenders. The interaction term with the state policemen dummy is not significant for out-of-town offenders and is positive for out-of-state offenders. Finally, as expected, the probability of receiving a fine is lower for drivers with a commercial license. In the two-step model, the inverse mills ratio is positive and highly significant. The implied coefficient of correlation is 0.506 and the estimated value using ML is 0.360. Therefore, we can conclude that the unobserved parts of the selection and the outcome equations are positively correlated.</span>
<span id="cb31-2016"><a href="#cb31-2016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2017"><a href="#cb31-2017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2018"><a href="#cb31-2018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2019"><a href="#cb31-2019" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - coefficients: the vector of coefficients --&gt;</span></span>
<span id="cb31-2020"><a href="#cb31-2020" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - model: the data frame used for the estimation --&gt;</span></span>
<span id="cb31-2021"><a href="#cb31-2021" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - gradient: a $N \times (K + 1)$ matrix of individual contributions to the gradient --&gt;</span></span>
<span id="cb31-2022"><a href="#cb31-2022" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - hessian: a $(K + 1) \times (K + 1)$ matrix --&gt;</span></span>
<span id="cb31-2023"><a href="#cb31-2023" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - info: a $(K + 1) \times (K + 1)$ matrix --&gt;</span></span>
<span id="cb31-2024"><a href="#cb31-2024" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - linear.predictors: the linear predictor: $\eta_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n$ --&gt;</span></span>
<span id="cb31-2025"><a href="#cb31-2025" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - logLik: the log-likelihood a numeric containing the value of the log-likelihood function for the proposed, the null and the saturated model --&gt;</span></span>
<span id="cb31-2026"><a href="#cb31-2026" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - fitted.values: the fitted values --&gt;</span></span>
<span id="cb31-2027"><a href="#cb31-2027" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - df.residual: the residual degrees of freedom --&gt;</span></span>
<span id="cb31-2028"><a href="#cb31-2028" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - est_method: the method of estimation --&gt;</span></span>
<span id="cb31-2029"><a href="#cb31-2029" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - formula: the formula used to describe the model --&gt;</span></span>
<span id="cb31-2030"><a href="#cb31-2030" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - npar: a named numeric containing the number of coefficients for the different subsets and the name of these subsets (there is a default attribute which can be problematic, especially for testing functions) --&gt;</span></span>
<span id="cb31-2031"><a href="#cb31-2031" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - value: the individual contribution to the objective function, a numeric of length $N$ --&gt;</span></span>
<span id="cb31-2032"><a href="#cb31-2032" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - tests: a numeric of length three giving the value of the test that all the coefficients of the covariates are 0 --&gt;</span></span>
<span id="cb31-2033"><a href="#cb31-2033" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - call: the matched call --&gt;</span></span>
<span id="cb31-2034"><a href="#cb31-2034" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - xlevels: the levels of the factors used in the estimation --&gt;</span></span>
<span id="cb31-2035"><a href="#cb31-2035" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - na.action: information returned model.frame on the handling of NAs --&gt;</span></span>
<span id="cb31-2036"><a href="#cb31-2036" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - **weights**: the specified weights --&gt;</span></span>
<span id="cb31-2037"><a href="#cb31-2037" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - **contrats**: the contrasts used --&gt;</span></span>
<span id="cb31-2038"><a href="#cb31-2038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2039"><a href="#cb31-2039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2040"><a href="#cb31-2040" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- We have $y_2 = \gamma_2 ^ \top z_2 + \sigma z_2$ and $y_1 ^ * = \gamma_1 ^ \top z_1 + z_1$. Then, $y_2$ is observed if $z_1 &gt; - \gamma_1 ^ \top z_1$ and, therefore --&gt;</span></span>
<span id="cb31-2041"><a href="#cb31-2041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-2042"><a href="#cb31-2042" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb31-2043"><a href="#cb31-2043" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{E}(y_2 \mid x_1, x_2, z_1 &gt; - \gamma_1 ^ \top z_1) = \gamma_2 ^ \top z_2 + \sigma \mbox{E}(z_2 \mid z_1 &gt; - \gamma_1 ^ \top z_1) = \gamma_2 ^ \top z_2 + \sigma \rho \frac{\phi(- \gamma_1 ^ \top z_1)}{1 - \Phi(- \gamma_1 ^ \top z_1)} =  --&gt;</span></span>
<span id="cb31-2044"><a href="#cb31-2044" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \gamma_2 ^ \top z_2 + \sigma\rho \frac{\phi(\gamma_1 ^ \top z_1)}{\Phi(\gamma_1 ^ \top z_1)} --&gt;</span></span>
<span id="cb31-2045"><a href="#cb31-2045" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>