<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Microeconometrics with R - 14&nbsp; Discrete choice models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../references.html" rel="next">
<link href="../chapters/duration.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Discrete choice models</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Microeconometrics with R</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../OLS.html" class="sidebar-item-text sidebar-link">Ordinary least squares estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression_properties.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistical properties of the simple linear estimator</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/multiple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Multiple regression model</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/coefficients.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interpretation of the Coefficients</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../beyond_OLS.html" class="sidebar-item-text sidebar-link">Beyond the OLS estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/maximum_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Maximum likelihood estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/non_spherical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Non-spherical disturbances</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/endogeneity.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Endogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/treateff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Treatment effect</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/spatial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial econometrics</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../special_responses.html" class="sidebar-item-text sidebar-link">Special responses</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/binomial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/tobit.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/count.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Count data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/duration.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Duration models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/rum.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Discrete choice models</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-data_formula_rum" id="toc-sec-data_formula_rum" class="nav-link active" data-scroll-target="#sec-data_formula_rum"><span class="toc-section-number">14.1</span>  Data management and model description</a>
  <ul class="collapse">
<li><a href="#data-management" id="toc-data-management" class="nav-link" data-scroll-target="#data-management">Data management</a></li>
  <li><a href="#model-description" id="toc-model-description" class="nav-link" data-scroll-target="#model-description">Model description</a></li>
  </ul>
</li>
  <li>
<a href="#sec-multinom_logit" id="toc-sec-multinom_logit" class="nav-link" data-scroll-target="#sec-multinom_logit"><span class="toc-section-number">14.2</span>  Random utility model and multinomial logit model</a>
  <ul class="collapse">
<li><a href="#random-utility-model" id="toc-random-utility-model" class="nav-link" data-scroll-target="#random-utility-model">Random utility model</a></li>
  <li><a href="#distribution-of-the-error-terms" id="toc-distribution-of-the-error-terms" class="nav-link" data-scroll-target="#distribution-of-the-error-terms">Distribution of the error terms</a></li>
  <li><a href="#iia-property" id="toc-iia-property" class="nav-link" data-scroll-target="#iia-property">IIA property</a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation</a></li>
  <li><a href="#sec-appl_mult_logit" id="toc-sec-appl_mult_logit" class="nav-link" data-scroll-target="#sec-appl_mult_logit">Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-relaxing_iid" id="toc-sec-relaxing_iid" class="nav-link" data-scroll-target="#sec-relaxing_iid"><span class="toc-section-number">14.3</span>  Logit models relaxing the iid hypothesis</a>
  <ul class="collapse">
<li><a href="#heteroskedastic-logit-model" id="toc-heteroskedastic-logit-model" class="nav-link" data-scroll-target="#heteroskedastic-logit-model">Heteroskedastic logit model</a></li>
  <li><a href="#nested-logit-model" id="toc-nested-logit-model" class="nav-link" data-scroll-target="#nested-logit-model">Nested logit model</a></li>
  </ul>
</li>
  <li>
<a href="#sec-mixed_logit" id="toc-sec-mixed_logit" class="nav-link" data-scroll-target="#sec-mixed_logit"><span class="toc-section-number">14.4</span>  Random parameters (or mixed) logit model</a>
  <ul class="collapse">
<li><a href="#derivation-of-the-model" id="toc-derivation-of-the-model" class="nav-link" data-scroll-target="#derivation-of-the-model">Derivation of the model</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-multinom_probit" id="toc-sec-multinom_probit" class="nav-link" data-scroll-target="#sec-multinom_probit"><span class="toc-section-number">14.5</span>  Multinomial probit</a>
  <ul class="collapse">
<li><a href="#the-model" id="toc-the-model" class="nav-link" data-scroll-target="#the-model">The model</a></li>
  <li><a href="#identification" id="toc-identification" class="nav-link" data-scroll-target="#identification">Identification</a></li>
  <li><a href="#simulations" id="toc-simulations" class="nav-link" data-scroll-target="#simulations">Simulations</a></li>
  <li><a href="#application-1" id="toc-application-1" class="nav-link" data-scroll-target="#application-1">Application</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-rum" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Discrete choice models</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Consider the case where the response is the choice of an alternative among a set of mutually exclusive alternatives. This choice can be modeled in a utility maximization framework, which means that we hypothesize that the individual chooses the alternative which corresponds to the maximum level of utility.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Namely, denoting <span class="math inline">\(j = 1 \ldots J\)</span> the set of alternatives, we’ll denote <span class="math inline">\(U_{nj}\)</span> the level of utility of individual <span class="math inline">\(n\)</span> if he chooses alternative <span class="math inline">\(j\)</span> and the <span class="math inline">\(j\)</span><sup>th</sup>alternative will be chosen if <span class="math inline">\(U_{nj} &gt; U_{nk}\; \forall k \neq j\)</span>. The level of utility will depends on some observable covariates and on some other unobservables whose effect will be summarized in a variable <span class="math inline">\(\epsilon_{nj}\)</span> that will be considered, from the researcher’s point of view, as the realization of a random variable. Two key questions for these models are how the covariates enter the utility function and what is the assumed distribution of the error. <a href="#sec-data_formula_rum"><span>Section&nbsp;14.1</span></a> will deal with the first point, namely how to deal with covariates in discrete choice model. <a href="#sec-multinom_logit"><span>Section&nbsp;14.2</span></a> will present the landmark model in this field, the multinomial logit model. <a href="#sec-relaxing_iid"><span>Section&nbsp;14.3</span></a> will go beyond the hypothesis of iid errors to present two extensions of the basic model, the nested and the heteroscedastic logit models. <a href="#sec-mixed_logit"><span>Section&nbsp;14.4</span></a> will introduce the rich field of random parameters logit models. Finally, <a href="#sec-multinom_probit"><span>Section&nbsp;14.5</span></a> will be devoted to the multinomial probit model.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Throughout this chapter, we’ll use the <strong>mlogit</strong> package which is devoted to the estimation of discrete choice models:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=mlogit">mlogit</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="sec-data_formula_rum" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="sec-data_formula_rum">
<span class="header-section-number">14.1</span> Data management and model description</h2>
<!-- In discrete choice models, the unit of observation is a choice situation, defined by an individual $n$ which should choose one alternative $j$ among a set of mutually exclusive alternatives. His choice is partly driven by some covariates that can depend either on the individual, the choice situation or both.  -->
<!-- To illustrate this typology of the covariates, consider the case of -->
<!-- repeated choices of destinations for vacations by families: -->
<!-- - the length of the vacation, the season are choice situation -->
<!--   specific variables, -->
<!-- - income, family size are individual specific variables, -->
<!-- - distance to destination, cost are alternative specific -->
<!--   variables. -->
<!-- Such data have therefore a specific structure that can be -->
<!-- characterized by three indexes: the alternative, the choice situation -->
<!-- and the individual. These three indexes will be denoted `alt`, `chid` -->
<!-- and `id`.  Note that the distinction between `chid` and `id` is only -->
<!-- relevant if we have repeated observations for the same individual. -->
<section id="data-management" class="level3"><h3 class="anchored" data-anchor-id="data-management">Data management</h3>
<p>Data sets used for discrete choice models estimation concern some individuals, who make one or a sequential choice of one alternative among a set of mutually exclusive alternatives. The determinants of these choices are covariates that can depend on the alternative and the choice situation, only on the alternative or only on the choice situation. Data sets can have two different shapes: a <em>wide</em> shape (one row for each choice situation) or a <em>long</em> shape (one row for each alternative and, therefore, as many rows as there are alternatives for each choice situation). <strong>mlogit</strong> deals with both formats. It depends on the <strong>dfidx</strong> package which takes as first argument a <code>data.frame</code> and returns a <code>dfidx</code> object, which is a <code>data.frame</code> in “long” format with a special data frame column which contains the indexes. The second argument is called <code>idx</code>. In its simple use, it should be a list (or a vector) of two characters containing the choice situation and the alternative indexes.</p>
<section id="sec-wide_format" class="level4"><h4 class="anchored" data-anchor-id="sec-wide_format">Wide format</h4>
<p><code>dutch_railways</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is an example of a <em>wide</em> data set:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dutch_railways</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,929 × 11
     id choiceid choice price_A price_B time_A time_B change_A
  &lt;int&gt;    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;int&gt;
1     1        1 A         10.9    18.2   2.5    2.5         0
2     1        2 A         10.9    14.5   2.5    2.17        0
3     1        3 A         10.9    18.2   1.92   1.92        0
4     1        4 B         18.2    14.5   2.17   2.5         0
# ℹ 2,925 more rows
# ℹ 3 more variables: change_B &lt;int&gt;, comfort_A &lt;int&gt;,
#   comfort_B &lt;int&gt;</code></pre>
</div>
</div>
<p> This data set contains data about a stated preference survey in the Netherlands in 1987. Each individual has responded to several (up to 16) scenarios. For every scenario, two train trips are proposed to the user, with different combinations of four attributes: <code>price</code> (the price in euros), <code>time</code> (travel time in minutes), <code>change</code> (the number of changes) and <code>comfort</code> (the class of comfort, 0, 1 or 2, 0 being the most comfortable class). This “wide” format is suitable to store choice situation (or individual specific) variables because, in this case, they are stored only once in the data. It is cumbersome for alternative-specific variables because there are as many columns for such variables as there are alternatives.</p>
<p>For such a wide data set, the <code>shape</code> argument of <code>dfidx</code> is mandatory, as its default value is <code>"long"</code>. The alternative-specific variables are indicated with the <code>varying</code> argument which is a numeric vector that indicates their position in the data frame. This argument is then passed to <code><a href="https://rdrr.io/r/stats/reshape.html">stats::reshape</a></code> that coerced the original <code>data.frame</code> in “long” format. Further arguments may be passed to <code>reshape</code>. For example, as the names of the variables are of the form <code>price_A</code>, one must add <code>sep = "_"</code> (the default value being <code>"."</code>). The <code>choice</code> argument is also mandatory because the response has to be transformed in a logical value in the long format. In “wide” format, there is no alternative index. The choice situation index is not mandatory, as there is one line for each choice situation. In this data set, there is a choice situation index called <code>id</code>, and it is nested in the individual index called <code>choiceid</code>. To take the panel dimension into account, <code>idx</code> is a list of length 1 (the choice situation) containing a vector of length 2 with <code>choiceid</code> and <code>id</code>. The <code>idnames</code> is used to give a relevant name for the second index, the <code>NA</code> in first position indicating that the name of the first index is unchanged. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">dutch_railways</span>, shape <span class="op">=</span> <span class="st">"wide"</span>, varying <span class="op">=</span> <span class="fl">4</span><span class="op">:</span><span class="fl">11</span>, sep <span class="op">=</span> <span class="st">"_"</span>,</span>
<span>            idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"choiceid"</span>, <span class="st">"id"</span><span class="op">)</span><span class="op">)</span>, idnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="st">"alt"</span><span class="op">)</span>,</span>
<span>            opposite <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"price"</span>, <span class="st">"time"</span>, <span class="st">"change"</span>, <span class="st">"comfort"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note the use of the <code>opposite</code> argument for the four covariates: we expect negative coefficients for all of them, taking the opposite of the covariates will lead to expected positive coefficients.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Tr</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5,858 × 6
# Index:    2929 (choiceid) x 2 (alt)
# Balanced: yes
# Nesting:  choiceid (id)
  idx   choice price  time change comfort
  &lt;idx&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;   &lt;int&gt;
1 1:A   A      -10.9 -2.5       0      -1
2 1:B   A      -18.2 -2.5       0      -1
3 2:A   A      -10.9 -2.5       0      -1
4 2:B   A      -14.5 -2.17      0      -1
5 3:A   A      -10.9 -1.92      0      -1
# ℹ 5,853 more rows</code></pre>
</div>
</div>
<p>An <code>idx</code> column is added to the data, which contains the three relevant indexes: <code>choiceid</code> is the choice situation index, <code>alt</code> the alternative index and <code>id</code> the individual index. This column can be extracted using the <code>idx</code> function: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/idx.html">idx</a></span><span class="op">(</span><span class="va">Tr</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="long-format" class="level4"><h4 class="anchored" data-anchor-id="long-format">Long format</h4>
<p><code>toronto_montreal</code>,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> is an example of a data set in long format. It presents the choice of individuals for a transport mode for the Toronto-Montreal corridor in 1989: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">toronto_montreal</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 15,520 × 11
   case alt   choice  dist  cost   ivt   ovt  freq income urban
  &lt;int&gt; &lt;fct&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;int&gt;
1     1 train      0    83  28.2    50    66     4     45     0
2     1 car        1    83  15.8    61     0     0     45     0
3     2 train      0    83  28.2    50    66     4     25     0
4     2 car        1    83  15.8    61     0     0     25     0
5     3 train      0    83  28.2    50    66     4     70     0
# ℹ 15,515 more rows
# ℹ 1 more variable: noalt &lt;int&gt;</code></pre>
</div>
</div>
<p>There are four transport modes (<code>air</code>, <code>train</code>, <code>bus</code> and <code>car</code>) and most of the variables are alternative-specific (<code>cost</code> for monetary cost, <code>ivt</code> for in-vehicle time, <code>ovt</code> for out-vehicle time, <code>freq</code> for frequency). The only choice situation-specific variables are <code>dist</code> (distance of the trip), <code>income</code> (household income), <code>urban</code> (a dummy for trips which have a large city at the origin or the destination) and <code>noalt</code> (the number of available alternatives). The advantage of this shape is that there are much fewer columns than in the wide format, the caveat being that values of <code>dist</code>, <code>income</code> and <code>urban</code> are repeated up to four times. For data in “long” format, the <code>shape</code> and the <code>choice</code> arguments are no longer mandatory. To replicate published results later in the text, we’ll use only a subset of the choice situations, namely those for which the four alternatives are available. This can be done using the <code>subset</code> function with the <code>subset</code> argument set to <code>noalt == 4</code> while estimating the model. This can also be done within <code>dfidx</code>, using the <code>subset</code> argument.</p>
<p>The information about the structure of the data can be explicitly indicated using choice situations and alternative indexes (respectively <code>case</code> and <code>alt</code> in this data set) or, in part, guessed by the <code>dfidx</code> function. Here, after subsetting, we have 2779 choice situations with 4 alternatives, and the rows are ordered first by choice situation and then by alternative (<code>train</code>, <code>air</code>, <code>bus</code>, and <code>car</code> in this order). The first way to read correctly this data frame is to ignore completely the two index variables. In this case, the only supplementary argument to provide is the <code>alt.levels</code> argument, which is a character vector that contains the name of the alternatives in their order of appearance: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>,</span>
<span>            alt.levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"train"</span>, <span class="st">"air"</span>, <span class="st">"bus"</span>, <span class="st">"car"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that this can only be used if the data set is “balanced”, which means that the same set of alternatives is available for all choice situations. It is also possible to provide the name of the variable that contains the alternatives through the argument <code>idx</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="st">"alt"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The name of the variable that contains the information about the choice situations can also be indicated through the argument <code>idx</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, idx <span class="op">=</span> <span class="st">"case"</span>,</span>
<span>            alt.levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"train"</span>, <span class="st">"air"</span>, <span class="st">"bus"</span>, <span class="st">"car"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Both alternative and choice situation variables can also be provided: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, </span>
<span>            idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"case"</span>, <span class="st">"alt"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>More simply, as the two indexes are stored in the first two columns of the original data frame, the <code>idx</code> argument can be unset: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and the indexes can be kept as standalone series if the <code>drop.index</code> argument is set to <code>FALSE</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, </span>
<span>            idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"case"</span>, <span class="st">"alt"</span><span class="op">)</span>, drop.index <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">MC</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 11,116 × 12
# Index:    2779 (case) x 4 (alt)
# Balanced: yes
  idx        case alt   choice  dist  cost   ivt   ovt  freq income
  &lt;idx&gt;     &lt;int&gt; &lt;fct&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;
1 109:train   109 train      0   377  58.2   215    74     4     45
2 109:air     109 air        1   377 143.     56    85     9     45
3 109:bus     109 bus        0   377  27.5   301    63     8     45
4 109:car     109 car        0   377  71.6   262     0     0     45
5 110:train   110 train      0   377  58.2   215    74     4     70
# ℹ 11,111 more rows
# ℹ 2 more variables: urban &lt;int&gt;, noalt &lt;int&gt;</code></pre>
</div>
</div>
</section></section><section id="model-description" class="level3"><h3 class="anchored" data-anchor-id="model-description">Model description</h3>
<p>Standard <code>formula</code>s are not very practical to describe random utility models, as these models may use different sets of covariates. Actually, working with random utility models, one has to consider at most three sets of covariates:</p>
<ol type="1">
<li>alternative- and choice situation-specific covariates <span class="math inline">\(x_{nj}\)</span> with generic coefficients <span class="math inline">\(\beta\)</span> and alternative-specific covariates <span class="math inline">\(t_j\)</span> with a generic coefficient <span class="math inline">\(\nu\)</span>,</li>
<li>choice situation-specific covariates <span class="math inline">\(z_n\)</span> with alternative-specific coefficients <span class="math inline">\(\gamma_j\)</span>,</li>
<li>alternative- and choice situation-specific covariates <span class="math inline">\(w_{nj}\)</span> with alternative-specific coefficients <span class="math inline">\(\delta_j\)</span>.</li>
</ol>
<p>The covariates enter the observable part of the utility which can be written, for alternative <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[
V_{nj}=\alpha_j + \beta x_{nj} + \nu t_j + \gamma_j z_n + \delta_j w_{nj}
\]</span></p>
<p>As the absolute value of utility is irrelevant, only utility differences are useful to modelize the choice for one alternative. For two alternatives <span class="math inline">\(j\)</span> and <span class="math inline">\(l\)</span>, we obtain:</p>
<p><span class="math display">\[
V_{nj}-V_{nl}=(\alpha_j-\alpha_l) + \beta (x_{nj}-x_{nl}) + \nu(t_j - t_l) +
(\gamma_j-\gamma_l) z_n + (\delta_j w_{nj} - \delta_k w_{nl})
\]</span></p>
<p>It is clear from the previous expression that coefficients of choice situation-specific variables (the intercept being one of those) should be alternative-specific; otherwise they would disappear in the differentiation. Moreover, only differences of these coefficients are relevant and can be identified. For example, with three alternatives 1, 2 and 3, the three coefficients <span class="math inline">\(\gamma_1, \gamma_2, \gamma_3\)</span> associated with a choice situation-specific variable cannot be identified, but only two linear combinations. Therefore, one has to make a choice of normalization, and the simplest one is just to set <span class="math inline">\(\gamma_1 = 0\)</span>.</p>
<p>Coefficients for alternative and choice situation-specific variables may (or may not) be alternative-specific. For example, transport time is alternative-specific, but 10 mn in public transport may not have the same impact on utility than 10 mn in a car. In this case, alternative-specific coefficients are relevant. Monetary cost is also alternative-specific, but in this case, one can consider than $1 is $1 however it is spent for the use of a car or in public transports. In this case, a generic coefficient is relevant. The treatment of alternative-specific variables doesn’t differ much from the alternative and choice situation-specific variables with a generic coefficient. However, if some of these variables are introduced, the <span class="math inline">\(\nu\)</span> parameter can only be estimated in a model without intercepts to avoid perfect multicolinearity.</p>
<p> A logit model with only choice situation-specific variables is sometimes called a <em>multinomial logit model</em>, one with only alternative-specific variables, a <em>conditional logit model</em>, and one with both kinds of variables, a <em>mixed logit model</em>. This is seriously misleading: <em>conditional logit model</em> is also a logit model for longitudinal data in the statistical literature, and <em>mixed logit</em> is one of the names of a logit model with random parameters. Therefore, in what follows, we’ll use the name <em>multinomial logit model</em> for the model we’ve just described whatever the nature of the explanatory variables used.</p>
<p>The <strong>mlogit</strong> package provides objects of class <code>mFormula</code> which are built upon <code>Formula</code> objects provided by the <strong>Formula</strong> package. To illustrate the use of <code>mFormula</code> objects, we use again the <code>toronto_montreal</code> data set and consider three sets of covariates that will be indicated in a three-part formula, which refers to the three items at the beginning of this section.</p>
<ul>
<li>
<code>cost</code> (monetary cost) is an alternative-specific covariate with a generic coefficient (part 1),</li>
<li>
<code>income</code> and <code>urban</code> are choice situation-specific covariates (part 2),</li>
<li>
<code>ivt</code> (in-vehicle travel time) is alternative-specific and alternative-specific coefficients are expected (part 3). </li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">Formula</span><span class="op">)</span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">|</span> <span class="va">income</span> <span class="op">+</span> <span class="va">urban</span> <span class="op">|</span> <span class="va">ivt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Some parts of the formula may be omitted when there is no ambiguity. For example, the following sets of <code>formula</code>s are identical: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">|</span> <span class="va">income</span> <span class="op">+</span> <span class="va">urban</span><span class="op">)</span></span>
<span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">|</span> <span class="va">income</span> <span class="op">+</span> <span class="va">urban</span> <span class="op">|</span> <span class="fl">0</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">f3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">income</span> <span class="op">|</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">f3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">income</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">f4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span><span class="op">)</span></span>
<span><span class="va">f4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">|</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">f4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">|</span> <span class="fl">1</span> <span class="op">|</span> <span class="fl">0</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By default, an intercept is added to the model; it can be removed by using <code>+ 0</code> or <code>- 1</code> in the second part. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">f5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">|</span> <span class="va">income</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">ivt</span><span class="op">)</span></span>
<span><span class="va">f5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">|</span> <span class="va">income</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">|</span> <span class="va">ivt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A <code>model.frame</code> method is provided for <code>dfidx</code> objects. It differs from the <code>formula</code> method by the fact that the returned object is an object of class <code>dfidx</code> and not an ordinary data frame, which means that the information about the structure of the data is not lost. Defining a specific <code>model.frame</code> method for <code>dfidx</code> objects implies that the first argument of the function should be a <code>dfidx</code> object, which results in an unusual order of the arguments in the function (the data first, and then the formula). Moreover, as the model matrix for random utility models has specific features, we add a supplementary argument called <code>pkg</code> to the <code>dfidx</code> function so that the returned object has a specific class (and inherits the <code>dfidx</code> class): </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, pkg <span class="op">=</span> <span class="st">"mlogit"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">MC</span><span class="op">)</span></span>
<span><span class="co">## [1] "dfidx_mlogit" "dfidx"        "tbl_df"       "tbl"         </span></span>
<span><span class="co">## [5] "data.frame"</span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Formula/man/Formula.html">Formula</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">|</span> <span class="va">income</span>  <span class="op">|</span> <span class="va">ivt</span><span class="op">)</span></span>
<span><span class="va">mf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.frame.html">model.frame</a></span><span class="op">(</span><span class="va">MC</span>, <span class="va">f</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">mf</span><span class="op">)</span></span>
<span><span class="co">## [1] "dfidx_mlogit" "dfidx"        "tbl_df"       "tbl"         </span></span>
<span><span class="co">## [5] "data.frame"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using <code>mf</code> as the argument of <code>model.matrix</code> enables the construction of the relevant model matrix for random utility model, as a specific <code>model.matrix</code> method for <code>dfidx_mlogit</code> objects is provided. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">mf</span><span class="op">)</span>, <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept):air (Intercept):bus (Intercept):car   cost income:air
1               0               0               0  58.25          0
2               1               0               0 142.80         45
3               0               1               0  27.52          0
4               0               0               1  71.63          0
  income:bus income:car ivt:train ivt:air ivt:bus ivt:car
1          0          0       215       0       0       0
2          0          0         0      56       0       0
3         45          0         0       0     301       0
4          0         45         0       0       0     262</code></pre>
</div>
</div>
<p>The model matrix contains <span class="math inline">\(J-1\)</span> columns for every choice situation-specific variables (<code>income</code> and the intercept), which means that the coefficient associated with the first alternative (<code>train</code>) is set to 0. It contains only one column for <code>cost</code> because we want a generic coefficient for this variable. It contains <span class="math inline">\(J\)</span> columns for <code>ivt</code>, because it is an alternative specific variable for which we want alternative specific coefficients. </p>
</section></section><section id="sec-multinom_logit" class="level2" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="sec-multinom_logit">
<span class="header-section-number">14.2</span> Random utility model and multinomial logit model</h2>
<section id="random-utility-model" class="level3"><h3 class="anchored" data-anchor-id="random-utility-model">Random utility model</h3>
<p> The utility for alternative <span class="math inline">\(l\)</span> is written as: <span class="math inline">\(U_l=V_l+\epsilon_l\)</span> where <span class="math inline">\(V_l\)</span> is a function of some observable covariates and unknown parameters to be estimated, and <span class="math inline">\(\epsilon_l\)</span> is a random deviate which contains all the unobserved determinants of the utility. Alternative <span class="math inline">\(l\)</span> is therefore chosen if <span class="math inline">\(\epsilon_j &lt; (V_l-V_j)+\epsilon_l \;\forall\;j\neq l\)</span> and the probability of choosing this alternative is then:</p>
<p><span class="math display">\[
\mbox{P}(\epsilon_1 &lt; V_l-V_1+\epsilon_l,
\epsilon_2 &lt; V_l-V_2+\epsilon_l, ...,
\epsilon_J &lt; V_l-V_J+\epsilon_l).
\]</span></p>
<p>Denoting <span class="math inline">\(F_{-l}\)</span> as the cumulative density function of all the <span class="math inline">\(\epsilon\)</span>s except <span class="math inline">\(\epsilon_l\)</span>, this probability is:</p>
<p><span class="math display">\[
(\mbox{P}_l \mid \epsilon_l)=
F_{-l}(V_l-V_1+\epsilon_l, ..., V_l-V_J+\epsilon_l).
\]</span></p>
<p>Note that this probability is conditional on the value of <span class="math inline">\(\epsilon_l\)</span>. The unconditional probability (which depends only on <span class="math inline">\(\beta\)</span> and on the value of the observed covariates) is obtained by integrating out the conditional probability using the marginal density of <span class="math inline">\(\epsilon_l\)</span>, denoted by <span class="math inline">\(f_l\)</span>:</p>
<p><span class="math display">\[
\mbox{P}_l=\int F_{-l}(V_l-V_1+\epsilon_l, ...,V_l-V_J)+\epsilon_l)f_l(\epsilon_l) d\epsilon_l.
\]</span></p>
<p>The conditional probability is an integral of dimension <span class="math inline">\(J-1\)</span>, and the computation of the unconditional probability adds one more dimension of integration. </p>
</section><section id="distribution-of-the-error-terms" class="level3"><h3 class="anchored" data-anchor-id="distribution-of-the-error-terms">Distribution of the error terms</h3>
<p> The multinomial logit model <span class="citation" data-cites="MCFAD:74">(<a href="#ref-MCFAD:74" role="doc-biblioref">McFadden 1974</a>)</span> is a special case of the model developed in the previous section. It is based on three hypotheses. The first hypothesis is the independence of the errors. In this case, the univariate distribution of the errors can be used, which leads to the following conditional and unconditional probabilities:</p>
<p><span class="math display">\[
(\mbox{P}_l \mid \epsilon_l)=\prod_{j\neq l}F_j(V_l-V_j+\epsilon_l)
\mbox{ and }
\mbox{P}_l =\int \prod_{j\neq l}F_j(V_l-V_j+\epsilon_l) \; f_l(\epsilon_l) \;d\epsilon_l,
\]</span></p>
<p>which means that the conditional probability is the product of <span class="math inline">\(J-1\)</span> univariate cumulative density functions, and the evaluation of only a one-dimensional integral is required to compute the unconditional probability. The second hypothesis is that each <span class="math inline">\(\epsilon\)</span> follows a Gumbel (maximum) distribution, whose density and probability functions are respectively:</p>
<p><span class="math display">\[
f(z)=\frac{1}{\theta}e^{-\frac{z-\mu}{\theta}} e^{-e^{-\frac{z-\mu}{\theta}}}
\mbox{ and }
F(z)=\int_{-\infty}^{z} f(t) dt=e^{-e^{-\frac{z-\mu}{\theta}}},
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the location parameter and <span class="math inline">\(\theta\)</span> the scale parameter. The first two moments of the Gumbel distribution are <span class="math inline">\(\mbox{E}(z)=\mu+\theta \gamma\)</span>, where <span class="math inline">\(\gamma\)</span> is the Euler-Mascheroni constant (<span class="math inline">\(\approx 0.57721\)</span>) and <span class="math inline">\(\mbox{V}(z)=\frac{\pi^2}{6}\theta^2\)</span>. The mean of <span class="math inline">\(\epsilon_j\)</span> is not identified if <span class="math inline">\(V_j\)</span> contains an intercept. We can then, without loss of generality suppose that <span class="math inline">\(\mu_j=0, \; \forall j\)</span>. Moreover, the overall scale of utility is not identified. Therefore, only <span class="math inline">\(J-1\)</span> scale parameters may be identified, and a natural choice of normalization is to impose that one of the <span class="math inline">\(\theta_j\)</span> is equal to 1. The last hypothesis is that the errors are identically distributed. As the location parameter is not identified for any error term, this hypothesis is essentially a homoskedasticity hypothesis, which means that the scale parameter of the Gumbel distribution is the same for all the alternatives. As one of them has been previously set to 1, we can therefore suppose that, without loss of generality, <span class="math inline">\(\theta_j = 1, \;\forall j \in 1... J\)</span>. The conditional and unconditional probabilities then further simplify to:</p>
<p><span class="math display">\[
  (\mbox{P}_l \mid \epsilon_l)%=\prod_{j\neq l}F(V_l-V_j+\epsilon_l)
  =\prod_{j\neq l}e^{-e^{-(V_l-Vj+\epsilon_l)}}
\mbox{ and }
  \mbox{P}_l =\int_{-\infty}^{+\infty}\prod_{j\neq l}e^{-e^{-(V_l-Vj+t)}}e^{-t}e^{-e^{-t}}dt.
\]</span></p>
<p>The probabilities have then very simple, closed forms, which correspond to the logit transformation of the deterministic part of the utility.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p><span class="math display">\[
  P_l=\frac{e^{V_l}}{\sum_{j=1}^J e^{V_j}}.
\]</span></p>
</section><section id="iia-property" class="level3"><h3 class="anchored" data-anchor-id="iia-property">IIA property</h3>
<p> If we consider the probabilities of choice for two alternatives <span class="math inline">\(l\)</span> and <span class="math inline">\(m\)</span>, we have <span class="math inline">\(P_l=e^{V_l}/\sum_j e^{V_j}\)</span> and <span class="math inline">\(P_m=e^{V_m}/\sum_j e^{V_j}\)</span>. The ratio of these two probabilities is:</p>
<p><span class="math display">\[
\frac{P_l}{P_m}=\frac{e^{V_l}}{e^{V_m}}=e^{V_l-V_m}.
\]</span></p>
<p>This probability ratio for the two alternatives depends only on the characteristics of these two alternatives and not on those of other alternatives. This is called the independence of irrelevant alternatives (<strong>IIA</strong>) property. IIA relies on the hypothesis that the errors are identical and independent. It is not a problem in itself and may even be considered as a useful feature for a well-specified model. However, this hypothesis may be in practice violated, especially if some important variables are omitted. </p>
</section><section id="interpretation" class="level3"><h3 class="anchored" data-anchor-id="interpretation">Interpretation</h3>
<section id="marginal-effects" class="level4"><h4 class="anchored" data-anchor-id="marginal-effects">Marginal effects</h4>
<p>The marginal effects are the derivatives of the probabilities with respect to the covariates, which can be choice situation-specific (<span class="math inline">\(z_n\)</span>) or alternative-specific (<span class="math inline">\(x_{nj}\)</span>):</p>
<p><span class="math display">\[
  \begin{array}{rcl}
    \displaystyle \frac{\partial P_{nl}}{\partial z_{n}}&amp;=&amp;P_{nl}\left(\beta_l-\sum_j
    P_{nj}\beta_j\right) \\
    \displaystyle    \frac{\partial P_{nl}}{\partial x_{nl}}&amp;=&amp;\gamma P_{nl}(1-P_{nl})\\
    \displaystyle    \frac{\partial P_{nl}}{\partial x_{nk}}&amp;=&amp;-\gamma P_{nl}P_{nk}.
  \end{array}
\]</span></p>
<ul>
<li><p>For a choice situation-specific variable, the sign of the marginal effect is not necessarily the sign of the coefficient. Actually, the sign of the marginal effect is given by <span class="math inline">\(\left(\beta_l-\sum_j P_{nj}\beta_j\right)\)</span>, which is positive if the coefficient for alternative <span class="math inline">\(l\)</span> is greater than a weighted average of the coefficients for all the alternatives, the weights being the probabilities of choosing the alternatives. In this case, the sign of the marginal effect can be established with no ambiguity only for the alternatives with the lowest and the greatest coefficients.</p></li>
<li><p>For an alternative-specific variable, the sign of the coefficient can be directly interpreted. The marginal effect is obtained by multiplying the coefficient by the product of two probabilities which is at most 0.25. The rule of thumb is therefore to divide the coefficient by 4 in order to have an upper bound of the marginal effect.</p></li>
</ul>
<p>Note that the last equation can be rewritten: <span class="math inline">\(\frac{\mbox{d} P_{nl} / P_{nl}}{\mbox{d}x_{nk}} = -\gamma P_{nk}\)</span>. Therefore, when a characteristic of alternative <span class="math inline">\(k\)</span> changes, the relative changes of the probabilities for every alternative except <span class="math inline">\(k\)</span> are the same, which is a consequence of the IIA property.</p>
</section><section id="marginal-rates-of-substitution" class="level4"><h4 class="anchored" data-anchor-id="marginal-rates-of-substitution">Marginal rates of substitution</h4>
<p>Coefficients are marginal utilities, which cannot be interpreted. However, ratios of coefficients are marginal rates of substitution. For example, if the observable part of utility is: <span class="math inline">\(V=\beta_o +\beta_1 x_1 +\beta x_2 + \beta x_3\)</span>, joint variations of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> which ensure the same level of utility are such that: <span class="math inline">\(dV=\beta_1 dx_1+\beta_2 dx_2=0\)</span> so that:</p>
<p><span class="math display">\[
- \frac{dx_2}{dx_1}\mid_{dV = 0} = \frac{\beta_1}{\beta_2}.
\]</span></p>
<p>For example, if <span class="math inline">\(x_2\)</span> is transport cost (in dollars), <span class="math inline">\(x_1\)</span> transport time (in hours), <span class="math inline">\(\beta_1 = 1.5\)</span> and <span class="math inline">\(\beta_2=0.05\)</span>, <span class="math inline">\(\frac{\beta_1}{\beta_2}=30\)</span> is the marginal rate of substitution of time in terms of dollars and the value of 30 means that, to reduce the travel time of 1 hour, the individual is willing to pay at most $30 more. Stated more simply, time value is $30 per hour.</p>
</section><section id="sec-consumer_surplus" class="level4"><h4 class="anchored" data-anchor-id="sec-consumer_surplus">Consumer surplus</h4>
<p>Consumer’s surplus has a very simple expression for multinomial logit models, which was first derived by <span class="citation" data-cites="SMAL:ROSE:81">Small and Rosen (<a href="#ref-SMAL:ROSE:81" role="doc-biblioref">1981</a>)</span>. The level of utility attained by an individual is <span class="math inline">\(U_j=V_j+\epsilon_j\)</span>, <span class="math inline">\(j\)</span> being the chosen alternative. The expected utility, from the searcher’s point of view is then: <span class="math inline">\(\mbox{E}(\max_j U_j)\)</span>, where the expectation is taken over the values of all the error terms. Its expression is simply, up to an additive unknown constant, the log of the denominator of the logit probabilities, often called the “log-sum”:</p>
<p><span class="math display">\[
\mbox{E}(U)=\ln \sum_{j=1}^Je^{V_j}+C.
\]</span></p>
<p>If the marginal utility of income (<span class="math inline">\(\alpha\)</span>) is known and constant, the expected surplus is simply <span class="math inline">\(\frac{\mbox{E}(U)}{\alpha}\)</span>.</p>
</section></section><section id="sec-appl_mult_logit" class="level3"><h3 class="anchored" data-anchor-id="sec-appl_mult_logit">Application</h3>
<p>Random utility models are fitted using the <code>mlogit</code> function. Basically, only two arguments are mandatory, <code>formula</code> and <code>data</code>, if an <code>dfidx</code> object (and not an ordinary <code>data.frame</code>) is provided. We use the <code>toronto_montreal</code> data set, which was already coerced to a <code>dfidx</code> object (called <code>MC</code>) in the previous section. The same model can then be estimated using as <code>data</code> argument this <code>dfidx</code> object: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">ml.MC1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">freq</span> <span class="op">+</span> <span class="va">ovt</span> <span class="op">|</span> <span class="va">income</span> <span class="op">|</span> <span class="va">ivt</span>, <span class="va">MC</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>or a <code>data.frame</code>. In this latter case, further arguments that will be passed to <code>dfidx</code> should be indicated: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ml.MC1b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">freq</span> <span class="op">+</span> <span class="va">ovt</span> <span class="op">|</span> <span class="va">income</span> <span class="op">|</span> <span class="va">ivt</span>, </span>
<span>                  <span class="va">toronto_montreal</span>, subset <span class="op">=</span> <span class="va">noalt</span> <span class="op">==</span> <span class="fl">4</span>, </span>
<span>                  idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"case"</span>, <span class="st">"alt"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>mlogit</code> provides two further useful arguments:</p>
<ul>
<li>
<code>reflevel</code> indicates which alternative is the “reference” alternative, i.e., the one for which the coefficients of choice situation-specific covariates are set to 0,</li>
<li>
<code>alt.subset</code> indicates a subset of alternatives on which the estimation has to be performed; in this case, only the lines that correspond to the selected alternatives are used, and all the choice situations where unselected alternatives have been chosen are removed.</li>
</ul>
<p>We estimate the model on the subset of three alternatives (we exclude <code>bus</code> whose market share is negligible in our sample) and we set <code>car</code> as the reference alternative. Moreover, we use a total transport time variable computed as the sum of the in-vehicle and out-vehicle time variables. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MC</span> <span class="op">&lt;-</span> <span class="va">MC</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>time <span class="op">=</span> <span class="va">ivt</span> <span class="op">+</span> <span class="va">ovt</span><span class="op">)</span></span>
<span><span class="va">ml.MC1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">freq</span> <span class="op">|</span> <span class="va">income</span> <span class="op">|</span> <span class="va">time</span>, <span class="va">MC</span>, </span>
<span>                 alt.subset <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span><span class="op">)</span>, reflevel <span class="op">=</span> <span class="st">"car"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The main results of the model are computed and displayed using the <code>summary</code> method:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
mlogit(formula = choice ~ cost + freq | income | time, data = MC, 
    alt.subset = c("car", "train", "air"), reflevel = "car", 
    method = "nr")

Frequencies of alternatives:choice
  car train   air 
0.458 0.167 0.375 

nr method
6 iterations, 0h:0m:0s 
g'(-H)^-1g = 6.94E-06 
successive function values within tolerance limits 

Coefficients :
                   Estimate Std. Error z-value Pr(&gt;|z|)    
(Intercept):train -0.970344   0.265131   -3.66  0.00025 ***
(Intercept):air   -1.898566   0.684143   -2.78  0.00552 ** 
cost              -0.028497   0.006559   -4.34  1.4e-05 ***
freq               0.074029   0.004733   15.64  &lt; 2e-16 ***
income:train      -0.006469   0.003104   -2.08  0.03713 *  
income:air         0.028246   0.003654    7.73  1.1e-14 ***
time:car          -0.014024   0.001380  -10.16  &lt; 2e-16 ***
time:train        -0.010969   0.000818  -13.40  &lt; 2e-16 ***
time:air          -0.017551   0.003992   -4.40  1.1e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Log-Likelihood: -1950
McFadden R^2:  0.312 
Likelihood ratio test : chisq = 1770 (p.value = &lt;2e-16)</code></pre>
</div>
</div>
<p>The frequencies of the different alternatives in the sample are first indicated. Next, some information about the optimization is displayed: the Newton-Raphson method (with analytical gradient and hessian) is used, as it is the most efficient method for this simple model for which the log-likelihood function is globally concave. Note that very few iterations and computing times are required to estimate this model. Then the usual table of coefficients is displayed, followed by some goodness-of-fit measures: the value of the log-likelihood function, which is compared to the value when only intercepts are introduced, which leads to the computation of the McFadden <span class="math inline">\(R^2\)</span> and to the likelihood ratio test. The <code>fitted</code> method can be used either to obtain the probability of actual choices (<code>type = "outcome"</code>) or the probabilities for all the alternatives (<code>type = "probabilities"</code>). </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">ml.MC1</span>, type <span class="op">=</span> <span class="st">"outcome"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   109    110    111    112    113    114 
0.1909 0.3400 0.1471 0.3400 0.3400 0.2440 </code></pre>
</div>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">ml.MC1</span>, type <span class="op">=</span> <span class="st">"probabilities"</span><span class="op">)</span>, <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       car  train    air
109 0.4206 0.3884 0.1909
110 0.3696 0.2904 0.3400
111 0.4297 0.4233 0.1471
112 0.3696 0.2904 0.3400</code></pre>
</div>
</div>
<p>Note that the log-likelihood is the sum of the log of the fitted outcome probabilities and that, as the model contains intercepts, the average fitted probabilities for every alternative equals the market shares of the alternatives in the sample. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">ml.MC1</span>, type <span class="op">=</span> <span class="st">"outcome"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] -1951</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span></span>
<span><span class="co">## 'log Lik.' -1951 (df=9)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">ml.MC1</span>, type <span class="op">=</span> <span class="st">"probabilities"</span><span class="op">)</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="co">##    car  train    air </span></span>
<span><span class="co">## 0.4576 0.1672 0.3752</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Predictions can be made using the <code>predict</code> method. If no data is provided, predictions are made for the sample mean values of the covariates. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span></span>
<span><span class="co">##    car  train    air </span></span>
<span><span class="co">## 0.5066 0.2117 0.2817</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Assume, for example, that we wish to predict the effect of a reduction of train transport time of 20%. We first create a new <code>data.frame</code> simply by multiplying train transport time by 0.8 and then using the <code>predict</code> method with this new <code>data.frame</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">NMC</span> <span class="op">&lt;-</span> <span class="va">MC</span></span>
<span><span class="va">NMC</span> <span class="op">&lt;-</span> <span class="va">NMC</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">idx</span><span class="op">$</span><span class="va">alt</span> <span class="op">==</span> <span class="st">"train"</span>, <span class="fl">0.8</span> <span class="op">*</span> <span class="va">time</span>, <span class="va">time</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Oprob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">ml.MC1</span>, type <span class="op">=</span> <span class="st">"probabilities"</span><span class="op">)</span></span>
<span><span class="va">Nprob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ml.MC1</span>, newdata <span class="op">=</span> <span class="va">NMC</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span>old <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">Oprob</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span>, new <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">Nprob</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       car  train    air
old 0.4576 0.1672 0.3752
new 0.4045 0.2636 0.3319</code></pre>
</div>
</div>
<p>If, for the first individuals in the sample, we compute the ratio of the probabilities of the air and the car mode, we obtain: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Nprob</span><span class="op">[</span>, <span class="st">"air"</span><span class="op">]</span> <span class="op">/</span> <span class="va">Nprob</span><span class="op">[</span>, <span class="st">"car"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##    109    110    111    112    113    114 </span></span>
<span><span class="co">## 0.4539 0.9198 0.3422 0.9198 0.9198 0.6021</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Oprob</span><span class="op">[</span>, <span class="st">"air"</span><span class="op">]</span> <span class="op">/</span> <span class="va">Oprob</span><span class="op">[</span>, <span class="st">"car"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">##    109    110    111    112    113    114 </span></span>
<span><span class="co">## 0.4539 0.9198 0.3422 0.9198 0.9198 0.6021</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>which is an illustration of the IIA property. If train time changes, it changes the probabilities of choosing air and car, but not their ratio. We next compute the surplus for individuals of the sample induced by train time reduction. This requires the computation of the log-sum term (also called inclusive value or inclusive utility) for every choice situation, which is:</p>
<p><span class="math display">\[
\mbox{iv}_n = \ln \sum_{j = 1} ^ J e^{\beta^\top x_{nj}}.
\]</span></p>
<p>For this purpose, we use the <code>logsum</code> function, which works on a vector of coefficients and a model matrix. The basic use of <code>logsum</code> consists of providing as unique argument (called <code>coef</code>) a <code>mlogit</code> object. In this case, the <code>model.matrix</code> and the <code>coef</code> are extracted from the same model: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ivbefore</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/logsum.html">logsum</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To compute the log-sum after train time reduction, we must provide a model matrix which is not the one corresponding to the fitted model. This can be done using the <code>X</code> argument which is a matrix or an object from which a model matrix can be extracted. This can also be done by filling the <code>data</code> argument (a data frame or an object from which a data frame can be extracted using <code>model.frame</code>), and eventually the <code>formula</code> argument (a formula or an object for which the <code>formula</code> method can be applied). If no formula is provided, but if <code>data</code> is a <code>dfidx</code> object, the formula is extracted from it. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ivafter</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/logsum.html">logsum</a></span><span class="op">(</span><span class="va">ml.MC1</span>, data <span class="op">=</span> <span class="va">NMC</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Surplus variation is then computed as the difference of the log-sums divided by the opposite of the cost coefficient which can be interpreted as the marginal utility of income: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">surplus</span> <span class="op">&lt;-</span> <span class="op">-</span> <span class="op">(</span><span class="va">ivafter</span> <span class="op">-</span> <span class="va">ivbefore</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span><span class="op">[</span><span class="st">"cost"</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">surplus</span><span class="op">)</span></span>
<span><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">##   0.585   2.844   3.900   4.697   5.844  31.391</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Consumer surplus variations range from 0.6 to 31 Canadian dollars, with a median value of about $4. Marginal effects are computed using the <code>effects</code> method. By default, they are computed at the sample mean, but a <code>data</code> argument can be provided. The variation of the probability and the covariate can be either absolute or relative. This is indicated with the <code>type</code> argument which is a combination of two <code>a</code> (as absolute) and <code>r</code> (as relative) characters. For example, <code>type = "ar"</code> means that what is measured is an absolute variation of the probability for a relative variation of the covariate. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/effects.html">effects</a></span><span class="op">(</span><span class="va">ml.MC1</span>, covariate <span class="op">=</span> <span class="st">"income"</span>, type <span class="op">=</span> <span class="st">"ar"</span><span class="op">)</span></span>
<span><span class="co">##     car   train     air </span></span>
<span><span class="co">## -0.1822 -0.1509  0.3331</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results indicate that, for a 100% increase of income, the probability of choosing <code>air</code> increases by 33 percentage points, as the probabilities of choosing <code>car</code> and <code>train</code> decrease by 18 and 15 percentage points.</p>
<p>For an alternative specific covariate, a matrix of marginal effects is displayed. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/effects.html">effects</a></span><span class="op">(</span><span class="va">ml.MC1</span>, covariate <span class="op">=</span> <span class="st">"cost"</span>, type <span class="op">=</span> <span class="st">"rr"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          car   train     air
car   -0.9131  0.9377  0.9377
train  0.3358 -1.2505  0.3358
air    1.2317  1.2317 -3.1410</code></pre>
</div>
</div>
<p>The cell in the <span class="math inline">\(l^{\mbox{th}}\)</span> row and the <span class="math inline">\(c^{\mbox{th}}\)</span> column indicates the change of the probability of choosing alternative <span class="math inline">\(c\)</span> when the cost of alternative <span class="math inline">\(l\)</span> changes. As <code>type = "rr"</code>, elasticities are computed. For example, a 10% change of train cost increases the probabilities of choosing car and air by 3.36%. Note that the relative changes of the probabilities of choosing one of these two modes are equal, which is a consequence of the IIA property. Finally, in order to compute travel time valuation, we divide the coefficients of travel times (in minutes) by the coefficient of monetary cost (in dollars). </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/grep.html">grep</a></span><span class="op">(</span><span class="st">"time"</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">]</span> <span class="op">/</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">ml.MC1</span><span class="op">)</span><span class="op">[</span><span class="st">"cost"</span><span class="op">]</span> <span class="op">*</span> <span class="fl">60</span></span>
<span><span class="co">##   time:car time:train   time:air </span></span>
<span><span class="co">##      29.53      23.09      36.95</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The value of travel time ranges from 23 for a train to 37 Canadian dollars per hour for a plane.</p>
</section></section><section id="sec-relaxing_iid" class="level2" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="sec-relaxing_iid">
<span class="header-section-number">14.3</span> Logit models relaxing the iid hypothesis</h2>
<p>In the previous section, we assumed that the error terms were iid (identically and independently distributed), i.e., uncorrelated and homoskedastic. Extensions of the basic multinomial logit model have been proposed by relaxing one of these two hypotheses while maintaining the hypothesis of a Gumbel distribution.</p>
<section id="heteroskedastic-logit-model" class="level3"><h3 class="anchored" data-anchor-id="heteroskedastic-logit-model">Heteroskedastic logit model</h3>
<p> The heteroskedastic logit model was proposed by <span class="citation" data-cites="BHAT:95">Bhat (<a href="#ref-BHAT:95" role="doc-biblioref">1995</a>)</span>. The probability that <span class="math inline">\(U_l&gt;U_j\)</span> is:</p>
<p><span class="math display">\[
P(\epsilon_j&lt;V_l-V_j+\epsilon_l)=e^{-e^{-\frac{(V_l-V_j+\epsilon_l)}{\theta_j}}},
\]</span></p>
<p>which implies the following conditional and unconditional probabilities</p>
<p><span class="math display">\[
  (P_l \mid \epsilon_l) =\prod_{j\neq
    l}e^{-e^{-\frac{(V_l-V_j+\epsilon_l)}{\theta_j}}},
\]</span></p>
<p><span id="eq-prob_heterosc_logit"><span class="math display">\[
  \begin{array}{rcl}
  P_l&amp;=&amp;\displaystyle\int_{-\infty}^{+\infty} \prod_{j\neq l}
  \left(e^{-e^{-\frac{(V_l-V_j+t)}{\theta_j}}}\right)\frac{1}{\theta_l}e^{-\frac{t}{\theta_l}}e^{-e^{-\frac{t}{\theta_l}}}
  dt\\
&amp;=&amp; \displaystyle \int_{0}^{+\infty}\left(e^{-\sum_{j \neq
      l}e^{-\frac{V_l-V_j-\theta_l \ln t}{\theta_j}}}\right)e^{-t}dt.
     \end{array}
\tag{14.1}\]</span></span></p>
<p>There is no closed form for this integral, but it can be efficiently computed using a Gauss quadrature method, and more precisely the Gauss-Laguerre quadrature method. <span class="citation" data-cites="BHAT:95">Bhat (<a href="#ref-BHAT:95" role="doc-biblioref">1995</a>)</span> estimated the heteroskedastic logit model on the <code>toronto_montreal</code> data set. Using <code>mlogit</code>, the heteroskedastic logit model is obtained by setting the <code>heterosc</code> argument to <code>TRUE</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ml.MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">freq</span> <span class="op">+</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">+</span> <span class="va">ovt</span> <span class="op">|</span> </span>
<span>                  <span class="va">urban</span> <span class="op">+</span> <span class="va">income</span>, <span class="va">MC</span>, reflevel <span class="op">=</span> <span class="st">'car'</span>, </span>
<span>                alt.subset <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">hl.MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">freq</span> <span class="op">+</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivt</span> <span class="op">+</span> <span class="va">ovt</span> <span class="op">|</span> </span>
<span>                  <span class="va">urban</span> <span class="op">+</span> <span class="va">income</span>, <span class="va">MC</span>, reflevel <span class="op">=</span> <span class="st">'car'</span>, </span>
<span>                alt.subset <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span><span class="op">)</span>, </span>
<span>                heterosc <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">hl.MC</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">gaze</span><span class="op">(</span>coef <span class="op">=</span> <span class="fl">11</span><span class="op">:</span><span class="fl">12</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Estimate Std. Error z-value Pr(&gt;|z|)
sp.train    1.237      0.110   11.20  &lt; 2e-16
sp.air      0.540      0.112    4.83  1.4e-06</code></pre>
</div>
</div>
<p>Two supplementary coefficients (<code>sp.train</code> and <code>sp.air</code>) are estimated (<span class="math inline">\(\theta_j\)</span> in <a href="#eq-prob_heterosc_logit">Equation&nbsp;<span>14.1</span></a>), the third for the reference modality being set to 1. The variance of the error terms of train and air are respectively higher and lower than the variance of the error term of car (set to 1). Note that the z-values and p-values of the output are not particularly meaningful, as the hypothesis that the coefficient is zero (and not 1) is tested. The homoskedasticity hypothesis can be tested using any of the three tests. For the likelihood ratio and the Wald test, one can use only the fitted heteroskedastic model as argument. In this case, it is guessed that the hypothesis that the user wants to test is the homoskedasticity hypothesis. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">hl.MC</span>, <span class="va">ml.MC</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 6.888, df: 2, pval = 0.032</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">hl.MC</span>, heterosc <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 25.196, df: 2, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>or, more simply: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">hl.MC</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">hl.MC</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The Wald test can also be computed using the <code>linearHypothesis</code> function from the <code>car</code> package: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">hl.MC</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'sp.air = 1'</span>, <span class="st">'sp.train = 1'</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 25.196, df: 2, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> For the score test, we provide the constrained model as argument, which is the standard multinomial logit model and the supplementary argument which defines the unconstrained model, which is in this case <code>heterosc = TRUE</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/scoretest.html">scoretest</a></span><span class="op">(</span><span class="va">ml.MC</span>, heterosc <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 9.488, df: 2, pval = 0.009</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The homoskedasticity hypothesis is therefore strongly rejected using the Wald test, but only at the 1 and 5% level for, respectively, the score and the likelihood ratio tests. </p>
</section><section id="nested-logit-model" class="level3"><h3 class="anchored" data-anchor-id="nested-logit-model">Nested logit model</h3>
<p> The nested logit model was first proposed by <span class="citation" data-cites="MCFAD:78">McFadden (<a href="#ref-MCFAD:78" role="doc-biblioref">1978</a>)</span>. It is a generalization of the multinomial logit model that is based on the idea that some alternatives may be joined in several groups (called nests). The error terms may then present some correlation in the same nest, whereas error terms of different nests are still uncorrelated. Denoting <span class="math inline">\(m=1... M\)</span> the nests and <span class="math inline">\(B_m\)</span> the set of alternatives belonging to nest <span class="math inline">\(m\)</span>, the cumulative distribution of the errors is:</p>
<p><span class="math display">\[
\mbox{exp}\left(-\sum_{m=1}^M \left( \sum_{j \in B_m}
    e^{-\epsilon_j/\lambda_m}\right)^{\lambda_m}\right).
\]</span></p>
<p>The marginal distributions of the <span class="math inline">\(\epsilon\)</span>s are still univariate extreme values, but there is now some correlation within nests. <span class="math inline">\(1-\lambda_m\)</span> is a measure of the correlation, i.e., <span class="math inline">\(\lambda_m = 1\)</span> implies no correlation. In the special case where <span class="math inline">\(\lambda_m=1\; \forall m\)</span>, the errors are iid Gumbel errors and the nested logit model reduce to the multinomial logit model. It can then be shown that the probability of choosing alternative <span class="math inline">\(j\)</span> that belongs to nest <span class="math inline">\(l\)</span> is:</p>
<p><span class="math display">\[
P_j = \frac{e^{V_j/\lambda_l}\left(\sum_{k \in B_l}
    e^{V_k/\lambda_l}\right)^{\lambda_l-1}} {\sum_{m=1}^M\left(\sum_{k
      \in B_m} e^{V_k/\lambda_m}\right)^{\lambda_m}},
\]</span></p>
<p>and that this model is a random utility model if all the <span class="math inline">\(\lambda\)</span> parameters are in the <span class="math inline">\(0-1\)</span> interval.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Let us now write the deterministic part of the utility of alternative <span class="math inline">\(j\)</span> as the sum of two terms: the first (<span class="math inline">\(Z_j\)</span>) being specific to the alternative and the second (<span class="math inline">\(W_l\)</span>) to the nest it belongs to:</p>
<p><span class="math display">\[V_j=Z_j+W_l.\]</span></p>
<p>We can then rewrite the probabilities as follow:</p>
<p><span class="math display">\[
\begin{array}{rcl}
P_j&amp;=&amp;\frac{e^{(Z_j+W_l)/\lambda_l}}{\sum_{k \in B_l}
  e^{(Z_k+W_l)/\lambda_l}}\times \frac{\left(\sum_{k \in B_l}
    e^{(Z_k+W_l)/\lambda_l}\right)^{\lambda_l}}
{\sum_{m=1}^M\left(\sum_{k \in B_m}
    e^{(Z_k+W_m)/\lambda_m}\right)^{\lambda_m}}\\
&amp;=&amp;\frac{e^{Z_j/\lambda_l}}{\sum_{k \in B_l}
    e^{Z_k/\lambda_l}}\times
\frac{\left(e^{W_l/\lambda_l}\sum_{k \in B_l} e^{Z_k/\lambda_l}\right)^{\lambda_l}}
{\sum_{m=1}^M\left(e^{W_m/\lambda_m}\sum_{k
      \in B_m} e^{Z_k/\lambda_m}\right)^{\lambda_m}}.
\end{array}
\]</span></p>
<p>Then denote <span class="math inline">\(I_l=\ln \sum_{k \in B_l} e^{Z_k/\lambda_l}\)</span> which is often called the log-sum, the inclusive value or the inclusive utility.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> We then can write the probability of choosing alternative <span class="math inline">\(j\)</span> as:</p>
<p><span class="math display">\[
P_j=\frac{e^{Z_j/\lambda_l}}{\sum_{k \in B_l}
    e^{Z_k/\lambda_l}}\times
\frac{e^{W_l+\lambda_l I_l}}{\sum_{m=1}^Me^{W_m+\lambda_m I_m}}.
\]</span></p>
<p>The first term <span class="math inline">\(\mbox{P}_{j\mid l}\)</span> is the conditional probability of choosing alternative <span class="math inline">\(j\)</span> if nest <span class="math inline">\(l\)</span> is chosen. It is often referred to as the <em>lower model</em>. The second term <span class="math inline">\(\mbox{P}_l\)</span> is the marginal probability of choosing nest <span class="math inline">\(l\)</span> and is referred to as the <em>upper model</em>. <span class="math inline">\(W_l+\lambda_l I_l\)</span> can be interpreted as the expected utility of choosing the best alternative in <span class="math inline">\(l\)</span>, <span class="math inline">\(W_l\)</span> being the expected utility of choosing an alternative in this nest (whatever this alternative is) and <span class="math inline">\(\lambda_l I_l\)</span> being the expected extra utility gained by being able to choose the best alternative in the nest. The inclusive values link the two models. It is then straightforward to show that IIA applies within nests, but not for two alternatives in different nests.</p>
<p>A consistent but inefficient way of estimating the nested logit model is to estimate separately its two components. The coefficients of the lower model are first estimated, which enables the computation of the inclusive values <span class="math inline">\(I_l\)</span>. The coefficients of the upper model are then estimated, using <span class="math inline">\(I_l\)</span> as covariates. Maximizing directly the likelihood function of the nested model leads to a more efficient estimator. </p>
<p> </p>
<p>To illustrate the estimation of the nested logit model, we use the <code>telephone</code> data set, used by <span class="citation" data-cites="TRAI:MCFA:BENA:87">Train, McFadden, and Ben-Akiva (<a href="#ref-TRAI:MCFA:BENA:87" role="doc-biblioref">1987</a>)</span> and <span class="citation" data-cites="WALK:BENA:BOLD:07">Walker, Ben-Akiva, and Bolduc (<a href="#ref-WALK:BENA:BOLD:07" role="doc-biblioref">2007</a>)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">telephone</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,170 × 4
  choice service  household  cost
  &lt;lgl&gt;  &lt;fct&gt;        &lt;int&gt; &lt;dbl&gt;
1 FALSE  budget           1  1.76
2 FALSE  extended         1 13.8 
3 FALSE  local            1  2.55
4 FALSE  metro            1  3.15
5 TRUE   standard         1  1.75
# ℹ 2,165 more rows</code></pre>
</div>
</div>
<p>A total of 428 households were surveyed in 1984 about their choice of a local telephone service, which typically involves the choice between a flat service (a fixed monthly charge for an unlimited calls within a specified geographical area) and a measured (a reduced fixed monthly charge for a limited number of calls plus usage charges for additional calls) service. Households had the choice between five services:</p>
<ul>
<li>
<em>budget measured</em> (<code>budget</code>): no fixed monthly charge; usage charges apply to each call made,</li>
<li>
<em>standard measured</em> (<code>standard</code>): a fixed monthly charge covers up to a specified dollar amount (greater than the fixed charge) of local calling, after which usage charges apply to each call made,</li>
<li>
<em>local flat</em> (<code>local</code>): a greater monthly charge that may depend upon residential location; unlimited free calling within a local calling area; usage charges apply to calls made outside local calling area,</li>
<li>
<em>extended area flat</em> (<code>extended</code>): a further increase in the fixed monthly charge to permit unlimited free calling within an extended area,</li>
<li>
<em>metro area flat</em> (<code>metro</code>): the greatest fixed monthly charge that permits unlimited free calling within the entire metropolitan area.</li>
</ul>
<div style="page-break-after: always;"></div>
<p>The first two services are measured, and the last three are flat services. There is therefore an obvious nesting structure for this example. We first estimate the multinomial logit model, with the log of cost as the unique covariate: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ml_tel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">cost</span><span class="op">)</span>, <span class="va">telephone</span>, </span>
<span>                 idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"household"</span>, <span class="st">"service"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then update this model in order to introduce nests, using the <code>nests</code> argument. It is a list of characters that contains the alternatives for the different nests. It is advisable to use a named list (we use here <code>"measured"</code> and <code>"flat"</code> as names of the nests): </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">nl_tel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span>, <span class="va">telephone</span>, </span>
<span>                 idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"household"</span>, <span class="st">"service"</span><span class="op">)</span>, </span>
<span>                 nests <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>measured <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"budget"</span>, <span class="st">"standard"</span><span class="op">)</span>, </span>
<span>                              flat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"local"</span>, <span class="st">"metro"</span>, <span class="st">"extended"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">nl_tel</span><span class="op">)</span></span>
<span><span class="co">## (Intercept):extended    (Intercept):local    (Intercept):metro </span></span>
<span><span class="co">##               1.2255               1.2716               1.7837 </span></span>
<span><span class="co">## (Intercept):standard                 cost          iv:measured </span></span>
<span><span class="co">##               0.3782              -1.4900               0.4848 </span></span>
<span><span class="co">##              iv:flat </span></span>
<span><span class="co">##               0.4362</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Two supplementary coefficients are estimated, <code>iv:measured</code> and <code>iv:flat</code>. The two values are in the 0-1 interval and close to each other. The <code>un.nest.el</code> argument enables to estimate a unique supplementary coefficient for the two nests: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">nl_tel_u</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">nl_tel</span>, un.nest.el <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then have three nested models and the hypothesis of a unique parameter can be tested using any of the three tests: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/scoretest.html">scoretest</a></span><span class="op">(</span><span class="va">nl_tel_u</span>, un.nest.el <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 0.109, df: 1, pval = 0.741</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">nl_tel</span>, <span class="va">nl_tel_u</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 0.137, df: 1, pval = 0.712</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">nl_tel</span>, un.nest.el <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 0.160, df: 1, pval = 0.689</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The three tests conclude that a unique parameter can be estimated. Then, we can test whether this parameter is 1, in which case the nested logit model reduces to the multinomial logit model: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/scoretest.html">scoretest</a></span><span class="op">(</span><span class="va">ml_tel</span>, </span>
<span>          nests <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>measured <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"budget"</span>, <span class="st">"standard"</span><span class="op">)</span>, </span>
<span>                       flat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"local"</span>, <span class="st">"metro"</span>, <span class="st">"extended"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 5.685, df: 2, pval = 0.058</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">nl_tel_u</span>, <span class="va">ml_tel</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 17.177, df: 1, pval = 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">nl_tel_u</span>, nests <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 25.541, df: 1, pval = 0.000</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">nl_tel_u</span>, <span class="st">"iv = 1"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 25.541, df: 1, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Based on the Wald and the likelihood ratio, the preferred specification is the nested logit model (but note that the p-value for the score test is slightly higher than 5%). </p>
</section></section><section id="sec-mixed_logit" class="level2" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="sec-mixed_logit">
<span class="header-section-number">14.4</span> Random parameters (or mixed) logit model</h2>
<section id="derivation-of-the-model" class="level3"><h3 class="anchored" data-anchor-id="derivation-of-the-model">Derivation of the model</h3>
<p> A <strong>mixed logit</strong> model (or random parameters logit model) is a logit model whose parameters are assumed to vary from one individual to another. It is therefore a model that takes the heterogeneity of the population into account. For the standard logit model, the probability that individual <span class="math inline">\(n\)</span> chooses alternative <span class="math inline">\(j\)</span> is:</p>
<p><span class="math display">\[
P_{nl}=\frac{e^{\beta'x_{nl}}}{\sum_j e^{\beta'x_{nj}}}.
\]</span></p>
<p>Suppose now that the coefficients are individual-specific. The probabilities are then:</p>
<p><span class="math display">\[
P_{nl}=\frac{e^{\beta_n'x_{nl}}}{\sum_j e^{\beta_n'x_{nj}}}.
\]</span></p>
<p>A first approach consists of estimating the parameters for every individual. However, these parameters are identified and can be consistently estimated only if a large number of choice situations per individual is available, which is scarcely the case. A more appealing approach consists of considering <span class="math inline">\(\beta_n\)</span> as random draws on a distribution whose parameters are estimated, which leads to the mixed logit model. The probability that individual <span class="math inline">\(n\)</span> will choose alternative <span class="math inline">\(l\)</span>, for a given value of <span class="math inline">\(\beta_n\)</span> is:</p>
<p><span class="math display">\[
P_{nl} \mid \beta_n =\frac{e^{\beta_n'x_{nl}}}{\sum_j e^{\beta_n'x_{nj}}}.
\]</span></p>
<p>To get the unconditional probability, we have to integrate out this conditional probability, using the density function of <span class="math inline">\(\beta\)</span>. Suppose that <span class="math inline">\(V_{nl}=\beta_n x_{nl}\)</span>, i.e., that there is only one individual-specific coefficient and that the density of <span class="math inline">\(\beta_n\)</span> is <span class="math inline">\(f(\beta,\theta)\)</span>, <span class="math inline">\(\theta\)</span> being the vector of the parameters of the distribution of <span class="math inline">\(\beta\)</span>. The unconditional probability is then:</p>
<p><span class="math display">\[
P_{nl}= \mbox{E}(P_{nl} \mid \beta_n) =
\int_{\beta}(P_{nl} \mid \beta)f(\beta,\theta)d\beta
=
\int_{\beta}\frac{e^{\beta^\top x_{nl}}}{\sum_j e^{\beta^\top x_{nj}}}f(\beta,\theta)d\beta,
\]</span></p>
<p>which is a one-dimensional integral that can be efficiently estimated by quadrature methods. If <span class="math inline">\(V_{nl}=\beta_n^{\top} x_{nl}\)</span> where <span class="math inline">\(\beta_n\)</span> is a vector of length <span class="math inline">\(K\)</span> and <span class="math inline">\(f(\beta,\theta)\)</span> is the joint density of the <span class="math inline">\(K\)</span> individual-specific coefficients, the unconditional probability is:</p>
<p><span class="math display">\[
P_{nl}= \mbox{E}(P_{nl} \mid \beta_n) =
\int_{\beta_1}\int_{\beta_2}...\int_{\beta_K}(P_{nl} \mid
\beta)f(\beta,\theta)d\beta_1d\beta_2... d\beta_K.
\]</span></p>
<p>This is a <span class="math inline">\(K\)</span>-dimensional integral which cannot easily be estimated by quadrature methods. The only practical method is then to use simulations. More precisely, <span class="math inline">\(R\)</span> draws of the parameters are taken from the distribution of <span class="math inline">\(\beta\)</span>, the probability is computed for every draw and the unconditional probability, which is the expected value of the conditional probabilities is estimated by the average of the <span class="math inline">\(R\)</span> probabilities.</p>
<p>The expected value of a random coefficient (<span class="math inline">\(\mbox{E}(\beta)\)</span>) is simply estimated by the mean of the <span class="math inline">\(R\)</span> draws on its distribution: <span class="math inline">\(\bar{\beta}=\sum_{r=1}^R \beta_r\)</span>. Individual parameters are obtained by first computing the probabilities of the observed choice of <span class="math inline">\(n\)</span> for every value of <span class="math inline">\(\beta_r\)</span>:</p>
<p><span class="math display">\[
P_{nr}=\frac{\sum_j y_{nj} e^{\beta_r^{'}x_{nj}}}{\sum_j e^{\beta_r^{'}x_{nj}}},
\]</span></p>
<p>where <span class="math inline">\(y_{nj}\)</span> is a dummy equal to 1 if <span class="math inline">\(n\)</span> has chosen alternative <span class="math inline">\(j\)</span>. The expected value of the parameter for an individual is then estimated by using these probabilities to weight the <span class="math inline">\(R\)</span> <span class="math inline">\(\beta\)</span> values:</p>
<p><span class="math display">\[
\hat{\beta}_n = \frac{\sum_r P_{nr} \beta_r}{\sum_r P_{nr}}.
\]</span></p>
<p>If there are repeated observations for the same individuals, the longitudinal dimension of the data can be taken into account in the mixed logit model, assuming that the random parameters of individual <span class="math inline">\(n\)</span> are the same for all their choice situations. Denoting <span class="math inline">\(y_{ntl}\)</span> a dummy equal to 1 if <span class="math inline">\(n\)</span> chooses alternative <span class="math inline">\(l\)</span> for the <span class="math inline">\(t\)</span><sup>th</sup> choice situation, the probability of the observed choice is:</p>
<p><span class="math display">\[
P_{nt}\mid \beta_n=\prod_j \frac{\sum_j y_{ntj}e^{\beta_n ^\top x_{ntj}}}{\sum_j e^{\beta_n ^\top x_{ntj}}}.
\]</span></p>
<p>The joint probability for the <span class="math inline">\(T\)</span> observations of individual <span class="math inline">\(n\)</span> is then:</p>
<p><span class="math display">\[
P_{n}\mid \beta_n=\prod_t \prod_j \frac{\sum_jy_{ntj}e^{\beta_n ^\top x_{ntj}}}{\sum_j e^{\beta_n ^\top x_{ntj}}}
\]</span></p>
<p> </p>
</section><section id="application" class="level3"><h3 class="anchored" data-anchor-id="application">Application</h3>
<p>The random parameter logit model is estimated by providing a <code>rpar</code> argument to <code>mlogit</code>. This argument is a named vector, the names being the random coefficients and the acronyms for the law of distribution. Currently, the normal (<code>"n"</code>), log-normal (<code>"ln"</code>), zero-censored normal (<code>"cn"</code>), uniform (<code>"u"</code>) and triangular (<code>"t"</code>) distributions are available. For these distributions, two parameters are estimated which are, for normal related distributions, the mean and the standard-deviation of the underlying normal distribution and for the uniform and triangular distribution, the mean and the half-range of the distribution. For these last two distributions, zero-bounded variants are also provided (<code>"zbt"</code> and <code>"zbu"</code>). These two distributions are defined by only one parameter (the mean) and their definition domain varies from 0 to twice the mean.</p>
<p>Several considerations may lead to the choice of a specific distribution:</p>
<ul>
<li>if correlated coefficients are required, the natural choice is a (transformed-) normal distribution, <code>"n"</code>, <code>"ln"</code>, <code>"tn"</code> and <code>"cn"</code>,</li>
<li>it’s often the case that one wants to impose that the distribution of a random parameter takes only positive or negative values. For example, the price coefficient should be negative for every individual. In this case, <code>"zbt"</code> and <code>"zbu"</code> can be used. The use of <code>"ln"</code> and <code>"cn"</code> can also be relevant but, in this case, if only negative values are expected, one should consider the distribution of the opposite of the random price coefficient. This can easily be done using the <code>opposite</code> argument of <code>dfidx</code>,<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>
</li>
<li>the use of unbounded distributions often leads to implausible values of some statistics of the random parameters, especially the mean. This is particularly the case of the log-normal distribution, which has an heavy right tail. In this case, the use of bounded distribution like the uniform and the triangular distributions can be used.</li>
</ul>
<p><code>R</code> is the number of draws, <code>halton</code> indicates whether Halton draws <span class="citation" data-cites="TRAI:09">(see <a href="#ref-TRAI:09" role="doc-biblioref">Train 2009</a>, , chapter 9)</span> should be used (<code>NA</code> and <code>NULL</code> indicate respectively that default Halton draws are used and that pseudo-random numbers are used), <code>panel</code> is a boolean which indicates if the panel data version of the log-likelihood should be used.</p>
<p>Correlations between random parameters can be introduced only for normal-related distributed random parameters, using the <code>correlation</code> argument. If <code>TRUE</code>, all the normal-related random parameters are correlated. The <code>correlation</code> argument can also be a character vector indicating a subset of the random parameters that are assumed to be correlated.</p>
<p>We use the <code>dutch_railways</code> data set, previously coerced to a <code>dfidx</code> object called <code>Tr</code>. We first estimate the multinomial model: both alternatives being virtual train trips, it is relevant to use only generic coefficients and to remove the intercept: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dfidx/man/dfidx.html">dfidx</a></span><span class="op">(</span><span class="va">dutch_railways</span>, choice <span class="op">=</span> <span class="st">"choice"</span>, varying <span class="op">=</span> <span class="fl">4</span><span class="op">:</span><span class="fl">11</span>, sep <span class="op">=</span> <span class="st">"_"</span>, </span>
<span>            opposite <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"price"</span>, <span class="st">"comfort"</span>, <span class="st">"time"</span>, <span class="st">"change"</span><span class="op">)</span>,</span>
<span>            idx <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"choiceid"</span>, <span class="st">"id"</span><span class="op">)</span><span class="op">)</span>, idnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"chid"</span>, <span class="st">"alt"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Train.ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">time</span> <span class="op">+</span> <span class="va">change</span> <span class="op">+</span> <span class="va">comfort</span> <span class="op">|</span> <span class="op">-</span> <span class="fl">1</span>, <span class="va">Tr</span><span class="op">)</span></span>
<span><span class="va">Train.ml</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        Estimate Std. Error z-value Pr(&gt;|z|)
price     0.3271     0.0165   19.85  &lt; 2e-16
time      1.7206     0.1604   10.73  &lt; 2e-16
change    0.3263     0.0595    5.49  4.1e-08
comfort   0.9457     0.0649   14.56  &lt; 2e-16</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
<p>All the coefficients are highly significant and have the predicted positive sign (remember than an increase in the variable <code>comfort</code> implies using a less comfortable class). The coefficients can’t be directly interpreted, but dividing them by the price coefficient, we get monetary values: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.ml</span><span class="op">)</span><span class="op">[</span><span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.ml</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">##    time  change comfort </span></span>
<span><span class="co">##  5.2598  0.9976  2.8911</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.ml</span><span class="op">)</span><span class="op">[</span><span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.ml</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We obtain the value of 5.3 euros for an hour of traveling, 1 euro for a change and 2.9 euros to travel in a more comfortable class.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> We then estimate a model with three random parameters, <code>time</code>, <code>change</code> and <code>comfort</code>. We first estimate the uncorrelated mixed logit model: </p>
<div class="cell" data-layout-align="center" data-hash="rum_cache/html/mixed logit estimation for Train (1)_08b6b00f1175bb8203aac0939968cb29">
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Train.mxlu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span><span class="va">choice</span> <span class="op">~</span> <span class="va">price</span> <span class="op">+</span> <span class="va">time</span> <span class="op">+</span> <span class="va">change</span> <span class="op">+</span> <span class="va">comfort</span> <span class="op">|</span> <span class="op">-</span> <span class="fl">1</span>, <span class="va">Tr</span>, </span>
<span>                     rpar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>time <span class="op">=</span> <span class="st">"n"</span>, change <span class="op">=</span> <span class="st">"n"</span>, comfort <span class="op">=</span> <span class="st">"n"</span><span class="op">)</span>, </span>
<span>                     R <span class="op">=</span> <span class="fl">100</span>, panel <span class="op">=</span> <span class="cn">TRUE</span>, correlation <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>                     halton <span class="op">=</span> <span class="cn">NA</span>, method <span class="op">=</span> <span class="st">"bhhh"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.mxlu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] "price"      "time"       "change"     "comfort"    "sd.time"   </span></span>
<span><span class="co">## [6] "sd.change"  "sd.comfort"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compared to the multinomial logit model, there are now three more coefficients which are the standard deviations of the distribution of the three random parameters. The correlated model is obtained by setting the <code>correlation</code> argument to <code>TRUE</code>. </p>
<div class="cell" data-layout-align="center" data-hash="rum_cache/html/mixed logit estimation for Train (2)_9d9a7f635db17083c62bc9a36a498e62">
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Train.mxlc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">Train.mxlu</span>, correlation <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">Train.mxlc</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "price"                "time"                
 [3] "change"               "comfort"             
 [5] "chol.time:time"       "chol.time:change"    
 [7] "chol.change:change"   "chol.time:comfort"   
 [9] "chol.change:comfort"  "chol.comfort:comfort"</code></pre>
</div>
</div>
<p>There are now six parameters which are the elements of the Choleski decomposition of the covariance matrix of the three random parameters. These six parameters are therefore the elements of the following matrix:</p>
<p><span class="math display">\[
C=
\left(
  \begin{array}{ccc}
    c_{11} &amp; c_{12}  &amp; c_{13} \\
    0 &amp; c_{22} &amp; c_{23} \\
    0 &amp; 0 &amp; c_{33}
  \end{array}
\right)
\]</span></p>
<p>such that:</p>
<p><span class="math display">\[
C^{\top}C=
\left(
  \begin{array}{ccc}
    c_{11}^2 &amp; c_{11} c_{12}  &amp; c_{11}c_{13} \\
    c_{11}c_{12} &amp; c_{12}^2 + c_{22}^2 &amp; c_{12}c_{23}+c_{22}c_{23} \\
    c_{11}c_{13} &amp; c_{12}c_{3} + c_{22}c_{23} &amp; c_{13}^2 + c_{23}^2 c_{33}^2
  \end{array}
\right)
=
\left(
  \begin{array}{ccc}
    \sigma_{1}^2 &amp; \sigma_{12}  &amp; \sigma_{13} \\
    \sigma_{12} &amp; \sigma_{2}^2 &amp; \sigma_{23} \\
    \sigma_{13} &amp; \sigma_{23} &amp; \sigma_{3}^2
  \end{array}
\right)
\]</span></p>
<p>where <span class="math inline">\(\sigma_k^2\)</span> and <span class="math inline">\(\sigma_{kl}\)</span> are respectively the variance of the random parameter <span class="math inline">\(k\)</span> and the covariance between two random parameters <span class="math inline">\(k\)</span> and <span class="math inline">\(l\)</span>. Therefore, the first estimated parameter can be simply interpreted as the standard deviation of the first random parameter, but the five other can’t be interpreted easily. Random parameters may be extracted using the function <code>rpar</code> which takes as first argument a <code>mlogit</code> object and as second argument <code>par</code> the parameter(s) to be extracted. This function returns a <code>rpar</code> object and a <code>summary</code> method is provided to describe it: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">marg.ut.time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/rpar.html">rpar</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="st">"time"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">marg.ut.time</span><span class="op">)</span></span>
<span><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">##    -Inf   1.284   4.894   4.894   8.504     Inf</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The estimated random parameter is in the “preference space”, which means that it is the marginal utility of time. Parameters in the “willingness to pay” (WTP) space are more easy to interpret. They can be estimated directly (a feature not supported by <code>mlogit</code>) or can be obtained from the marginal utility by dividing by the coefficient of a covariate expressed in monetary value (a price for example), taken as a non-random parameter. The ratio can then be interpreted as a monetary value (or willingness to pay). To obtain the distribution of the random parameters in the WTP space, one can use the <code>norm</code> argument of <code>rpar</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">wtp.time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/rpar.html">rpar</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="st">"time"</span>, norm <span class="op">=</span> <span class="st">"price"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">wtp.time</span><span class="op">)</span></span>
<span><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">##    -Inf   1.802   6.871   6.871  11.939     Inf</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The median value (and the mean value as the distribution is symmetric) of transport time is about 33 euros. Several methods/functions are provided to extract the individual statistics (<code>mean</code>, <code>med</code> and <code>stdev</code> respectively for the mean, median and standard deviation): </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/rpar.html">rpar</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="st">"time"</span>, norm <span class="op">=</span> <span class="st">"price"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] 6.871</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/distribution.html">med</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/rpar.html">rpar</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="st">"time"</span>, norm <span class="op">=</span> <span class="st">"price"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] 6.871</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/distribution.html">stdev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/rpar.html">rpar</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="st">"time"</span>, norm <span class="op">=</span> <span class="st">"price"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] 7.515</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In case of correlated random parameters, as the estimated parameters can’t be directly interpreted, a <code>vcov</code> method for <code>mlogit</code> objects is provided. It has a <code>what</code> argument whose default value is <code>coefficient</code>. In this case the usual covariance matrix of the coefficients is return. If <code>what = "rpar"</code>, the covariance matrix of the correlated random parameters is returned if <code>type = "cov"</code> (the default) and the correlation matrix (with standard deviations on the diagonal) is returned if <code>type = "cor"</code>. The object is of class <code>vcov.mlogit</code> and a <code>summary</code> method for this object is provided which computes, using the delta method, the standard errors of the parameters of the covariance or the correlation matrix. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, what <span class="op">=</span> <span class="st">"rpar"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           time  change comfort
time    28.6460 -0.2788   5.558
change  -0.2788  3.1047   1.232
comfort  5.5579  1.2325   7.896</code></pre>
</div>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, what <span class="op">=</span> <span class="st">"rpar"</span>, type <span class="op">=</span> <span class="st">"cor"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            time   change comfort
time     5.35220 -0.02956  0.3696
change  -0.02956  1.76203  0.2489
comfort  0.36956  0.24893  2.8099</code></pre>
</div>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, what <span class="op">=</span> <span class="st">"rpar"</span>, type <span class="op">=</span> <span class="st">"cor"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   Estimate Std. Error z-value Pr(&gt;|z|)    
sd.time              5.3522     0.3811   14.04   &lt;2e-16 ***
sd.change            1.7620     0.1446   12.19   &lt;2e-16 ***
sd.comfort           2.8099     0.1783   15.76   &lt;2e-16 ***
cor.time:change     -0.0296     0.2324   -0.13   0.8988    
cor.time:comfort     0.3696     0.1141    3.24   0.0012 ** 
cor.change:comfort   0.2489     0.1103    2.26   0.0240 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The correlation can be restricted to a subset of random parameters by filling the <code>correlation</code> argument with a character vector indicating the corresponding covariates: </p>
<div class="cell" data-layout-align="center" data-hash="rum_cache/html/mixed logit with a subset of correlated paramaters_cb9daf3079b86bf9bed33fe18064091c">
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Train.mxlc2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, correlation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"time"</span>, <span class="st">"comfort"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">Train.mxlc2</span>, what <span class="op">=</span> <span class="st">"rpar"</span>, type <span class="op">=</span> <span class="st">"cor"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          time comfort
time    5.5726  0.3909
comfort 0.3909  3.0631</code></pre>
</div>
</div>
<p>The presence of random coefficients and their correlation can be investigated using any of the three tests. Actually, three nested models can be considered, a model with no random effects, a model with random but uncorrelated effects and a model with random and correlated effects. We first present the three tests of no correlated random effects: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="va">Train.ml</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 388.057, df: 6, pval = 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">Train.mxlc</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 288.287, df: 6, pval = 0.000</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, </span>
<span>                      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"chol.time:time = 0"</span>, <span class="st">"chol.time:change =  0"</span>, </span>
<span>                        <span class="st">"chol.time:comfort = 0"</span>, <span class="st">"chol.change:change = 0"</span>, </span>
<span>                        <span class="st">"chol.change:comfort = 0"</span>, </span>
<span>                        <span class="st">"chol.comfort:comfort = 0"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 288.287, df: 6, pval = 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/scoretest.html">scoretest</a></span><span class="op">(</span><span class="va">Train.ml</span>, rpar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>time <span class="op">=</span> <span class="st">"n"</span>, change <span class="op">=</span> <span class="st">"n"</span>, comfort <span class="op">=</span> <span class="st">"n"</span><span class="op">)</span>, </span>
<span>          R <span class="op">=</span> <span class="fl">100</span>, correlation <span class="op">=</span> <span class="cn">TRUE</span>, halton <span class="op">=</span> <span class="cn">NA</span>, </span>
<span>          panel <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 208.765, df: 6, pval = 0.000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The hypothesis of no correlated random parameters is strongly rejected. We then present the three tests of no correlation, the existence of random parameters being maintained. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, <span class="va">Train.mxlu</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 42.621, df: 3, pval = 0.000</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, </span>
<span>                      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"chol.time:change = 0"</span>,<span class="st">"chol.time:comfort = 0"</span>, </span>
<span>                        <span class="st">"chol.change:comfort = 0"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 103.195, df: 3, pval = 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">Train.mxlc</span>, correlation <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 103.195, df: 3, pval = 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/scoretest.html">scoretest</a></span><span class="op">(</span><span class="va">Train.mxlu</span>, correlation <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 10.483, df: 3, pval = 0.015</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The hypothesis of no correlation is strongly rejected with the Wald and the likelihood ratio test, only at the 5% level for the score test. </p>
</section></section><section id="sec-multinom_probit" class="level2" data-number="14.5"><h2 data-number="14.5" class="anchored" data-anchor-id="sec-multinom_probit">
<span class="header-section-number">14.5</span> Multinomial probit</h2>
<p></p>
<section id="the-model" class="level3"><h3 class="anchored" data-anchor-id="the-model">The model</h3>
<p>The multinomial probit is obtained with the same modeling that we used while presenting the random utility model. The utility of an alternative is still the sum of two components : <span class="math inline">\(U_j = V_j + \epsilon_j\)</span> but the joint distribution of the error terms is now a multivariate normal with mean 0 and with a matrix of covariance denoted by <span class="math inline">\(\Omega\)</span>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Alternative <span class="math inline">\(l\)</span> is chosen if: <span class="math display">\[
\left\{
\begin{array}{rcl}
U_1-U_l&amp;=&amp;(V_1-V_l)+(\epsilon_1-\epsilon_l)&lt;0\\
U_2-U_l&amp;=&amp;(V_2-V_l)+(\epsilon_2-\epsilon_l)&lt;0\\
&amp; \vdots &amp;  \\
U_J-U_l&amp;=&amp;(V_J-V_l)+(\epsilon_J-\epsilon_l)&lt;0\\
\end{array}
\right.
\]</span></p>
<p>wich implies, denoting <span class="math inline">\(V^l_j=V_j-V_l\)</span> :</p>
<p><span class="math display">\[
\left\{
\begin{array}{rclrcl}
  \epsilon^l_1 &amp;=&amp; (\epsilon_1-\epsilon_l) &amp;&lt;&amp; - V^l_1\\
  \epsilon^l_2 &amp;=&amp; (\epsilon_2-\epsilon_l) &amp;&lt;&amp; - V^l_2\\
  &amp;\vdots &amp; &amp; \vdots &amp;  \\
  \epsilon^l_J &amp;=&amp; (\epsilon_J-\epsilon_l) &amp;&lt;&amp; - V^l_J\\
\end{array}
\right.
\]</span></p>
<p>The initial vector of errors <span class="math inline">\(\epsilon\)</span> are transformed using the following transformation: <span class="math inline">\(\epsilon^l = M^l \epsilon\)</span>, where the transformation matrix <span class="math inline">\(M^l\)</span> is a <span class="math inline">\((J-1) \times J\)</span> matrix obtained by inserting in an identity matrix a <span class="math inline">\(l^{\mbox{th}}\)</span> column of <span class="math inline">\(-1\)</span>. For example, if <span class="math inline">\(J = 4\)</span> and <span class="math inline">\(l = 3\)</span>:</p>
<p><span class="math display">\[
M^3 =
\left(
\begin{array}{cccc}
1 &amp; 0 &amp; -1 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 1 \\
\end{array}
\right)
\]</span></p>
<p>The covariance matrix of the error differences is:</p>
<p><span id="eq-cov-err_diff-mprobit"><span class="math display">\[
\mbox{V}\left(\epsilon^l\right)=\mbox{V}\left(M^l\epsilon\right)
=
M^l\mbox{V}\left(\epsilon\right){M^l}^{\top}
=
M^l\Omega{M^l}^{\top}
\tag{14.2}\]</span></span></p>
<p>The probability of choosing <span class="math inline">\(l\)</span> is then:</p>
<p><span id="eq-prob_choice_probit"><span class="math display">\[
P_l =\mbox{P}(\epsilon^l_1&lt;-V_1^l \;\&amp;\; \epsilon^l_2&lt;-V_2^l \;\&amp;\; ... \; \epsilon^l_J&lt;-V_J^l)
\tag{14.3}\]</span></span></p>
<p>with the hypothesis of normal distribution, this writes:</p>
<p><span class="math display">\[
P_l = \int_{-\infty}^{-V_1^l}\int_{-\infty}^{-V_2^l}...\int_{-\infty}^{-V_J^l}\phi(\epsilon^l)
d\epsilon^l_1 d\epsilon^l_2... d^l_J
\]</span></p>
<p>with :</p>
<p><span class="math display">\[
\phi\left(\epsilon^l\right)=\frac{1}{(2\pi)^{(J-1)/2}\mid\Omega^l\mid^{1/2}}
e^{-\frac{1}{2}\epsilon^l{\Omega^l}^{-1}\epsilon^l}
\]</span></p>
<p>Two problems arise with this model:</p>
<ul>
<li>the identified parameters are the elements of <span class="math inline">\(\Omega^l\)</span> and not of <span class="math inline">\(\Omega\)</span>. We must then carefully investigate the meanings of these elements,</li>
<li>the probability is a <span class="math inline">\(J-1\)</span> integral, which should be numerically computed. The relevant strategy in this context is to use simulations.</li>
</ul></section><section id="identification" class="level3"><h3 class="anchored" data-anchor-id="identification">Identification</h3>
<p>The meaningful parameters are those of the covariance matrix of the error <span class="math inline">\(\Omega\)</span>. For example, with <span class="math inline">\(J = 3\)</span>:</p>
<p><span class="math display">\[
\Omega =
\left(
\begin{array}{ccc}
\sigma_1 ^ 2 &amp; \sigma_{12} &amp; \sigma_{13}  \\
\sigma_{21} &amp; \sigma_2^2 &amp; \sigma_{23} \\
\sigma_{31} &amp; \sigma_{32} &amp; \sigma_3^3 \\
\end{array}
\right)
\]</span> Computing <a href="#eq-cov-err_diff-mprobit">Equation&nbsp;<span>14.2</span></a> for <span class="math inline">\(l=1\)</span>, we get:</p>
<p><span class="math display">\[
\Omega^1 = M^1 \Omega {M^1}^{\top}=
\left(
\begin{array}{cc}
\sigma_1^2+\sigma_2^2-2\sigma_{12} &amp; \sigma_1^2 + \sigma_{23} - \sigma_{12} -\sigma_{13} \\
\sigma_1^2+\sigma_{23}- \sigma_{12} - \sigma_{13} &amp; \sigma_1^2 + \sigma_3^2 - 2 \sigma_{13} \\
\end{array}
\right)
\]</span></p>
<p>The overall scale of utility being unidentified, one has to impose the value of one of the variance, for example the first one is set to 1. We then have :</p>
<p><span class="math display">\[ \Omega^1 = \left( \begin{array}{cc} 1 &amp; \frac{\sigma_1^2+
\sigma_{23} - \sigma_{12}
-\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} \\
\frac{\sigma_1^2+\sigma_{23}- \sigma_{12} -
\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} &amp;
\frac{\sigma_1^2 + \sigma_3^2 - 2
\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} \\ \end{array}
\right)
\]</span></p>
<p>Therefore, out of the six structural parameters of the covariance matrix, only three can be identified. Moreover, it’s almost impossible to interpret these parameters. More generally, with <span class="math inline">\(J\)</span> alternatives, the number of the parameters of the covariance matrix is <span class="math inline">\((J+1)\times J/2\)</span> and the number of identified parameters is <span class="math inline">\(J\times(J-1)/2-1\)</span>.</p>
</section><section id="simulations" class="level3"><h3 class="anchored" data-anchor-id="simulations">Simulations</h3>
<p>Let <span class="math inline">\(C^l\)</span> be the Choleski decomposition of the covariance matrix of the error differences:</p>
<p><span class="math display">\[
\Omega^C= {C^l}^{\top}C^l
\]</span></p>
<p>This matrix is an upper triangular matrix of dimension <span class="math inline">\((J-1)\)</span> :</p>
<p><span class="math display">\[
C^l=
\left(
\begin{array}{ccccc}
l_{11} &amp; l_{12} &amp; l_{13} &amp;... &amp; l_{1(J-1)} \\
0 &amp; l_{22} &amp; l_{23} &amp; ... &amp; l_{2(J-1)} \\
0 &amp; 0 &amp; l_{33} &amp; ... &amp; l_{3(J-1)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; ... &amp; l_{(J-1)(J-1)} \\
\end{array}
\right)
\]</span></p>
<p>Let <span class="math inline">\(\nu\)</span> be a vector of standard normal deviates: <span class="math inline">\(\nu \sim \mathcal{N}(0, I)\)</span></p>
<p>Therefore, we have :</p>
<p><span class="math display">\[
\mbox{V}\left({C^l}^\top\nu\right)={C^l}^\top V(\nu){C^l}={C^l}^{\top}IC^l=\Omega^l
\]</span></p>
<p>Therefore, if we draw a vector of standard normal deviates <span class="math inline">\(\nu\)</span> and apply to it this transformation, we get a realization of <span class="math inline">\(\epsilon^l\)</span>. This probability of choosing <span class="math inline">\(l\)</span> given by <a href="#eq-prob_choice_probit">Equation&nbsp;<span>14.3</span></a> can be written as a product of conditional and marginal probabilities:</p>
<p><span class="math display">\[
\begin{array}{rcl}
  P_l &amp;=&amp; \mbox{P}(\epsilon^l_1&lt;- V_1^l \;\&amp;\; \epsilon^l_2&lt;-V_2^l \;\&amp;\; ... \;\&amp;\; \epsilon^l_J&lt;-V_J^l))\\
  &amp;=&amp; \mbox{P}(\epsilon^l_1&lt;- V_1^l))\\
  &amp;\times&amp;\mbox{P}(\epsilon^l_2&lt;-V_2^l \mid \epsilon^l_1&lt;-V_1^l) \\
  &amp;\times&amp;\mbox{P}(\epsilon^l_3&lt;-V_3^l \mid \epsilon^l_1&lt;-V_1^l \;\&amp;\; \epsilon^l_2&lt;-V_2^l) \\
  &amp; \vdots &amp; \\
  &amp;\times&amp;\mbox{P}(\epsilon^l_J&lt;-V_J^l \mid \epsilon^l_1&lt;-V_1^l \;\&amp;\; ... \;\&amp;\; \epsilon^l_{J-1}&lt;-V_{J-1}^l)) \\
\end{array}
\]</span></p>
<p>The vector of error difference deviates is:</p>
<p><span class="math display">\[
\left(
\begin{array}{c}
  \epsilon^l_1 \\ \epsilon^l_2 \\ \epsilon^l_3 \\ \vdots \\ \epsilon^l_J
\end{array}
\right)
=
{C^l} ^ \top \nu
=
\left(
\begin{array}{ccccc}
l_{11} &amp; 0 &amp; 0 &amp;... &amp; 0 \\
l_{12} &amp; l_{22} &amp; 0 &amp; ... &amp; 0 \\
l_{13} &amp; l_{23} &amp; l_{33} &amp; ... &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
l_{1(J-1)} &amp; l_{2(J-1)} &amp; l_{3(J-1)} &amp; ... &amp; l_{(J-1)(J-1)} \\
\end{array}
\right)
\times
\left(
\begin{array}{c}
\nu_1 \\ \nu_2 \\ \nu_3 \\ \vdots \\ \nu_J
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\left(
\begin{array}{c}
  \epsilon^l_1 \\ \epsilon^l_2 \\ \epsilon^l_3 \\ \vdots \\ \epsilon^l_J
\end{array}
\right)
=
\left(
\begin{array}{l}
l_{11}\nu_1 \\
l_{12}\nu_1+l_{22}\nu_2 \\
l_{13}\nu_1+l_{23}\nu_2 + l_{33}\nu_3\\
\vdots \\
l_{1(J-1)}\nu_1+l_{2(J-1)}\nu_2+...+l_{(J-1)(J-1)}\nu_{J-1}
\end{array}
\right)
\]</span></p>
<p>Let’s now investigate the marginal and conditional probabilities:</p>
<ul>
<li>the first is simply the marginal probability for a standard normal deviate, therefore we have: <span class="math inline">\(\mbox{P}(\epsilon^l_1&lt;-V_1^l) = \Phi\left(-\frac{V_1^l}{l_{11}}\right)\)</span>
</li>
<li>the second is, for a given value of <span class="math inline">\(\nu_1\)</span> equal to <span class="math inline">\(\Phi\left(-\frac{V^l_2+l_{21}\nu_1}{l_{22}}\right)\)</span>. We then have to compute the mean of this expression for any value of <span class="math inline">\(\nu_1\)</span> lower than <span class="math inline">\(-\frac{V^l_1}{l_{11}}\)</span>. We then have, denoting <span class="math inline">\(\bar{\phi}_1\)</span> the truncated normal density: <span class="math display">\[\mbox{P}(\epsilon^l_2&lt;-V_2^l)=\int_{-\infty}^{-\frac{V^l_1}{l_{11}}}\Phi\left(-\frac{V^l_2+l_{21}\nu_1}{l_{22}}\right)
\bar{\phi}_1(\nu_1)d\nu_1\]</span>
</li>
<li>the third is, for given values of <span class="math inline">\(\nu_1\)</span> and <span class="math inline">\(\nu_2\)</span> equal to: <span class="math inline">\(\Phi\left(-\frac{V^l_3+l_{31}\nu_1+l_{32}\nu_2}{l_{33}}\right)\)</span>. We then have: <span class="math display">\[\mbox{P}(\epsilon^l_3&lt;-V_3^l)=\int_{-\infty}^{-\frac{V^l_1}{l_{11}}}\int_{-\infty}^{-\frac{V^l_2+l_{21}\nu_1}{l_{22}}}
\Phi\left(-\frac{V^l_3+l_{31}\nu_1+l_{32}\nu_2}{l_{33}}\right)\bar{\phi}_1(\nu_1)\bar{\phi}_2(\nu_2)d\nu_1d\nu_2\]</span>
</li>
<li>and so on.</li>
</ul>
<p>These probabilities can easily be simulated by drawing numbers from a truncated normal distribution. This so called GHK (for Geweke, Hajivassiliou and Keane) algorithm <span class="citation" data-cites="GEWE:KEAN:RUNK:94">(see for example <a href="#ref-GEWE:KEAN:RUNK:94" role="doc-biblioref">Geweke, Keane, and Runkle 1994</a>)</span> can be described as follow:</p>
<ol type="1">
<li>compute <span class="math inline">\(\Phi\left(-\frac{V_1^l}{l_{11}}\right)\)</span>,</li>
<li>draw a number called <span class="math inline">\(\nu_1^r\)</span> from a standard normal distribution upper-truncated at <span class="math inline">\(-\frac{V_1^l}{l_{11}}\)</span> and compute <span class="math inline">\(\Phi\left(-\frac{V^l_2+l_{12}\nu_1^r}{l_{22}}\right)\)</span>,</li>
<li>draw a number called <span class="math inline">\(\nu_2^r\)</span> from a standard normal distribution upper-truncated at <span class="math inline">\(-\frac{V^l_2+l_{12}\nu_1^r}{l_{22}}\)</span> and compute <span class="math inline">\(\Phi\left(-\frac{V^l_3+l_{13}\nu_1^r+l_{23}\nu_2^r}{l_{33}}\right)\)</span>,</li>
<li>
<span class="math inline">\(...\)</span> draw a number called <span class="math inline">\(\nu_{J-1}^r\)</span> from a standard normal distribution upper-truncated at <span class="math inline">\(-\frac{V^l_{J-1}+l_{1(J-1)}\nu_1^r+... l_{(J-2)(J-1)}\nu_{J-2}^r}{l_{(J-1)(J-1)}}\)</span>,</li>
<li>multiply all these probabilities and get a realization of the probability of choosing <span class="math inline">\(l\)</span> called <span class="math inline">\(P^r_l\)</span>,</li>
<li>repeat all these steps many times and average all these probabilities; this average is an estimation of the probability: <span class="math inline">\(\bar{P}_l = \sum_{r=1}^R P^r_l/R\)</span>.</li>
</ol>
<p>Several points should be noted concerning this algorithm:</p>
<ul>
<li><p>the utility differences should be computed respective to the chosen alternative for each individual,</p></li>
<li>
<p>the Choleski decomposition used should rely on the same covariance matrix of the errors. One method to attained this goal is to start from a given difference, e.g., the difference respective with the first alternative. The vector of error difference is then <span class="math inline">\(\epsilon^1\)</span> and its covariance matrix is <span class="math inline">\(\Omega^1={L^1}^{\top}L^1\)</span>. To apply a difference with another alternative <span class="math inline">\(l\)</span>, we construct a matrix called <span class="math inline">\(S^l\)</span> which is obtained by using a <span class="math inline">\(J-2\)</span> identity matrix, adding a first row of 0 and inserting a column of <span class="math inline">\(-1\)</span> at the <span class="math inline">\(l-1\)</span>th position. For example, with four alternatives and <span class="math inline">\(l=3\)</span>, we have:</p>
<p><span class="math display">\[S^3=
\left(
  \begin{array}{ccc}
    0 &amp; -1 &amp; 0 \\
    1 &amp; -1 &amp; 0 \\
    0 &amp; -1 &amp; 1 \\
  \end{array}
\right)
\]</span> The elements of the Choleski decomposition of the covariance matrix is then obtained as follow: <span class="math display">\[
\Omega^l = S^l \Omega^1 {S^l}^{\top}=L^l {L^l}^{\top}
\]</span></p>
</li>
<li><p>to compute draws from a normal distribution truncated at <span class="math inline">\(a\)</span>, the following trick is used : take a draw <span class="math inline">\(\mu\)</span> from a uniform distribution (between 0 and 1); then <span class="math inline">\(\nu = \Phi^{-1}\left(\mu  \Phi(a)\right)\)</span> is a draw from a normal distribution truncated at <span class="math inline">\(a\)</span>.</p></li>
</ul>
<p></p>
</section><section id="application-1" class="level3"><h3 class="anchored" data-anchor-id="application-1">Application</h3>
<p>In <a href="#sec-appl_mult_logit"><span>Section&nbsp;14.2.5</span></a>, we estimated a multinomial logit for mode choice in the Toronto-Montreal corridor, using <code>cost</code> and <code>freq</code> as alternative specific covariates with a generic coefficient, <code>income</code> as a choice situation specific covariate and <code>time</code> as an alternative specific covariate with a specific coefficient. We fit the same model using this time a probit. This is simply done by setting the <code>probit</code> argument to <code>TRUE</code>. </p>
<div class="cell" data-layout-align="center" data-hash="rum_cache/html/unnamed-chunk-59_3f39d49edc089777a064a4004cefbba8">
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pbt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mlogit/man/mlogit.html">mlogit</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">choice</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">freq</span> <span class="op">|</span> <span class="va">income</span> <span class="op">|</span> <span class="va">time</span>, data <span class="op">=</span> <span class="va">MC</span>, </span>
<span>              probit <span class="op">=</span> <span class="cn">TRUE</span>, alt.subset <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span><span class="op">)</span>, </span>
<span>              reflevel <span class="op">=</span> <span class="st">"car"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As previously, we want to predict the effect of a reduction of 20% of a train’s fare: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Oprob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">pbt</span>, type <span class="op">=</span> <span class="st">"probabilities"</span><span class="op">)</span></span>
<span><span class="va">Nprob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">pbt</span>, newdata <span class="op">=</span> <span class="va">NMC</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span>old <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">Oprob</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span>, new <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">Nprob</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       car  train    air
old 0.4606 0.1676 0.3721
new 0.4194 0.2457 0.3353</code></pre>
</div>
</div>
<p>With this model, the IIA property is not operative, as the ratio of probabilities of choosing air and car is no longer the same before and after the change of a train’s fare. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Nprob</span><span class="op">[</span>, <span class="st">"air"</span><span class="op">]</span> <span class="op">/</span> <span class="va">Nprob</span><span class="op">[</span>, <span class="st">"car"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.4549 0.8923 0.3402 0.8972 0.9090 0.6034</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Oprob</span><span class="op">[</span>, <span class="st">"air"</span><span class="op">]</span> <span class="op">/</span> <span class="va">Oprob</span><span class="op">[</span>, <span class="st">"car"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.4737 0.8897 0.3585 0.9016 0.9288 0.6299</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-BENA:BOLD:BRAD:93" class="csl-entry" role="doc-biblioentry">
Ben-Akiva, M., D. Bolduc, and M. Bradley. 1993. <span>“Estimation of Travel Choice Models with Randomly Distributed Values of Time.”</span> <em>Transportation Research Record</em> 1413: 88–97.
</div>
<div id="ref-BHAT:95" class="csl-entry" role="doc-biblioentry">
Bhat, C. R. 1995. <span>“A Heterocedastic Extreme Value Model of Intercity Travel Mode Choice.”</span> <em>Transportation Research B</em> 29 (6): 471–83.
</div>
<div id="ref-CROI:20" class="csl-entry" role="doc-biblioentry">
Croissant, Yves. 2020. <span>“Estimation of Random Utility Models in r: The Mlogit Package".”</span> <em>Journal of Statistical Software</em> 95 (11): 1–41. <a href="https://doi.org/10.18637/jss.v095.i11">https://doi.org/10.18637/jss.v095.i11</a>.
</div>
<div id="ref-DAGA:79" class="csl-entry" role="doc-biblioentry">
Daganzo, C. 1979. <em>Multinomial Probit: The Theory and Its Application to Demand Forecasting</em>. Academic Press, New York.
</div>
<div id="ref-DALY:87" class="csl-entry" role="doc-biblioentry">
Daly, A. 1987. <span>“Estimating <span>‘Tree’</span> Logit Models.”</span> <em>Transportation Research B</em>, 251–67.
</div>
<div id="ref-FORI:KOPP:93" class="csl-entry" role="doc-biblioentry">
Forinash, C. V., and F. S. Koppelman. 1993. <span>“Application and Interpretation of Nested Logit Models and Intercity Mode Choice.”</span> <em>Transportation Record</em> 1413: 98–106.
</div>
<div id="ref-GEWE:KEAN:RUNK:94" class="csl-entry" role="doc-biblioentry">
Geweke, J., M. Keane, and D. Runkle. 1994. <span>“Alternative Computational Approaches to Inference in the Multinomial Probit Model.”</span> <em>Review of Economics and Statistics</em> 76: 609–32.
</div>
<div id="ref-HAUS:WISE:78" class="csl-entry" role="doc-biblioentry">
Hausman, Jerry, and D. Wise. 1978. <span>“A Conditional Probit Model for Qualitative Choice: Discrete Decisions Recognizing Interdemendence and Heterogeneous Preferences.”</span> <em>Econometrica</em> 48: 403–29.
</div>
<div id="ref-HEIS:02" class="csl-entry" role="doc-biblioentry">
Heiss, Florian. 2002. <span>“Structural Choice Analysis with Nested Logit Models.”</span> <em>The Stata Journal</em> 2 (3): 227–52.
</div>
<div id="ref-HENS:GREEN:02" class="csl-entry" role="doc-biblioentry">
Hensher, David A., and William H. Greene. 2002. <span>“Specification and Estimation of the Nested Logit Model: Alternative Normalisations.”</span> <em>Transportation Research Part B</em> 36: 1–17.
</div>
<div id="ref-KOPP:WEN:98" class="csl-entry" role="doc-biblioentry">
Koppelman, Franck S., and Chieh-Hua Wen. 1998. <span>“Alternative Nested Logit Models: Structure, Properties and Estimation.”</span> <em>Transportation Research B</em> 32 (5): 289–98.
</div>
<div id="ref-KOPP:WEN:00" class="csl-entry" role="doc-biblioentry">
———. 2000. <span>“The Paired Combinatorial Logit Model: Properties, Estimation and Application.”</span> <em>Transportation Research B</em> 34: 75–89.
</div>
<div id="ref-MCFAD:74" class="csl-entry" role="doc-biblioentry">
McFadden, Daniel. 1974. <span>“The Measurement of Urban Travel Demand.”</span> <em>Journal of Public Economics</em> 3: 303–28.
</div>
<div id="ref-MCFAD:78" class="csl-entry" role="doc-biblioentry">
———. 1978. <span>“Spatial Interaction Theory and Planning Models.”</span> In <em>Modeling the Choice of Residential Location</em>, edited by A. Karlqvist, 75–96. North-Holland, Amsterdam.
</div>
<div id="ref-MEIJ:ROUW:06" class="csl-entry" role="doc-biblioentry">
Meijer, Erik, and Jan Rouwendal. 2006. <span>“Measuring Welfare Effects in Models with Random Coefficients.”</span> <em>Journal of Applied Econometrics</em> 21 (2): 227–44. <a href="https://doi.org/10.1002/jae.841">https://doi.org/10.1002/jae.841</a>.
</div>
<div id="ref-SMAL:ROSE:81" class="csl-entry" role="doc-biblioentry">
Small, K. A., and H. S. Rosen. 1981. <span>“Applied Welfare Economics with Discrete Choice Models.”</span> <em>Econometrica</em> 49: 105–30.
</div>
<div id="ref-TRAI:09" class="csl-entry" role="doc-biblioentry">
Train, Kenneth. 2009. <em>Discrete Choice Methods with Simulation</em>. Cambridge University Press. <a href="https://EconPapers.repec.org/RePEc:cup:cbooks:9780521766555">https://EconPapers.repec.org/RePEc:cup:cbooks:9780521766555</a>.
</div>
<div id="ref-TRAI:MCFA:BENA:87" class="csl-entry" role="doc-biblioentry">
Train, Kenneth, Daniel McFadden, and Moshe Ben-Akiva. 1987. <span>“The Demand for Local Telephone Service: A Fully Discrete Model of Residential Calling Patterns and Service Choices.”</span> <em>The RAND Journal of Economics</em> 18 (1): 109–23. <a href="http://www.jstor.org/stable/2555538">http://www.jstor.org/stable/2555538</a>.
</div>
<div id="ref-WALK:BENA:BOLD:07" class="csl-entry" role="doc-biblioentry">
Walker, Joan L., Moshe Ben-Akiva, and Denis Bolduc. 2007. <span>“Identification of Parameters in Normal Error Component Logit-Mixture (NECLM) Models.”</span> <em>Journal of Applied Econometrics</em> 22 (6): 1095–125. <a href="http://www.jstor.org/stable/25146565">http://www.jstor.org/stable/25146565</a>.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>We’ve already encountered this model in the special case where the response is binomial in <a href="binomial.html#sec-rum_binomial"><span>Section&nbsp;10.2.2</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This chapter is largely based on <span class="citation" data-cites="CROI:20">Croissant (<a href="#ref-CROI:20" role="doc-biblioref">2020</a>)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Used by <span class="citation" data-cites="BENA:BOLD:BRAD:93">Ben-Akiva, Bolduc, and Bradley (<a href="#ref-BENA:BOLD:BRAD:93" role="doc-biblioref">1993</a>)</span> and <span class="citation" data-cites="MEIJ:ROUW:06">Meijer and Rouwendal (<a href="#ref-MEIJ:ROUW:06" role="doc-biblioref">2006</a>)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Used in particular by <span class="citation" data-cites="FORI:KOPP:93">Forinash and Koppelman (<a href="#ref-FORI:KOPP:93" role="doc-biblioref">1993</a>)</span>, <span class="citation" data-cites="BHAT:95">Bhat (<a href="#ref-BHAT:95" role="doc-biblioref">1995</a>)</span>, <span class="citation" data-cites="KOPP:WEN:98">Koppelman and Wen (<a href="#ref-KOPP:WEN:98" role="doc-biblioref">1998</a>)</span> and <span class="citation" data-cites="KOPP:WEN:00">Koppelman and Wen (<a href="#ref-KOPP:WEN:00" role="doc-biblioref">2000</a>)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See <span class="citation" data-cites="TRAI:09">Train (<a href="#ref-TRAI:09" role="doc-biblioref">2009</a>)</span>, pp.&nbsp;74-75.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>A slightly different version of the nested logit model <span class="citation" data-cites="DALY:87">(<a href="#ref-DALY:87" role="doc-biblioref">Daly 1987</a>)</span> is often used, but is not compatible with the random utility maximization hypothesis. Its difference from the previous expression is that the deterministic parts of the utility for each alternative are not divided by the nest elasticity. The differences between the two versions have been discussed in <span class="citation" data-cites="KOPP:WEN:98">Koppelman and Wen (<a href="#ref-KOPP:WEN:98" role="doc-biblioref">1998</a>)</span>, <span class="citation" data-cites="HEIS:02">Heiss (<a href="#ref-HEIS:02" role="doc-biblioref">2002</a>)</span> and <span class="citation" data-cites="HENS:GREEN:02">Hensher and Greene (<a href="#ref-HENS:GREEN:02" role="doc-biblioref">2002</a>)</span>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>We’ve already encountered this expression in <a href="#sec-consumer_surplus"><span>Section&nbsp;14.2.4.3</span></a>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>See <a href="#sec-wide_format"><span>Section&nbsp;14.1.1.1</span></a>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Remember that the survey took place in 1987. The values should be multiplied by 1.73 to get the value of 1 euro in 2024.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>See <span class="citation" data-cites="HAUS:WISE:78">Hausman and Wise (<a href="#ref-HAUS:WISE:78" role="doc-biblioref">1978</a>)</span> and <span class="citation" data-cites="DAGA:79">Daganzo (<a href="#ref-DAGA:79" role="doc-biblioref">1979</a>)</span>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../chapters/duration.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Duration models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb83" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discrete choice models {#sec-rum}</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"../_commonR.R"</span>)</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>Consider the case where the response is the choice of an alternative among a set of mutually exclusive alternatives. This choice can be modeled in a utility maximization framework, which means that we hypothesize that the individual chooses the alternative which corresponds to the maximum level of utility.^<span class="co">[</span><span class="ot">We've already encountered this model in the special case where the response is binomial in @sec-rum_binomial.</span><span class="co">]</span> Namely, denoting $j = 1 \ldots J$ the set of alternatives, we'll denote $U_{nj}$ the level of utility of individual $n$ if he chooses alternative $j$ and the $j$^th^alternative will be chosen if $U_{nj} &gt; U_{nk}\; \forall k \neq j$. The level of utility will depends on some observable covariates and on some other unobservables whose effect will be summarized in a variable $\epsilon_{nj}$ that will be considered, from the researcher's point of view, as the realization of a random variable. Two key questions for these models are how the covariates enter the utility function and what is the assumed distribution of the error. @sec-data_formula_rum will deal with the first point, namely how to deal with covariates in discrete choice model. @sec-multinom_logit will present the landmark model in this field, the multinomial logit model. @sec-relaxing_iid will go beyond the hypothesis of iid errors to present two extensions of the basic model, the nested and the heteroscedastic logit models. @sec-mixed_logit will introduce the rich field of random parameters logit models. Finally, @sec-multinom_probit will be devoted to the multinomial probit model.^<span class="co">[</span><span class="ot">This chapter is largely based on @CROI:20\index[author]{Croissant}.</span><span class="co">]</span></span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>Throughout this chapter, we'll use the **mlogit** package which is devoted to the estimation of discrete choice models:</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'loading mlogit'</span></span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlogit)</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a><span class="fu">##  Data management and model description {#sec-data_formula_rum}</span></span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- In discrete choice models, the unit of observation is a choice situation, defined by an individual $n$ which should choose one alternative $j$ among a set of mutually exclusive alternatives. His choice is partly driven by some covariates that can depend either on the individual, the choice situation or both.  --&gt;</span></span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- To illustrate this typology of the covariates, consider the case of --&gt;</span></span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- repeated choices of destinations for vacations by families: --&gt;</span></span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-24"><a href="#cb83-24" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - the length of the vacation, the season are choice situation --&gt;</span></span>
<span id="cb83-25"><a href="#cb83-25" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   specific variables, --&gt;</span></span>
<span id="cb83-26"><a href="#cb83-26" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - income, family size are individual specific variables, --&gt;</span></span>
<span id="cb83-27"><a href="#cb83-27" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - distance to destination, cost are alternative specific --&gt;</span></span>
<span id="cb83-28"><a href="#cb83-28" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   variables. --&gt;</span></span>
<span id="cb83-29"><a href="#cb83-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-30"><a href="#cb83-30" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Such data have therefore a specific structure that can be --&gt;</span></span>
<span id="cb83-31"><a href="#cb83-31" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- characterized by three indexes: the alternative, the choice situation --&gt;</span></span>
<span id="cb83-32"><a href="#cb83-32" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- and the individual. These three indexes will be denoted `alt`, `chid` --&gt;</span></span>
<span id="cb83-33"><a href="#cb83-33" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- and `id`.  Note that the distinction between `chid` and `id` is only --&gt;</span></span>
<span id="cb83-34"><a href="#cb83-34" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- relevant if we have repeated observations for the same individual. --&gt;</span></span>
<span id="cb83-35"><a href="#cb83-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-36"><a href="#cb83-36" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data management</span></span>
<span id="cb83-37"><a href="#cb83-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-38"><a href="#cb83-38" aria-hidden="true" tabindex="-1"></a>Data sets used for discrete choice models estimation concern some individuals, who make one or a sequential choice of one alternative among a set of mutually exclusive</span>
<span id="cb83-39"><a href="#cb83-39" aria-hidden="true" tabindex="-1"></a>alternatives. The determinants of these choices are covariates that</span>
<span id="cb83-40"><a href="#cb83-40" aria-hidden="true" tabindex="-1"></a>can depend on the alternative and the choice situation, only on the</span>
<span id="cb83-41"><a href="#cb83-41" aria-hidden="true" tabindex="-1"></a>alternative or only on the choice situation.</span>
<span id="cb83-42"><a href="#cb83-42" aria-hidden="true" tabindex="-1"></a>Data sets can have two different shapes: a *wide* shape (one row for</span>
<span id="cb83-43"><a href="#cb83-43" aria-hidden="true" tabindex="-1"></a>each choice situation) or a *long* shape (one row for each alternative</span>
<span id="cb83-44"><a href="#cb83-44" aria-hidden="true" tabindex="-1"></a>and, therefore, as many rows as there are alternatives for each choice</span>
<span id="cb83-45"><a href="#cb83-45" aria-hidden="true" tabindex="-1"></a>situation).</span>
<span id="cb83-46"><a href="#cb83-46" aria-hidden="true" tabindex="-1"></a>**mlogit** deals with both formats. It depends on the **dfidx** package</span>
<span id="cb83-47"><a href="#cb83-47" aria-hidden="true" tabindex="-1"></a>which takes as first argument a <span class="in">`data.frame`</span> and returns a</span>
<span id="cb83-48"><a href="#cb83-48" aria-hidden="true" tabindex="-1"></a><span class="in">`dfidx`</span> object, which is a <span class="in">`data.frame`</span> in "long" format with a</span>
<span id="cb83-49"><a href="#cb83-49" aria-hidden="true" tabindex="-1"></a>special data frame column which contains the indexes. The second argument is called <span class="in">`idx`</span>. In its simple use, it should be a list (or a vector) of two characters containing the choice situation and the alternative indexes.</span>
<span id="cb83-50"><a href="#cb83-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-51"><a href="#cb83-51" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wide format {#sec-wide_format}</span></span>
<span id="cb83-52"><a href="#cb83-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-53"><a href="#cb83-53" aria-hidden="true" tabindex="-1"></a><span class="in">`dutch_railways`</span>^<span class="co">[</span><span class="ot">Used by @BENA:BOLD:BRAD:93\index[author]{Ben-Akiva}\index[author]{Bolduc}\index[author]{Bradley} and @MEIJ:ROUW:06\index[author]{Meijer}\index[author]{Rouwendal}.</span><span class="co">]</span> is an example</span>
<span id="cb83-54"><a href="#cb83-54" aria-hidden="true" tabindex="-1"></a>  of a *wide* data set:\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{dutch<span class="sc">\_</span>railways}{micsr.data}</span>
<span id="cb83-55"><a href="#cb83-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-56"><a href="#cb83-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-57"><a href="#cb83-57" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-58"><a href="#cb83-58" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'Train data'</span></span>
<span id="cb83-59"><a href="#cb83-59" aria-hidden="true" tabindex="-1"></a>dutch_railways <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">4</span>)</span>
<span id="cb83-60"><a href="#cb83-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-61"><a href="#cb83-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-62"><a href="#cb83-62" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{stated preference survey}</span>
<span id="cb83-63"><a href="#cb83-63" aria-hidden="true" tabindex="-1"></a>This data set contains data about a stated preference survey in</span>
<span id="cb83-64"><a href="#cb83-64" aria-hidden="true" tabindex="-1"></a>the Netherlands in 1987. Each individual has responded to several (up to 16)</span>
<span id="cb83-65"><a href="#cb83-65" aria-hidden="true" tabindex="-1"></a>scenarios. For every scenario, two train trips are proposed to the</span>
<span id="cb83-66"><a href="#cb83-66" aria-hidden="true" tabindex="-1"></a>user, with different combinations of four attributes: <span class="in">`price`</span> (the</span>
<span id="cb83-67"><a href="#cb83-67" aria-hidden="true" tabindex="-1"></a>price in euros), <span class="in">`time`</span> (travel time in minutes),</span>
<span id="cb83-68"><a href="#cb83-68" aria-hidden="true" tabindex="-1"></a><span class="in">`change`</span> (the number of changes) and <span class="in">`comfort`</span> (the class of</span>
<span id="cb83-69"><a href="#cb83-69" aria-hidden="true" tabindex="-1"></a>comfort, 0, 1 or 2, 0 being the most comfortable class).</span>
<span id="cb83-70"><a href="#cb83-70" aria-hidden="true" tabindex="-1"></a>This "wide" format is suitable to store choice situation (or</span>
<span id="cb83-71"><a href="#cb83-71" aria-hidden="true" tabindex="-1"></a>individual specific) variables because, in this case, they are stored</span>
<span id="cb83-72"><a href="#cb83-72" aria-hidden="true" tabindex="-1"></a>only once in the data. It is cumbersome for alternative-specific variables because there are as many columns for such variables as there are alternatives.</span>
<span id="cb83-73"><a href="#cb83-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-74"><a href="#cb83-74" aria-hidden="true" tabindex="-1"></a>For such a wide data set, the <span class="in">`shape`</span> argument of <span class="in">`dfidx`</span> is</span>
<span id="cb83-75"><a href="#cb83-75" aria-hidden="true" tabindex="-1"></a>mandatory, as its default value is <span class="in">`"long"`</span>. The alternative-specific</span>
<span id="cb83-76"><a href="#cb83-76" aria-hidden="true" tabindex="-1"></a>variables are indicated with the <span class="in">`varying`</span> argument which is a numeric</span>
<span id="cb83-77"><a href="#cb83-77" aria-hidden="true" tabindex="-1"></a>vector that indicates their position in the data frame. This argument</span>
<span id="cb83-78"><a href="#cb83-78" aria-hidden="true" tabindex="-1"></a>is then passed to <span class="in">`stats::reshape`</span> that coerced the original</span>
<span id="cb83-79"><a href="#cb83-79" aria-hidden="true" tabindex="-1"></a><span class="in">`data.frame`</span> in "long" format. Further arguments may be passed to</span>
<span id="cb83-80"><a href="#cb83-80" aria-hidden="true" tabindex="-1"></a><span class="in">`reshape`</span>. For example, as the names of the variables are of the form</span>
<span id="cb83-81"><a href="#cb83-81" aria-hidden="true" tabindex="-1"></a><span class="in">`price_A`</span>, one must add <span class="in">`sep = "_"`</span> (the default value being</span>
<span id="cb83-82"><a href="#cb83-82" aria-hidden="true" tabindex="-1"></a><span class="in">`"."`</span>). The <span class="in">`choice`</span> argument is also mandatory because the response</span>
<span id="cb83-83"><a href="#cb83-83" aria-hidden="true" tabindex="-1"></a>has to be transformed in a logical value in the long format.  In "wide" format, there is no alternative index. The choice situation index is not mandatory, as there is one line for each choice situation. In this data set, there is a choice situation index called <span class="in">`id`</span>, and it is nested in the individual index called <span class="in">`choiceid`</span>. To take</span>
<span id="cb83-84"><a href="#cb83-84" aria-hidden="true" tabindex="-1"></a>the panel dimension into account, <span class="in">`idx`</span> is a list of length 1 (the choice situation) containing a vector of length 2 with <span class="in">`choiceid`</span> and <span class="in">`id`</span>. The <span class="in">`idnames`</span> is used to give a relevant name for the second index, the <span class="in">`NA`</span> in first position indicating that the name of the first index is unchanged.</span>
<span id="cb83-85"><a href="#cb83-85" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-86"><a href="#cb83-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-87"><a href="#cb83-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-88"><a href="#cb83-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'dfidx for Train'</span></span>
<span id="cb83-89"><a href="#cb83-89" aria-hidden="true" tabindex="-1"></a>Tr <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(dutch_railways, <span class="at">shape =</span> <span class="st">"wide"</span>, <span class="at">varying =</span> <span class="dv">4</span><span class="sc">:</span><span class="dv">11</span>, <span class="at">sep =</span> <span class="st">"_"</span>,</span>
<span id="cb83-90"><a href="#cb83-90" aria-hidden="true" tabindex="-1"></a>            <span class="at">idx =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="st">"choiceid"</span>, <span class="st">"id"</span>)), <span class="at">idnames =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="st">"alt"</span>),</span>
<span id="cb83-91"><a href="#cb83-91" aria-hidden="true" tabindex="-1"></a>            <span class="at">opposite =</span> <span class="fu">c</span>(<span class="st">"price"</span>, <span class="st">"time"</span>, <span class="st">"change"</span>, <span class="st">"comfort"</span>))</span>
<span id="cb83-92"><a href="#cb83-92" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-93"><a href="#cb83-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-94"><a href="#cb83-94" aria-hidden="true" tabindex="-1"></a>Note the use of the <span class="in">`opposite`</span> argument for the four covariates: we</span>
<span id="cb83-95"><a href="#cb83-95" aria-hidden="true" tabindex="-1"></a>expect negative coefficients for all of them, taking the opposite of</span>
<span id="cb83-96"><a href="#cb83-96" aria-hidden="true" tabindex="-1"></a>the covariates will lead to expected positive coefficients.  </span>
<span id="cb83-97"><a href="#cb83-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-98"><a href="#cb83-98" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-99"><a href="#cb83-99" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'head of the transformed Train data set'</span></span>
<span id="cb83-100"><a href="#cb83-100" aria-hidden="true" tabindex="-1"></a>Tr <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">4</span>)</span>
<span id="cb83-101"><a href="#cb83-101" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-102"><a href="#cb83-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-103"><a href="#cb83-103" aria-hidden="true" tabindex="-1"></a>An <span class="in">`idx`</span> column is added to the data, which contains the three</span>
<span id="cb83-104"><a href="#cb83-104" aria-hidden="true" tabindex="-1"></a>relevant indexes: <span class="in">`choiceid`</span> is the choice situation index, <span class="in">`alt`</span> the</span>
<span id="cb83-105"><a href="#cb83-105" aria-hidden="true" tabindex="-1"></a>alternative index and <span class="in">`id`</span> the individual index. This column can be</span>
<span id="cb83-106"><a href="#cb83-106" aria-hidden="true" tabindex="-1"></a>extracted using the <span class="in">`idx`</span> function:</span>
<span id="cb83-107"><a href="#cb83-107" aria-hidden="true" tabindex="-1"></a>\idxfun{idx}{dfidx}</span>
<span id="cb83-108"><a href="#cb83-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-109"><a href="#cb83-109" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-110"><a href="#cb83-110" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'index of the transformed Train data set'</span></span>
<span id="cb83-111"><a href="#cb83-111" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: false</span></span>
<span id="cb83-112"><a href="#cb83-112" aria-hidden="true" tabindex="-1"></a><span class="fu">idx</span>(Tr)</span>
<span id="cb83-113"><a href="#cb83-113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-114"><a href="#cb83-114" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{dutch<span class="sc">\_</span>railways}{micsr.data}</span>
<span id="cb83-115"><a href="#cb83-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-116"><a href="#cb83-116" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Long format</span></span>
<span id="cb83-117"><a href="#cb83-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-118"><a href="#cb83-118" aria-hidden="true" tabindex="-1"></a><span class="in">`toronto_montreal`</span>,^<span class="co">[</span><span class="ot">Used in particular by @FORI:KOPP:93\index[author</span><span class="co">]</span>{Forinash}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Koppelman},</span>
<span id="cb83-119"><a href="#cb83-119" aria-hidden="true" tabindex="-1"></a>  @BHAT:95\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Bhat}, @KOPP:WEN:98\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Koppelman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wen} and @KOPP:WEN:00.] is an example of a data set in long format. It presents the choice of individuals for a transport mode for the Toronto-Montreal corridor in 1989:</span>
<span id="cb83-120"><a href="#cb83-120" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-121"><a href="#cb83-121" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb83-122"><a href="#cb83-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-123"><a href="#cb83-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'loading ModeCanada'</span></span>
<span id="cb83-124"><a href="#cb83-124" aria-hidden="true" tabindex="-1"></a>toronto_montreal <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">5</span>)</span>
<span id="cb83-125"><a href="#cb83-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-126"><a href="#cb83-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-127"><a href="#cb83-127" aria-hidden="true" tabindex="-1"></a>There are four transport modes (<span class="in">`air`</span>, <span class="in">`train`</span>, <span class="in">`bus`</span> and <span class="in">`car`</span>) and</span>
<span id="cb83-128"><a href="#cb83-128" aria-hidden="true" tabindex="-1"></a>most of the variables are alternative-specific (<span class="in">`cost`</span> for monetary</span>
<span id="cb83-129"><a href="#cb83-129" aria-hidden="true" tabindex="-1"></a>cost, <span class="in">`ivt`</span> for in-vehicle time, <span class="in">`ovt`</span> for out-vehicle time, <span class="in">`freq`</span></span>
<span id="cb83-130"><a href="#cb83-130" aria-hidden="true" tabindex="-1"></a>for frequency). The only choice situation-specific variables are</span>
<span id="cb83-131"><a href="#cb83-131" aria-hidden="true" tabindex="-1"></a><span class="in">`dist`</span> (distance of the trip), <span class="in">`income`</span> (household income),</span>
<span id="cb83-132"><a href="#cb83-132" aria-hidden="true" tabindex="-1"></a><span class="in">`urban`</span> (a dummy for trips which have a large city at the origin or</span>
<span id="cb83-133"><a href="#cb83-133" aria-hidden="true" tabindex="-1"></a>the destination) and <span class="in">`noalt`</span> (the number of available alternatives). The</span>
<span id="cb83-134"><a href="#cb83-134" aria-hidden="true" tabindex="-1"></a>advantage of this shape is that there are much fewer columns than in</span>
<span id="cb83-135"><a href="#cb83-135" aria-hidden="true" tabindex="-1"></a>the wide format, the caveat being that values of <span class="in">`dist`</span>, <span class="in">`income`</span> and</span>
<span id="cb83-136"><a href="#cb83-136" aria-hidden="true" tabindex="-1"></a><span class="in">`urban`</span> are repeated up to four times.</span>
<span id="cb83-137"><a href="#cb83-137" aria-hidden="true" tabindex="-1"></a>For data in "long" format, the <span class="in">`shape`</span> and the <span class="in">`choice`</span> arguments are</span>
<span id="cb83-138"><a href="#cb83-138" aria-hidden="true" tabindex="-1"></a>no longer mandatory.</span>
<span id="cb83-139"><a href="#cb83-139" aria-hidden="true" tabindex="-1"></a>To replicate published results later in the text, we'll use only a</span>
<span id="cb83-140"><a href="#cb83-140" aria-hidden="true" tabindex="-1"></a>subset of the choice situations, namely those for which the four</span>
<span id="cb83-141"><a href="#cb83-141" aria-hidden="true" tabindex="-1"></a>alternatives are available. This can be done using the <span class="in">`subset`</span></span>
<span id="cb83-142"><a href="#cb83-142" aria-hidden="true" tabindex="-1"></a>function with the <span class="in">`subset`</span> argument set to <span class="in">`noalt == 4`</span> while</span>
<span id="cb83-143"><a href="#cb83-143" aria-hidden="true" tabindex="-1"></a>estimating the model. This can also be done within <span class="in">`dfidx`</span>, using the</span>
<span id="cb83-144"><a href="#cb83-144" aria-hidden="true" tabindex="-1"></a><span class="in">`subset`</span> argument.</span>
<span id="cb83-145"><a href="#cb83-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-146"><a href="#cb83-146" aria-hidden="true" tabindex="-1"></a>The information about the structure of the data can be explicitly</span>
<span id="cb83-147"><a href="#cb83-147" aria-hidden="true" tabindex="-1"></a>indicated using choice situations and alternative indexes</span>
<span id="cb83-148"><a href="#cb83-148" aria-hidden="true" tabindex="-1"></a>(respectively <span class="in">`case`</span> and <span class="in">`alt`</span> in this data set) or, in part, guessed</span>
<span id="cb83-149"><a href="#cb83-149" aria-hidden="true" tabindex="-1"></a>by the <span class="in">`dfidx`</span> function. Here, after subsetting, we have 2779 choice</span>
<span id="cb83-150"><a href="#cb83-150" aria-hidden="true" tabindex="-1"></a>situations with 4 alternatives, and the rows are ordered first by</span>
<span id="cb83-151"><a href="#cb83-151" aria-hidden="true" tabindex="-1"></a>choice situation and then by alternative (<span class="in">`train`</span>, <span class="in">`air`</span>, <span class="in">`bus`</span>, and</span>
<span id="cb83-152"><a href="#cb83-152" aria-hidden="true" tabindex="-1"></a><span class="in">`car`</span> in this order).</span>
<span id="cb83-153"><a href="#cb83-153" aria-hidden="true" tabindex="-1"></a>The first way to read correctly this data frame is to ignore</span>
<span id="cb83-154"><a href="#cb83-154" aria-hidden="true" tabindex="-1"></a>completely the two index variables. In this case, the only</span>
<span id="cb83-155"><a href="#cb83-155" aria-hidden="true" tabindex="-1"></a>supplementary argument to provide is the <span class="in">`alt.levels`</span> argument, which</span>
<span id="cb83-156"><a href="#cb83-156" aria-hidden="true" tabindex="-1"></a>is a character vector that contains the name of the alternatives in</span>
<span id="cb83-157"><a href="#cb83-157" aria-hidden="true" tabindex="-1"></a>their order of appearance:</span>
<span id="cb83-158"><a href="#cb83-158" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-159"><a href="#cb83-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-160"><a href="#cb83-160" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-161"><a href="#cb83-161" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'applying dfidx to Modecanada (1)'</span></span>
<span id="cb83-162"><a href="#cb83-162" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>,</span>
<span id="cb83-163"><a href="#cb83-163" aria-hidden="true" tabindex="-1"></a>            <span class="at">alt.levels =</span> <span class="fu">c</span>(<span class="st">"train"</span>, <span class="st">"air"</span>, <span class="st">"bus"</span>, <span class="st">"car"</span>))</span>
<span id="cb83-164"><a href="#cb83-164" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-165"><a href="#cb83-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-166"><a href="#cb83-166" aria-hidden="true" tabindex="-1"></a>Note that this can only be used if the data set is "balanced", which</span>
<span id="cb83-167"><a href="#cb83-167" aria-hidden="true" tabindex="-1"></a>means that the same set of alternatives is available for all choice</span>
<span id="cb83-168"><a href="#cb83-168" aria-hidden="true" tabindex="-1"></a>situations.</span>
<span id="cb83-169"><a href="#cb83-169" aria-hidden="true" tabindex="-1"></a>It is also possible to provide the name of</span>
<span id="cb83-170"><a href="#cb83-170" aria-hidden="true" tabindex="-1"></a>the variable that contains the alternatives through the argument <span class="in">`idx`</span>:</span>
<span id="cb83-171"><a href="#cb83-171" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-172"><a href="#cb83-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-173"><a href="#cb83-173" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-174"><a href="#cb83-174" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'applying dfidx to Modecanada (2)'</span></span>
<span id="cb83-175"><a href="#cb83-175" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, <span class="at">idx =</span> <span class="fu">list</span>(<span class="cn">NA</span>, <span class="st">"alt"</span>))</span>
<span id="cb83-176"><a href="#cb83-176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-177"><a href="#cb83-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-178"><a href="#cb83-178" aria-hidden="true" tabindex="-1"></a>The name of the variable that contains the information about the choice situations can also</span>
<span id="cb83-179"><a href="#cb83-179" aria-hidden="true" tabindex="-1"></a>be indicated through the argument <span class="in">`idx`</span>:</span>
<span id="cb83-180"><a href="#cb83-180" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-181"><a href="#cb83-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-182"><a href="#cb83-182" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-183"><a href="#cb83-183" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'applying dfidx to Modecanada (3)'</span></span>
<span id="cb83-184"><a href="#cb83-184" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, <span class="at">idx =</span> <span class="st">"case"</span>,</span>
<span id="cb83-185"><a href="#cb83-185" aria-hidden="true" tabindex="-1"></a>            <span class="at">alt.levels =</span> <span class="fu">c</span>(<span class="st">"train"</span>, <span class="st">"air"</span>, <span class="st">"bus"</span>, <span class="st">"car"</span>))</span>
<span id="cb83-186"><a href="#cb83-186" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-187"><a href="#cb83-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-188"><a href="#cb83-188" aria-hidden="true" tabindex="-1"></a>Both alternative and choice situation variables can also be provided:</span>
<span id="cb83-189"><a href="#cb83-189" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-190"><a href="#cb83-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-191"><a href="#cb83-191" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-192"><a href="#cb83-192" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'applying dfidx to Modecanada (4)'</span></span>
<span id="cb83-193"><a href="#cb83-193" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, </span>
<span id="cb83-194"><a href="#cb83-194" aria-hidden="true" tabindex="-1"></a>            <span class="at">idx =</span> <span class="fu">c</span>(<span class="st">"case"</span>, <span class="st">"alt"</span>))</span>
<span id="cb83-195"><a href="#cb83-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-196"><a href="#cb83-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-197"><a href="#cb83-197" aria-hidden="true" tabindex="-1"></a>More simply, as the two indexes are stored in the first two columns of</span>
<span id="cb83-198"><a href="#cb83-198" aria-hidden="true" tabindex="-1"></a>the original data frame, the <span class="in">`idx`</span> argument can be unset:</span>
<span id="cb83-199"><a href="#cb83-199" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-200"><a href="#cb83-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-201"><a href="#cb83-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-202"><a href="#cb83-202" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'ModeCanada without idx'</span></span>
<span id="cb83-203"><a href="#cb83-203" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>)</span>
<span id="cb83-204"><a href="#cb83-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-205"><a href="#cb83-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-206"><a href="#cb83-206" aria-hidden="true" tabindex="-1"></a>and the indexes can be kept as standalone series if the <span class="in">`drop.index`</span></span>
<span id="cb83-207"><a href="#cb83-207" aria-hidden="true" tabindex="-1"></a>argument is set to <span class="in">`FALSE`</span>:</span>
<span id="cb83-208"><a href="#cb83-208" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}</span>
<span id="cb83-209"><a href="#cb83-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-210"><a href="#cb83-210" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-211"><a href="#cb83-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'applying dfidx to Modecanada (5)'</span></span>
<span id="cb83-212"><a href="#cb83-212" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, </span>
<span id="cb83-213"><a href="#cb83-213" aria-hidden="true" tabindex="-1"></a>            <span class="at">idx =</span> <span class="fu">c</span>(<span class="st">"case"</span>, <span class="st">"alt"</span>), <span class="at">drop.index =</span> <span class="cn">FALSE</span>)</span>
<span id="cb83-214"><a href="#cb83-214" aria-hidden="true" tabindex="-1"></a>MC <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">5</span>)</span>
<span id="cb83-215"><a href="#cb83-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb83-216"><a href="#cb83-216" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-217"><a href="#cb83-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-218"><a href="#cb83-218" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model description</span></span>
<span id="cb83-219"><a href="#cb83-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-220"><a href="#cb83-220" aria-hidden="true" tabindex="-1"></a>Standard <span class="in">`formula`</span>s are not very practical to describe random utility</span>
<span id="cb83-221"><a href="#cb83-221" aria-hidden="true" tabindex="-1"></a>models, as these models may use different sets of covariates.</span>
<span id="cb83-222"><a href="#cb83-222" aria-hidden="true" tabindex="-1"></a>Actually, working with random utility models, one has to consider at</span>
<span id="cb83-223"><a href="#cb83-223" aria-hidden="true" tabindex="-1"></a>most three sets of covariates:</span>
<span id="cb83-224"><a href="#cb83-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-225"><a href="#cb83-225" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>alternative- and choice situation-specific covariates $x_{nj}$</span>
<span id="cb83-226"><a href="#cb83-226" aria-hidden="true" tabindex="-1"></a>  with generic coefficients $\beta$ and alternative-specific</span>
<span id="cb83-227"><a href="#cb83-227" aria-hidden="true" tabindex="-1"></a>  covariates $t_j$ with a generic coefficient $\nu$,</span>
<span id="cb83-228"><a href="#cb83-228" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>choice situation-specific covariates $z_n$ with alternative-specific coefficients $\gamma_j$,</span>
<span id="cb83-229"><a href="#cb83-229" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>alternative- and choice situation-specific covariates $w_{nj}$ with</span>
<span id="cb83-230"><a href="#cb83-230" aria-hidden="true" tabindex="-1"></a>  alternative-specific coefficients $\delta_j$.</span>
<span id="cb83-231"><a href="#cb83-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-232"><a href="#cb83-232" aria-hidden="true" tabindex="-1"></a>The covariates enter the observable part of the</span>
<span id="cb83-233"><a href="#cb83-233" aria-hidden="true" tabindex="-1"></a>utility which can be written, for alternative $j$:</span>
<span id="cb83-234"><a href="#cb83-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-235"><a href="#cb83-235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-236"><a href="#cb83-236" aria-hidden="true" tabindex="-1"></a>V_{nj}=\alpha_j + \beta x_{nj} + \nu t_j + \gamma_j z_n + \delta_j w_{nj}</span>
<span id="cb83-237"><a href="#cb83-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-238"><a href="#cb83-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-239"><a href="#cb83-239" aria-hidden="true" tabindex="-1"></a>As the absolute value of utility is irrelevant, only utility</span>
<span id="cb83-240"><a href="#cb83-240" aria-hidden="true" tabindex="-1"></a>differences are useful to modelize the choice for one alternative. For</span>
<span id="cb83-241"><a href="#cb83-241" aria-hidden="true" tabindex="-1"></a>two alternatives $j$ and $l$, we obtain:</span>
<span id="cb83-242"><a href="#cb83-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-243"><a href="#cb83-243" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb83-244"><a href="#cb83-244" aria-hidden="true" tabindex="-1"></a>V_{nj}-V_{nl}=(\alpha_j-\alpha_l) + \beta (x_{nj}-x_{nl}) + \nu(t_j - t_l) +</span>
<span id="cb83-245"><a href="#cb83-245" aria-hidden="true" tabindex="-1"></a>(\gamma_j-\gamma_l) z_n + (\delta_j w_{nj} - \delta_k w_{nl})</span>
<span id="cb83-246"><a href="#cb83-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-247"><a href="#cb83-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-248"><a href="#cb83-248" aria-hidden="true" tabindex="-1"></a>It is clear from the previous expression that coefficients of choice</span>
<span id="cb83-249"><a href="#cb83-249" aria-hidden="true" tabindex="-1"></a>situation-specific variables (the intercept being one of those) should</span>
<span id="cb83-250"><a href="#cb83-250" aria-hidden="true" tabindex="-1"></a>be alternative-specific; otherwise they would disappear in the</span>
<span id="cb83-251"><a href="#cb83-251" aria-hidden="true" tabindex="-1"></a>differentiation. Moreover, only differences of these coefficients are</span>
<span id="cb83-252"><a href="#cb83-252" aria-hidden="true" tabindex="-1"></a>relevant and can be identified. For example, with three alternatives</span>
<span id="cb83-253"><a href="#cb83-253" aria-hidden="true" tabindex="-1"></a>1, 2 and 3, the three coefficients $\gamma_1, \gamma_2, \gamma_3$</span>
<span id="cb83-254"><a href="#cb83-254" aria-hidden="true" tabindex="-1"></a>associated with a choice situation-specific variable cannot be</span>
<span id="cb83-255"><a href="#cb83-255" aria-hidden="true" tabindex="-1"></a>identified, but only two linear combinations. Therefore, one</span>
<span id="cb83-256"><a href="#cb83-256" aria-hidden="true" tabindex="-1"></a>has to make a choice of normalization, and the simplest one is just to</span>
<span id="cb83-257"><a href="#cb83-257" aria-hidden="true" tabindex="-1"></a>set $\gamma_1 = 0$.</span>
<span id="cb83-258"><a href="#cb83-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-259"><a href="#cb83-259" aria-hidden="true" tabindex="-1"></a>Coefficients for alternative and choice situation-specific variables</span>
<span id="cb83-260"><a href="#cb83-260" aria-hidden="true" tabindex="-1"></a>may (or may not) be alternative-specific. For example, transport time</span>
<span id="cb83-261"><a href="#cb83-261" aria-hidden="true" tabindex="-1"></a>is alternative-specific, but 10 mn in public transport may not have</span>
<span id="cb83-262"><a href="#cb83-262" aria-hidden="true" tabindex="-1"></a>the same impact on utility than 10 mn in a car. In this case,</span>
<span id="cb83-263"><a href="#cb83-263" aria-hidden="true" tabindex="-1"></a>alternative-specific coefficients are relevant. Monetary cost is also</span>
<span id="cb83-264"><a href="#cb83-264" aria-hidden="true" tabindex="-1"></a>alternative-specific, but in this case, one can consider than $1 is $1 however it is spent for the use of a car or in public transports. In this case, a generic coefficient is relevant.</span>
<span id="cb83-265"><a href="#cb83-265" aria-hidden="true" tabindex="-1"></a>The treatment of alternative-specific variables doesn't differ much from</span>
<span id="cb83-266"><a href="#cb83-266" aria-hidden="true" tabindex="-1"></a>the alternative and choice situation-specific variables with a generic</span>
<span id="cb83-267"><a href="#cb83-267" aria-hidden="true" tabindex="-1"></a>coefficient. However, if some of these variables are introduced, the</span>
<span id="cb83-268"><a href="#cb83-268" aria-hidden="true" tabindex="-1"></a>$\nu$ parameter can only be estimated in a model without intercepts to</span>
<span id="cb83-269"><a href="#cb83-269" aria-hidden="true" tabindex="-1"></a>avoid perfect multicolinearity.</span>
<span id="cb83-270"><a href="#cb83-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-271"><a href="#cb83-271" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{multinomial logit model}</span>
<span id="cb83-272"><a href="#cb83-272" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{conditional logit model}</span>
<span id="cb83-273"><a href="#cb83-273" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{mixed logit model}</span>
<span id="cb83-274"><a href="#cb83-274" aria-hidden="true" tabindex="-1"></a>A logit model with only choice situation-specific variables is</span>
<span id="cb83-275"><a href="#cb83-275" aria-hidden="true" tabindex="-1"></a>sometimes called a *multinomial logit model*, one with only</span>
<span id="cb83-276"><a href="#cb83-276" aria-hidden="true" tabindex="-1"></a>alternative-specific variables, a *conditional logit model*, and one</span>
<span id="cb83-277"><a href="#cb83-277" aria-hidden="true" tabindex="-1"></a>with both kinds of variables, a *mixed logit model*. This is seriously</span>
<span id="cb83-278"><a href="#cb83-278" aria-hidden="true" tabindex="-1"></a>misleading: *conditional logit model* is also a logit model for</span>
<span id="cb83-279"><a href="#cb83-279" aria-hidden="true" tabindex="-1"></a>longitudinal data in the statistical literature, and *mixed logit* is</span>
<span id="cb83-280"><a href="#cb83-280" aria-hidden="true" tabindex="-1"></a>one of the names of a logit model with random parameters. Therefore,</span>
<span id="cb83-281"><a href="#cb83-281" aria-hidden="true" tabindex="-1"></a>in what follows, we'll use the name *multinomial logit model* for the</span>
<span id="cb83-282"><a href="#cb83-282" aria-hidden="true" tabindex="-1"></a>model we've just described whatever the nature of the explanatory</span>
<span id="cb83-283"><a href="#cb83-283" aria-hidden="true" tabindex="-1"></a>variables used.</span>
<span id="cb83-284"><a href="#cb83-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-285"><a href="#cb83-285" aria-hidden="true" tabindex="-1"></a>The **mlogit** package provides objects of class <span class="in">`mFormula`</span> which are built</span>
<span id="cb83-286"><a href="#cb83-286" aria-hidden="true" tabindex="-1"></a>upon <span class="in">`Formula`</span> objects provided by the **Formula** package.</span>
<span id="cb83-287"><a href="#cb83-287" aria-hidden="true" tabindex="-1"></a>To illustrate the use of <span class="in">`mFormula`</span> objects, we use again the</span>
<span id="cb83-288"><a href="#cb83-288" aria-hidden="true" tabindex="-1"></a><span class="in">`toronto_montreal`</span> data set\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-289"><a href="#cb83-289" aria-hidden="true" tabindex="-1"></a> and consider three sets of covariates that will</span>
<span id="cb83-290"><a href="#cb83-290" aria-hidden="true" tabindex="-1"></a>be indicated in a three-part formula, which refers to the three</span>
<span id="cb83-291"><a href="#cb83-291" aria-hidden="true" tabindex="-1"></a>items at the beginning of this section.</span>
<span id="cb83-292"><a href="#cb83-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-293"><a href="#cb83-293" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`cost`</span> (monetary cost) is an alternative-specific covariate</span>
<span id="cb83-294"><a href="#cb83-294" aria-hidden="true" tabindex="-1"></a>  with a generic coefficient (part 1),</span>
<span id="cb83-295"><a href="#cb83-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`income`</span> and <span class="in">`urban`</span> are choice situation-specific</span>
<span id="cb83-296"><a href="#cb83-296" aria-hidden="true" tabindex="-1"></a>covariates (part 2),</span>
<span id="cb83-297"><a href="#cb83-297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`ivt`</span> (in-vehicle travel time) is alternative-specific and</span>
<span id="cb83-298"><a href="#cb83-298" aria-hidden="true" tabindex="-1"></a>  alternative-specific coefficients  are expected (part 3).</span>
<span id="cb83-299"><a href="#cb83-299" aria-hidden="true" tabindex="-1"></a>\idxfun{Formula}{Formula}</span>
<span id="cb83-300"><a href="#cb83-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-301"><a href="#cb83-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-302"><a href="#cb83-302" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'a three parts formula'</span></span>
<span id="cb83-303"><a href="#cb83-303" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Formula)</span>
<span id="cb83-304"><a href="#cb83-304" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">|</span> income <span class="sc">+</span> urban <span class="sc">|</span> ivt)</span>
<span id="cb83-305"><a href="#cb83-305" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-306"><a href="#cb83-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-307"><a href="#cb83-307" aria-hidden="true" tabindex="-1"></a>Some parts of the formula may be omitted when there is no</span>
<span id="cb83-308"><a href="#cb83-308" aria-hidden="true" tabindex="-1"></a>ambiguity. For example, the following sets of <span class="in">`formula`</span>s are</span>
<span id="cb83-309"><a href="#cb83-309" aria-hidden="true" tabindex="-1"></a>identical:</span>
<span id="cb83-310"><a href="#cb83-310" aria-hidden="true" tabindex="-1"></a>\idxfun{Formula}{Formula}</span>
<span id="cb83-311"><a href="#cb83-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-312"><a href="#cb83-312" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-313"><a href="#cb83-313" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'ommission of some parts (1)'</span></span>
<span id="cb83-314"><a href="#cb83-314" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> ivt <span class="sc">|</span> income <span class="sc">+</span> urban)</span>
<span id="cb83-315"><a href="#cb83-315" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> ivt <span class="sc">|</span> income <span class="sc">+</span> urban <span class="sc">|</span> <span class="dv">0</span>)</span>
<span id="cb83-316"><a href="#cb83-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-317"><a href="#cb83-317" aria-hidden="true" tabindex="-1"></a>\idxfun{Formula}{Formula}</span>
<span id="cb83-318"><a href="#cb83-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-319"><a href="#cb83-319" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-320"><a href="#cb83-320" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'ommission of some parts (2)'</span></span>
<span id="cb83-321"><a href="#cb83-321" aria-hidden="true" tabindex="-1"></a>f3 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> <span class="dv">0</span> <span class="sc">|</span> income <span class="sc">|</span> <span class="dv">0</span>)</span>
<span id="cb83-322"><a href="#cb83-322" aria-hidden="true" tabindex="-1"></a>f3 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> <span class="dv">0</span> <span class="sc">|</span> income)</span>
<span id="cb83-323"><a href="#cb83-323" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-324"><a href="#cb83-324" aria-hidden="true" tabindex="-1"></a>\idxfun{Formula}{Formula}</span>
<span id="cb83-325"><a href="#cb83-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-326"><a href="#cb83-326" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-327"><a href="#cb83-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'ommission of some parts (3)'</span></span>
<span id="cb83-328"><a href="#cb83-328" aria-hidden="true" tabindex="-1"></a>f4 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> ivt)</span>
<span id="cb83-329"><a href="#cb83-329" aria-hidden="true" tabindex="-1"></a>f4 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> ivt <span class="sc">|</span> <span class="dv">1</span>)</span>
<span id="cb83-330"><a href="#cb83-330" aria-hidden="true" tabindex="-1"></a>f4 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> ivt <span class="sc">|</span> <span class="dv">1</span> <span class="sc">|</span> <span class="dv">0</span>)</span>
<span id="cb83-331"><a href="#cb83-331" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-332"><a href="#cb83-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-333"><a href="#cb83-333" aria-hidden="true" tabindex="-1"></a>By default, an intercept is added to the model; it can be removed by</span>
<span id="cb83-334"><a href="#cb83-334" aria-hidden="true" tabindex="-1"></a>using <span class="in">`+ 0`</span> or <span class="in">`- 1`</span> in the second part.</span>
<span id="cb83-335"><a href="#cb83-335" aria-hidden="true" tabindex="-1"></a>\idxfun{Formula}{Formula}</span>
<span id="cb83-336"><a href="#cb83-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-337"><a href="#cb83-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-338"><a href="#cb83-338" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'removing the intercept'</span></span>
<span id="cb83-339"><a href="#cb83-339" aria-hidden="true" tabindex="-1"></a>f5 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">|</span> income <span class="sc">+</span> <span class="dv">0</span> <span class="sc">|</span> ivt)</span>
<span id="cb83-340"><a href="#cb83-340" aria-hidden="true" tabindex="-1"></a>f5 <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">|</span> income <span class="sc">-</span> <span class="dv">1</span> <span class="sc">|</span> ivt)</span>
<span id="cb83-341"><a href="#cb83-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-342"><a href="#cb83-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-343"><a href="#cb83-343" aria-hidden="true" tabindex="-1"></a>A <span class="in">`model.frame`</span> method is provided for <span class="in">`dfidx`</span> objects. It differs from the <span class="in">`formula`</span> method</span>
<span id="cb83-344"><a href="#cb83-344" aria-hidden="true" tabindex="-1"></a>by the fact that the returned object is an object of class <span class="in">`dfidx`</span> and not an ordinary data frame, which means that the information about the structure of the data is not lost. Defining a specific <span class="in">`model.frame`</span> method for <span class="in">`dfidx`</span> objects implies that the first argument of the function should</span>
<span id="cb83-345"><a href="#cb83-345" aria-hidden="true" tabindex="-1"></a>be a <span class="in">`dfidx`</span> object, which results in an unusual order of the arguments in the function (the</span>
<span id="cb83-346"><a href="#cb83-346" aria-hidden="true" tabindex="-1"></a>data first, and then the formula). Moreover, as the model matrix for random utility models</span>
<span id="cb83-347"><a href="#cb83-347" aria-hidden="true" tabindex="-1"></a>has specific features, we add a supplementary argument called <span class="in">`pkg`</span> to the <span class="in">`dfidx`</span> function so</span>
<span id="cb83-348"><a href="#cb83-348" aria-hidden="true" tabindex="-1"></a>that the returned object has a specific class (and inherits the <span class="in">`dfidx`</span> class):</span>
<span id="cb83-349"><a href="#cb83-349" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}\idxfun{class}{base}\idxfun{Formula}{Formula}\idxfun{model.frame}{stats}</span>
<span id="cb83-350"><a href="#cb83-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-351"><a href="#cb83-351" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-352"><a href="#cb83-352" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'model.matrix method for Formula objects'</span></span>
<span id="cb83-353"><a href="#cb83-353" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-354"><a href="#cb83-354" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, <span class="at">pkg =</span> <span class="st">"mlogit"</span>)</span>
<span id="cb83-355"><a href="#cb83-355" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(MC)</span>
<span id="cb83-356"><a href="#cb83-356" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">Formula</span>(choice <span class="sc">~</span> cost <span class="sc">|</span> income  <span class="sc">|</span> ivt)</span>
<span id="cb83-357"><a href="#cb83-357" aria-hidden="true" tabindex="-1"></a>mf <span class="ot">&lt;-</span> <span class="fu">model.frame</span>(MC, f)</span>
<span id="cb83-358"><a href="#cb83-358" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(mf)</span>
<span id="cb83-359"><a href="#cb83-359" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-360"><a href="#cb83-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-361"><a href="#cb83-361" aria-hidden="true" tabindex="-1"></a>Using <span class="in">`mf`</span> as the argument of <span class="in">`model.matrix`</span> enables the construction of the relevant model matrix for random utility model, as a specific <span class="in">`model.matrix`</span> method for <span class="in">`dfidx_mlogit`</span> objects is provided.</span>
<span id="cb83-362"><a href="#cb83-362" aria-hidden="true" tabindex="-1"></a>\idxfun{head}{utils}\idxfun{model.matrix}{stats}</span>
<span id="cb83-363"><a href="#cb83-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-366"><a href="#cb83-366" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-367"><a href="#cb83-367" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(mf), <span class="dv">4</span>)</span>
<span id="cb83-368"><a href="#cb83-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-369"><a href="#cb83-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-370"><a href="#cb83-370" aria-hidden="true" tabindex="-1"></a>The model matrix contains $J-1$ columns for every choice situation-specific</span>
<span id="cb83-371"><a href="#cb83-371" aria-hidden="true" tabindex="-1"></a>variables (<span class="in">`income`</span> and the intercept), which means that the</span>
<span id="cb83-372"><a href="#cb83-372" aria-hidden="true" tabindex="-1"></a>coefficient associated with the first alternative (<span class="in">`train`</span>) is set to</span>
<span id="cb83-373"><a href="#cb83-373" aria-hidden="true" tabindex="-1"></a><span class="ss">0. </span>It contains only one column for <span class="in">`cost`</span> because we want a generic</span>
<span id="cb83-374"><a href="#cb83-374" aria-hidden="true" tabindex="-1"></a>coefficient for this variable. It contains $J$ columns for <span class="in">`ivt`</span>,</span>
<span id="cb83-375"><a href="#cb83-375" aria-hidden="true" tabindex="-1"></a>because it is an alternative specific variable for which we want</span>
<span id="cb83-376"><a href="#cb83-376" aria-hidden="true" tabindex="-1"></a>alternative specific coefficients.</span>
<span id="cb83-377"><a href="#cb83-377" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-378"><a href="#cb83-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-379"><a href="#cb83-379" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random utility model and multinomial logit model {#sec-multinom_logit}</span></span>
<span id="cb83-380"><a href="#cb83-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-381"><a href="#cb83-381" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random utility model</span></span>
<span id="cb83-382"><a href="#cb83-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-383"><a href="#cb83-383" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random utility model|(}</span>
<span id="cb83-384"><a href="#cb83-384" aria-hidden="true" tabindex="-1"></a>The utility for alternative $l$  is written as:</span>
<span id="cb83-385"><a href="#cb83-385" aria-hidden="true" tabindex="-1"></a>$U_l=V_l+\epsilon_l$ where $V_l$ is a function of some observable</span>
<span id="cb83-386"><a href="#cb83-386" aria-hidden="true" tabindex="-1"></a>covariates and unknown parameters to be estimated, and $\epsilon_l$ is a</span>
<span id="cb83-387"><a href="#cb83-387" aria-hidden="true" tabindex="-1"></a>random deviate which contains all the unobserved determinants of the</span>
<span id="cb83-388"><a href="#cb83-388" aria-hidden="true" tabindex="-1"></a>utility. Alternative $l$ is therefore chosen if</span>
<span id="cb83-389"><a href="#cb83-389" aria-hidden="true" tabindex="-1"></a>$\epsilon_j &lt; (V_l-V_j)+\epsilon_l \;\forall\;j\neq l$ and the</span>
<span id="cb83-390"><a href="#cb83-390" aria-hidden="true" tabindex="-1"></a>probability of choosing this alternative is then:</span>
<span id="cb83-391"><a href="#cb83-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-392"><a href="#cb83-392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-393"><a href="#cb83-393" aria-hidden="true" tabindex="-1"></a>\mbox{P}(\epsilon_1 &lt; V_l-V_1+\epsilon_l,</span>
<span id="cb83-394"><a href="#cb83-394" aria-hidden="true" tabindex="-1"></a>\epsilon_2 &lt; V_l-V_2+\epsilon_l, ...,</span>
<span id="cb83-395"><a href="#cb83-395" aria-hidden="true" tabindex="-1"></a>\epsilon_J &lt; V_l-V_J+\epsilon_l).</span>
<span id="cb83-396"><a href="#cb83-396" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-397"><a href="#cb83-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-398"><a href="#cb83-398" aria-hidden="true" tabindex="-1"></a>Denoting $F_{-l}$ as the cumulative density function of all the $\epsilon$s</span>
<span id="cb83-399"><a href="#cb83-399" aria-hidden="true" tabindex="-1"></a>except $\epsilon_l$, this probability is:</span>
<span id="cb83-400"><a href="#cb83-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-401"><a href="#cb83-401" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-402"><a href="#cb83-402" aria-hidden="true" tabindex="-1"></a>(\mbox{P}_l \mid \epsilon_l)=</span>
<span id="cb83-403"><a href="#cb83-403" aria-hidden="true" tabindex="-1"></a>F_{-l}(V_l-V_1+\epsilon_l, ..., V_l-V_J+\epsilon_l).</span>
<span id="cb83-404"><a href="#cb83-404" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-405"><a href="#cb83-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-406"><a href="#cb83-406" aria-hidden="true" tabindex="-1"></a>Note that this probability is conditional on the value of</span>
<span id="cb83-407"><a href="#cb83-407" aria-hidden="true" tabindex="-1"></a>$\epsilon_l$.  The unconditional probability (which depends only on</span>
<span id="cb83-408"><a href="#cb83-408" aria-hidden="true" tabindex="-1"></a>$\beta$ and on the value of the observed covariates) is</span>
<span id="cb83-409"><a href="#cb83-409" aria-hidden="true" tabindex="-1"></a>obtained by integrating out the conditional probability using the</span>
<span id="cb83-410"><a href="#cb83-410" aria-hidden="true" tabindex="-1"></a>marginal density of $\epsilon_l$, denoted by $f_l$:</span>
<span id="cb83-411"><a href="#cb83-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-412"><a href="#cb83-412" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-413"><a href="#cb83-413" aria-hidden="true" tabindex="-1"></a>\mbox{P}_l=\int F_{-l}(V_l-V_1+\epsilon_l, ...,V_l-V_J)+\epsilon_l)f_l(\epsilon_l) d\epsilon_l.</span>
<span id="cb83-414"><a href="#cb83-414" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-415"><a href="#cb83-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-416"><a href="#cb83-416" aria-hidden="true" tabindex="-1"></a>The conditional probability is an integral of dimension $J-1$, and the</span>
<span id="cb83-417"><a href="#cb83-417" aria-hidden="true" tabindex="-1"></a>computation of the unconditional probability adds one more dimension of</span>
<span id="cb83-418"><a href="#cb83-418" aria-hidden="true" tabindex="-1"></a>integration.</span>
<span id="cb83-419"><a href="#cb83-419" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random utility model|)}</span>
<span id="cb83-420"><a href="#cb83-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-421"><a href="#cb83-421" aria-hidden="true" tabindex="-1"></a><span class="fu">### Distribution of the error terms</span></span>
<span id="cb83-422"><a href="#cb83-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-423"><a href="#cb83-423" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{uncorrelated errors!random utility model}</span>
<span id="cb83-424"><a href="#cb83-424" aria-hidden="true" tabindex="-1"></a>The multinomial logit model <span class="co">[</span><span class="ot">@MCFAD:74</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McFadden} is a special case of the</span>
<span id="cb83-425"><a href="#cb83-425" aria-hidden="true" tabindex="-1"></a>model developed in the previous section. It is based on three</span>
<span id="cb83-426"><a href="#cb83-426" aria-hidden="true" tabindex="-1"></a>hypotheses.</span>
<span id="cb83-427"><a href="#cb83-427" aria-hidden="true" tabindex="-1"></a>The first hypothesis is the independence of the errors. In this case,</span>
<span id="cb83-428"><a href="#cb83-428" aria-hidden="true" tabindex="-1"></a>the univariate distribution of the errors can be used, which leads to</span>
<span id="cb83-429"><a href="#cb83-429" aria-hidden="true" tabindex="-1"></a>the following conditional and unconditional probabilities:</span>
<span id="cb83-430"><a href="#cb83-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-431"><a href="#cb83-431" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-432"><a href="#cb83-432" aria-hidden="true" tabindex="-1"></a>(\mbox{P}_l \mid \epsilon_l)=\prod_{j\neq l}F_j(V_l-V_j+\epsilon_l)</span>
<span id="cb83-433"><a href="#cb83-433" aria-hidden="true" tabindex="-1"></a>\mbox{ and }</span>
<span id="cb83-434"><a href="#cb83-434" aria-hidden="true" tabindex="-1"></a>\mbox{P}_l =\int \prod_{j\neq l}F_j(V_l-V_j+\epsilon_l) \; f_l(\epsilon_l) \;d\epsilon_l,</span>
<span id="cb83-435"><a href="#cb83-435" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-436"><a href="#cb83-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-437"><a href="#cb83-437" aria-hidden="true" tabindex="-1"></a>which means that the conditional probability is the product of $J-1$</span>
<span id="cb83-438"><a href="#cb83-438" aria-hidden="true" tabindex="-1"></a>univariate cumulative density functions, and the evaluation of only a</span>
<span id="cb83-439"><a href="#cb83-439" aria-hidden="true" tabindex="-1"></a>one-dimensional integral is required to compute the unconditional</span>
<span id="cb83-440"><a href="#cb83-440" aria-hidden="true" tabindex="-1"></a>probability.</span>
<span id="cb83-441"><a href="#cb83-441" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Gumbel distribution}</span>
<span id="cb83-442"><a href="#cb83-442" aria-hidden="true" tabindex="-1"></a>The second hypothesis is that each $\epsilon$ follows a Gumbel (maximum)</span>
<span id="cb83-443"><a href="#cb83-443" aria-hidden="true" tabindex="-1"></a>distribution, whose density and probability functions are</span>
<span id="cb83-444"><a href="#cb83-444" aria-hidden="true" tabindex="-1"></a>respectively:</span>
<span id="cb83-445"><a href="#cb83-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-446"><a href="#cb83-446" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-447"><a href="#cb83-447" aria-hidden="true" tabindex="-1"></a>f(z)=\frac{1}{\theta}e^{-\frac{z-\mu}{\theta}} e^{-e^{-\frac{z-\mu}{\theta}}}</span>
<span id="cb83-448"><a href="#cb83-448" aria-hidden="true" tabindex="-1"></a>\mbox{ and }</span>
<span id="cb83-449"><a href="#cb83-449" aria-hidden="true" tabindex="-1"></a>F(z)=\int_{-\infty}^{z} f(t) dt=e^{-e^{-\frac{z-\mu}{\theta}}},</span>
<span id="cb83-450"><a href="#cb83-450" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-451"><a href="#cb83-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-452"><a href="#cb83-452" aria-hidden="true" tabindex="-1"></a>where $\mu$ is the location parameter and $\theta$ the scale</span>
<span id="cb83-453"><a href="#cb83-453" aria-hidden="true" tabindex="-1"></a>parameter.  The first two moments of the Gumbel distribution are</span>
<span id="cb83-454"><a href="#cb83-454" aria-hidden="true" tabindex="-1"></a>$\mbox{E}(z)=\mu+\theta \gamma$, where $\gamma$ is the</span>
<span id="cb83-455"><a href="#cb83-455" aria-hidden="true" tabindex="-1"></a>Euler-Mascheroni constant ($\approx 0.57721$) and</span>
<span id="cb83-456"><a href="#cb83-456" aria-hidden="true" tabindex="-1"></a>$\mbox{V}(z)=\frac{\pi^2}{6}\theta^2$.  The mean of $\epsilon_j$ is</span>
<span id="cb83-457"><a href="#cb83-457" aria-hidden="true" tabindex="-1"></a>not identified if $V_j$ contains an intercept. We can then, without</span>
<span id="cb83-458"><a href="#cb83-458" aria-hidden="true" tabindex="-1"></a>loss of generality suppose that $\mu_j=0, \; \forall j$. Moreover, the</span>
<span id="cb83-459"><a href="#cb83-459" aria-hidden="true" tabindex="-1"></a>overall scale of utility is not identified. Therefore, only $J-1$</span>
<span id="cb83-460"><a href="#cb83-460" aria-hidden="true" tabindex="-1"></a>scale parameters may be identified, and a natural choice of</span>
<span id="cb83-461"><a href="#cb83-461" aria-hidden="true" tabindex="-1"></a>normalization is to impose that one of the $\theta_j$ is equal to 1.</span>
<span id="cb83-462"><a href="#cb83-462" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{homoskedasticity!random utility model}</span>
<span id="cb83-463"><a href="#cb83-463" aria-hidden="true" tabindex="-1"></a>The last hypothesis is that the errors are identically distributed. As</span>
<span id="cb83-464"><a href="#cb83-464" aria-hidden="true" tabindex="-1"></a>the location parameter is not identified for any error term, this</span>
<span id="cb83-465"><a href="#cb83-465" aria-hidden="true" tabindex="-1"></a>hypothesis is essentially a homoskedasticity hypothesis, which means</span>
<span id="cb83-466"><a href="#cb83-466" aria-hidden="true" tabindex="-1"></a>that the scale parameter of the Gumbel distribution is the same for</span>
<span id="cb83-467"><a href="#cb83-467" aria-hidden="true" tabindex="-1"></a>all the alternatives. As one of them has been previously set to 1, we</span>
<span id="cb83-468"><a href="#cb83-468" aria-hidden="true" tabindex="-1"></a>can therefore suppose that, without loss of generality, $\theta_j = 1,</span>
<span id="cb83-469"><a href="#cb83-469" aria-hidden="true" tabindex="-1"></a>\;\forall j \in 1... J$. The conditional and unconditional</span>
<span id="cb83-470"><a href="#cb83-470" aria-hidden="true" tabindex="-1"></a>probabilities then further simplify to:</span>
<span id="cb83-471"><a href="#cb83-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-472"><a href="#cb83-472" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-473"><a href="#cb83-473" aria-hidden="true" tabindex="-1"></a>  (\mbox{P}_l \mid \epsilon_l)%=\prod_{j\neq l}F(V_l-V_j+\epsilon_l)</span>
<span id="cb83-474"><a href="#cb83-474" aria-hidden="true" tabindex="-1"></a>  =\prod_{j\neq l}e^{-e^{-(V_l-Vj+\epsilon_l)}}</span>
<span id="cb83-475"><a href="#cb83-475" aria-hidden="true" tabindex="-1"></a>\mbox{ and }</span>
<span id="cb83-476"><a href="#cb83-476" aria-hidden="true" tabindex="-1"></a>  \mbox{P}_l =\int_{-\infty}^{+\infty}\prod_{j\neq l}e^{-e^{-(V_l-Vj+t)}}e^{-t}e^{-e^{-t}}dt.</span>
<span id="cb83-477"><a href="#cb83-477" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-478"><a href="#cb83-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-479"><a href="#cb83-479" aria-hidden="true" tabindex="-1"></a>The probabilities have then very simple, closed forms, which</span>
<span id="cb83-480"><a href="#cb83-480" aria-hidden="true" tabindex="-1"></a>correspond to the logit transformation of the deterministic part of</span>
<span id="cb83-481"><a href="#cb83-481" aria-hidden="true" tabindex="-1"></a>the utility.^<span class="co">[</span><span class="ot">See @TRAI:09, pp. 74-75.</span><span class="co">]</span></span>
<span id="cb83-482"><a href="#cb83-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-483"><a href="#cb83-483" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-484"><a href="#cb83-484" aria-hidden="true" tabindex="-1"></a>  P_l=\frac{e^{V_l}}{\sum_{j=1}^J e^{V_j}}.</span>
<span id="cb83-485"><a href="#cb83-485" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-486"><a href="#cb83-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-487"><a href="#cb83-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-488"><a href="#cb83-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-489"><a href="#cb83-489" aria-hidden="true" tabindex="-1"></a><span class="fu">### IIA property</span></span>
<span id="cb83-490"><a href="#cb83-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-491"><a href="#cb83-491" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{independence of irrelevant alternatives hypothesis|(}</span>
<span id="cb83-492"><a href="#cb83-492" aria-hidden="true" tabindex="-1"></a>If we consider the probabilities of choice for two alternatives $l$</span>
<span id="cb83-493"><a href="#cb83-493" aria-hidden="true" tabindex="-1"></a>and $m$, we have $P_l=e^{V_l}/\sum_j e^{V_j}$ and</span>
<span id="cb83-494"><a href="#cb83-494" aria-hidden="true" tabindex="-1"></a>$P_m=e^{V_m}/\sum_j e^{V_j}$.  The ratio of these two</span>
<span id="cb83-495"><a href="#cb83-495" aria-hidden="true" tabindex="-1"></a>probabilities is:</span>
<span id="cb83-496"><a href="#cb83-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-497"><a href="#cb83-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-498"><a href="#cb83-498" aria-hidden="true" tabindex="-1"></a>\frac{P_l}{P_m}=\frac{e^{V_l}}{e^{V_m}}=e^{V_l-V_m}.</span>
<span id="cb83-499"><a href="#cb83-499" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-500"><a href="#cb83-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-501"><a href="#cb83-501" aria-hidden="true" tabindex="-1"></a>This probability ratio for the two alternatives depends only on the</span>
<span id="cb83-502"><a href="#cb83-502" aria-hidden="true" tabindex="-1"></a>characteristics of these two alternatives and not on those of other</span>
<span id="cb83-503"><a href="#cb83-503" aria-hidden="true" tabindex="-1"></a>alternatives. This is called the independence of</span>
<span id="cb83-504"><a href="#cb83-504" aria-hidden="true" tabindex="-1"></a>irrelevant alternatives (**IIA**) property. IIA relies on the hypothesis that the</span>
<span id="cb83-505"><a href="#cb83-505" aria-hidden="true" tabindex="-1"></a>errors are identical and independent. It is not a problem in itself</span>
<span id="cb83-506"><a href="#cb83-506" aria-hidden="true" tabindex="-1"></a>and may even be considered as a useful feature for a well-specified</span>
<span id="cb83-507"><a href="#cb83-507" aria-hidden="true" tabindex="-1"></a>model. However, this hypothesis may be in practice violated,</span>
<span id="cb83-508"><a href="#cb83-508" aria-hidden="true" tabindex="-1"></a>especially if some important variables are omitted.</span>
<span id="cb83-509"><a href="#cb83-509" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{independence of irrelevant alternatives hypothesis|)}</span>
<span id="cb83-510"><a href="#cb83-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-511"><a href="#cb83-511" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation</span></span>
<span id="cb83-512"><a href="#cb83-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-513"><a href="#cb83-513" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Marginal effects</span></span>
<span id="cb83-514"><a href="#cb83-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-515"><a href="#cb83-515" aria-hidden="true" tabindex="-1"></a>The marginal effects are the derivatives of the probabilities with</span>
<span id="cb83-516"><a href="#cb83-516" aria-hidden="true" tabindex="-1"></a>respect to the covariates, which can be choice situation-specific ($z_n$)</span>
<span id="cb83-517"><a href="#cb83-517" aria-hidden="true" tabindex="-1"></a>or alternative-specific ($x_{nj}$):</span>
<span id="cb83-518"><a href="#cb83-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-519"><a href="#cb83-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-520"><a href="#cb83-520" aria-hidden="true" tabindex="-1"></a>  \begin{array}{rcl}</span>
<span id="cb83-521"><a href="#cb83-521" aria-hidden="true" tabindex="-1"></a>    \displaystyle \frac{\partial P_{nl}}{\partial z_{n}}&amp;=&amp;P_{nl}\left(\beta_l-\sum_j</span>
<span id="cb83-522"><a href="#cb83-522" aria-hidden="true" tabindex="-1"></a>    P_{nj}\beta_j\right) <span class="sc">\\</span></span>
<span id="cb83-523"><a href="#cb83-523" aria-hidden="true" tabindex="-1"></a>    \displaystyle    \frac{\partial P_{nl}}{\partial x_{nl}}&amp;=&amp;\gamma P_{nl}(1-P_{nl})<span class="sc">\\</span></span>
<span id="cb83-524"><a href="#cb83-524" aria-hidden="true" tabindex="-1"></a>    \displaystyle    \frac{\partial P_{nl}}{\partial x_{nk}}&amp;=&amp;-\gamma P_{nl}P_{nk}.</span>
<span id="cb83-525"><a href="#cb83-525" aria-hidden="true" tabindex="-1"></a>  \end{array}</span>
<span id="cb83-526"><a href="#cb83-526" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-527"><a href="#cb83-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-528"><a href="#cb83-528" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For a choice situation-specific variable, the sign of the marginal</span>
<span id="cb83-529"><a href="#cb83-529" aria-hidden="true" tabindex="-1"></a>  effect is not necessarily the sign of the coefficient. Actually, the</span>
<span id="cb83-530"><a href="#cb83-530" aria-hidden="true" tabindex="-1"></a>  sign of the marginal effect is given by</span>
<span id="cb83-531"><a href="#cb83-531" aria-hidden="true" tabindex="-1"></a>  $\left(\beta_l-\sum_j P_{nj}\beta_j\right)$, which is positive if</span>
<span id="cb83-532"><a href="#cb83-532" aria-hidden="true" tabindex="-1"></a>  the coefficient for alternative $l$ is greater than a weighted</span>
<span id="cb83-533"><a href="#cb83-533" aria-hidden="true" tabindex="-1"></a>  average of the coefficients for all the alternatives, the weights</span>
<span id="cb83-534"><a href="#cb83-534" aria-hidden="true" tabindex="-1"></a>  being the probabilities of choosing the alternatives. In this case,</span>
<span id="cb83-535"><a href="#cb83-535" aria-hidden="true" tabindex="-1"></a>  the sign of the marginal effect can be established with no ambiguity</span>
<span id="cb83-536"><a href="#cb83-536" aria-hidden="true" tabindex="-1"></a>  only for the alternatives with the lowest and the greatest</span>
<span id="cb83-537"><a href="#cb83-537" aria-hidden="true" tabindex="-1"></a>  coefficients.</span>
<span id="cb83-538"><a href="#cb83-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-539"><a href="#cb83-539" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For an alternative-specific variable, the sign of the</span>
<span id="cb83-540"><a href="#cb83-540" aria-hidden="true" tabindex="-1"></a>  coefficient can be directly interpreted. The marginal effect is</span>
<span id="cb83-541"><a href="#cb83-541" aria-hidden="true" tabindex="-1"></a>  obtained by multiplying the coefficient by the product of two</span>
<span id="cb83-542"><a href="#cb83-542" aria-hidden="true" tabindex="-1"></a>  probabilities which is at most 0.25. The rule of thumb is therefore</span>
<span id="cb83-543"><a href="#cb83-543" aria-hidden="true" tabindex="-1"></a>  to divide the coefficient by 4 in order to have an upper bound of</span>
<span id="cb83-544"><a href="#cb83-544" aria-hidden="true" tabindex="-1"></a>  the marginal effect.</span>
<span id="cb83-545"><a href="#cb83-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-546"><a href="#cb83-546" aria-hidden="true" tabindex="-1"></a>Note that the last equation can be rewritten:</span>
<span id="cb83-547"><a href="#cb83-547" aria-hidden="true" tabindex="-1"></a>$\frac{\mbox{d} P_{nl} / P_{nl}}{\mbox{d}x_{nk}} = -\gamma P_{nk}$.</span>
<span id="cb83-548"><a href="#cb83-548" aria-hidden="true" tabindex="-1"></a>Therefore, when a characteristic of alternative $k$ changes, the</span>
<span id="cb83-549"><a href="#cb83-549" aria-hidden="true" tabindex="-1"></a>relative changes of the probabilities for every alternative except $k$</span>
<span id="cb83-550"><a href="#cb83-550" aria-hidden="true" tabindex="-1"></a>are the same, which is a consequence of the IIA property.</span>
<span id="cb83-551"><a href="#cb83-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-552"><a href="#cb83-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-553"><a href="#cb83-553" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Marginal rates of substitution</span></span>
<span id="cb83-554"><a href="#cb83-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-555"><a href="#cb83-555" aria-hidden="true" tabindex="-1"></a>Coefficients are marginal utilities, which cannot be</span>
<span id="cb83-556"><a href="#cb83-556" aria-hidden="true" tabindex="-1"></a>interpreted. However, ratios of coefficients are marginal rates of</span>
<span id="cb83-557"><a href="#cb83-557" aria-hidden="true" tabindex="-1"></a>substitution. For example, if the observable part of utility is:</span>
<span id="cb83-558"><a href="#cb83-558" aria-hidden="true" tabindex="-1"></a>$V=\beta_o +\beta_1 x_1 +\beta x_2 + \beta x_3$, joint variations of</span>
<span id="cb83-559"><a href="#cb83-559" aria-hidden="true" tabindex="-1"></a>$x_1$ and $x_2$ which ensure the same level of utility are such that:</span>
<span id="cb83-560"><a href="#cb83-560" aria-hidden="true" tabindex="-1"></a>$dV=\beta_1 dx_1+\beta_2 dx_2=0$ so that:</span>
<span id="cb83-561"><a href="#cb83-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-562"><a href="#cb83-562" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-563"><a href="#cb83-563" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\frac{dx_2}{dx_1}\mid_{dV = 0} = \frac{\beta_1}{\beta_2}.</span>
<span id="cb83-564"><a href="#cb83-564" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-565"><a href="#cb83-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-566"><a href="#cb83-566" aria-hidden="true" tabindex="-1"></a>For example, if $x_2$ is transport cost (in dollars), $x_1$ transport time</span>
<span id="cb83-567"><a href="#cb83-567" aria-hidden="true" tabindex="-1"></a>(in hours), $\beta_1 = 1.5$ and $\beta_2=0.05$,</span>
<span id="cb83-568"><a href="#cb83-568" aria-hidden="true" tabindex="-1"></a>$\frac{\beta_1}{\beta_2}=30$ is the marginal rate of substitution of</span>
<span id="cb83-569"><a href="#cb83-569" aria-hidden="true" tabindex="-1"></a>time in terms of dollars and the value of 30 means that, to reduce the</span>
<span id="cb83-570"><a href="#cb83-570" aria-hidden="true" tabindex="-1"></a>travel time of 1 hour, the individual is willing to pay at most $30</span>
<span id="cb83-571"><a href="#cb83-571" aria-hidden="true" tabindex="-1"></a>more. Stated more simply, time value is $30 per hour.</span>
<span id="cb83-572"><a href="#cb83-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-573"><a href="#cb83-573" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Consumer surplus {#sec-consumer_surplus}</span></span>
<span id="cb83-574"><a href="#cb83-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-575"><a href="#cb83-575" aria-hidden="true" tabindex="-1"></a>Consumer's surplus has a very simple expression for multinomial logit</span>
<span id="cb83-576"><a href="#cb83-576" aria-hidden="true" tabindex="-1"></a>models, which was first derived by @SMAL:ROSE:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Small}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Rosen}. The level of</span>
<span id="cb83-577"><a href="#cb83-577" aria-hidden="true" tabindex="-1"></a>utility attained by an individual is $U_j=V_j+\epsilon_j$, $j$ being</span>
<span id="cb83-578"><a href="#cb83-578" aria-hidden="true" tabindex="-1"></a>the chosen alternative. The expected utility, from the searcher's</span>
<span id="cb83-579"><a href="#cb83-579" aria-hidden="true" tabindex="-1"></a>point of view is then: $\mbox{E}(\max_j U_j)$, where the expectation</span>
<span id="cb83-580"><a href="#cb83-580" aria-hidden="true" tabindex="-1"></a>is taken over the values of all the error terms. Its expression is</span>
<span id="cb83-581"><a href="#cb83-581" aria-hidden="true" tabindex="-1"></a>simply, up to an additive unknown constant, the log of the denominator</span>
<span id="cb83-582"><a href="#cb83-582" aria-hidden="true" tabindex="-1"></a>of the logit probabilities, often called the "log-sum":\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{log-sum}</span>
<span id="cb83-583"><a href="#cb83-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-584"><a href="#cb83-584" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-585"><a href="#cb83-585" aria-hidden="true" tabindex="-1"></a>\mbox{E}(U)=\ln \sum_{j=1}^Je^{V_j}+C.</span>
<span id="cb83-586"><a href="#cb83-586" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-587"><a href="#cb83-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-588"><a href="#cb83-588" aria-hidden="true" tabindex="-1"></a>If the marginal utility of income ($\alpha$) is known and constant,</span>
<span id="cb83-589"><a href="#cb83-589" aria-hidden="true" tabindex="-1"></a>the expected surplus is simply $\frac{\mbox{E}(U)}{\alpha}$.</span>
<span id="cb83-590"><a href="#cb83-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-591"><a href="#cb83-591" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application {#sec-appl_mult_logit}</span></span>
<span id="cb83-592"><a href="#cb83-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-593"><a href="#cb83-593" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-594"><a href="#cb83-594" aria-hidden="true" tabindex="-1"></a>Random utility models are fitted using the <span class="in">`mlogit`</span></span>
<span id="cb83-595"><a href="#cb83-595" aria-hidden="true" tabindex="-1"></a>function. Basically, only two arguments are mandatory,</span>
<span id="cb83-596"><a href="#cb83-596" aria-hidden="true" tabindex="-1"></a><span class="in">`formula`</span> and <span class="in">`data`</span>, if an <span class="in">`dfidx`</span></span>
<span id="cb83-597"><a href="#cb83-597" aria-hidden="true" tabindex="-1"></a>object (and not an ordinary <span class="in">`data.frame`</span>) is provided.</span>
<span id="cb83-598"><a href="#cb83-598" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`toronto_montreal`</span> data set, which was already coerced to a</span>
<span id="cb83-599"><a href="#cb83-599" aria-hidden="true" tabindex="-1"></a><span class="in">`dfidx`</span> object (called <span class="in">`MC`</span>) in the previous section. The same model</span>
<span id="cb83-600"><a href="#cb83-600" aria-hidden="true" tabindex="-1"></a>can then be estimated using as <span class="in">`data`</span> argument this <span class="in">`dfidx`</span></span>
<span id="cb83-601"><a href="#cb83-601" aria-hidden="true" tabindex="-1"></a>object:</span>
<span id="cb83-602"><a href="#cb83-602" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}</span>
<span id="cb83-603"><a href="#cb83-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-604"><a href="#cb83-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-605"><a href="#cb83-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'multinomial logit with a dfidx'</span></span>
<span id="cb83-606"><a href="#cb83-606" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>)</span>
<span id="cb83-607"><a href="#cb83-607" aria-hidden="true" tabindex="-1"></a>ml.MC1 <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> freq <span class="sc">+</span> ovt <span class="sc">|</span> income <span class="sc">|</span> ivt, MC)</span>
<span id="cb83-608"><a href="#cb83-608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-609"><a href="#cb83-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-610"><a href="#cb83-610" aria-hidden="true" tabindex="-1"></a>or a <span class="in">`data.frame`</span>. In this latter case, further arguments that</span>
<span id="cb83-611"><a href="#cb83-611" aria-hidden="true" tabindex="-1"></a>will be passed to <span class="in">`dfidx`</span> should be indicated:</span>
<span id="cb83-612"><a href="#cb83-612" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}</span>
<span id="cb83-613"><a href="#cb83-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-614"><a href="#cb83-614" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-615"><a href="#cb83-615" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'multinomial logit with an ordinary data.frame'</span></span>
<span id="cb83-616"><a href="#cb83-616" aria-hidden="true" tabindex="-1"></a>ml.MC1b <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> freq <span class="sc">+</span> ovt <span class="sc">|</span> income <span class="sc">|</span> ivt, </span>
<span id="cb83-617"><a href="#cb83-617" aria-hidden="true" tabindex="-1"></a>                  toronto_montreal, <span class="at">subset =</span> noalt <span class="sc">==</span> <span class="dv">4</span>, </span>
<span id="cb83-618"><a href="#cb83-618" aria-hidden="true" tabindex="-1"></a>                  <span class="at">idx =</span> <span class="fu">c</span>(<span class="st">"case"</span>, <span class="st">"alt"</span>))</span>
<span id="cb83-619"><a href="#cb83-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-620"><a href="#cb83-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-621"><a href="#cb83-621" aria-hidden="true" tabindex="-1"></a><span class="in">`mlogit`</span> provides two further useful arguments:</span>
<span id="cb83-622"><a href="#cb83-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-623"><a href="#cb83-623" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`reflevel`</span> indicates which alternative is the "reference"</span>
<span id="cb83-624"><a href="#cb83-624" aria-hidden="true" tabindex="-1"></a>  alternative, i.e., the one for which the coefficients of choice</span>
<span id="cb83-625"><a href="#cb83-625" aria-hidden="true" tabindex="-1"></a>  situation-specific covariates are set to 0,</span>
<span id="cb83-626"><a href="#cb83-626" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`alt.subset`</span> indicates a subset of alternatives on</span>
<span id="cb83-627"><a href="#cb83-627" aria-hidden="true" tabindex="-1"></a>  which the estimation has to be performed; in this case, only the</span>
<span id="cb83-628"><a href="#cb83-628" aria-hidden="true" tabindex="-1"></a>  lines that correspond to the selected alternatives are used, and all</span>
<span id="cb83-629"><a href="#cb83-629" aria-hidden="true" tabindex="-1"></a>  the choice situations where unselected alternatives have been</span>
<span id="cb83-630"><a href="#cb83-630" aria-hidden="true" tabindex="-1"></a>  chosen are removed.</span>
<span id="cb83-631"><a href="#cb83-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-632"><a href="#cb83-632" aria-hidden="true" tabindex="-1"></a>We estimate the model on the subset of three alternatives (we exclude</span>
<span id="cb83-633"><a href="#cb83-633" aria-hidden="true" tabindex="-1"></a><span class="in">`bus`</span> whose market share is negligible in our sample) and we set</span>
<span id="cb83-634"><a href="#cb83-634" aria-hidden="true" tabindex="-1"></a><span class="in">`car`</span> as the reference alternative. Moreover, we use a total</span>
<span id="cb83-635"><a href="#cb83-635" aria-hidden="true" tabindex="-1"></a>transport time variable computed as the sum of the in-vehicle and</span>
<span id="cb83-636"><a href="#cb83-636" aria-hidden="true" tabindex="-1"></a>out-vehicle time variables.</span>
<span id="cb83-637"><a href="#cb83-637" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{mlogit}{mlogit}</span>
<span id="cb83-638"><a href="#cb83-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-639"><a href="#cb83-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-640"><a href="#cb83-640" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'estimation on a subset of alternatives'</span></span>
<span id="cb83-641"><a href="#cb83-641" aria-hidden="true" tabindex="-1"></a>MC <span class="ot">&lt;-</span> MC <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">time =</span> ivt <span class="sc">+</span> ovt)</span>
<span id="cb83-642"><a href="#cb83-642" aria-hidden="true" tabindex="-1"></a>ml.MC1 <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> cost <span class="sc">+</span> freq <span class="sc">|</span> income <span class="sc">|</span> time, MC, </span>
<span id="cb83-643"><a href="#cb83-643" aria-hidden="true" tabindex="-1"></a>                 <span class="at">alt.subset =</span> <span class="fu">c</span>(<span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span>), <span class="at">reflevel =</span> <span class="st">"car"</span>)</span>
<span id="cb83-644"><a href="#cb83-644" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-645"><a href="#cb83-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-646"><a href="#cb83-646" aria-hidden="true" tabindex="-1"></a>The main results of the model are computed and displayed using the</span>
<span id="cb83-647"><a href="#cb83-647" aria-hidden="true" tabindex="-1"></a> <span class="in">`summary`</span> method:</span>
<span id="cb83-648"><a href="#cb83-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-649"><a href="#cb83-649" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-650"><a href="#cb83-650" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'summary method for mlogit'</span></span>
<span id="cb83-651"><a href="#cb83-651" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ml.MC1)</span>
<span id="cb83-652"><a href="#cb83-652" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-653"><a href="#cb83-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-654"><a href="#cb83-654" aria-hidden="true" tabindex="-1"></a>The frequencies of the different alternatives in the sample are first</span>
<span id="cb83-655"><a href="#cb83-655" aria-hidden="true" tabindex="-1"></a>indicated. Next, some information about the optimization is</span>
<span id="cb83-656"><a href="#cb83-656" aria-hidden="true" tabindex="-1"></a>displayed: the Newton-Raphson method (with analytical gradient and</span>
<span id="cb83-657"><a href="#cb83-657" aria-hidden="true" tabindex="-1"></a>hessian) is used, as it is the most efficient method for this simple</span>
<span id="cb83-658"><a href="#cb83-658" aria-hidden="true" tabindex="-1"></a>model for which the log-likelihood function is globally concave. Note that very</span>
<span id="cb83-659"><a href="#cb83-659" aria-hidden="true" tabindex="-1"></a>few iterations and computing times are required to estimate this</span>
<span id="cb83-660"><a href="#cb83-660" aria-hidden="true" tabindex="-1"></a>model. Then the usual table of coefficients is displayed, followed by</span>
<span id="cb83-661"><a href="#cb83-661" aria-hidden="true" tabindex="-1"></a>some goodness-of-fit measures: the value of the log-likelihood</span>
<span id="cb83-662"><a href="#cb83-662" aria-hidden="true" tabindex="-1"></a>function, which is compared to the value when only intercepts are</span>
<span id="cb83-663"><a href="#cb83-663" aria-hidden="true" tabindex="-1"></a>introduced, which leads to the computation of the McFadden $R^2$ and</span>
<span id="cb83-664"><a href="#cb83-664" aria-hidden="true" tabindex="-1"></a>to the likelihood ratio test.</span>
<span id="cb83-665"><a href="#cb83-665" aria-hidden="true" tabindex="-1"></a>The <span class="in">`fitted`</span> method can be used either to obtain the probability</span>
<span id="cb83-666"><a href="#cb83-666" aria-hidden="true" tabindex="-1"></a>of actual choices (<span class="in">`type = "outcome"`</span>) or the probabilities for</span>
<span id="cb83-667"><a href="#cb83-667" aria-hidden="true" tabindex="-1"></a>all the alternatives (<span class="in">`type = "probabilities"`</span>).</span>
<span id="cb83-668"><a href="#cb83-668" aria-hidden="true" tabindex="-1"></a>\idxfun{fitted}{stats}\idxfun{head}{utils}</span>
<span id="cb83-669"><a href="#cb83-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-670"><a href="#cb83-670" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-671"><a href="#cb83-671" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'fitted method for mlogit'</span></span>
<span id="cb83-672"><a href="#cb83-672" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">fitted</span>(ml.MC1, <span class="at">type =</span> <span class="st">"outcome"</span>))</span>
<span id="cb83-673"><a href="#cb83-673" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">fitted</span>(ml.MC1, <span class="at">type =</span> <span class="st">"probabilities"</span>), <span class="dv">4</span>)</span>
<span id="cb83-674"><a href="#cb83-674" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-675"><a href="#cb83-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-676"><a href="#cb83-676" aria-hidden="true" tabindex="-1"></a>Note that the log-likelihood is the sum of the log of the fitted</span>
<span id="cb83-677"><a href="#cb83-677" aria-hidden="true" tabindex="-1"></a>outcome probabilities and that, as the model contains intercepts, the</span>
<span id="cb83-678"><a href="#cb83-678" aria-hidden="true" tabindex="-1"></a>average fitted probabilities for every alternative equals the market</span>
<span id="cb83-679"><a href="#cb83-679" aria-hidden="true" tabindex="-1"></a>shares of the alternatives in the sample.</span>
<span id="cb83-680"><a href="#cb83-680" aria-hidden="true" tabindex="-1"></a>\idxfun{fitted}{stats}\idxfun{logLik}{stats}\idxfun{apply}{base}</span>
<span id="cb83-681"><a href="#cb83-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-682"><a href="#cb83-682" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-683"><a href="#cb83-683" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'computation of the log likelihood and the market shares'</span></span>
<span id="cb83-684"><a href="#cb83-684" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-685"><a href="#cb83-685" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">fitted</span>(ml.MC1, <span class="at">type =</span> <span class="st">"outcome"</span>)))</span>
<span id="cb83-686"><a href="#cb83-686" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(ml.MC1)</span>
<span id="cb83-687"><a href="#cb83-687" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(<span class="fu">fitted</span>(ml.MC1, <span class="at">type =</span> <span class="st">"probabilities"</span>), <span class="dv">2</span>, mean)</span>
<span id="cb83-688"><a href="#cb83-688" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-689"><a href="#cb83-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-690"><a href="#cb83-690" aria-hidden="true" tabindex="-1"></a>Predictions can be made using the <span class="in">`predict`</span> method. If no data is</span>
<span id="cb83-691"><a href="#cb83-691" aria-hidden="true" tabindex="-1"></a>provided, predictions are made for the sample mean values of the</span>
<span id="cb83-692"><a href="#cb83-692" aria-hidden="true" tabindex="-1"></a>covariates.</span>
<span id="cb83-693"><a href="#cb83-693" aria-hidden="true" tabindex="-1"></a>\idxfun{predict}{stats}</span>
<span id="cb83-694"><a href="#cb83-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-695"><a href="#cb83-695" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-696"><a href="#cb83-696" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'default behaviour of the predict method'</span></span>
<span id="cb83-697"><a href="#cb83-697" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-698"><a href="#cb83-698" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(ml.MC1)</span>
<span id="cb83-699"><a href="#cb83-699" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-700"><a href="#cb83-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-701"><a href="#cb83-701" aria-hidden="true" tabindex="-1"></a>Assume, for example, that we wish to predict the effect of a reduction</span>
<span id="cb83-702"><a href="#cb83-702" aria-hidden="true" tabindex="-1"></a>of train transport time of 20\%. We first create a new</span>
<span id="cb83-703"><a href="#cb83-703" aria-hidden="true" tabindex="-1"></a><span class="in">`data.frame`</span> simply by multiplying train transport time by 0.8</span>
<span id="cb83-704"><a href="#cb83-704" aria-hidden="true" tabindex="-1"></a>and then using the <span class="in">`predict`</span> method with this new</span>
<span id="cb83-705"><a href="#cb83-705" aria-hidden="true" tabindex="-1"></a><span class="in">`data.frame`</span>.</span>
<span id="cb83-706"><a href="#cb83-706" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{ifelse}{base}\idxfun{fitted}{stats}\idxfun{predict}{stats}</span>
<span id="cb83-707"><a href="#cb83-707" aria-hidden="true" tabindex="-1"></a>\idxfun{rbind}{base}\idxfun{apply}{base}</span>
<span id="cb83-708"><a href="#cb83-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-709"><a href="#cb83-709" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-710"><a href="#cb83-710" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'predicting with different data'</span></span>
<span id="cb83-711"><a href="#cb83-711" aria-hidden="true" tabindex="-1"></a>NMC <span class="ot">&lt;-</span> MC</span>
<span id="cb83-712"><a href="#cb83-712" aria-hidden="true" tabindex="-1"></a>NMC <span class="ot">&lt;-</span> NMC <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">time =</span> <span class="fu">ifelse</span>(idx<span class="sc">$</span>alt <span class="sc">==</span> <span class="st">"train"</span>, <span class="fl">0.8</span> <span class="sc">*</span> time, time))</span>
<span id="cb83-713"><a href="#cb83-713" aria-hidden="true" tabindex="-1"></a>Oprob <span class="ot">&lt;-</span> <span class="fu">fitted</span>(ml.MC1, <span class="at">type =</span> <span class="st">"probabilities"</span>)</span>
<span id="cb83-714"><a href="#cb83-714" aria-hidden="true" tabindex="-1"></a>Nprob <span class="ot">&lt;-</span> <span class="fu">predict</span>(ml.MC1, <span class="at">newdata =</span> NMC)</span>
<span id="cb83-715"><a href="#cb83-715" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(<span class="at">old =</span> <span class="fu">apply</span>(Oprob, <span class="dv">2</span>, mean), <span class="at">new =</span> <span class="fu">apply</span>(Nprob, <span class="dv">2</span>, mean))</span>
<span id="cb83-716"><a href="#cb83-716" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-717"><a href="#cb83-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-718"><a href="#cb83-718" aria-hidden="true" tabindex="-1"></a>If, for the first individuals in the sample, we compute the ratio of</span>
<span id="cb83-719"><a href="#cb83-719" aria-hidden="true" tabindex="-1"></a>the probabilities of the air and the car mode, we obtain:</span>
<span id="cb83-720"><a href="#cb83-720" aria-hidden="true" tabindex="-1"></a>\idxfun{head}{utils}</span>
<span id="cb83-721"><a href="#cb83-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-722"><a href="#cb83-722" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-723"><a href="#cb83-723" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'illustration of the IIA property'</span></span>
<span id="cb83-724"><a href="#cb83-724" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-725"><a href="#cb83-725" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Nprob[, <span class="st">"air"</span>] <span class="sc">/</span> Nprob[, <span class="st">"car"</span>])</span>
<span id="cb83-726"><a href="#cb83-726" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Oprob[, <span class="st">"air"</span>] <span class="sc">/</span> Oprob[, <span class="st">"car"</span>])</span>
<span id="cb83-727"><a href="#cb83-727" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-728"><a href="#cb83-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-729"><a href="#cb83-729" aria-hidden="true" tabindex="-1"></a>which is an illustration of the IIA property.</span>
<span id="cb83-730"><a href="#cb83-730" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{independence of irrelevant alternatives hypothesis} </span>
<span id="cb83-731"><a href="#cb83-731" aria-hidden="true" tabindex="-1"></a>If train time changes,</span>
<span id="cb83-732"><a href="#cb83-732" aria-hidden="true" tabindex="-1"></a>it changes the probabilities of choosing air and car, but not their</span>
<span id="cb83-733"><a href="#cb83-733" aria-hidden="true" tabindex="-1"></a>ratio.</span>
<span id="cb83-734"><a href="#cb83-734" aria-hidden="true" tabindex="-1"></a>We next compute the surplus for individuals of the sample induced by</span>
<span id="cb83-735"><a href="#cb83-735" aria-hidden="true" tabindex="-1"></a>train time reduction. This requires the computation of the log-sum</span>
<span id="cb83-736"><a href="#cb83-736" aria-hidden="true" tabindex="-1"></a>term (also called inclusive value or inclusive utility) for every</span>
<span id="cb83-737"><a href="#cb83-737" aria-hidden="true" tabindex="-1"></a>choice situation, which is:</span>
<span id="cb83-738"><a href="#cb83-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-739"><a href="#cb83-739" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-740"><a href="#cb83-740" aria-hidden="true" tabindex="-1"></a>\mbox{iv}_n = \ln \sum_{j = 1} ^ J e^{\beta^\top x_{nj}}.</span>
<span id="cb83-741"><a href="#cb83-741" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-742"><a href="#cb83-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-743"><a href="#cb83-743" aria-hidden="true" tabindex="-1"></a>For this purpose, we use the <span class="in">`logsum`</span> function, which works on a</span>
<span id="cb83-744"><a href="#cb83-744" aria-hidden="true" tabindex="-1"></a>vector of coefficients and a model matrix. The basic use</span>
<span id="cb83-745"><a href="#cb83-745" aria-hidden="true" tabindex="-1"></a>of <span class="in">`logsum`</span> consists of providing as unique argument (called</span>
<span id="cb83-746"><a href="#cb83-746" aria-hidden="true" tabindex="-1"></a><span class="in">`coef`</span>) a <span class="in">`mlogit`</span> object. In this case, the</span>
<span id="cb83-747"><a href="#cb83-747" aria-hidden="true" tabindex="-1"></a><span class="in">`model.matrix`</span> and the <span class="in">`coef`</span> are extracted from the same</span>
<span id="cb83-748"><a href="#cb83-748" aria-hidden="true" tabindex="-1"></a>model:</span>
<span id="cb83-749"><a href="#cb83-749" aria-hidden="true" tabindex="-1"></a>\idxfun{logsum}{mlogit}</span>
<span id="cb83-750"><a href="#cb83-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-751"><a href="#cb83-751" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-752"><a href="#cb83-752" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'computation of the initital logsum'</span></span>
<span id="cb83-753"><a href="#cb83-753" aria-hidden="true" tabindex="-1"></a>ivbefore <span class="ot">&lt;-</span> <span class="fu">logsum</span>(ml.MC1)</span>
<span id="cb83-754"><a href="#cb83-754" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-755"><a href="#cb83-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-756"><a href="#cb83-756" aria-hidden="true" tabindex="-1"></a>To compute the log-sum after train time reduction, we must provide a</span>
<span id="cb83-757"><a href="#cb83-757" aria-hidden="true" tabindex="-1"></a>model matrix which is not the one corresponding to the fitted</span>
<span id="cb83-758"><a href="#cb83-758" aria-hidden="true" tabindex="-1"></a>model. This can be done using the <span class="in">`X`</span> argument which is a matrix or an</span>
<span id="cb83-759"><a href="#cb83-759" aria-hidden="true" tabindex="-1"></a>object from which a  model matrix  can be extracted. This can also be</span>
<span id="cb83-760"><a href="#cb83-760" aria-hidden="true" tabindex="-1"></a>done by filling the <span class="in">`data`</span> argument (a data frame or an object from</span>
<span id="cb83-761"><a href="#cb83-761" aria-hidden="true" tabindex="-1"></a>which a data frame can be extracted using <span class="in">`model.frame`</span>),</span>
<span id="cb83-762"><a href="#cb83-762" aria-hidden="true" tabindex="-1"></a>and eventually the <span class="in">`formula`</span> argument (a formula or an object for</span>
<span id="cb83-763"><a href="#cb83-763" aria-hidden="true" tabindex="-1"></a>which the <span class="in">`formula`</span> method can be applied). If no formula is provided,</span>
<span id="cb83-764"><a href="#cb83-764" aria-hidden="true" tabindex="-1"></a>but if <span class="in">`data`</span> is a <span class="in">`dfidx`</span> object, the formula is extracted from</span>
<span id="cb83-765"><a href="#cb83-765" aria-hidden="true" tabindex="-1"></a>it.</span>
<span id="cb83-766"><a href="#cb83-766" aria-hidden="true" tabindex="-1"></a>\idxfun{logsum}{mlogit}</span>
<span id="cb83-767"><a href="#cb83-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-768"><a href="#cb83-768" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-769"><a href="#cb83-769" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'computation of the after change logsum'</span></span>
<span id="cb83-770"><a href="#cb83-770" aria-hidden="true" tabindex="-1"></a>ivafter <span class="ot">&lt;-</span> <span class="fu">logsum</span>(ml.MC1, <span class="at">data =</span> NMC)</span>
<span id="cb83-771"><a href="#cb83-771" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-772"><a href="#cb83-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-773"><a href="#cb83-773" aria-hidden="true" tabindex="-1"></a>Surplus variation is then computed as the difference of the log-sums</span>
<span id="cb83-774"><a href="#cb83-774" aria-hidden="true" tabindex="-1"></a>divided by the opposite of the cost coefficient which can be</span>
<span id="cb83-775"><a href="#cb83-775" aria-hidden="true" tabindex="-1"></a>interpreted as the marginal utility of income:</span>
<span id="cb83-776"><a href="#cb83-776" aria-hidden="true" tabindex="-1"></a>\idxfun{coef}{stats}</span>
<span id="cb83-777"><a href="#cb83-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-778"><a href="#cb83-778" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-779"><a href="#cb83-779" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'computation of consumers surplus'</span></span>
<span id="cb83-780"><a href="#cb83-780" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-781"><a href="#cb83-781" aria-hidden="true" tabindex="-1"></a>surplus <span class="ot">&lt;-</span> <span class="sc">-</span> (ivafter <span class="sc">-</span> ivbefore) <span class="sc">/</span> <span class="fu">coef</span>(ml.MC1)[<span class="st">"cost"</span>]</span>
<span id="cb83-782"><a href="#cb83-782" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(surplus)</span>
<span id="cb83-783"><a href="#cb83-783" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-784"><a href="#cb83-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-785"><a href="#cb83-785" aria-hidden="true" tabindex="-1"></a>Consumer surplus variations range from 0.6 to 31 Canadian dollars, with a</span>
<span id="cb83-786"><a href="#cb83-786" aria-hidden="true" tabindex="-1"></a>median value of about $4.</span>
<span id="cb83-787"><a href="#cb83-787" aria-hidden="true" tabindex="-1"></a>Marginal effects are computed using the <span class="in">`effects`</span> method. By default,</span>
<span id="cb83-788"><a href="#cb83-788" aria-hidden="true" tabindex="-1"></a>they are computed at the sample mean, but a <span class="in">`data`</span> argument can be</span>
<span id="cb83-789"><a href="#cb83-789" aria-hidden="true" tabindex="-1"></a>provided. The variation of the probability and the covariate can be</span>
<span id="cb83-790"><a href="#cb83-790" aria-hidden="true" tabindex="-1"></a>either absolute or relative. This is indicated with the <span class="in">`type`</span></span>
<span id="cb83-791"><a href="#cb83-791" aria-hidden="true" tabindex="-1"></a>argument which is a combination of two <span class="in">`a`</span> (as absolute) and <span class="in">`r`</span> (as</span>
<span id="cb83-792"><a href="#cb83-792" aria-hidden="true" tabindex="-1"></a>relative) characters. For example, <span class="in">`type = "ar"`</span> means that what is</span>
<span id="cb83-793"><a href="#cb83-793" aria-hidden="true" tabindex="-1"></a>measured is an absolute variation of the probability for a relative</span>
<span id="cb83-794"><a href="#cb83-794" aria-hidden="true" tabindex="-1"></a>variation of the covariate.</span>
<span id="cb83-795"><a href="#cb83-795" aria-hidden="true" tabindex="-1"></a>\idxfun{effects}{stats}</span>
<span id="cb83-796"><a href="#cb83-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-797"><a href="#cb83-797" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-798"><a href="#cb83-798" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'marginal effects for an individual specific covariate'</span></span>
<span id="cb83-799"><a href="#cb83-799" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-800"><a href="#cb83-800" aria-hidden="true" tabindex="-1"></a><span class="fu">effects</span>(ml.MC1, <span class="at">covariate =</span> <span class="st">"income"</span>, <span class="at">type =</span> <span class="st">"ar"</span>)</span>
<span id="cb83-801"><a href="#cb83-801" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-802"><a href="#cb83-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-803"><a href="#cb83-803" aria-hidden="true" tabindex="-1"></a>The results indicate that, for a 100\% increase of income, the</span>
<span id="cb83-804"><a href="#cb83-804" aria-hidden="true" tabindex="-1"></a>probability of choosing <span class="in">`air`</span> increases by 33 percentage points, as</span>
<span id="cb83-805"><a href="#cb83-805" aria-hidden="true" tabindex="-1"></a>the probabilities of choosing <span class="in">`car`</span> and <span class="in">`train`</span> decrease by 18 and 15</span>
<span id="cb83-806"><a href="#cb83-806" aria-hidden="true" tabindex="-1"></a>percentage points.</span>
<span id="cb83-807"><a href="#cb83-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-808"><a href="#cb83-808" aria-hidden="true" tabindex="-1"></a>For an alternative specific covariate, a matrix of marginal effects is</span>
<span id="cb83-809"><a href="#cb83-809" aria-hidden="true" tabindex="-1"></a>displayed.</span>
<span id="cb83-810"><a href="#cb83-810" aria-hidden="true" tabindex="-1"></a>\idxfun{effects}{stats}</span>
<span id="cb83-811"><a href="#cb83-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-812"><a href="#cb83-812" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-813"><a href="#cb83-813" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'marginal effects for an alternative specific covariate'</span></span>
<span id="cb83-814"><a href="#cb83-814" aria-hidden="true" tabindex="-1"></a><span class="fu">effects</span>(ml.MC1, <span class="at">covariate =</span> <span class="st">"cost"</span>, <span class="at">type =</span> <span class="st">"rr"</span>)</span>
<span id="cb83-815"><a href="#cb83-815" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-816"><a href="#cb83-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-817"><a href="#cb83-817" aria-hidden="true" tabindex="-1"></a>The cell in the $l^{\mbox{th}}$ row and the $c^{\mbox{th}}$ column</span>
<span id="cb83-818"><a href="#cb83-818" aria-hidden="true" tabindex="-1"></a>indicates the change of the probability of choosing alternative $c$</span>
<span id="cb83-819"><a href="#cb83-819" aria-hidden="true" tabindex="-1"></a>when the cost of alternative $l$ changes. As <span class="in">`type = "rr"`</span>,</span>
<span id="cb83-820"><a href="#cb83-820" aria-hidden="true" tabindex="-1"></a>elasticities are computed. For example, a 10\% change of train cost</span>
<span id="cb83-821"><a href="#cb83-821" aria-hidden="true" tabindex="-1"></a>increases the probabilities of choosing car and air by 3.36\%. Note</span>
<span id="cb83-822"><a href="#cb83-822" aria-hidden="true" tabindex="-1"></a>that the relative changes of the probabilities of choosing one of</span>
<span id="cb83-823"><a href="#cb83-823" aria-hidden="true" tabindex="-1"></a>these two modes are equal, which is a consequence of the IIA property.</span>
<span id="cb83-824"><a href="#cb83-824" aria-hidden="true" tabindex="-1"></a>Finally, in order to compute travel time valuation, we divide the</span>
<span id="cb83-825"><a href="#cb83-825" aria-hidden="true" tabindex="-1"></a>coefficients of travel times (in minutes) by the coefficient of</span>
<span id="cb83-826"><a href="#cb83-826" aria-hidden="true" tabindex="-1"></a>monetary cost (in dollars).</span>
<span id="cb83-827"><a href="#cb83-827" aria-hidden="true" tabindex="-1"></a>\idxfun{coef}{stats}\idxfun{names}{base}</span>
<span id="cb83-828"><a href="#cb83-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-829"><a href="#cb83-829" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-830"><a href="#cb83-830" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'computation of the marginal rate of substitution'</span></span>
<span id="cb83-831"><a href="#cb83-831" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-832"><a href="#cb83-832" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(ml.MC1)[<span class="fu">grep</span>(<span class="st">"time"</span>, <span class="fu">names</span>(<span class="fu">coef</span>(ml.MC1)))] <span class="sc">/</span></span>
<span id="cb83-833"><a href="#cb83-833" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coef</span>(ml.MC1)[<span class="st">"cost"</span>] <span class="sc">*</span> <span class="dv">60</span></span>
<span id="cb83-834"><a href="#cb83-834" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-835"><a href="#cb83-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-836"><a href="#cb83-836" aria-hidden="true" tabindex="-1"></a>The value of travel time ranges from 23 for a train to 37 Canadian dollars</span>
<span id="cb83-837"><a href="#cb83-837" aria-hidden="true" tabindex="-1"></a>per hour for a plane.</span>
<span id="cb83-838"><a href="#cb83-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-839"><a href="#cb83-839" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-840"><a href="#cb83-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-841"><a href="#cb83-841" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logit models relaxing the iid hypothesis {#sec-relaxing_iid}</span></span>
<span id="cb83-842"><a href="#cb83-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-843"><a href="#cb83-843" aria-hidden="true" tabindex="-1"></a>In the previous section, we assumed that the error terms were iid</span>
<span id="cb83-844"><a href="#cb83-844" aria-hidden="true" tabindex="-1"></a>(identically and independently distributed), i.e., uncorrelated and</span>
<span id="cb83-845"><a href="#cb83-845" aria-hidden="true" tabindex="-1"></a>homoskedastic. Extensions of the basic multinomial logit model have</span>
<span id="cb83-846"><a href="#cb83-846" aria-hidden="true" tabindex="-1"></a>been proposed by relaxing one of these two hypotheses while</span>
<span id="cb83-847"><a href="#cb83-847" aria-hidden="true" tabindex="-1"></a>maintaining the hypothesis of a Gumbel distribution.</span>
<span id="cb83-848"><a href="#cb83-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-849"><a href="#cb83-849" aria-hidden="true" tabindex="-1"></a><span class="fu">### Heteroskedastic logit model</span></span>
<span id="cb83-850"><a href="#cb83-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-851"><a href="#cb83-851" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heteroskedasticity!random utility model|(}</span>
<span id="cb83-852"><a href="#cb83-852" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heteroskedastic logit model|(}</span>
<span id="cb83-853"><a href="#cb83-853" aria-hidden="true" tabindex="-1"></a>The heteroskedastic logit model was proposed by @BHAT:95\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Bhat}.  The</span>
<span id="cb83-854"><a href="#cb83-854" aria-hidden="true" tabindex="-1"></a>probability that $U_l&gt;U_j$ is:</span>
<span id="cb83-855"><a href="#cb83-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-856"><a href="#cb83-856" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-857"><a href="#cb83-857" aria-hidden="true" tabindex="-1"></a>P(\epsilon_j&lt;V_l-V_j+\epsilon_l)=e^{-e^{-\frac{(V_l-V_j+\epsilon_l)}{\theta_j}}},</span>
<span id="cb83-858"><a href="#cb83-858" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-859"><a href="#cb83-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-860"><a href="#cb83-860" aria-hidden="true" tabindex="-1"></a>which implies the following conditional and unconditional</span>
<span id="cb83-861"><a href="#cb83-861" aria-hidden="true" tabindex="-1"></a>probabilities</span>
<span id="cb83-862"><a href="#cb83-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-863"><a href="#cb83-863" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-864"><a href="#cb83-864" aria-hidden="true" tabindex="-1"></a>  (P_l \mid \epsilon_l) =\prod_{j\neq</span>
<span id="cb83-865"><a href="#cb83-865" aria-hidden="true" tabindex="-1"></a>    l}e^{-e^{-\frac{(V_l-V_j+\epsilon_l)}{\theta_j}}},</span>
<span id="cb83-866"><a href="#cb83-866" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-867"><a href="#cb83-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-868"><a href="#cb83-868" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-869"><a href="#cb83-869" aria-hidden="true" tabindex="-1"></a>  \begin{array}{rcl}</span>
<span id="cb83-870"><a href="#cb83-870" aria-hidden="true" tabindex="-1"></a>  P_l&amp;=&amp;\displaystyle\int_{-\infty}^{+\infty} \prod_{j\neq l}</span>
<span id="cb83-871"><a href="#cb83-871" aria-hidden="true" tabindex="-1"></a>  \left(e^{-e^{-\frac{(V_l-V_j+t)}{\theta_j}}}\right)\frac{1}{\theta_l}e^{-\frac{t}{\theta_l}}e^{-e^{-\frac{t}{\theta_l}}}</span>
<span id="cb83-872"><a href="#cb83-872" aria-hidden="true" tabindex="-1"></a>  dt<span class="sc">\\</span></span>
<span id="cb83-873"><a href="#cb83-873" aria-hidden="true" tabindex="-1"></a> &amp;=&amp; \displaystyle \int_{0}^{+\infty}\left(e^{-\sum_{j \neq</span>
<span id="cb83-874"><a href="#cb83-874" aria-hidden="true" tabindex="-1"></a>      l}e^{-\frac{V_l-V_j-\theta_l \ln t}{\theta_j}}}\right)e^{-t}dt.</span>
<span id="cb83-875"><a href="#cb83-875" aria-hidden="true" tabindex="-1"></a>     \end{array}</span>
<span id="cb83-876"><a href="#cb83-876" aria-hidden="true" tabindex="-1"></a>$$ {#eq-prob_heterosc_logit}</span>
<span id="cb83-877"><a href="#cb83-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-878"><a href="#cb83-878" aria-hidden="true" tabindex="-1"></a>There is no closed form for this integral, but it can be efficiently</span>
<span id="cb83-879"><a href="#cb83-879" aria-hidden="true" tabindex="-1"></a>computed using a Gauss quadrature method, and more precisely the</span>
<span id="cb83-880"><a href="#cb83-880" aria-hidden="true" tabindex="-1"></a>Gauss-Laguerre quadrature method.</span>
<span id="cb83-881"><a href="#cb83-881" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heteroskedasticity!random utility model|(}</span>
<span id="cb83-882"><a href="#cb83-882" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{heteroskedastic logit model|(}</span>
<span id="cb83-883"><a href="#cb83-883" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{gaussian quadrature}</span>
<span id="cb83-884"><a href="#cb83-884" aria-hidden="true" tabindex="-1"></a>@BHAT:95\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Bhat} estimated the heteroskedastic logit model on the</span>
<span id="cb83-885"><a href="#cb83-885" aria-hidden="true" tabindex="-1"></a><span class="in">`toronto_montreal`</span> data set. Using <span class="in">`mlogit`</span>, the heteroskedastic</span>
<span id="cb83-886"><a href="#cb83-886" aria-hidden="true" tabindex="-1"></a>logit model is obtained by setting the <span class="in">`heterosc`</span> argument</span>
<span id="cb83-887"><a href="#cb83-887" aria-hidden="true" tabindex="-1"></a>to <span class="in">`TRUE`</span>:</span>
<span id="cb83-888"><a href="#cb83-888" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-889"><a href="#cb83-889" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}\idxfun{gaze}{micsr}</span>
<span id="cb83-890"><a href="#cb83-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-891"><a href="#cb83-891" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-892"><a href="#cb83-892" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'heteroscedastic model for the ModeCanada data'</span></span>
<span id="cb83-893"><a href="#cb83-893" aria-hidden="true" tabindex="-1"></a>ml.MC <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> freq <span class="sc">+</span> cost <span class="sc">+</span> ivt <span class="sc">+</span> ovt <span class="sc">|</span> </span>
<span id="cb83-894"><a href="#cb83-894" aria-hidden="true" tabindex="-1"></a>                  urban <span class="sc">+</span> income, MC, <span class="at">reflevel =</span> <span class="st">'car'</span>, </span>
<span id="cb83-895"><a href="#cb83-895" aria-hidden="true" tabindex="-1"></a>                <span class="at">alt.subset =</span> <span class="fu">c</span>(<span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span>))</span>
<span id="cb83-896"><a href="#cb83-896" aria-hidden="true" tabindex="-1"></a>hl.MC <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> freq <span class="sc">+</span> cost <span class="sc">+</span> ivt <span class="sc">+</span> ovt <span class="sc">|</span> </span>
<span id="cb83-897"><a href="#cb83-897" aria-hidden="true" tabindex="-1"></a>                  urban <span class="sc">+</span> income, MC, <span class="at">reflevel =</span> <span class="st">'car'</span>, </span>
<span id="cb83-898"><a href="#cb83-898" aria-hidden="true" tabindex="-1"></a>                <span class="at">alt.subset =</span> <span class="fu">c</span>(<span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span>), </span>
<span id="cb83-899"><a href="#cb83-899" aria-hidden="true" tabindex="-1"></a>                <span class="at">heterosc =</span> <span class="cn">TRUE</span>)</span>
<span id="cb83-900"><a href="#cb83-900" aria-hidden="true" tabindex="-1"></a>hl.MC <span class="sc">%&gt;%</span> <span class="fu">gaze</span>(<span class="at">coef =</span> <span class="dv">11</span><span class="sc">:</span><span class="dv">12</span>)</span>
<span id="cb83-901"><a href="#cb83-901" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-902"><a href="#cb83-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-903"><a href="#cb83-903" aria-hidden="true" tabindex="-1"></a>Two supplementary coefficients (<span class="in">`sp.train`</span> and <span class="in">`sp.air`</span>) are estimated ($\theta_j$ in @eq-prob_heterosc_logit), the third for the reference modality being set to 1.</span>
<span id="cb83-904"><a href="#cb83-904" aria-hidden="true" tabindex="-1"></a>The variance of the error terms of train and air are respectively</span>
<span id="cb83-905"><a href="#cb83-905" aria-hidden="true" tabindex="-1"></a>higher and lower than the variance of the error term of car (set to</span>
<span id="cb83-906"><a href="#cb83-906" aria-hidden="true" tabindex="-1"></a>1). Note that the z-values and p-values of the output are not</span>
<span id="cb83-907"><a href="#cb83-907" aria-hidden="true" tabindex="-1"></a>particularly meaningful, as the hypothesis that the coefficient is</span>
<span id="cb83-908"><a href="#cb83-908" aria-hidden="true" tabindex="-1"></a>zero (and not 1) is tested.  The homoskedasticity hypothesis can be</span>
<span id="cb83-909"><a href="#cb83-909" aria-hidden="true" tabindex="-1"></a>tested using any of the three tests. For the likelihood ratio and the Wald test,</span>
<span id="cb83-910"><a href="#cb83-910" aria-hidden="true" tabindex="-1"></a>one can use only the fitted heteroskedastic model as argument. In this</span>
<span id="cb83-911"><a href="#cb83-911" aria-hidden="true" tabindex="-1"></a>case, it is guessed that the hypothesis that the user wants to test is</span>
<span id="cb83-912"><a href="#cb83-912" aria-hidden="true" tabindex="-1"></a>the homoskedasticity hypothesis.</span>
<span id="cb83-913"><a href="#cb83-913" aria-hidden="true" tabindex="-1"></a>\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}\idxfun{gaze}{micsr}</span>
<span id="cb83-914"><a href="#cb83-914" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{likelihood ratio test!heteroskedastic logit model}</span>
<span id="cb83-915"><a href="#cb83-915" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Wald test!heteroskedastic logit model}</span>
<span id="cb83-916"><a href="#cb83-916" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-917"><a href="#cb83-917" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'homoscedasticity tests: lr and Wald (1)'</span></span>
<span id="cb83-918"><a href="#cb83-918" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-919"><a href="#cb83-919" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(hl.MC, ml.MC) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-920"><a href="#cb83-920" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(hl.MC, <span class="at">heterosc =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-921"><a href="#cb83-921" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-922"><a href="#cb83-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-923"><a href="#cb83-923" aria-hidden="true" tabindex="-1"></a>or, more simply:</span>
<span id="cb83-924"><a href="#cb83-924" aria-hidden="true" tabindex="-1"></a>\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}</span>
<span id="cb83-925"><a href="#cb83-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-926"><a href="#cb83-926" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-927"><a href="#cb83-927" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'homoscedasticity tests: lr and Wald (2)'</span></span>
<span id="cb83-928"><a href="#cb83-928" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: 'hide'</span></span>
<span id="cb83-929"><a href="#cb83-929" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(hl.MC)</span>
<span id="cb83-930"><a href="#cb83-930" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(hl.MC)</span>
<span id="cb83-931"><a href="#cb83-931" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-932"><a href="#cb83-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-933"><a href="#cb83-933" aria-hidden="true" tabindex="-1"></a>The Wald test can also be computed using the <span class="in">`linearHypothesis`</span></span>
<span id="cb83-934"><a href="#cb83-934" aria-hidden="true" tabindex="-1"></a>function from the <span class="in">`car`</span> package:</span>
<span id="cb83-935"><a href="#cb83-935" aria-hidden="true" tabindex="-1"></a>\idxfun{linearHypothesis}{car}\idxfun{gaze}{micsr}</span>
<span id="cb83-936"><a href="#cb83-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-937"><a href="#cb83-937" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-938"><a href="#cb83-938" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'homoscedasticity tests: Wald test'</span></span>
<span id="cb83-939"><a href="#cb83-939" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-940"><a href="#cb83-940" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(hl.MC, <span class="fu">c</span>(<span class="st">'sp.air = 1'</span>, <span class="st">'sp.train = 1'</span>)) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-941"><a href="#cb83-941" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-942"><a href="#cb83-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-943"><a href="#cb83-943" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{score test!heteroskedastic logit model}</span>
<span id="cb83-944"><a href="#cb83-944" aria-hidden="true" tabindex="-1"></a>For the score test, we provide the constrained model as argument,</span>
<span id="cb83-945"><a href="#cb83-945" aria-hidden="true" tabindex="-1"></a>which is the standard multinomial logit model and the supplementary</span>
<span id="cb83-946"><a href="#cb83-946" aria-hidden="true" tabindex="-1"></a>argument which defines the unconstrained model, which is in this case</span>
<span id="cb83-947"><a href="#cb83-947" aria-hidden="true" tabindex="-1"></a><span class="in">`heterosc = TRUE`</span>.</span>
<span id="cb83-948"><a href="#cb83-948" aria-hidden="true" tabindex="-1"></a>\idxfun{scoretest}{mlogit}\idxfun{gaze}{micsr}</span>
<span id="cb83-949"><a href="#cb83-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-950"><a href="#cb83-950" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-951"><a href="#cb83-951" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'homoscedasticity tests: score test'</span></span>
<span id="cb83-952"><a href="#cb83-952" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-953"><a href="#cb83-953" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(ml.MC, <span class="at">heterosc =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-954"><a href="#cb83-954" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-955"><a href="#cb83-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-956"><a href="#cb83-956" aria-hidden="true" tabindex="-1"></a>The homoskedasticity hypothesis is therefore strongly rejected using the Wald</span>
<span id="cb83-957"><a href="#cb83-957" aria-hidden="true" tabindex="-1"></a>test, but only at the 1 and 5\% level for, respectively, the score and</span>
<span id="cb83-958"><a href="#cb83-958" aria-hidden="true" tabindex="-1"></a>the likelihood ratio tests.</span>
<span id="cb83-959"><a href="#cb83-959" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-960"><a href="#cb83-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-961"><a href="#cb83-961" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nested logit model</span></span>
<span id="cb83-962"><a href="#cb83-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-963"><a href="#cb83-963" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{correlated errors!random utility model|(}</span>
<span id="cb83-964"><a href="#cb83-964" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{nested logit model|(}</span>
<span id="cb83-965"><a href="#cb83-965" aria-hidden="true" tabindex="-1"></a>The nested logit model was first proposed by @MCFAD:78\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McFadden}. It is a</span>
<span id="cb83-966"><a href="#cb83-966" aria-hidden="true" tabindex="-1"></a>generalization of the multinomial logit model that is based on the</span>
<span id="cb83-967"><a href="#cb83-967" aria-hidden="true" tabindex="-1"></a>idea that some alternatives may be joined in several groups (called</span>
<span id="cb83-968"><a href="#cb83-968" aria-hidden="true" tabindex="-1"></a>nests). The error terms may then present some correlation in the same</span>
<span id="cb83-969"><a href="#cb83-969" aria-hidden="true" tabindex="-1"></a>nest, whereas error terms of different nests are still uncorrelated.</span>
<span id="cb83-970"><a href="#cb83-970" aria-hidden="true" tabindex="-1"></a>Denoting $m=1... M$ the nests and $B_m$ the set of alternatives</span>
<span id="cb83-971"><a href="#cb83-971" aria-hidden="true" tabindex="-1"></a>belonging to nest $m$, the cumulative distribution of the errors is:</span>
<span id="cb83-972"><a href="#cb83-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-973"><a href="#cb83-973" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-974"><a href="#cb83-974" aria-hidden="true" tabindex="-1"></a>\mbox{exp}\left(-\sum_{m=1}^M \left( \sum_{j \in B_m}</span>
<span id="cb83-975"><a href="#cb83-975" aria-hidden="true" tabindex="-1"></a>    e^{-\epsilon_j/\lambda_m}\right)^{\lambda_m}\right).</span>
<span id="cb83-976"><a href="#cb83-976" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-977"><a href="#cb83-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-978"><a href="#cb83-978" aria-hidden="true" tabindex="-1"></a>The marginal distributions of the $\epsilon$s are still univariate</span>
<span id="cb83-979"><a href="#cb83-979" aria-hidden="true" tabindex="-1"></a>extreme values, but there is now some correlation within</span>
<span id="cb83-980"><a href="#cb83-980" aria-hidden="true" tabindex="-1"></a>nests. $1-\lambda_m$ is a measure of the correlation, i.e., $\lambda_m</span>
<span id="cb83-981"><a href="#cb83-981" aria-hidden="true" tabindex="-1"></a>= 1$ implies no correlation. In the special case where $\lambda_m=1\;</span>
<span id="cb83-982"><a href="#cb83-982" aria-hidden="true" tabindex="-1"></a>\forall m$, the errors are iid Gumbel errors and the nested logit</span>
<span id="cb83-983"><a href="#cb83-983" aria-hidden="true" tabindex="-1"></a>model reduce to the multinomial logit model.  It can then be shown</span>
<span id="cb83-984"><a href="#cb83-984" aria-hidden="true" tabindex="-1"></a>that the probability of choosing alternative $j$ that belongs to nest</span>
<span id="cb83-985"><a href="#cb83-985" aria-hidden="true" tabindex="-1"></a>$l$ is:</span>
<span id="cb83-986"><a href="#cb83-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-987"><a href="#cb83-987" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-988"><a href="#cb83-988" aria-hidden="true" tabindex="-1"></a>P_j = \frac{e^{V_j/\lambda_l}\left(\sum_{k \in B_l}</span>
<span id="cb83-989"><a href="#cb83-989" aria-hidden="true" tabindex="-1"></a>    e^{V_k/\lambda_l}\right)^{\lambda_l-1}} {\sum_{m=1}^M\left(\sum_{k</span>
<span id="cb83-990"><a href="#cb83-990" aria-hidden="true" tabindex="-1"></a>      \in B_m} e^{V_k/\lambda_m}\right)^{\lambda_m}},</span>
<span id="cb83-991"><a href="#cb83-991" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-992"><a href="#cb83-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-993"><a href="#cb83-993" aria-hidden="true" tabindex="-1"></a>and that this model is a random utility model if all the $\lambda$</span>
<span id="cb83-994"><a href="#cb83-994" aria-hidden="true" tabindex="-1"></a>parameters are in the $0-1$ interval.^[A slightly different</span>
<span id="cb83-995"><a href="#cb83-995" aria-hidden="true" tabindex="-1"></a>version of the nested logit model <span class="co">[</span><span class="ot">@DALY:87</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Daly} is often used, but is not</span>
<span id="cb83-996"><a href="#cb83-996" aria-hidden="true" tabindex="-1"></a>compatible with the random utility maximization hypothesis. Its</span>
<span id="cb83-997"><a href="#cb83-997" aria-hidden="true" tabindex="-1"></a>difference from the previous expression is that the deterministic</span>
<span id="cb83-998"><a href="#cb83-998" aria-hidden="true" tabindex="-1"></a>parts of the utility for each alternative are not divided by the nest</span>
<span id="cb83-999"><a href="#cb83-999" aria-hidden="true" tabindex="-1"></a>elasticity. The differences between the two versions have been</span>
<span id="cb83-1000"><a href="#cb83-1000" aria-hidden="true" tabindex="-1"></a>discussed in @KOPP:WEN:98\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Koppelman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Wen}, @HEIS:02\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Heiss} and @HENS:GREEN:02\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Hensher}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Greene}.]</span>
<span id="cb83-1001"><a href="#cb83-1001" aria-hidden="true" tabindex="-1"></a>Let us now write the deterministic part of the utility of alternative</span>
<span id="cb83-1002"><a href="#cb83-1002" aria-hidden="true" tabindex="-1"></a>$j$ as the sum of two terms: the first ($Z_j$) being specific to</span>
<span id="cb83-1003"><a href="#cb83-1003" aria-hidden="true" tabindex="-1"></a>the alternative and the second ($W_l$) to the nest it belongs to:</span>
<span id="cb83-1004"><a href="#cb83-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1005"><a href="#cb83-1005" aria-hidden="true" tabindex="-1"></a>$$V_j=Z_j+W_l.$$</span>
<span id="cb83-1006"><a href="#cb83-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1007"><a href="#cb83-1007" aria-hidden="true" tabindex="-1"></a>We can then rewrite the probabilities as follow:</span>
<span id="cb83-1008"><a href="#cb83-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1009"><a href="#cb83-1009" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1010"><a href="#cb83-1010" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb83-1011"><a href="#cb83-1011" aria-hidden="true" tabindex="-1"></a>P_j&amp;=&amp;\frac{e^{(Z_j+W_l)/\lambda_l}}{\sum_{k \in B_l}</span>
<span id="cb83-1012"><a href="#cb83-1012" aria-hidden="true" tabindex="-1"></a>  e^{(Z_k+W_l)/\lambda_l}}\times \frac{\left(\sum_{k \in B_l}</span>
<span id="cb83-1013"><a href="#cb83-1013" aria-hidden="true" tabindex="-1"></a>    e^{(Z_k+W_l)/\lambda_l}\right)^{\lambda_l}}</span>
<span id="cb83-1014"><a href="#cb83-1014" aria-hidden="true" tabindex="-1"></a>{\sum_{m=1}^M\left(\sum_{k \in B_m}</span>
<span id="cb83-1015"><a href="#cb83-1015" aria-hidden="true" tabindex="-1"></a>    e^{(Z_k+W_m)/\lambda_m}\right)^{\lambda_m}}<span class="sc">\\</span></span>
<span id="cb83-1016"><a href="#cb83-1016" aria-hidden="true" tabindex="-1"></a>&amp;=&amp;\frac{e^{Z_j/\lambda_l}}{\sum_{k \in B_l}</span>
<span id="cb83-1017"><a href="#cb83-1017" aria-hidden="true" tabindex="-1"></a>    e^{Z_k/\lambda_l}}\times</span>
<span id="cb83-1018"><a href="#cb83-1018" aria-hidden="true" tabindex="-1"></a>\frac{\left(e^{W_l/\lambda_l}\sum_{k \in B_l} e^{Z_k/\lambda_l}\right)^{\lambda_l}}</span>
<span id="cb83-1019"><a href="#cb83-1019" aria-hidden="true" tabindex="-1"></a>{\sum_{m=1}^M\left(e^{W_m/\lambda_m}\sum_{k</span>
<span id="cb83-1020"><a href="#cb83-1020" aria-hidden="true" tabindex="-1"></a>      \in B_m} e^{Z_k/\lambda_m}\right)^{\lambda_m}}.</span>
<span id="cb83-1021"><a href="#cb83-1021" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1022"><a href="#cb83-1022" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1023"><a href="#cb83-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1024"><a href="#cb83-1024" aria-hidden="true" tabindex="-1"></a>Then denote $I_l=\ln \sum_{k \in B_l} e^{Z_k/\lambda_l}$ which is</span>
<span id="cb83-1025"><a href="#cb83-1025" aria-hidden="true" tabindex="-1"></a>often called the log-sum, the inclusive value or the inclusive</span>
<span id="cb83-1026"><a href="#cb83-1026" aria-hidden="true" tabindex="-1"></a>utility.^[We've already encountered this expression in</span>
<span id="cb83-1027"><a href="#cb83-1027" aria-hidden="true" tabindex="-1"></a>@sec-consumer_surplus.] We</span>
<span id="cb83-1028"><a href="#cb83-1028" aria-hidden="true" tabindex="-1"></a>then can write the probability of choosing alternative $j$ as:</span>
<span id="cb83-1029"><a href="#cb83-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1030"><a href="#cb83-1030" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1031"><a href="#cb83-1031" aria-hidden="true" tabindex="-1"></a>P_j=\frac{e^{Z_j/\lambda_l}}{\sum_{k \in B_l}</span>
<span id="cb83-1032"><a href="#cb83-1032" aria-hidden="true" tabindex="-1"></a>    e^{Z_k/\lambda_l}}\times</span>
<span id="cb83-1033"><a href="#cb83-1033" aria-hidden="true" tabindex="-1"></a>\frac{e^{W_l+\lambda_l I_l}}{\sum_{m=1}^Me^{W_m+\lambda_m I_m}}.</span>
<span id="cb83-1034"><a href="#cb83-1034" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1035"><a href="#cb83-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1036"><a href="#cb83-1036" aria-hidden="true" tabindex="-1"></a>The first term $\mbox{P}_{j\mid l}$ is the conditional probability of</span>
<span id="cb83-1037"><a href="#cb83-1037" aria-hidden="true" tabindex="-1"></a>choosing alternative $j$ if nest $l$ is chosen. It is often referred</span>
<span id="cb83-1038"><a href="#cb83-1038" aria-hidden="true" tabindex="-1"></a>to as the *lower model*. The second term $\mbox{P}_l$ is the marginal</span>
<span id="cb83-1039"><a href="#cb83-1039" aria-hidden="true" tabindex="-1"></a>probability of choosing nest $l$ and is referred to as the *upper model*.</span>
<span id="cb83-1040"><a href="#cb83-1040" aria-hidden="true" tabindex="-1"></a>$W_l+\lambda_l I_l$ can be interpreted as the expected utility of</span>
<span id="cb83-1041"><a href="#cb83-1041" aria-hidden="true" tabindex="-1"></a>choosing the best alternative in $l$, $W_l$ being the expected utility</span>
<span id="cb83-1042"><a href="#cb83-1042" aria-hidden="true" tabindex="-1"></a>of choosing an alternative in this nest (whatever this alternative is)</span>
<span id="cb83-1043"><a href="#cb83-1043" aria-hidden="true" tabindex="-1"></a>and $\lambda_l I_l$ being the expected extra utility gained by being</span>
<span id="cb83-1044"><a href="#cb83-1044" aria-hidden="true" tabindex="-1"></a>able to choose the best alternative in the nest.  The inclusive values</span>
<span id="cb83-1045"><a href="#cb83-1045" aria-hidden="true" tabindex="-1"></a>link the two models.  It is then straightforward to show that IIA</span>
<span id="cb83-1046"><a href="#cb83-1046" aria-hidden="true" tabindex="-1"></a>applies within nests, but not for two alternatives in different nests.</span>
<span id="cb83-1047"><a href="#cb83-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1048"><a href="#cb83-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1049"><a href="#cb83-1049" aria-hidden="true" tabindex="-1"></a>A consistent but inefficient way of estimating the nested logit model</span>
<span id="cb83-1050"><a href="#cb83-1050" aria-hidden="true" tabindex="-1"></a>is to estimate separately its two components. The coefficients of the</span>
<span id="cb83-1051"><a href="#cb83-1051" aria-hidden="true" tabindex="-1"></a>lower model are first estimated, which enables the computation of the</span>
<span id="cb83-1052"><a href="#cb83-1052" aria-hidden="true" tabindex="-1"></a>inclusive values $I_l$. The coefficients of the upper model are then</span>
<span id="cb83-1053"><a href="#cb83-1053" aria-hidden="true" tabindex="-1"></a>estimated, using $I_l$ as covariates. Maximizing directly the</span>
<span id="cb83-1054"><a href="#cb83-1054" aria-hidden="true" tabindex="-1"></a>likelihood function of the nested model leads to a more efficient</span>
<span id="cb83-1055"><a href="#cb83-1055" aria-hidden="true" tabindex="-1"></a>estimator.</span>
<span id="cb83-1056"><a href="#cb83-1056" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{upper model}</span>
<span id="cb83-1057"><a href="#cb83-1057" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{lower model}</span>
<span id="cb83-1058"><a href="#cb83-1058" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{nested logit model!two-step estimation|)}</span>
<span id="cb83-1059"><a href="#cb83-1059" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!nested logit}</span>
<span id="cb83-1060"><a href="#cb83-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1061"><a href="#cb83-1061" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{correlated errors!random utility model|)}</span>
<span id="cb83-1062"><a href="#cb83-1062" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{nested logit model|)}</span>
<span id="cb83-1063"><a href="#cb83-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1064"><a href="#cb83-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1065"><a href="#cb83-1065" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{telephone}{micsr}</span>
<span id="cb83-1066"><a href="#cb83-1066" aria-hidden="true" tabindex="-1"></a>To illustrate the estimation of the nested logit model, we use the <span class="in">`telephone`</span> data set, used by @TRAI:MCFA:BENA:87\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Train}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McFadden}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Ben-Akiva} and @WALK:BENA:BOLD:07\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Walker}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Ben-Akiva}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Bolduc}.</span>
<span id="cb83-1067"><a href="#cb83-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1070"><a href="#cb83-1070" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1071"><a href="#cb83-1071" aria-hidden="true" tabindex="-1"></a>telephone <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">5</span>)</span>
<span id="cb83-1072"><a href="#cb83-1072" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1073"><a href="#cb83-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1074"><a href="#cb83-1074" aria-hidden="true" tabindex="-1"></a>A total of 428 households were surveyed in 1984 about their choice of a local telephone service, which typically involves the choice between a flat service (a fixed monthly charge for an unlimited calls within a specified geographical area) and a measured (a reduced fixed monthly charge for a limited number of calls plus usage charges for additional calls) service. Households had the choice between five services:</span>
<span id="cb83-1075"><a href="#cb83-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1076"><a href="#cb83-1076" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*budget measured* (<span class="in">`budget`</span>): no fixed monthly charge; usage charges apply to each call made,</span>
<span id="cb83-1077"><a href="#cb83-1077" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*standard measured* (<span class="in">`standard`</span>): a fixed monthly charge covers up to a specified dollar amount (greater than the fixed charge) of local calling, after which usage charges apply to each call made,</span>
<span id="cb83-1078"><a href="#cb83-1078" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*local flat* (<span class="in">`local`</span>): a greater monthly charge that may depend upon residential location; unlimited free calling within a local calling area; usage charges apply to calls made outside local calling area,</span>
<span id="cb83-1079"><a href="#cb83-1079" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*extended area flat* (<span class="in">`extended`</span>): a further increase in the fixed monthly charge to permit unlimited free  calling within an extended area,</span>
<span id="cb83-1080"><a href="#cb83-1080" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*metro area flat* (<span class="in">`metro`</span>): the greatest fixed monthly charge that permits unlimited free calling within the entire metropolitan area.</span>
<span id="cb83-1081"><a href="#cb83-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1082"><a href="#cb83-1082" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb83-1083"><a href="#cb83-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1084"><a href="#cb83-1084" aria-hidden="true" tabindex="-1"></a>The first two services are measured, and the last three are flat services. There is therefore an obvious nesting structure for this example. We first estimate the multinomial logit model, with the log of cost as the unique covariate:</span>
<span id="cb83-1085"><a href="#cb83-1085" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}</span>
<span id="cb83-1086"><a href="#cb83-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1089"><a href="#cb83-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1090"><a href="#cb83-1090" aria-hidden="true" tabindex="-1"></a>ml_tel <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> <span class="fu">log</span>(cost), telephone, </span>
<span id="cb83-1091"><a href="#cb83-1091" aria-hidden="true" tabindex="-1"></a>                 <span class="at">idx =</span> <span class="fu">c</span>(<span class="st">"household"</span>, <span class="st">"service"</span>))</span>
<span id="cb83-1092"><a href="#cb83-1092" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1093"><a href="#cb83-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1094"><a href="#cb83-1094" aria-hidden="true" tabindex="-1"></a>We then update this model in order to introduce nests, using the <span class="in">`nests`</span> argument. It is a list of characters that contains the alternatives for the different nests. It is advisable to use a named list (we use here <span class="in">`"measured"`</span> and <span class="in">`"flat"`</span> as names of the nests):</span>
<span id="cb83-1095"><a href="#cb83-1095" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}\idxfun{coef}{stats}</span>
<span id="cb83-1096"><a href="#cb83-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1099"><a href="#cb83-1099" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1100"><a href="#cb83-1100" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1101"><a href="#cb83-1101" aria-hidden="true" tabindex="-1"></a>nl_tel <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> cost, telephone, </span>
<span id="cb83-1102"><a href="#cb83-1102" aria-hidden="true" tabindex="-1"></a>                 <span class="at">idx =</span> <span class="fu">c</span>(<span class="st">"household"</span>, <span class="st">"service"</span>), </span>
<span id="cb83-1103"><a href="#cb83-1103" aria-hidden="true" tabindex="-1"></a>                 <span class="at">nests =</span> <span class="fu">list</span>(<span class="at">measured =</span> <span class="fu">c</span>(<span class="st">"budget"</span>, <span class="st">"standard"</span>), </span>
<span id="cb83-1104"><a href="#cb83-1104" aria-hidden="true" tabindex="-1"></a>                              <span class="at">flat =</span> <span class="fu">c</span>(<span class="st">"local"</span>, <span class="st">"metro"</span>, <span class="st">"extended"</span>)))</span>
<span id="cb83-1105"><a href="#cb83-1105" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(nl_tel)</span>
<span id="cb83-1106"><a href="#cb83-1106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1107"><a href="#cb83-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1108"><a href="#cb83-1108" aria-hidden="true" tabindex="-1"></a>Two supplementary coefficients are estimated, <span class="in">`iv:measured`</span> and <span class="in">`iv:flat`</span>. The two values are in the 0-1 interval and close to each other. The <span class="in">`un.nest.el`</span> argument enables to estimate a unique supplementary coefficient for the two nests:</span>
<span id="cb83-1109"><a href="#cb83-1109" aria-hidden="true" tabindex="-1"></a>\idxfun{update}{stats}</span>
<span id="cb83-1110"><a href="#cb83-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1113"><a href="#cb83-1113" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1114"><a href="#cb83-1114" aria-hidden="true" tabindex="-1"></a>nl_tel_u <span class="ot">&lt;-</span> <span class="fu">update</span>(nl_tel, <span class="at">un.nest.el =</span> <span class="cn">TRUE</span>)</span>
<span id="cb83-1115"><a href="#cb83-1115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1116"><a href="#cb83-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1117"><a href="#cb83-1117" aria-hidden="true" tabindex="-1"></a>We then have three nested models and the hypothesis of a unique parameter can be tested using any of the three tests:</span>
<span id="cb83-1118"><a href="#cb83-1118" aria-hidden="true" tabindex="-1"></a>\idxfun{scoretest}{mlogit}\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}\idxfun{gaze}{micsr}</span>
<span id="cb83-1119"><a href="#cb83-1119" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{score test!nested logit}</span>
<span id="cb83-1120"><a href="#cb83-1120" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Wald test!nested logit}</span>
<span id="cb83-1121"><a href="#cb83-1121" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Lagrange multiplier test!nested logit}</span>
<span id="cb83-1122"><a href="#cb83-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1125"><a href="#cb83-1125" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1126"><a href="#cb83-1126" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1127"><a href="#cb83-1127" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(nl_tel_u, <span class="at">un.nest.el =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1128"><a href="#cb83-1128" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(nl_tel, nl_tel_u) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1129"><a href="#cb83-1129" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(nl_tel, <span class="at">un.nest.el =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1130"><a href="#cb83-1130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1131"><a href="#cb83-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1132"><a href="#cb83-1132" aria-hidden="true" tabindex="-1"></a>The three tests conclude that a unique parameter can be estimated. Then, we can test whether this parameter is 1, in which case the nested logit model reduces to the multinomial logit model:</span>
<span id="cb83-1133"><a href="#cb83-1133" aria-hidden="true" tabindex="-1"></a>\idxfun{scoretest}{mlogit}\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}\idxfun{gaze}{micsr}</span>
<span id="cb83-1134"><a href="#cb83-1134" aria-hidden="true" tabindex="-1"></a>\idxfun{list}{base}\idxfun{linearHypothesis}{car}</span>
<span id="cb83-1135"><a href="#cb83-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1138"><a href="#cb83-1138" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1139"><a href="#cb83-1139" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1140"><a href="#cb83-1140" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(ml_tel, </span>
<span id="cb83-1141"><a href="#cb83-1141" aria-hidden="true" tabindex="-1"></a>          <span class="at">nests =</span> <span class="fu">list</span>(<span class="at">measured =</span> <span class="fu">c</span>(<span class="st">"budget"</span>, <span class="st">"standard"</span>), </span>
<span id="cb83-1142"><a href="#cb83-1142" aria-hidden="true" tabindex="-1"></a>                       <span class="at">flat =</span> <span class="fu">c</span>(<span class="st">"local"</span>, <span class="st">"metro"</span>, <span class="st">"extended"</span>))) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1143"><a href="#cb83-1143" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(nl_tel_u, ml_tel) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1144"><a href="#cb83-1144" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(nl_tel_u, <span class="at">nests =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1145"><a href="#cb83-1145" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(nl_tel_u, <span class="st">"iv = 1"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1146"><a href="#cb83-1146" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1147"><a href="#cb83-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1148"><a href="#cb83-1148" aria-hidden="true" tabindex="-1"></a>Based on the Wald and the likelihood ratio, the preferred specification is the nested logit model (but note that the p-value for the score test is slightly higher than 5%).</span>
<span id="cb83-1149"><a href="#cb83-1149" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{telephone}{micsr}</span>
<span id="cb83-1150"><a href="#cb83-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1151"><a href="#cb83-1151" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random parameters (or mixed) logit model {#sec-mixed_logit}</span></span>
<span id="cb83-1152"><a href="#cb83-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1153"><a href="#cb83-1153" aria-hidden="true" tabindex="-1"></a><span class="fu">### Derivation of the model</span></span>
<span id="cb83-1154"><a href="#cb83-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1155"><a href="#cb83-1155" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{mixed model!multinomial logit|(}</span>
<span id="cb83-1156"><a href="#cb83-1156" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random parameter logit model|(}</span>
<span id="cb83-1157"><a href="#cb83-1157" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{mixed logit model|see{random parameter logit model}}</span>
<span id="cb83-1158"><a href="#cb83-1158" aria-hidden="true" tabindex="-1"></a>A **mixed logit** model (or random parameters logit model) is a logit model</span>
<span id="cb83-1159"><a href="#cb83-1159" aria-hidden="true" tabindex="-1"></a>whose parameters are assumed to vary from one individual to</span>
<span id="cb83-1160"><a href="#cb83-1160" aria-hidden="true" tabindex="-1"></a>another. It is therefore a model that takes the heterogeneity of the</span>
<span id="cb83-1161"><a href="#cb83-1161" aria-hidden="true" tabindex="-1"></a>population into account.</span>
<span id="cb83-1162"><a href="#cb83-1162" aria-hidden="true" tabindex="-1"></a>For the standard logit model, the probability that individual $n$</span>
<span id="cb83-1163"><a href="#cb83-1163" aria-hidden="true" tabindex="-1"></a>chooses alternative $j$ is:</span>
<span id="cb83-1164"><a href="#cb83-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1165"><a href="#cb83-1165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1166"><a href="#cb83-1166" aria-hidden="true" tabindex="-1"></a>P_{nl}=\frac{e^{\beta'x_{nl}}}{\sum_j e^{\beta'x_{nj}}}.</span>
<span id="cb83-1167"><a href="#cb83-1167" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1168"><a href="#cb83-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1169"><a href="#cb83-1169" aria-hidden="true" tabindex="-1"></a>Suppose now that the coefficients are individual-specific. The</span>
<span id="cb83-1170"><a href="#cb83-1170" aria-hidden="true" tabindex="-1"></a>probabilities are then:</span>
<span id="cb83-1171"><a href="#cb83-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1172"><a href="#cb83-1172" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1173"><a href="#cb83-1173" aria-hidden="true" tabindex="-1"></a>P_{nl}=\frac{e^{\beta_n'x_{nl}}}{\sum_j e^{\beta_n'x_{nj}}}.</span>
<span id="cb83-1174"><a href="#cb83-1174" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1175"><a href="#cb83-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1176"><a href="#cb83-1176" aria-hidden="true" tabindex="-1"></a>A first approach consists of estimating the parameters for every</span>
<span id="cb83-1177"><a href="#cb83-1177" aria-hidden="true" tabindex="-1"></a>individual. However, these parameters are identified and can be</span>
<span id="cb83-1178"><a href="#cb83-1178" aria-hidden="true" tabindex="-1"></a>consistently estimated only if a large number of choice situations per</span>
<span id="cb83-1179"><a href="#cb83-1179" aria-hidden="true" tabindex="-1"></a>individual is available, which is scarcely the case.</span>
<span id="cb83-1180"><a href="#cb83-1180" aria-hidden="true" tabindex="-1"></a>A more appealing approach consists of considering $\beta_n$ as</span>
<span id="cb83-1181"><a href="#cb83-1181" aria-hidden="true" tabindex="-1"></a>random draws on a distribution whose parameters are estimated, which</span>
<span id="cb83-1182"><a href="#cb83-1182" aria-hidden="true" tabindex="-1"></a>leads to the mixed logit model.  The probability that individual $n$</span>
<span id="cb83-1183"><a href="#cb83-1183" aria-hidden="true" tabindex="-1"></a>will choose alternative $l$, for a given value of $\beta_n$ is:</span>
<span id="cb83-1184"><a href="#cb83-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1185"><a href="#cb83-1185" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1186"><a href="#cb83-1186" aria-hidden="true" tabindex="-1"></a>P_{nl} \mid \beta_n =\frac{e^{\beta_n'x_{nl}}}{\sum_j e^{\beta_n'x_{nj}}}.</span>
<span id="cb83-1187"><a href="#cb83-1187" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1188"><a href="#cb83-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1189"><a href="#cb83-1189" aria-hidden="true" tabindex="-1"></a>To get the unconditional probability, we have to integrate out this</span>
<span id="cb83-1190"><a href="#cb83-1190" aria-hidden="true" tabindex="-1"></a>conditional probability, using the density function of $\beta$.</span>
<span id="cb83-1191"><a href="#cb83-1191" aria-hidden="true" tabindex="-1"></a>Suppose that $V_{nl}=\beta_n x_{nl}$, i.e., that there is only</span>
<span id="cb83-1192"><a href="#cb83-1192" aria-hidden="true" tabindex="-1"></a>one individual-specific coefficient and that the density of $\beta_n$</span>
<span id="cb83-1193"><a href="#cb83-1193" aria-hidden="true" tabindex="-1"></a>is $f(\beta,\theta)$, $\theta$ being the vector of the parameters of</span>
<span id="cb83-1194"><a href="#cb83-1194" aria-hidden="true" tabindex="-1"></a>the distribution of $\beta$. The unconditional probability is then:</span>
<span id="cb83-1195"><a href="#cb83-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1196"><a href="#cb83-1196" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1197"><a href="#cb83-1197" aria-hidden="true" tabindex="-1"></a>P_{nl}= \mbox{E}(P_{nl} \mid \beta_n) =</span>
<span id="cb83-1198"><a href="#cb83-1198" aria-hidden="true" tabindex="-1"></a>\int_{\beta}(P_{nl} \mid \beta)f(\beta,\theta)d\beta</span>
<span id="cb83-1199"><a href="#cb83-1199" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1200"><a href="#cb83-1200" aria-hidden="true" tabindex="-1"></a>\int_{\beta}\frac{e^{\beta^\top x_{nl}}}{\sum_j e^{\beta^\top x_{nj}}}f(\beta,\theta)d\beta,</span>
<span id="cb83-1201"><a href="#cb83-1201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1202"><a href="#cb83-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1203"><a href="#cb83-1203" aria-hidden="true" tabindex="-1"></a>which is a one-dimensional integral that can be efficiently estimated</span>
<span id="cb83-1204"><a href="#cb83-1204" aria-hidden="true" tabindex="-1"></a>by quadrature methods.  If $V_{nl}=\beta_n^{\top} x_{nl}$ where</span>
<span id="cb83-1205"><a href="#cb83-1205" aria-hidden="true" tabindex="-1"></a>$\beta_n$ is a vector of length $K$ and $f(\beta,\theta)$ is the joint</span>
<span id="cb83-1206"><a href="#cb83-1206" aria-hidden="true" tabindex="-1"></a>density of the $K$ individual-specific coefficients, the unconditional</span>
<span id="cb83-1207"><a href="#cb83-1207" aria-hidden="true" tabindex="-1"></a>probability is:</span>
<span id="cb83-1208"><a href="#cb83-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1209"><a href="#cb83-1209" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1210"><a href="#cb83-1210" aria-hidden="true" tabindex="-1"></a>P_{nl}= \mbox{E}(P_{nl} \mid \beta_n) =</span>
<span id="cb83-1211"><a href="#cb83-1211" aria-hidden="true" tabindex="-1"></a>\int_{\beta_1}\int_{\beta_2}...\int_{\beta_K}(P_{nl} \mid</span>
<span id="cb83-1212"><a href="#cb83-1212" aria-hidden="true" tabindex="-1"></a>\beta)f(\beta,\theta)d\beta_1d\beta_2... d\beta_K.</span>
<span id="cb83-1213"><a href="#cb83-1213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1214"><a href="#cb83-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1215"><a href="#cb83-1215" aria-hidden="true" tabindex="-1"></a>This is a $K$-dimensional integral which cannot easily be estimated by</span>
<span id="cb83-1216"><a href="#cb83-1216" aria-hidden="true" tabindex="-1"></a>quadrature methods. The only practical method is then to use</span>
<span id="cb83-1217"><a href="#cb83-1217" aria-hidden="true" tabindex="-1"></a>simulations. More precisely, $R$ draws of the parameters are taken</span>
<span id="cb83-1218"><a href="#cb83-1218" aria-hidden="true" tabindex="-1"></a>from the distribution of $\beta$, the probability is computed for</span>
<span id="cb83-1219"><a href="#cb83-1219" aria-hidden="true" tabindex="-1"></a>every draw and the unconditional probability, which is the expected</span>
<span id="cb83-1220"><a href="#cb83-1220" aria-hidden="true" tabindex="-1"></a>value of the conditional probabilities is estimated by the average of</span>
<span id="cb83-1221"><a href="#cb83-1221" aria-hidden="true" tabindex="-1"></a>the $R$ probabilities.</span>
<span id="cb83-1222"><a href="#cb83-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1223"><a href="#cb83-1223" aria-hidden="true" tabindex="-1"></a>The expected value of a random coefficient ($\mbox{E}(\beta)$) is</span>
<span id="cb83-1224"><a href="#cb83-1224" aria-hidden="true" tabindex="-1"></a>simply estimated by the mean of the $R$ draws on its distribution:</span>
<span id="cb83-1225"><a href="#cb83-1225" aria-hidden="true" tabindex="-1"></a>$\bar{\beta}=\sum_{r=1}^R \beta_r$.  Individual parameters are</span>
<span id="cb83-1226"><a href="#cb83-1226" aria-hidden="true" tabindex="-1"></a>obtained by first computing the probabilities of the observed choice</span>
<span id="cb83-1227"><a href="#cb83-1227" aria-hidden="true" tabindex="-1"></a>of $n$ for every value of $\beta_r$:</span>
<span id="cb83-1228"><a href="#cb83-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1229"><a href="#cb83-1229" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1230"><a href="#cb83-1230" aria-hidden="true" tabindex="-1"></a>P_{nr}=\frac{\sum_j y_{nj} e^{\beta_r^{'}x_{nj}}}{\sum_j e^{\beta_r^{'}x_{nj}}},</span>
<span id="cb83-1231"><a href="#cb83-1231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1232"><a href="#cb83-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1233"><a href="#cb83-1233" aria-hidden="true" tabindex="-1"></a>where $y_{nj}$ is a dummy equal to 1 if $n$ has chosen alternative</span>
<span id="cb83-1234"><a href="#cb83-1234" aria-hidden="true" tabindex="-1"></a>$j$. The expected value of the parameter for an individual is then</span>
<span id="cb83-1235"><a href="#cb83-1235" aria-hidden="true" tabindex="-1"></a>estimated by using these probabilities to weight the $R$ $\beta$</span>
<span id="cb83-1236"><a href="#cb83-1236" aria-hidden="true" tabindex="-1"></a>values:</span>
<span id="cb83-1237"><a href="#cb83-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1238"><a href="#cb83-1238" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1239"><a href="#cb83-1239" aria-hidden="true" tabindex="-1"></a>\hat{\beta}_n = \frac{\sum_r P_{nr} \beta_r}{\sum_r P_{nr}}.</span>
<span id="cb83-1240"><a href="#cb83-1240" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1241"><a href="#cb83-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1242"><a href="#cb83-1242" aria-hidden="true" tabindex="-1"></a>If there are repeated observations for the same individuals, the</span>
<span id="cb83-1243"><a href="#cb83-1243" aria-hidden="true" tabindex="-1"></a>longitudinal dimension of the data can be taken into account in the</span>
<span id="cb83-1244"><a href="#cb83-1244" aria-hidden="true" tabindex="-1"></a>mixed logit model, assuming that the random parameters of individual</span>
<span id="cb83-1245"><a href="#cb83-1245" aria-hidden="true" tabindex="-1"></a>$n$ are the same for all their choice situations. Denoting $y_{ntl}$ a</span>
<span id="cb83-1246"><a href="#cb83-1246" aria-hidden="true" tabindex="-1"></a>dummy equal to 1 if $n$ chooses alternative $l$ for the $t$^th^ choice</span>
<span id="cb83-1247"><a href="#cb83-1247" aria-hidden="true" tabindex="-1"></a>situation, the probability of the observed choice is:</span>
<span id="cb83-1248"><a href="#cb83-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1249"><a href="#cb83-1249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1250"><a href="#cb83-1250" aria-hidden="true" tabindex="-1"></a>P_{nt}\mid \beta_n=\prod_j \frac{\sum_j y_{ntj}e^{\beta_n ^\top x_{ntj}}}{\sum_j e^{\beta_n ^\top x_{ntj}}}.</span>
<span id="cb83-1251"><a href="#cb83-1251" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1252"><a href="#cb83-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1253"><a href="#cb83-1253" aria-hidden="true" tabindex="-1"></a>The joint probability for the $T$ observations of individual $n$ is then:</span>
<span id="cb83-1254"><a href="#cb83-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1255"><a href="#cb83-1255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1256"><a href="#cb83-1256" aria-hidden="true" tabindex="-1"></a>P_{n}\mid \beta_n=\prod_t \prod_j \frac{\sum_jy_{ntj}e^{\beta_n ^\top x_{ntj}}}{\sum_j e^{\beta_n ^\top x_{ntj}}}</span>
<span id="cb83-1257"><a href="#cb83-1257" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1258"><a href="#cb83-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1259"><a href="#cb83-1259" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{mixed model!multinomial logit|)}</span>
<span id="cb83-1260"><a href="#cb83-1260" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random parameter logit model|)}</span>
<span id="cb83-1261"><a href="#cb83-1261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1262"><a href="#cb83-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1263"><a href="#cb83-1263" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application</span></span>
<span id="cb83-1264"><a href="#cb83-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1265"><a href="#cb83-1265" aria-hidden="true" tabindex="-1"></a>The random parameter logit model is estimated by providing a <span class="in">`rpar`</span></span>
<span id="cb83-1266"><a href="#cb83-1266" aria-hidden="true" tabindex="-1"></a>argument to <span class="in">`mlogit`</span>. This argument is a named vector, the names being</span>
<span id="cb83-1267"><a href="#cb83-1267" aria-hidden="true" tabindex="-1"></a>the random coefficients and the acronyms for the law of</span>
<span id="cb83-1268"><a href="#cb83-1268" aria-hidden="true" tabindex="-1"></a>distribution. Currently, the normal (<span class="in">`"n"`</span>), log-normal (<span class="in">`"ln"`</span>),</span>
<span id="cb83-1269"><a href="#cb83-1269" aria-hidden="true" tabindex="-1"></a>zero-censored normal (<span class="in">`"cn"`</span>), uniform (<span class="in">`"u"`</span>) and triangular (<span class="in">`"t"`</span>)</span>
<span id="cb83-1270"><a href="#cb83-1270" aria-hidden="true" tabindex="-1"></a>distributions are available. For these distributions, two parameters</span>
<span id="cb83-1271"><a href="#cb83-1271" aria-hidden="true" tabindex="-1"></a>are estimated which are, for normal related distributions, the mean</span>
<span id="cb83-1272"><a href="#cb83-1272" aria-hidden="true" tabindex="-1"></a>and the standard-deviation of the underlying normal distribution and</span>
<span id="cb83-1273"><a href="#cb83-1273" aria-hidden="true" tabindex="-1"></a>for the uniform and triangular distribution, the mean and the half-range of the distribution. For these last two distributions,</span>
<span id="cb83-1274"><a href="#cb83-1274" aria-hidden="true" tabindex="-1"></a>zero-bounded variants are also provided (<span class="in">`"zbt"`</span> and <span class="in">`"zbu"`</span>). These</span>
<span id="cb83-1275"><a href="#cb83-1275" aria-hidden="true" tabindex="-1"></a>two distributions are defined by only one parameter (the mean) and</span>
<span id="cb83-1276"><a href="#cb83-1276" aria-hidden="true" tabindex="-1"></a>their definition domain varies from 0 to twice the mean.</span>
<span id="cb83-1277"><a href="#cb83-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1278"><a href="#cb83-1278" aria-hidden="true" tabindex="-1"></a>Several considerations may lead to the choice of a specific</span>
<span id="cb83-1279"><a href="#cb83-1279" aria-hidden="true" tabindex="-1"></a>distribution:</span>
<span id="cb83-1280"><a href="#cb83-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1281"><a href="#cb83-1281" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>if correlated coefficients are required, the natural choice is a</span>
<span id="cb83-1282"><a href="#cb83-1282" aria-hidden="true" tabindex="-1"></a>  (transformed-) normal distribution, <span class="in">`"n"`</span>, <span class="in">`"ln"`</span>, <span class="in">`"tn"`</span> and</span>
<span id="cb83-1283"><a href="#cb83-1283" aria-hidden="true" tabindex="-1"></a>  <span class="in">`"cn"`</span>,</span>
<span id="cb83-1284"><a href="#cb83-1284" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>it's often the case that one wants to impose that the distribution</span>
<span id="cb83-1285"><a href="#cb83-1285" aria-hidden="true" tabindex="-1"></a>  of a random parameter takes only positive or negative values. For</span>
<span id="cb83-1286"><a href="#cb83-1286" aria-hidden="true" tabindex="-1"></a>  example, the price coefficient should be negative for every</span>
<span id="cb83-1287"><a href="#cb83-1287" aria-hidden="true" tabindex="-1"></a>  individual. In this case, <span class="in">`"zbt"`</span> and <span class="in">`"zbu"`</span> can be used. The use</span>
<span id="cb83-1288"><a href="#cb83-1288" aria-hidden="true" tabindex="-1"></a>  of <span class="in">`"ln"`</span> and <span class="in">`"cn"`</span> can also be relevant but, in this case, if only</span>
<span id="cb83-1289"><a href="#cb83-1289" aria-hidden="true" tabindex="-1"></a>  negative values are expected, one should consider the distribution</span>
<span id="cb83-1290"><a href="#cb83-1290" aria-hidden="true" tabindex="-1"></a>  of the opposite of the random price coefficient. This can easily be</span>
<span id="cb83-1291"><a href="#cb83-1291" aria-hidden="true" tabindex="-1"></a>  done using the <span class="in">`opposite`</span> argument of <span class="in">`dfidx`</span>,^<span class="co">[</span><span class="ot">See @sec-wide_format.</span><span class="co">]</span></span>
<span id="cb83-1292"><a href="#cb83-1292" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the use of unbounded distributions often leads to implausible</span>
<span id="cb83-1293"><a href="#cb83-1293" aria-hidden="true" tabindex="-1"></a>  values of some statistics of the random parameters, especially the</span>
<span id="cb83-1294"><a href="#cb83-1294" aria-hidden="true" tabindex="-1"></a>  mean. This is particularly the case of the log-normal distribution,</span>
<span id="cb83-1295"><a href="#cb83-1295" aria-hidden="true" tabindex="-1"></a>  which has an heavy right tail. In this case, the use of bounded</span>
<span id="cb83-1296"><a href="#cb83-1296" aria-hidden="true" tabindex="-1"></a>  distribution like the uniform and the triangular distributions can be</span>
<span id="cb83-1297"><a href="#cb83-1297" aria-hidden="true" tabindex="-1"></a>  used.</span>
<span id="cb83-1298"><a href="#cb83-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1299"><a href="#cb83-1299" aria-hidden="true" tabindex="-1"></a><span class="in">`R`</span> is the number of draws, <span class="in">`halton`</span> indicates whether Halton draws</span>
<span id="cb83-1300"><a href="#cb83-1300" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">see @TRAI:09\index[author]{Train}, chapter 9</span><span class="co">]</span> should be used (<span class="in">`NA`</span> and <span class="in">`NULL`</span> indicate</span>
<span id="cb83-1301"><a href="#cb83-1301" aria-hidden="true" tabindex="-1"></a>respectively that default Halton draws are used and that pseudo-random</span>
<span id="cb83-1302"><a href="#cb83-1302" aria-hidden="true" tabindex="-1"></a>numbers are used), <span class="in">`panel`</span> is a boolean which indicates if the panel</span>
<span id="cb83-1303"><a href="#cb83-1303" aria-hidden="true" tabindex="-1"></a>data version of the log-likelihood should be used.</span>
<span id="cb83-1304"><a href="#cb83-1304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1305"><a href="#cb83-1305" aria-hidden="true" tabindex="-1"></a>Correlations between random parameters can be introduced only for</span>
<span id="cb83-1306"><a href="#cb83-1306" aria-hidden="true" tabindex="-1"></a>normal-related distributed random parameters, using the <span class="in">`correlation`</span></span>
<span id="cb83-1307"><a href="#cb83-1307" aria-hidden="true" tabindex="-1"></a>argument. If <span class="in">`TRUE`</span>, all the normal-related random parameters are</span>
<span id="cb83-1308"><a href="#cb83-1308" aria-hidden="true" tabindex="-1"></a>correlated. The <span class="in">`correlation`</span> argument can also be a character vector</span>
<span id="cb83-1309"><a href="#cb83-1309" aria-hidden="true" tabindex="-1"></a>indicating a subset of the random parameters that are assumed to be correlated.</span>
<span id="cb83-1310"><a href="#cb83-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1311"><a href="#cb83-1311" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{dutch<span class="sc">\_</span>railways}{micsr.data}</span>
<span id="cb83-1312"><a href="#cb83-1312" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`dutch_railways`</span> data set, previously coerced to a</span>
<span id="cb83-1313"><a href="#cb83-1313" aria-hidden="true" tabindex="-1"></a><span class="in">`dfidx`</span> object called <span class="in">`Tr`</span>. We first estimate the</span>
<span id="cb83-1314"><a href="#cb83-1314" aria-hidden="true" tabindex="-1"></a>multinomial model: both alternatives being virtual train trips, it is</span>
<span id="cb83-1315"><a href="#cb83-1315" aria-hidden="true" tabindex="-1"></a>relevant to use only generic coefficients and to remove the intercept:</span>
<span id="cb83-1316"><a href="#cb83-1316" aria-hidden="true" tabindex="-1"></a>\idxfun{dfidx}{dfidx}\idxfun{mlogit}{mlogit}\idxfun{gaze}{micsr}</span>
<span id="cb83-1317"><a href="#cb83-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1318"><a href="#cb83-1318" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1319"><a href="#cb83-1319" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'multinomial logit for the Train data'</span></span>
<span id="cb83-1320"><a href="#cb83-1320" aria-hidden="true" tabindex="-1"></a>Tr <span class="ot">&lt;-</span> <span class="fu">dfidx</span>(dutch_railways, <span class="at">choice =</span> <span class="st">"choice"</span>, <span class="at">varying =</span> <span class="dv">4</span><span class="sc">:</span><span class="dv">11</span>, <span class="at">sep =</span> <span class="st">"_"</span>, </span>
<span id="cb83-1321"><a href="#cb83-1321" aria-hidden="true" tabindex="-1"></a>            <span class="at">opposite =</span> <span class="fu">c</span>(<span class="st">"price"</span>, <span class="st">"comfort"</span>, <span class="st">"time"</span>, <span class="st">"change"</span>),</span>
<span id="cb83-1322"><a href="#cb83-1322" aria-hidden="true" tabindex="-1"></a>            <span class="at">idx =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="st">"choiceid"</span>, <span class="st">"id"</span>)), <span class="at">idnames =</span> <span class="fu">c</span>(<span class="st">"chid"</span>, <span class="st">"alt"</span>))</span>
<span id="cb83-1323"><a href="#cb83-1323" aria-hidden="true" tabindex="-1"></a>Train.ml <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> price <span class="sc">+</span> time <span class="sc">+</span> change <span class="sc">+</span> comfort <span class="sc">|</span> <span class="sc">-</span> <span class="dv">1</span>, Tr)</span>
<span id="cb83-1324"><a href="#cb83-1324" aria-hidden="true" tabindex="-1"></a>Train.ml <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1325"><a href="#cb83-1325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1326"><a href="#cb83-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1327"><a href="#cb83-1327" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb83-1328"><a href="#cb83-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1329"><a href="#cb83-1329" aria-hidden="true" tabindex="-1"></a>All the coefficients are highly significant and have the predicted</span>
<span id="cb83-1330"><a href="#cb83-1330" aria-hidden="true" tabindex="-1"></a>positive sign (remember than an increase in the variable <span class="in">`comfort`</span></span>
<span id="cb83-1331"><a href="#cb83-1331" aria-hidden="true" tabindex="-1"></a>implies using a less comfortable class). The coefficients can't be</span>
<span id="cb83-1332"><a href="#cb83-1332" aria-hidden="true" tabindex="-1"></a>directly interpreted, but dividing them by the price coefficient, we</span>
<span id="cb83-1333"><a href="#cb83-1333" aria-hidden="true" tabindex="-1"></a>get monetary values:</span>
<span id="cb83-1334"><a href="#cb83-1334" aria-hidden="true" tabindex="-1"></a>\idxfun{coef}{stats}</span>
<span id="cb83-1335"><a href="#cb83-1335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1336"><a href="#cb83-1336" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1337"><a href="#cb83-1337" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'marginal rates of substitution for Train'</span></span>
<span id="cb83-1338"><a href="#cb83-1338" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1339"><a href="#cb83-1339" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(Train.ml)[<span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> <span class="fu">coef</span>(Train.ml)[<span class="dv">1</span>]</span>
<span id="cb83-1340"><a href="#cb83-1340" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1341"><a href="#cb83-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1344"><a href="#cb83-1344" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1345"><a href="#cb83-1345" aria-hidden="true" tabindex="-1"></a>mv <span class="ot">&lt;-</span> <span class="fu">coef</span>(Train.ml)[<span class="sc">-</span> <span class="dv">1</span>] <span class="sc">/</span> <span class="fu">coef</span>(Train.ml)[<span class="dv">1</span>]</span>
<span id="cb83-1346"><a href="#cb83-1346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1347"><a href="#cb83-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1348"><a href="#cb83-1348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1349"><a href="#cb83-1349" aria-hidden="true" tabindex="-1"></a>We obtain the value of <span class="in">`r round(mv[1], 1)`</span> euros for an hour of traveling, <span class="in">`r round(mv[2], 1)`</span> euro for a change and <span class="in">`r round(mv[3], 1)`</span> euros to travel in a more comfortable class.^<span class="co">[</span><span class="ot">Remember that the survey took place in 1987. The values should be multiplied by 1.73 to get the value of 1 euro in 2024.</span><span class="co">]</span> We then estimate a model with three random parameters, <span class="in">`time`</span>, <span class="in">`change`</span> and</span>
<span id="cb83-1350"><a href="#cb83-1350" aria-hidden="true" tabindex="-1"></a><span class="in">`comfort`</span>. We first estimate the uncorrelated mixed logit model:</span>
<span id="cb83-1351"><a href="#cb83-1351" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}\idxfun{names}{base}\idxfun{coef}{stats}</span>
<span id="cb83-1352"><a href="#cb83-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1353"><a href="#cb83-1353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1354"><a href="#cb83-1354" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'mixed logit estimation for Train (1)'</span></span>
<span id="cb83-1355"><a href="#cb83-1355" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true</span></span>
<span id="cb83-1356"><a href="#cb83-1356" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1357"><a href="#cb83-1357" aria-hidden="true" tabindex="-1"></a>Train.mxlu <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(choice <span class="sc">~</span> price <span class="sc">+</span> time <span class="sc">+</span> change <span class="sc">+</span> comfort <span class="sc">|</span> <span class="sc">-</span> <span class="dv">1</span>, Tr, </span>
<span id="cb83-1358"><a href="#cb83-1358" aria-hidden="true" tabindex="-1"></a>                     <span class="at">rpar =</span> <span class="fu">c</span>(<span class="at">time =</span> <span class="st">"n"</span>, <span class="at">change =</span> <span class="st">"n"</span>, <span class="at">comfort =</span> <span class="st">"n"</span>), </span>
<span id="cb83-1359"><a href="#cb83-1359" aria-hidden="true" tabindex="-1"></a>                     <span class="at">R =</span> <span class="dv">100</span>, <span class="at">panel =</span> <span class="cn">TRUE</span>, <span class="at">correlation =</span> <span class="cn">FALSE</span>, </span>
<span id="cb83-1360"><a href="#cb83-1360" aria-hidden="true" tabindex="-1"></a>                     <span class="at">halton =</span> <span class="cn">NA</span>, <span class="at">method =</span> <span class="st">"bhhh"</span>)</span>
<span id="cb83-1361"><a href="#cb83-1361" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">coef</span>(Train.mxlu))</span>
<span id="cb83-1362"><a href="#cb83-1362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1363"><a href="#cb83-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1364"><a href="#cb83-1364" aria-hidden="true" tabindex="-1"></a>Compared to the multinomial logit model, there are now three more</span>
<span id="cb83-1365"><a href="#cb83-1365" aria-hidden="true" tabindex="-1"></a>coefficients which are the standard deviations of the distribution of</span>
<span id="cb83-1366"><a href="#cb83-1366" aria-hidden="true" tabindex="-1"></a>the three random parameters. The correlated model is obtained by</span>
<span id="cb83-1367"><a href="#cb83-1367" aria-hidden="true" tabindex="-1"></a>setting the <span class="in">`correlation`</span> argument to <span class="in">`TRUE`</span>.</span>
<span id="cb83-1368"><a href="#cb83-1368" aria-hidden="true" tabindex="-1"></a>\idxfun{names}{base}\idxfun{coef}{stats}\idxfun{update}{stats}</span>
<span id="cb83-1369"><a href="#cb83-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1370"><a href="#cb83-1370" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1371"><a href="#cb83-1371" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true</span></span>
<span id="cb83-1372"><a href="#cb83-1372" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'mixed logit estimation for Train (2)'</span></span>
<span id="cb83-1373"><a href="#cb83-1373" aria-hidden="true" tabindex="-1"></a>Train.mxlc <span class="ot">&lt;-</span> <span class="fu">update</span>(Train.mxlu, <span class="at">correlation =</span> <span class="cn">TRUE</span>)</span>
<span id="cb83-1374"><a href="#cb83-1374" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">coef</span>(Train.mxlc))</span>
<span id="cb83-1375"><a href="#cb83-1375" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1376"><a href="#cb83-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1377"><a href="#cb83-1377" aria-hidden="true" tabindex="-1"></a>There are now six parameters which are the elements of the Choleski</span>
<span id="cb83-1378"><a href="#cb83-1378" aria-hidden="true" tabindex="-1"></a>decomposition\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Choleski decomposition} of the covariance matrix of the three random parameters. These six parameters are therefore the elements of the following matrix:</span>
<span id="cb83-1379"><a href="#cb83-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1380"><a href="#cb83-1380" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1381"><a href="#cb83-1381" aria-hidden="true" tabindex="-1"></a>C=</span>
<span id="cb83-1382"><a href="#cb83-1382" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1383"><a href="#cb83-1383" aria-hidden="true" tabindex="-1"></a>  \begin{array}{ccc}</span>
<span id="cb83-1384"><a href="#cb83-1384" aria-hidden="true" tabindex="-1"></a>    c_{11} &amp; c_{12}  &amp; c_{13} <span class="sc">\\</span></span>
<span id="cb83-1385"><a href="#cb83-1385" aria-hidden="true" tabindex="-1"></a>    0 &amp; c_{22} &amp; c_{23} <span class="sc">\\</span></span>
<span id="cb83-1386"><a href="#cb83-1386" aria-hidden="true" tabindex="-1"></a>    0 &amp; 0 &amp; c_{33}</span>
<span id="cb83-1387"><a href="#cb83-1387" aria-hidden="true" tabindex="-1"></a>  \end{array}</span>
<span id="cb83-1388"><a href="#cb83-1388" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1389"><a href="#cb83-1389" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1390"><a href="#cb83-1390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1391"><a href="#cb83-1391" aria-hidden="true" tabindex="-1"></a>such that:</span>
<span id="cb83-1392"><a href="#cb83-1392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1393"><a href="#cb83-1393" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1394"><a href="#cb83-1394" aria-hidden="true" tabindex="-1"></a>C^{\top}C=</span>
<span id="cb83-1395"><a href="#cb83-1395" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1396"><a href="#cb83-1396" aria-hidden="true" tabindex="-1"></a>  \begin{array}{ccc}</span>
<span id="cb83-1397"><a href="#cb83-1397" aria-hidden="true" tabindex="-1"></a>    c_{11}^2 &amp; c_{11} c_{12}  &amp; c_{11}c_{13} <span class="sc">\\</span></span>
<span id="cb83-1398"><a href="#cb83-1398" aria-hidden="true" tabindex="-1"></a>    c_{11}c_{12} &amp; c_{12}^2 + c_{22}^2 &amp; c_{12}c_{23}+c_{22}c_{23} <span class="sc">\\</span></span>
<span id="cb83-1399"><a href="#cb83-1399" aria-hidden="true" tabindex="-1"></a>    c_{11}c_{13} &amp; c_{12}c_{3} + c_{22}c_{23} &amp; c_{13}^2 + c_{23}^2 c_{33}^2</span>
<span id="cb83-1400"><a href="#cb83-1400" aria-hidden="true" tabindex="-1"></a>  \end{array}</span>
<span id="cb83-1401"><a href="#cb83-1401" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1402"><a href="#cb83-1402" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1403"><a href="#cb83-1403" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1404"><a href="#cb83-1404" aria-hidden="true" tabindex="-1"></a>  \begin{array}{ccc}</span>
<span id="cb83-1405"><a href="#cb83-1405" aria-hidden="true" tabindex="-1"></a>    \sigma_{1}^2 &amp; \sigma_{12}  &amp; \sigma_{13} <span class="sc">\\</span></span>
<span id="cb83-1406"><a href="#cb83-1406" aria-hidden="true" tabindex="-1"></a>    \sigma_{12} &amp; \sigma_{2}^2 &amp; \sigma_{23} <span class="sc">\\</span></span>
<span id="cb83-1407"><a href="#cb83-1407" aria-hidden="true" tabindex="-1"></a>    \sigma_{13} &amp; \sigma_{23} &amp; \sigma_{3}^2</span>
<span id="cb83-1408"><a href="#cb83-1408" aria-hidden="true" tabindex="-1"></a>  \end{array}</span>
<span id="cb83-1409"><a href="#cb83-1409" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1410"><a href="#cb83-1410" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1411"><a href="#cb83-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1412"><a href="#cb83-1412" aria-hidden="true" tabindex="-1"></a>where $\sigma_k^2$ and $\sigma_{kl}$ are respectively the variance of</span>
<span id="cb83-1413"><a href="#cb83-1413" aria-hidden="true" tabindex="-1"></a>the random parameter $k$ and the covariance between two random</span>
<span id="cb83-1414"><a href="#cb83-1414" aria-hidden="true" tabindex="-1"></a>parameters $k$ and $l$. Therefore, the first estimated parameter can</span>
<span id="cb83-1415"><a href="#cb83-1415" aria-hidden="true" tabindex="-1"></a>be simply interpreted as the standard deviation of the first random</span>
<span id="cb83-1416"><a href="#cb83-1416" aria-hidden="true" tabindex="-1"></a>parameter, but the five other can't be interpreted easily.</span>
<span id="cb83-1417"><a href="#cb83-1417" aria-hidden="true" tabindex="-1"></a>Random parameters may be extracted using the function <span class="in">`rpar`</span> which</span>
<span id="cb83-1418"><a href="#cb83-1418" aria-hidden="true" tabindex="-1"></a>takes as first argument a <span class="in">`mlogit`</span> object and as second argument <span class="in">`par`</span></span>
<span id="cb83-1419"><a href="#cb83-1419" aria-hidden="true" tabindex="-1"></a>the parameter(s) to be extracted. This function returns a <span class="in">`rpar`</span></span>
<span id="cb83-1420"><a href="#cb83-1420" aria-hidden="true" tabindex="-1"></a>object and a <span class="in">`summary`</span> method is provided to describe it:</span>
<span id="cb83-1421"><a href="#cb83-1421" aria-hidden="true" tabindex="-1"></a>\idxfun{rpar}{mlogit}</span>
<span id="cb83-1422"><a href="#cb83-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1423"><a href="#cb83-1423" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1424"><a href="#cb83-1424" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'summary of a random parameter in the preference space'</span></span>
<span id="cb83-1425"><a href="#cb83-1425" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1426"><a href="#cb83-1426" aria-hidden="true" tabindex="-1"></a>marg.ut.time <span class="ot">&lt;-</span> <span class="fu">rpar</span>(Train.mxlc, <span class="st">"time"</span>)</span>
<span id="cb83-1427"><a href="#cb83-1427" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(marg.ut.time)</span>
<span id="cb83-1428"><a href="#cb83-1428" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1429"><a href="#cb83-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1430"><a href="#cb83-1430" aria-hidden="true" tabindex="-1"></a>The estimated random parameter is in the "preference space", which</span>
<span id="cb83-1431"><a href="#cb83-1431" aria-hidden="true" tabindex="-1"></a>means that it is the marginal utility of time.</span>
<span id="cb83-1432"><a href="#cb83-1432" aria-hidden="true" tabindex="-1"></a>Parameters in the "willingness to pay" (WTP) space are more easy to</span>
<span id="cb83-1433"><a href="#cb83-1433" aria-hidden="true" tabindex="-1"></a>interpret. They can be estimated directly (a feature not supported by</span>
<span id="cb83-1434"><a href="#cb83-1434" aria-hidden="true" tabindex="-1"></a><span class="in">`mlogit`</span>) or can be obtained from the marginal utility by dividing</span>
<span id="cb83-1435"><a href="#cb83-1435" aria-hidden="true" tabindex="-1"></a>by the coefficient of a covariate expressed in monetary value (a price</span>
<span id="cb83-1436"><a href="#cb83-1436" aria-hidden="true" tabindex="-1"></a>for example), taken as a non-random parameter. The ratio can then be</span>
<span id="cb83-1437"><a href="#cb83-1437" aria-hidden="true" tabindex="-1"></a>interpreted as a monetary value (or willingness to pay). To obtain the</span>
<span id="cb83-1438"><a href="#cb83-1438" aria-hidden="true" tabindex="-1"></a>distribution of the random parameters in the WTP space, one can use</span>
<span id="cb83-1439"><a href="#cb83-1439" aria-hidden="true" tabindex="-1"></a>the <span class="in">`norm`</span> argument of <span class="in">`rpar`</span>:</span>
<span id="cb83-1440"><a href="#cb83-1440" aria-hidden="true" tabindex="-1"></a>\idxfun{rpar}{mlogit}</span>
<span id="cb83-1441"><a href="#cb83-1441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1442"><a href="#cb83-1442" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1443"><a href="#cb83-1443" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'summary of a random parameter in the wtp space'</span></span>
<span id="cb83-1444"><a href="#cb83-1444" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1445"><a href="#cb83-1445" aria-hidden="true" tabindex="-1"></a>wtp.time <span class="ot">&lt;-</span> <span class="fu">rpar</span>(Train.mxlc, <span class="st">"time"</span>, <span class="at">norm =</span> <span class="st">"price"</span>)</span>
<span id="cb83-1446"><a href="#cb83-1446" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(wtp.time)</span>
<span id="cb83-1447"><a href="#cb83-1447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1448"><a href="#cb83-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1449"><a href="#cb83-1449" aria-hidden="true" tabindex="-1"></a>The median value (and the mean value as the distribution is symmetric)</span>
<span id="cb83-1450"><a href="#cb83-1450" aria-hidden="true" tabindex="-1"></a>of transport time is about 33 euros. Several methods/functions are</span>
<span id="cb83-1451"><a href="#cb83-1451" aria-hidden="true" tabindex="-1"></a>provided to extract the individual statistics (<span class="in">`mean`</span>, <span class="in">`med`</span> and</span>
<span id="cb83-1452"><a href="#cb83-1452" aria-hidden="true" tabindex="-1"></a><span class="in">`stdev`</span> respectively for the mean, median and standard</span>
<span id="cb83-1453"><a href="#cb83-1453" aria-hidden="true" tabindex="-1"></a>deviation):</span>
<span id="cb83-1454"><a href="#cb83-1454" aria-hidden="true" tabindex="-1"></a>\idxfun{rpar}{mlogit}\idxfun{med}{mlogit}\idxfun{stdev}{mlogit}</span>
<span id="cb83-1455"><a href="#cb83-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1456"><a href="#cb83-1456" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1457"><a href="#cb83-1457" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'statistics of the random parameter in the wtp space'</span></span>
<span id="cb83-1458"><a href="#cb83-1458" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1459"><a href="#cb83-1459" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">rpar</span>(Train.mxlc, <span class="st">"time"</span>, <span class="at">norm =</span> <span class="st">"price"</span>))</span>
<span id="cb83-1460"><a href="#cb83-1460" aria-hidden="true" tabindex="-1"></a><span class="fu">med</span>(<span class="fu">rpar</span>(Train.mxlc, <span class="st">"time"</span>, <span class="at">norm =</span> <span class="st">"price"</span>))</span>
<span id="cb83-1461"><a href="#cb83-1461" aria-hidden="true" tabindex="-1"></a><span class="fu">stdev</span>(<span class="fu">rpar</span>(Train.mxlc, <span class="st">"time"</span>, <span class="at">norm =</span> <span class="st">"price"</span>))</span>
<span id="cb83-1462"><a href="#cb83-1462" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1463"><a href="#cb83-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1464"><a href="#cb83-1464" aria-hidden="true" tabindex="-1"></a>In case of correlated random parameters, as the estimated parameters</span>
<span id="cb83-1465"><a href="#cb83-1465" aria-hidden="true" tabindex="-1"></a>can't be directly interpreted, a <span class="in">`vcov`</span> method for <span class="in">`mlogit`</span> objects is</span>
<span id="cb83-1466"><a href="#cb83-1466" aria-hidden="true" tabindex="-1"></a>provided. It has a <span class="in">`what`</span> argument whose default value is</span>
<span id="cb83-1467"><a href="#cb83-1467" aria-hidden="true" tabindex="-1"></a><span class="in">`coefficient`</span>. In this case the usual covariance matrix of the</span>
<span id="cb83-1468"><a href="#cb83-1468" aria-hidden="true" tabindex="-1"></a>coefficients is return. If <span class="in">`what = "rpar"`</span>, the covariance matrix of</span>
<span id="cb83-1469"><a href="#cb83-1469" aria-hidden="true" tabindex="-1"></a>the correlated random parameters is returned if <span class="in">`type = "cov"`</span> (the</span>
<span id="cb83-1470"><a href="#cb83-1470" aria-hidden="true" tabindex="-1"></a>default) and the correlation matrix (with standard deviations on the</span>
<span id="cb83-1471"><a href="#cb83-1471" aria-hidden="true" tabindex="-1"></a>diagonal) is returned if <span class="in">`type = "cor"`</span>. The object is of class</span>
<span id="cb83-1472"><a href="#cb83-1472" aria-hidden="true" tabindex="-1"></a><span class="in">`vcov.mlogit`</span> and a <span class="in">`summary`</span> method for this object is provided which</span>
<span id="cb83-1473"><a href="#cb83-1473" aria-hidden="true" tabindex="-1"></a>computes, using the delta method,\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{delta method} the standard errors of the</span>
<span id="cb83-1474"><a href="#cb83-1474" aria-hidden="true" tabindex="-1"></a>parameters of the covariance or the correlation matrix.</span>
<span id="cb83-1475"><a href="#cb83-1475" aria-hidden="true" tabindex="-1"></a>\idxfun{vcov}{stats}</span>
<span id="cb83-1476"><a href="#cb83-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1477"><a href="#cb83-1477" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1478"><a href="#cb83-1478" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'vcov method for mlogit objects'</span></span>
<span id="cb83-1479"><a href="#cb83-1479" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(Train.mxlc, <span class="at">what =</span> <span class="st">"rpar"</span>)</span>
<span id="cb83-1480"><a href="#cb83-1480" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(Train.mxlc, <span class="at">what =</span> <span class="st">"rpar"</span>, <span class="at">type =</span> <span class="st">"cor"</span>)</span>
<span id="cb83-1481"><a href="#cb83-1481" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">vcov</span>(Train.mxlc, <span class="at">what =</span> <span class="st">"rpar"</span>, <span class="at">type =</span> <span class="st">"cor"</span>))</span>
<span id="cb83-1482"><a href="#cb83-1482" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1483"><a href="#cb83-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1484"><a href="#cb83-1484" aria-hidden="true" tabindex="-1"></a>The correlation can be restricted to a subset of random parameters by</span>
<span id="cb83-1485"><a href="#cb83-1485" aria-hidden="true" tabindex="-1"></a>filling the <span class="in">`correlation`</span> argument with a character vector indicating</span>
<span id="cb83-1486"><a href="#cb83-1486" aria-hidden="true" tabindex="-1"></a>the corresponding covariates:</span>
<span id="cb83-1487"><a href="#cb83-1487" aria-hidden="true" tabindex="-1"></a>\idxfun{update}{stats}\idxfun{vcov}{stats}</span>
<span id="cb83-1488"><a href="#cb83-1488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1489"><a href="#cb83-1489" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1490"><a href="#cb83-1490" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'mixed logit with a subset of correlated paramaters'</span></span>
<span id="cb83-1491"><a href="#cb83-1491" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true</span></span>
<span id="cb83-1492"><a href="#cb83-1492" aria-hidden="true" tabindex="-1"></a>Train.mxlc2 <span class="ot">&lt;-</span> <span class="fu">update</span>(Train.mxlc, <span class="at">correlation =</span> <span class="fu">c</span>(<span class="st">"time"</span>, <span class="st">"comfort"</span>))</span>
<span id="cb83-1493"><a href="#cb83-1493" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(Train.mxlc2, <span class="at">what =</span> <span class="st">"rpar"</span>, <span class="at">type =</span> <span class="st">"cor"</span>)</span>
<span id="cb83-1494"><a href="#cb83-1494" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1495"><a href="#cb83-1495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1496"><a href="#cb83-1496" aria-hidden="true" tabindex="-1"></a>The presence of random coefficients and their correlation can be</span>
<span id="cb83-1497"><a href="#cb83-1497" aria-hidden="true" tabindex="-1"></a>investigated using any of the three tests. Actually, three nested</span>
<span id="cb83-1498"><a href="#cb83-1498" aria-hidden="true" tabindex="-1"></a>models can be considered, a model with no random effects, a model with</span>
<span id="cb83-1499"><a href="#cb83-1499" aria-hidden="true" tabindex="-1"></a>random but uncorrelated effects and a model with random and correlated</span>
<span id="cb83-1500"><a href="#cb83-1500" aria-hidden="true" tabindex="-1"></a>effects. We first present the three tests of no correlated random</span>
<span id="cb83-1501"><a href="#cb83-1501" aria-hidden="true" tabindex="-1"></a>effects:</span>
<span id="cb83-1502"><a href="#cb83-1502" aria-hidden="true" tabindex="-1"></a>\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}\idxfun{scoretest}{mlogit}</span>
<span id="cb83-1503"><a href="#cb83-1503" aria-hidden="true" tabindex="-1"></a>\idxfun{linearHypothesis}{car}\idxfun{gaze}{micsr}</span>
<span id="cb83-1504"><a href="#cb83-1504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1505"><a href="#cb83-1505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1506"><a href="#cb83-1506" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'tests of no correlated random effects'</span></span>
<span id="cb83-1507"><a href="#cb83-1507" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1508"><a href="#cb83-1508" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(Train.mxlc, Train.ml) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1509"><a href="#cb83-1509" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(Train.mxlc) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1510"><a href="#cb83-1510" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(Train.mxlc, </span>
<span id="cb83-1511"><a href="#cb83-1511" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">c</span>(<span class="st">"chol.time:time = 0"</span>, <span class="st">"chol.time:change =  0"</span>, </span>
<span id="cb83-1512"><a href="#cb83-1512" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"chol.time:comfort = 0"</span>, <span class="st">"chol.change:change = 0"</span>, </span>
<span id="cb83-1513"><a href="#cb83-1513" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"chol.change:comfort = 0"</span>, </span>
<span id="cb83-1514"><a href="#cb83-1514" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"chol.comfort:comfort = 0"</span>)) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1515"><a href="#cb83-1515" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(Train.ml, <span class="at">rpar =</span> <span class="fu">c</span>(<span class="at">time =</span> <span class="st">"n"</span>, <span class="at">change =</span> <span class="st">"n"</span>, <span class="at">comfort =</span> <span class="st">"n"</span>), </span>
<span id="cb83-1516"><a href="#cb83-1516" aria-hidden="true" tabindex="-1"></a>          <span class="at">R =</span> <span class="dv">100</span>, <span class="at">correlation =</span> <span class="cn">TRUE</span>, <span class="at">halton =</span> <span class="cn">NA</span>, </span>
<span id="cb83-1517"><a href="#cb83-1517" aria-hidden="true" tabindex="-1"></a>          <span class="at">panel =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1518"><a href="#cb83-1518" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1519"><a href="#cb83-1519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1520"><a href="#cb83-1520" aria-hidden="true" tabindex="-1"></a>The hypothesis of no correlated random parameters is strongly</span>
<span id="cb83-1521"><a href="#cb83-1521" aria-hidden="true" tabindex="-1"></a>rejected. We then present the three tests of no correlation, the</span>
<span id="cb83-1522"><a href="#cb83-1522" aria-hidden="true" tabindex="-1"></a>existence of random parameters being maintained.</span>
<span id="cb83-1523"><a href="#cb83-1523" aria-hidden="true" tabindex="-1"></a>\idxfun{lrtest}{lmtest}\idxfun{waldtest}{lmtest}\idxfun{scoretest}{mlogit}</span>
<span id="cb83-1524"><a href="#cb83-1524" aria-hidden="true" tabindex="-1"></a>\idxfun{linearHypothesis}{car}\idxfun{gaze}{micsr}</span>
<span id="cb83-1525"><a href="#cb83-1525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1526"><a href="#cb83-1526" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb83-1527"><a href="#cb83-1527" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 'tests of no correlation'</span></span>
<span id="cb83-1528"><a href="#cb83-1528" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1529"><a href="#cb83-1529" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(Train.mxlc, Train.mxlu) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1530"><a href="#cb83-1530" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(Train.mxlc, </span>
<span id="cb83-1531"><a href="#cb83-1531" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">c</span>(<span class="st">"chol.time:change = 0"</span>,<span class="st">"chol.time:comfort = 0"</span>, </span>
<span id="cb83-1532"><a href="#cb83-1532" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"chol.change:comfort = 0"</span>)) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1533"><a href="#cb83-1533" aria-hidden="true" tabindex="-1"></a><span class="fu">waldtest</span>(Train.mxlc, <span class="at">correlation =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1534"><a href="#cb83-1534" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(Train.mxlu, <span class="at">correlation =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb83-1535"><a href="#cb83-1535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1536"><a href="#cb83-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1537"><a href="#cb83-1537" aria-hidden="true" tabindex="-1"></a>The hypothesis of no correlation is strongly rejected with the Wald and</span>
<span id="cb83-1538"><a href="#cb83-1538" aria-hidden="true" tabindex="-1"></a>the likelihood ratio test, only at the 5\% level for the score test.</span>
<span id="cb83-1539"><a href="#cb83-1539" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{dutch<span class="sc">\_</span>railways}{micsr.data}</span>
<span id="cb83-1540"><a href="#cb83-1540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1541"><a href="#cb83-1541" aria-hidden="true" tabindex="-1"></a><span class="fu">##  Multinomial probit {#sec-multinom_probit}</span></span>
<span id="cb83-1542"><a href="#cb83-1542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1543"><a href="#cb83-1543" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{multinomial probit model|(}</span>
<span id="cb83-1544"><a href="#cb83-1544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1545"><a href="#cb83-1545" aria-hidden="true" tabindex="-1"></a><span class="fu">### The model</span></span>
<span id="cb83-1546"><a href="#cb83-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1547"><a href="#cb83-1547" aria-hidden="true" tabindex="-1"></a>The multinomial probit is obtained with the same modeling that we used</span>
<span id="cb83-1548"><a href="#cb83-1548" aria-hidden="true" tabindex="-1"></a>while presenting the random utility model. The utility of an</span>
<span id="cb83-1549"><a href="#cb83-1549" aria-hidden="true" tabindex="-1"></a>alternative is still the sum of two components : $U_j = V_j +</span>
<span id="cb83-1550"><a href="#cb83-1550" aria-hidden="true" tabindex="-1"></a>\epsilon_j$ but the joint distribution of the error terms is now a multivariate</span>
<span id="cb83-1551"><a href="#cb83-1551" aria-hidden="true" tabindex="-1"></a>normal with mean 0 and with a matrix of covariance denoted by</span>
<span id="cb83-1552"><a href="#cb83-1552" aria-hidden="true" tabindex="-1"></a>$\Omega$.^<span class="co">[</span><span class="ot">See @HAUS:WISE:78\index[author]{Hausman}\index[author]{Wise} and @DAGA:79\index[author]{Daganzo}.</span><span class="co">]</span></span>
<span id="cb83-1553"><a href="#cb83-1553" aria-hidden="true" tabindex="-1"></a>Alternative $l$ is chosen if:</span>
<span id="cb83-1554"><a href="#cb83-1554" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1555"><a href="#cb83-1555" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb83-1556"><a href="#cb83-1556" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb83-1557"><a href="#cb83-1557" aria-hidden="true" tabindex="-1"></a>U_1-U_l&amp;=&amp;(V_1-V_l)+(\epsilon_1-\epsilon_l)&lt;0<span class="sc">\\</span></span>
<span id="cb83-1558"><a href="#cb83-1558" aria-hidden="true" tabindex="-1"></a>U_2-U_l&amp;=&amp;(V_2-V_l)+(\epsilon_2-\epsilon_l)&lt;0<span class="sc">\\</span></span>
<span id="cb83-1559"><a href="#cb83-1559" aria-hidden="true" tabindex="-1"></a> &amp; \vdots &amp;  <span class="sc">\\</span></span>
<span id="cb83-1560"><a href="#cb83-1560" aria-hidden="true" tabindex="-1"></a>U_J-U_l&amp;=&amp;(V_J-V_l)+(\epsilon_J-\epsilon_l)&lt;0<span class="sc">\\</span></span>
<span id="cb83-1561"><a href="#cb83-1561" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1562"><a href="#cb83-1562" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb83-1563"><a href="#cb83-1563" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1564"><a href="#cb83-1564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1565"><a href="#cb83-1565" aria-hidden="true" tabindex="-1"></a>wich implies, denoting $V^l_j=V_j-V_l$ :</span>
<span id="cb83-1566"><a href="#cb83-1566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1567"><a href="#cb83-1567" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1568"><a href="#cb83-1568" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb83-1569"><a href="#cb83-1569" aria-hidden="true" tabindex="-1"></a>\begin{array}{rclrcl}</span>
<span id="cb83-1570"><a href="#cb83-1570" aria-hidden="true" tabindex="-1"></a>  \epsilon^l_1 &amp;=&amp; (\epsilon_1-\epsilon_l) &amp;&lt;&amp; - V^l_1<span class="sc">\\</span></span>
<span id="cb83-1571"><a href="#cb83-1571" aria-hidden="true" tabindex="-1"></a>  \epsilon^l_2 &amp;=&amp; (\epsilon_2-\epsilon_l) &amp;&lt;&amp; - V^l_2<span class="sc">\\</span></span>
<span id="cb83-1572"><a href="#cb83-1572" aria-hidden="true" tabindex="-1"></a>  &amp;\vdots &amp; &amp; \vdots &amp;  <span class="sc">\\</span></span>
<span id="cb83-1573"><a href="#cb83-1573" aria-hidden="true" tabindex="-1"></a>  \epsilon^l_J &amp;=&amp; (\epsilon_J-\epsilon_l) &amp;&lt;&amp; - V^l_J<span class="sc">\\</span></span>
<span id="cb83-1574"><a href="#cb83-1574" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1575"><a href="#cb83-1575" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb83-1576"><a href="#cb83-1576" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1577"><a href="#cb83-1577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1578"><a href="#cb83-1578" aria-hidden="true" tabindex="-1"></a>The initial vector of errors $\epsilon$ are transformed using the</span>
<span id="cb83-1579"><a href="#cb83-1579" aria-hidden="true" tabindex="-1"></a>following transformation: $\epsilon^l = M^l \epsilon$, where the transformation matrix $M^l$ is a $(J-1) \times J$ matrix</span>
<span id="cb83-1580"><a href="#cb83-1580" aria-hidden="true" tabindex="-1"></a>obtained by inserting in an identity matrix a $l^{\mbox{th}}$ column</span>
<span id="cb83-1581"><a href="#cb83-1581" aria-hidden="true" tabindex="-1"></a>of $-1$. For example, if $J = 4$ and $l = 3$:</span>
<span id="cb83-1582"><a href="#cb83-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1583"><a href="#cb83-1583" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1584"><a href="#cb83-1584" aria-hidden="true" tabindex="-1"></a>M^3 =</span>
<span id="cb83-1585"><a href="#cb83-1585" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1586"><a href="#cb83-1586" aria-hidden="true" tabindex="-1"></a>\begin{array}{cccc}</span>
<span id="cb83-1587"><a href="#cb83-1587" aria-hidden="true" tabindex="-1"></a>1 &amp; 0 &amp; -1 &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1588"><a href="#cb83-1588" aria-hidden="true" tabindex="-1"></a>0 &amp; 1 &amp; -1 &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1589"><a href="#cb83-1589" aria-hidden="true" tabindex="-1"></a>0 &amp; 0 &amp; -1 &amp; 1 <span class="sc">\\</span></span>
<span id="cb83-1590"><a href="#cb83-1590" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1591"><a href="#cb83-1591" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1592"><a href="#cb83-1592" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1593"><a href="#cb83-1593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1594"><a href="#cb83-1594" aria-hidden="true" tabindex="-1"></a>The covariance matrix of the error differences is:</span>
<span id="cb83-1595"><a href="#cb83-1595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1596"><a href="#cb83-1596" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1597"><a href="#cb83-1597" aria-hidden="true" tabindex="-1"></a>\mbox{V}\left(\epsilon^l\right)=\mbox{V}\left(M^l\epsilon\right)</span>
<span id="cb83-1598"><a href="#cb83-1598" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1599"><a href="#cb83-1599" aria-hidden="true" tabindex="-1"></a>M^l\mbox{V}\left(\epsilon\right){M^l}^{\top}</span>
<span id="cb83-1600"><a href="#cb83-1600" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1601"><a href="#cb83-1601" aria-hidden="true" tabindex="-1"></a>M^l\Omega{M^l}^{\top}</span>
<span id="cb83-1602"><a href="#cb83-1602" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cov-err_diff-mprobit}</span>
<span id="cb83-1603"><a href="#cb83-1603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1604"><a href="#cb83-1604" aria-hidden="true" tabindex="-1"></a>The probability of choosing $l$ is then:</span>
<span id="cb83-1605"><a href="#cb83-1605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1606"><a href="#cb83-1606" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1607"><a href="#cb83-1607" aria-hidden="true" tabindex="-1"></a>P_l =\mbox{P}(\epsilon^l_1&lt;-V_1^l \;<span class="sc">\&amp;</span>\; \epsilon^l_2&lt;-V_2^l \;<span class="sc">\&amp;</span>\; ... \; \epsilon^l_J&lt;-V_J^l)</span>
<span id="cb83-1608"><a href="#cb83-1608" aria-hidden="true" tabindex="-1"></a>$$ {#eq-prob_choice_probit}</span>
<span id="cb83-1609"><a href="#cb83-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1610"><a href="#cb83-1610" aria-hidden="true" tabindex="-1"></a>with the hypothesis of normal distribution, this writes:</span>
<span id="cb83-1611"><a href="#cb83-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1612"><a href="#cb83-1612" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1613"><a href="#cb83-1613" aria-hidden="true" tabindex="-1"></a>P_l = \int_{-\infty}^{-V_1^l}\int_{-\infty}^{-V_2^l}...\int_{-\infty}^{-V_J^l}\phi(\epsilon^l)</span>
<span id="cb83-1614"><a href="#cb83-1614" aria-hidden="true" tabindex="-1"></a>d\epsilon^l_1 d\epsilon^l_2... d^l_J</span>
<span id="cb83-1615"><a href="#cb83-1615" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1616"><a href="#cb83-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1617"><a href="#cb83-1617" aria-hidden="true" tabindex="-1"></a>with :</span>
<span id="cb83-1618"><a href="#cb83-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1619"><a href="#cb83-1619" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1620"><a href="#cb83-1620" aria-hidden="true" tabindex="-1"></a>\phi\left(\epsilon^l\right)=\frac{1}{(2\pi)^{(J-1)/2}\mid\Omega^l\mid^{1/2}}</span>
<span id="cb83-1621"><a href="#cb83-1621" aria-hidden="true" tabindex="-1"></a>e^{-\frac{1}{2}\epsilon^l{\Omega^l}^{-1}\epsilon^l}</span>
<span id="cb83-1622"><a href="#cb83-1622" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1623"><a href="#cb83-1623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1624"><a href="#cb83-1624" aria-hidden="true" tabindex="-1"></a>Two problems arise with this model:</span>
<span id="cb83-1625"><a href="#cb83-1625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1626"><a href="#cb83-1626" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the identified parameters are the elements</span>
<span id="cb83-1627"><a href="#cb83-1627" aria-hidden="true" tabindex="-1"></a>  of $\Omega^l$ and not of $\Omega$. We must then carefully investigate</span>
<span id="cb83-1628"><a href="#cb83-1628" aria-hidden="true" tabindex="-1"></a>  the meanings of these elements,</span>
<span id="cb83-1629"><a href="#cb83-1629" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the probability is a $J-1$ integral,</span>
<span id="cb83-1630"><a href="#cb83-1630" aria-hidden="true" tabindex="-1"></a>  which should be numerically computed. The relevant strategy in this</span>
<span id="cb83-1631"><a href="#cb83-1631" aria-hidden="true" tabindex="-1"></a>  context is to use simulations.</span>
<span id="cb83-1632"><a href="#cb83-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1633"><a href="#cb83-1633" aria-hidden="true" tabindex="-1"></a><span class="fu">### Identification</span></span>
<span id="cb83-1634"><a href="#cb83-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1635"><a href="#cb83-1635" aria-hidden="true" tabindex="-1"></a>The meaningful parameters are those of the covariance matrix of the</span>
<span id="cb83-1636"><a href="#cb83-1636" aria-hidden="true" tabindex="-1"></a>error $\Omega$. For example, with $J = 3$:</span>
<span id="cb83-1637"><a href="#cb83-1637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1638"><a href="#cb83-1638" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1639"><a href="#cb83-1639" aria-hidden="true" tabindex="-1"></a>\Omega =</span>
<span id="cb83-1640"><a href="#cb83-1640" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1641"><a href="#cb83-1641" aria-hidden="true" tabindex="-1"></a>\begin{array}{ccc}</span>
<span id="cb83-1642"><a href="#cb83-1642" aria-hidden="true" tabindex="-1"></a>\sigma_1 ^ 2 &amp; \sigma_{12} &amp; \sigma_{13}  <span class="sc">\\</span></span>
<span id="cb83-1643"><a href="#cb83-1643" aria-hidden="true" tabindex="-1"></a>\sigma_{21} &amp; \sigma_2^2 &amp; \sigma_{23} <span class="sc">\\</span></span>
<span id="cb83-1644"><a href="#cb83-1644" aria-hidden="true" tabindex="-1"></a>\sigma_{31} &amp; \sigma_{32} &amp; \sigma_3^3 <span class="sc">\\</span></span>
<span id="cb83-1645"><a href="#cb83-1645" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1646"><a href="#cb83-1646" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1647"><a href="#cb83-1647" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1648"><a href="#cb83-1648" aria-hidden="true" tabindex="-1"></a>Computing @eq-cov-err_diff-mprobit for $l=1$, we get:</span>
<span id="cb83-1649"><a href="#cb83-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1650"><a href="#cb83-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1651"><a href="#cb83-1651" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1652"><a href="#cb83-1652" aria-hidden="true" tabindex="-1"></a>\Omega^1 = M^1 \Omega {M^1}^{\top}=</span>
<span id="cb83-1653"><a href="#cb83-1653" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1654"><a href="#cb83-1654" aria-hidden="true" tabindex="-1"></a>\begin{array}{cc}</span>
<span id="cb83-1655"><a href="#cb83-1655" aria-hidden="true" tabindex="-1"></a>\sigma_1^2+\sigma_2^2-2\sigma_{12} &amp; \sigma_1^2 + \sigma_{23} - \sigma_{12} -\sigma_{13} <span class="sc">\\</span></span>
<span id="cb83-1656"><a href="#cb83-1656" aria-hidden="true" tabindex="-1"></a>\sigma_1^2+\sigma_{23}- \sigma_{12} - \sigma_{13} &amp; \sigma_1^2 + \sigma_3^2 - 2 \sigma_{13} <span class="sc">\\</span></span>
<span id="cb83-1657"><a href="#cb83-1657" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1658"><a href="#cb83-1658" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1659"><a href="#cb83-1659" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1660"><a href="#cb83-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1661"><a href="#cb83-1661" aria-hidden="true" tabindex="-1"></a>The overall scale of utility being unidentified, one has to impose the</span>
<span id="cb83-1662"><a href="#cb83-1662" aria-hidden="true" tabindex="-1"></a>value of one of the variance, for example the first one is set to</span>
<span id="cb83-1663"><a href="#cb83-1663" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We then have :</span>
<span id="cb83-1664"><a href="#cb83-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1665"><a href="#cb83-1665" aria-hidden="true" tabindex="-1"></a>$$ \Omega^1 = \left( \begin{array}{cc} 1 &amp; \frac{\sigma_1^2+</span>
<span id="cb83-1666"><a href="#cb83-1666" aria-hidden="true" tabindex="-1"></a>\sigma_{23} - \sigma_{12}</span>
<span id="cb83-1667"><a href="#cb83-1667" aria-hidden="true" tabindex="-1"></a>-\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} <span class="sc">\\</span></span>
<span id="cb83-1668"><a href="#cb83-1668" aria-hidden="true" tabindex="-1"></a>\frac{\sigma_1^2+\sigma_{23}- \sigma_{12} -</span>
<span id="cb83-1669"><a href="#cb83-1669" aria-hidden="true" tabindex="-1"></a>\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} &amp;</span>
<span id="cb83-1670"><a href="#cb83-1670" aria-hidden="true" tabindex="-1"></a>\frac{\sigma_1^2 + \sigma_3^2 - 2</span>
<span id="cb83-1671"><a href="#cb83-1671" aria-hidden="true" tabindex="-1"></a>\sigma_{13}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}} <span class="sc">\\</span> \end{array}</span>
<span id="cb83-1672"><a href="#cb83-1672" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1673"><a href="#cb83-1673" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1674"><a href="#cb83-1674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1675"><a href="#cb83-1675" aria-hidden="true" tabindex="-1"></a>Therefore, out of the six structural parameters of the covariance matrix,</span>
<span id="cb83-1676"><a href="#cb83-1676" aria-hidden="true" tabindex="-1"></a>only three can be identified. Moreover, it's almost impossible to</span>
<span id="cb83-1677"><a href="#cb83-1677" aria-hidden="true" tabindex="-1"></a>interpret these parameters.</span>
<span id="cb83-1678"><a href="#cb83-1678" aria-hidden="true" tabindex="-1"></a>More generally, with $J$ alternatives, the number of the parameters of</span>
<span id="cb83-1679"><a href="#cb83-1679" aria-hidden="true" tabindex="-1"></a>the covariance matrix is $(J+1)\times J/2$ and the number of identified</span>
<span id="cb83-1680"><a href="#cb83-1680" aria-hidden="true" tabindex="-1"></a>parameters is $J\times(J-1)/2-1$.</span>
<span id="cb83-1681"><a href="#cb83-1681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1682"><a href="#cb83-1682" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulations</span></span>
<span id="cb83-1683"><a href="#cb83-1683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1684"><a href="#cb83-1684" aria-hidden="true" tabindex="-1"></a>Let $C^l$ be the Choleski decomposition of the covariance matrix of</span>
<span id="cb83-1685"><a href="#cb83-1685" aria-hidden="true" tabindex="-1"></a>the error differences:\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Choleski decomposition}</span>
<span id="cb83-1686"><a href="#cb83-1686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1687"><a href="#cb83-1687" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1688"><a href="#cb83-1688" aria-hidden="true" tabindex="-1"></a>\Omega^C= {C^l}^{\top}C^l</span>
<span id="cb83-1689"><a href="#cb83-1689" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1690"><a href="#cb83-1690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1691"><a href="#cb83-1691" aria-hidden="true" tabindex="-1"></a>This matrix is an upper triangular matrix of dimension $(J-1)$ :</span>
<span id="cb83-1692"><a href="#cb83-1692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1693"><a href="#cb83-1693" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1694"><a href="#cb83-1694" aria-hidden="true" tabindex="-1"></a>C^l=</span>
<span id="cb83-1695"><a href="#cb83-1695" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1696"><a href="#cb83-1696" aria-hidden="true" tabindex="-1"></a>\begin{array}{ccccc}</span>
<span id="cb83-1697"><a href="#cb83-1697" aria-hidden="true" tabindex="-1"></a>l_{11} &amp; l_{12} &amp; l_{13} &amp;... &amp; l_{1(J-1)} <span class="sc">\\</span></span>
<span id="cb83-1698"><a href="#cb83-1698" aria-hidden="true" tabindex="-1"></a>0 &amp; l_{22} &amp; l_{23} &amp; ... &amp; l_{2(J-1)} <span class="sc">\\</span></span>
<span id="cb83-1699"><a href="#cb83-1699" aria-hidden="true" tabindex="-1"></a>0 &amp; 0 &amp; l_{33} &amp; ... &amp; l_{3(J-1)} <span class="sc">\\</span></span>
<span id="cb83-1700"><a href="#cb83-1700" aria-hidden="true" tabindex="-1"></a>\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span></span>
<span id="cb83-1701"><a href="#cb83-1701" aria-hidden="true" tabindex="-1"></a>0 &amp; 0 &amp; 0 &amp; ... &amp; l_{(J-1)(J-1)} <span class="sc">\\</span></span>
<span id="cb83-1702"><a href="#cb83-1702" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1703"><a href="#cb83-1703" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1704"><a href="#cb83-1704" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1705"><a href="#cb83-1705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1706"><a href="#cb83-1706" aria-hidden="true" tabindex="-1"></a>Let $\nu$ be a vector of standard normal deviates: $\nu \sim \mathcal{N}(0, I)$</span>
<span id="cb83-1707"><a href="#cb83-1707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1708"><a href="#cb83-1708" aria-hidden="true" tabindex="-1"></a>Therefore, we have :</span>
<span id="cb83-1709"><a href="#cb83-1709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1710"><a href="#cb83-1710" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1711"><a href="#cb83-1711" aria-hidden="true" tabindex="-1"></a>\mbox{V}\left({C^l}^\top\nu\right)={C^l}^\top V(\nu){C^l}={C^l}^{\top}IC^l=\Omega^l</span>
<span id="cb83-1712"><a href="#cb83-1712" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1713"><a href="#cb83-1713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1714"><a href="#cb83-1714" aria-hidden="true" tabindex="-1"></a>Therefore, if we draw a vector of standard normal deviates $\nu$ and</span>
<span id="cb83-1715"><a href="#cb83-1715" aria-hidden="true" tabindex="-1"></a>apply to it this transformation, we get a realization of $\epsilon^l$.</span>
<span id="cb83-1716"><a href="#cb83-1716" aria-hidden="true" tabindex="-1"></a>This probability of choosing $l$ given by @eq-prob_choice_probit can be written as a product of conditional and marginal probabilities:</span>
<span id="cb83-1717"><a href="#cb83-1717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1718"><a href="#cb83-1718" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1719"><a href="#cb83-1719" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb83-1720"><a href="#cb83-1720" aria-hidden="true" tabindex="-1"></a>  P_l &amp;=&amp; \mbox{P}(\epsilon^l_1&lt;- V_1^l \;<span class="sc">\&amp;</span>\; \epsilon^l_2&lt;-V_2^l \;<span class="sc">\&amp;</span>\; ... \;<span class="sc">\&amp;</span>\; \epsilon^l_J&lt;-V_J^l))<span class="sc">\\</span></span>
<span id="cb83-1721"><a href="#cb83-1721" aria-hidden="true" tabindex="-1"></a>  &amp;=&amp; \mbox{P}(\epsilon^l_1&lt;- V_1^l))<span class="sc">\\</span></span>
<span id="cb83-1722"><a href="#cb83-1722" aria-hidden="true" tabindex="-1"></a>  &amp;\times&amp;\mbox{P}(\epsilon^l_2&lt;-V_2^l \mid \epsilon^l_1&lt;-V_1^l) <span class="sc">\\</span></span>
<span id="cb83-1723"><a href="#cb83-1723" aria-hidden="true" tabindex="-1"></a>  &amp;\times&amp;\mbox{P}(\epsilon^l_3&lt;-V_3^l \mid \epsilon^l_1&lt;-V_1^l \;<span class="sc">\&amp;</span>\; \epsilon^l_2&lt;-V_2^l) <span class="sc">\\</span></span>
<span id="cb83-1724"><a href="#cb83-1724" aria-hidden="true" tabindex="-1"></a>  &amp; \vdots &amp; <span class="sc">\\</span></span>
<span id="cb83-1725"><a href="#cb83-1725" aria-hidden="true" tabindex="-1"></a>  &amp;\times&amp;\mbox{P}(\epsilon^l_J&lt;-V_J^l \mid \epsilon^l_1&lt;-V_1^l \;<span class="sc">\&amp;</span>\; ... \;<span class="sc">\&amp;</span>\; \epsilon^l_{J-1}&lt;-V_{J-1}^l)) <span class="sc">\\</span></span>
<span id="cb83-1726"><a href="#cb83-1726" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1727"><a href="#cb83-1727" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1728"><a href="#cb83-1728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1729"><a href="#cb83-1729" aria-hidden="true" tabindex="-1"></a>The vector of error difference deviates is:</span>
<span id="cb83-1730"><a href="#cb83-1730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1731"><a href="#cb83-1731" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1732"><a href="#cb83-1732" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1733"><a href="#cb83-1733" aria-hidden="true" tabindex="-1"></a>\begin{array}{c}</span>
<span id="cb83-1734"><a href="#cb83-1734" aria-hidden="true" tabindex="-1"></a>  \epsilon^l_1 <span class="sc">\\</span> \epsilon^l_2 <span class="sc">\\</span> \epsilon^l_3 <span class="sc">\\</span> \vdots <span class="sc">\\</span> \epsilon^l_J</span>
<span id="cb83-1735"><a href="#cb83-1735" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1736"><a href="#cb83-1736" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1737"><a href="#cb83-1737" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1738"><a href="#cb83-1738" aria-hidden="true" tabindex="-1"></a>{C^l} ^ \top \nu</span>
<span id="cb83-1739"><a href="#cb83-1739" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1740"><a href="#cb83-1740" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1741"><a href="#cb83-1741" aria-hidden="true" tabindex="-1"></a>\begin{array}{ccccc}</span>
<span id="cb83-1742"><a href="#cb83-1742" aria-hidden="true" tabindex="-1"></a>l_{11} &amp; 0 &amp; 0 &amp;... &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1743"><a href="#cb83-1743" aria-hidden="true" tabindex="-1"></a>l_{12} &amp; l_{22} &amp; 0 &amp; ... &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1744"><a href="#cb83-1744" aria-hidden="true" tabindex="-1"></a>l_{13} &amp; l_{23} &amp; l_{33} &amp; ... &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1745"><a href="#cb83-1745" aria-hidden="true" tabindex="-1"></a>\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span></span>
<span id="cb83-1746"><a href="#cb83-1746" aria-hidden="true" tabindex="-1"></a>l_{1(J-1)} &amp; l_{2(J-1)} &amp; l_{3(J-1)} &amp; ... &amp; l_{(J-1)(J-1)} <span class="sc">\\</span></span>
<span id="cb83-1747"><a href="#cb83-1747" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1748"><a href="#cb83-1748" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1749"><a href="#cb83-1749" aria-hidden="true" tabindex="-1"></a>\times</span>
<span id="cb83-1750"><a href="#cb83-1750" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1751"><a href="#cb83-1751" aria-hidden="true" tabindex="-1"></a>\begin{array}{c}</span>
<span id="cb83-1752"><a href="#cb83-1752" aria-hidden="true" tabindex="-1"></a>\nu_1 <span class="sc">\\</span> \nu_2 <span class="sc">\\</span> \nu_3 <span class="sc">\\</span> \vdots <span class="sc">\\</span> \nu_J</span>
<span id="cb83-1753"><a href="#cb83-1753" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1754"><a href="#cb83-1754" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1755"><a href="#cb83-1755" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1756"><a href="#cb83-1756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1757"><a href="#cb83-1757" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1758"><a href="#cb83-1758" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1759"><a href="#cb83-1759" aria-hidden="true" tabindex="-1"></a>\begin{array}{c}</span>
<span id="cb83-1760"><a href="#cb83-1760" aria-hidden="true" tabindex="-1"></a>  \epsilon^l_1 <span class="sc">\\</span> \epsilon^l_2 <span class="sc">\\</span> \epsilon^l_3 <span class="sc">\\</span> \vdots <span class="sc">\\</span> \epsilon^l_J</span>
<span id="cb83-1761"><a href="#cb83-1761" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1762"><a href="#cb83-1762" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1763"><a href="#cb83-1763" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb83-1764"><a href="#cb83-1764" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb83-1765"><a href="#cb83-1765" aria-hidden="true" tabindex="-1"></a>\begin{array}{l}</span>
<span id="cb83-1766"><a href="#cb83-1766" aria-hidden="true" tabindex="-1"></a>l_{11}\nu_1 <span class="sc">\\</span></span>
<span id="cb83-1767"><a href="#cb83-1767" aria-hidden="true" tabindex="-1"></a>l_{12}\nu_1+l_{22}\nu_2 <span class="sc">\\</span></span>
<span id="cb83-1768"><a href="#cb83-1768" aria-hidden="true" tabindex="-1"></a>l_{13}\nu_1+l_{23}\nu_2 + l_{33}\nu_3<span class="sc">\\</span></span>
<span id="cb83-1769"><a href="#cb83-1769" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb83-1770"><a href="#cb83-1770" aria-hidden="true" tabindex="-1"></a>l_{1(J-1)}\nu_1+l_{2(J-1)}\nu_2+...+l_{(J-1)(J-1)}\nu_{J-1}</span>
<span id="cb83-1771"><a href="#cb83-1771" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb83-1772"><a href="#cb83-1772" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb83-1773"><a href="#cb83-1773" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb83-1774"><a href="#cb83-1774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1775"><a href="#cb83-1775" aria-hidden="true" tabindex="-1"></a>Let's now investigate the marginal and conditional probabilities:</span>
<span id="cb83-1776"><a href="#cb83-1776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1777"><a href="#cb83-1777" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the first is simply the marginal probability for a standard</span>
<span id="cb83-1778"><a href="#cb83-1778" aria-hidden="true" tabindex="-1"></a>  normal deviate, therefore we have:</span>
<span id="cb83-1779"><a href="#cb83-1779" aria-hidden="true" tabindex="-1"></a>  $\mbox{P}(\epsilon^l_1&lt;-V_1^l) = \Phi\left(-\frac{V_1^l}{l_{11}}\right)$</span>
<span id="cb83-1780"><a href="#cb83-1780" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the second is, for a given value of $\nu_1$ equal to</span>
<span id="cb83-1781"><a href="#cb83-1781" aria-hidden="true" tabindex="-1"></a>  $\Phi\left(-\frac{V^l_2+l_{21}\nu_1}{l_{22}}\right)$. We then have to compute the</span>
<span id="cb83-1782"><a href="#cb83-1782" aria-hidden="true" tabindex="-1"></a>  mean of this expression for any value of $\nu_1$ lower than</span>
<span id="cb83-1783"><a href="#cb83-1783" aria-hidden="true" tabindex="-1"></a>  $-\frac{V^l_1}{l_{11}}$. We then have, denoting $\bar{\phi}_1$ the truncated</span>
<span id="cb83-1784"><a href="#cb83-1784" aria-hidden="true" tabindex="-1"></a>  normal density:</span>
<span id="cb83-1785"><a href="#cb83-1785" aria-hidden="true" tabindex="-1"></a>  $$\mbox{P}(\epsilon^l_2&lt;-V_2^l)=\int_{-\infty}^{-\frac{V^l_1}{l_{11}}}\Phi\left(-\frac{V^l_2+l_{21}\nu_1}{l_{22}}\right)</span>
<span id="cb83-1786"><a href="#cb83-1786" aria-hidden="true" tabindex="-1"></a>  \bar{\phi}_1(\nu_1)d\nu_1$$</span>
<span id="cb83-1787"><a href="#cb83-1787" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the third is, for given values of $\nu_1$ and $\nu_2$</span>
<span id="cb83-1788"><a href="#cb83-1788" aria-hidden="true" tabindex="-1"></a>  equal to:</span>
<span id="cb83-1789"><a href="#cb83-1789" aria-hidden="true" tabindex="-1"></a>  $\Phi\left(-\frac{V^l_3+l_{31}\nu_1+l_{32}\nu_2}{l_{33}}\right)$. We</span>
<span id="cb83-1790"><a href="#cb83-1790" aria-hidden="true" tabindex="-1"></a>  then have:</span>
<span id="cb83-1791"><a href="#cb83-1791" aria-hidden="true" tabindex="-1"></a>  $$\mbox{P}(\epsilon^l_3&lt;-V_3^l)=\int_{-\infty}^{-\frac{V^l_1}{l_{11}}}\int_{-\infty}^{-\frac{V^l_2+l_{21}\nu_1}{l_{22}}}</span>
<span id="cb83-1792"><a href="#cb83-1792" aria-hidden="true" tabindex="-1"></a>  \Phi\left(-\frac{V^l_3+l_{31}\nu_1+l_{32}\nu_2}{l_{33}}\right)\bar{\phi}_1(\nu_1)\bar{\phi}_2(\nu_2)d\nu_1d\nu_2$$</span>
<span id="cb83-1793"><a href="#cb83-1793" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and so on.</span>
<span id="cb83-1794"><a href="#cb83-1794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1795"><a href="#cb83-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1796"><a href="#cb83-1796" aria-hidden="true" tabindex="-1"></a>These probabilities can easily be simulated by drawing numbers from a</span>
<span id="cb83-1797"><a href="#cb83-1797" aria-hidden="true" tabindex="-1"></a>truncated normal distribution. This so called GHK (for Geweke, Hajivassiliou and Keane) algorithm <span class="co">[</span><span class="ot">see for example @GEWE:KEAN:RUNK:94</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Geweke}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Keane}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Runkle} can be described as follow:</span>
<span id="cb83-1798"><a href="#cb83-1798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1799"><a href="#cb83-1799" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>compute $\Phi\left(-\frac{V_1^l}{l_{11}}\right)$,</span>
<span id="cb83-1800"><a href="#cb83-1800" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>draw a number called $\nu_1^r$ from a standard normal</span>
<span id="cb83-1801"><a href="#cb83-1801" aria-hidden="true" tabindex="-1"></a>  distribution upper-truncated at $-\frac{V_1^l}{l_{11}}$ and compute</span>
<span id="cb83-1802"><a href="#cb83-1802" aria-hidden="true" tabindex="-1"></a>  $\Phi\left(-\frac{V^l_2+l_{12}\nu_1^r}{l_{22}}\right)$,</span>
<span id="cb83-1803"><a href="#cb83-1803" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>draw a number called $\nu_2^r$ from a standard normal</span>
<span id="cb83-1804"><a href="#cb83-1804" aria-hidden="true" tabindex="-1"></a>  distribution upper-truncated at</span>
<span id="cb83-1805"><a href="#cb83-1805" aria-hidden="true" tabindex="-1"></a>  $-\frac{V^l_2+l_{12}\nu_1^r}{l_{22}}$ and compute</span>
<span id="cb83-1806"><a href="#cb83-1806" aria-hidden="true" tabindex="-1"></a>  $\Phi\left(-\frac{V^l_3+l_{13}\nu_1^r+l_{23}\nu_2^r}{l_{33}}\right)$,</span>
<span id="cb83-1807"><a href="#cb83-1807" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$...$ draw a number called $\nu_{J-1}^r$ from a standard</span>
<span id="cb83-1808"><a href="#cb83-1808" aria-hidden="true" tabindex="-1"></a>  normal distribution upper-truncated at $-\frac{V^l_{J-1}+l_{1(J-1)}\nu_1^r+... l_{(J-2)(J-1)}\nu_{J-2}^r}{l_{(J-1)(J-1)}}$,</span>
<span id="cb83-1809"><a href="#cb83-1809" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>multiply all these probabilities and get a realization of the</span>
<span id="cb83-1810"><a href="#cb83-1810" aria-hidden="true" tabindex="-1"></a>  probability of choosing $l$ called $P^r_l$,</span>
<span id="cb83-1811"><a href="#cb83-1811" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>repeat all these steps many times and average all these</span>
<span id="cb83-1812"><a href="#cb83-1812" aria-hidden="true" tabindex="-1"></a>  probabilities; this average is an estimation of the probability:</span>
<span id="cb83-1813"><a href="#cb83-1813" aria-hidden="true" tabindex="-1"></a>  $\bar{P}_l = \sum_{r=1}^R P^r_l/R$.</span>
<span id="cb83-1814"><a href="#cb83-1814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1815"><a href="#cb83-1815" aria-hidden="true" tabindex="-1"></a>Several points should be noted concerning this algorithm:</span>
<span id="cb83-1816"><a href="#cb83-1816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1817"><a href="#cb83-1817" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the utility differences should be computed respective to the</span>
<span id="cb83-1818"><a href="#cb83-1818" aria-hidden="true" tabindex="-1"></a>  chosen alternative for each individual,</span>
<span id="cb83-1819"><a href="#cb83-1819" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the Choleski decomposition used should rely on the same\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Choleski decomposition}</span>
<span id="cb83-1820"><a href="#cb83-1820" aria-hidden="true" tabindex="-1"></a>  covariance matrix of the errors. One method to attained this goal is</span>
<span id="cb83-1821"><a href="#cb83-1821" aria-hidden="true" tabindex="-1"></a>  to start from a given difference, e.g., the difference</span>
<span id="cb83-1822"><a href="#cb83-1822" aria-hidden="true" tabindex="-1"></a>  respective with the first alternative. The vector of error</span>
<span id="cb83-1823"><a href="#cb83-1823" aria-hidden="true" tabindex="-1"></a>  difference is then $\epsilon^1$ and its covariance matrix is</span>
<span id="cb83-1824"><a href="#cb83-1824" aria-hidden="true" tabindex="-1"></a>  $\Omega^1={L^1}^{\top}L^1$. To apply a difference with another alternative $l$, we construct a matrix called $S^l$ which is</span>
<span id="cb83-1825"><a href="#cb83-1825" aria-hidden="true" tabindex="-1"></a>  obtained by using a $J-2$ identity matrix, adding a first row of 0</span>
<span id="cb83-1826"><a href="#cb83-1826" aria-hidden="true" tabindex="-1"></a>  and inserting a column of $-1$ at the $l-1$th</span>
<span id="cb83-1827"><a href="#cb83-1827" aria-hidden="true" tabindex="-1"></a>  position. For example, with four alternatives and $l=3$, we have:</span>
<span id="cb83-1828"><a href="#cb83-1828" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb83-1829"><a href="#cb83-1829" aria-hidden="true" tabindex="-1"></a>  $$S^3=</span>
<span id="cb83-1830"><a href="#cb83-1830" aria-hidden="true" tabindex="-1"></a>  \left(</span>
<span id="cb83-1831"><a href="#cb83-1831" aria-hidden="true" tabindex="-1"></a>    \begin{array}{ccc}</span>
<span id="cb83-1832"><a href="#cb83-1832" aria-hidden="true" tabindex="-1"></a>      0 &amp; -1 &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1833"><a href="#cb83-1833" aria-hidden="true" tabindex="-1"></a>      1 &amp; -1 &amp; 0 <span class="sc">\\</span></span>
<span id="cb83-1834"><a href="#cb83-1834" aria-hidden="true" tabindex="-1"></a>      0 &amp; -1 &amp; 1 <span class="sc">\\</span></span>
<span id="cb83-1835"><a href="#cb83-1835" aria-hidden="true" tabindex="-1"></a>    \end{array}</span>
<span id="cb83-1836"><a href="#cb83-1836" aria-hidden="true" tabindex="-1"></a>  \right)</span>
<span id="cb83-1837"><a href="#cb83-1837" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb83-1838"><a href="#cb83-1838" aria-hidden="true" tabindex="-1"></a>  The elements of the Choleski decomposition of the covariance matrix</span>
<span id="cb83-1839"><a href="#cb83-1839" aria-hidden="true" tabindex="-1"></a>  is then obtained as follow:</span>
<span id="cb83-1840"><a href="#cb83-1840" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb83-1841"><a href="#cb83-1841" aria-hidden="true" tabindex="-1"></a>  \Omega^l = S^l \Omega^1 {S^l}^{\top}=L^l {L^l}^{\top}</span>
<span id="cb83-1842"><a href="#cb83-1842" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb83-1843"><a href="#cb83-1843" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>to compute draws from a normal distribution truncated at $a$,</span>
<span id="cb83-1844"><a href="#cb83-1844" aria-hidden="true" tabindex="-1"></a>  the following trick is used : take a draw $\mu$ from a uniform</span>
<span id="cb83-1845"><a href="#cb83-1845" aria-hidden="true" tabindex="-1"></a>  distribution (between 0 and 1); then $\nu = \Phi^{-1}\left(\mu</span>
<span id="cb83-1846"><a href="#cb83-1846" aria-hidden="true" tabindex="-1"></a>    \Phi(a)\right)$ is a draw from a normal distribution truncated at</span>
<span id="cb83-1847"><a href="#cb83-1847" aria-hidden="true" tabindex="-1"></a>  $a$.</span>
<span id="cb83-1848"><a href="#cb83-1848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1849"><a href="#cb83-1849" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{multinomial probit model|)}</span>
<span id="cb83-1850"><a href="#cb83-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1851"><a href="#cb83-1851" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application</span></span>
<span id="cb83-1852"><a href="#cb83-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1853"><a href="#cb83-1853" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-1854"><a href="#cb83-1854" aria-hidden="true" tabindex="-1"></a>In @sec-appl_mult_logit, we estimated a multinomial logit for mode choice in the Toronto-Montreal corridor, using <span class="in">`cost`</span> and <span class="in">`freq`</span> as alternative specific covariates with a generic coefficient, <span class="in">`income`</span> as a choice situation specific covariate and <span class="in">`time`</span> as an alternative specific covariate with a specific coefficient. We fit the same model using this time a probit. This is simply done by setting the <span class="in">`probit`</span> argument to <span class="in">`TRUE`</span>.</span>
<span id="cb83-1855"><a href="#cb83-1855" aria-hidden="true" tabindex="-1"></a>\idxfun{mlogit}{mlogit}</span>
<span id="cb83-1856"><a href="#cb83-1856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1859"><a href="#cb83-1859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1860"><a href="#cb83-1860" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true</span></span>
<span id="cb83-1861"><a href="#cb83-1861" aria-hidden="true" tabindex="-1"></a>pbt <span class="ot">&lt;-</span> <span class="fu">mlogit</span>(<span class="at">formula =</span> choice <span class="sc">~</span> cost <span class="sc">+</span> freq <span class="sc">|</span> income <span class="sc">|</span> time, <span class="at">data =</span> MC, </span>
<span id="cb83-1862"><a href="#cb83-1862" aria-hidden="true" tabindex="-1"></a>              <span class="at">probit =</span> <span class="cn">TRUE</span>, <span class="at">alt.subset =</span> <span class="fu">c</span>(<span class="st">"car"</span>, <span class="st">"train"</span>, <span class="st">"air"</span>), </span>
<span id="cb83-1863"><a href="#cb83-1863" aria-hidden="true" tabindex="-1"></a>              <span class="at">reflevel =</span> <span class="st">"car"</span>)</span>
<span id="cb83-1864"><a href="#cb83-1864" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1865"><a href="#cb83-1865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1866"><a href="#cb83-1866" aria-hidden="true" tabindex="-1"></a>As previously, we want to predict the effect of a reduction of 20% of a train's fare:</span>
<span id="cb83-1867"><a href="#cb83-1867" aria-hidden="true" tabindex="-1"></a>\idxfun{fitted}{stats}\idxfun{predict}{stats}\idxfun{rbind}{base}\idxfun{apply}{base}</span>
<span id="cb83-1868"><a href="#cb83-1868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1871"><a href="#cb83-1871" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1872"><a href="#cb83-1872" aria-hidden="true" tabindex="-1"></a>Oprob <span class="ot">&lt;-</span> <span class="fu">fitted</span>(pbt, <span class="at">type =</span> <span class="st">"probabilities"</span>)</span>
<span id="cb83-1873"><a href="#cb83-1873" aria-hidden="true" tabindex="-1"></a>Nprob <span class="ot">&lt;-</span> <span class="fu">predict</span>(pbt, <span class="at">newdata =</span> NMC)</span>
<span id="cb83-1874"><a href="#cb83-1874" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(<span class="at">old =</span> <span class="fu">apply</span>(Oprob, <span class="dv">2</span>, mean), <span class="at">new =</span> <span class="fu">apply</span>(Nprob, <span class="dv">2</span>, mean))</span>
<span id="cb83-1875"><a href="#cb83-1875" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1876"><a href="#cb83-1876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1877"><a href="#cb83-1877" aria-hidden="true" tabindex="-1"></a>With this model, the IIA property is not operative, as the ratio of probabilities of choosing air and car is no longer the same before and after the change of a train's fare.</span>
<span id="cb83-1878"><a href="#cb83-1878" aria-hidden="true" tabindex="-1"></a>\idxfun{head}{utils}</span>
<span id="cb83-1879"><a href="#cb83-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1882"><a href="#cb83-1882" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb83-1883"><a href="#cb83-1883" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb83-1884"><a href="#cb83-1884" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Nprob[, <span class="st">"air"</span>] <span class="sc">/</span> Nprob[, <span class="st">"car"</span>])</span>
<span id="cb83-1885"><a href="#cb83-1885" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Oprob[, <span class="st">"air"</span>] <span class="sc">/</span> Oprob[, <span class="st">"car"</span>])</span>
<span id="cb83-1886"><a href="#cb83-1886" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb83-1887"><a href="#cb83-1887" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{toronto<span class="sc">\_</span>montreal}{micsr.data}</span>
<span id="cb83-1888"><a href="#cb83-1888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-1889"><a href="#cb83-1889" aria-hidden="true" tabindex="-1"></a>\backmatter</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>