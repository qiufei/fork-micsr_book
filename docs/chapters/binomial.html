<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Microeconometrics with R - 10&nbsp; Binomial models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/tobit.html" rel="next">
<link href="../special_responses.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="../site_libs/kePrint/kePrint.js"></script><link href="../site_libs/lightable/lightable.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Microeconometrics with R</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../OLS.html" class="sidebar-item-text sidebar-link">Ordinary least squares estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple linear regression model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/simple_regression_properties.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistical properties of the simple linear estimator</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/multiple_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Multiple regression model</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/coefficients.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interpretation of the Coefficients</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../beyond_OLS.html" class="sidebar-item-text sidebar-link">Beyond the OLS estimator</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/maximum_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Maximum likelihood estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/non_spherical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Non-spherical disturbances</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/endogeneity.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Endogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/treateff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Treatment effect</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/spatial.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial econometrics</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../special_responses.html" class="sidebar-item-text sidebar-link">Special responses</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/binomial.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/tobit.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/count.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Count data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/duration.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Duration models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/rum.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Discrete choice models</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sec-func_form_binom" id="toc-sec-func_form_binom" class="nav-link active" data-scroll-target="#sec-func_form_binom"><span class="toc-section-number">10.1</span>  Functional form and the linear-probability, probit and logit model</a></li>
  <li>
<a href="#sec-struct_binom" id="toc-sec-struct_binom" class="nav-link" data-scroll-target="#sec-struct_binom"><span class="toc-section-number">10.2</span>  Structural models for binomial responses</a>
  <ul class="collapse">
<li><a href="#sec-latent_variable" id="toc-sec-latent_variable" class="nav-link" data-scroll-target="#sec-latent_variable">Latent variable and index function</a></li>
  <li><a href="#sec-rum_binomial" id="toc-sec-rum_binomial" class="nav-link" data-scroll-target="#sec-rum_binomial">Random utility model</a></li>
  </ul>
</li>
  <li>
<a href="#sec-glm" id="toc-sec-glm" class="nav-link" data-scroll-target="#sec-glm"><span class="toc-section-number">10.3</span>  Binomial model as a generalized linear model</a>
  <ul class="collapse">
<li><a href="#generalized-linear-models" id="toc-generalized-linear-models" class="nav-link" data-scroll-target="#generalized-linear-models">Generalized linear models</a></li>
  <li><a href="#estimation-with-statsglm" id="toc-estimation-with-statsglm" class="nav-link" data-scroll-target="#estimation-with-statsglm">Estimation with <code>stats::glm</code></a></li>
  </ul>
</li>
  <li>
<a href="#sec-binom_evaluation" id="toc-sec-binom_evaluation" class="nav-link" data-scroll-target="#sec-binom_evaluation"><span class="toc-section-number">10.4</span>  Model estimation, evaluation and testing</a>
  <ul class="collapse">
<li><a href="#sec-estimation_binomial" id="toc-sec-estimation_binomial" class="nav-link" data-scroll-target="#sec-estimation_binomial">Estimation</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation">Evaluation</a></li>
  <li><a href="#testing" id="toc-testing" class="nav-link" data-scroll-target="#testing">Testing</a></li>
  </ul>
</li>
  <li>
<a href="#sec-endog_probit" id="toc-sec-endog_probit" class="nav-link" data-scroll-target="#sec-endog_probit"><span class="toc-section-number">10.5</span>  Endogeneity</a>
  <ul class="collapse">
<li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">Maximum likelihood estimation</a></li>
  <li><a href="#two-step-estimator" id="toc-two-step-estimator" class="nav-link" data-scroll-target="#two-step-estimator">Two-step estimator</a></li>
  <li><a href="#minimum-chi-2-estimator" id="toc-minimum-chi-2-estimator" class="nav-link" data-scroll-target="#minimum-chi-2-estimator">Minimum <span class="math inline">\(\chi ^ 2\)</span> estimator</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">Application</a></li>
  </ul>
</li>
  <li><a href="#sec-ordered" id="toc-sec-ordered" class="nav-link" data-scroll-target="#sec-ordered"><span class="toc-section-number">10.6</span>  Ordered models</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-binomial" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Binomial models</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Binomial responses can take only two mutually exclusive values that can be, without loss of generality coded as 1 and 0. Common examples are transport mode choice (car vs.&nbsp;public transit), working force participation for women, union membership, etc. For this kind of responses, the statistical distribution is obviously a binomial distribution with one trial. This is a major difference with the estimators that will be reviewed in the other chapters of this part, for which assuming a distribution function for the response is a crucial choice. Denoting 1 as “a success” and 0 as “a fail”, this distribution is fully characterized by a unique parameter, <span class="math inline">\(\mu\)</span>, which is the probability of success and is also the expected value of the variable, as: <span class="math inline">\(\mbox{E}(y) = (1 - \mu) \times 0 + \mu \times 1 = \mu\)</span>. The variance of the distribution is: <span class="math inline">\(\mbox{V}(y) = (1 - \mu) (0-\mu) ^ 2+ \mu (1-\mu) ^ 2 = \mu(1-\mu)\)</span>. It is therefore inversely U-shaped, has a maximum for <span class="math inline">\(\mu = 0.5\)</span> (with a value of 0.25) and is symmetric around this value. As <span class="math inline">\(\mu\)</span> tends to 0 or to 1, the variance of <span class="math inline">\(y\)</span> obviously tends to 0 as almost all the values in a given sample will be either equal to 0 or 1.</p>
<p> To get a regression model for a binomial response, we first define an <strong>index function</strong>, also called the <strong>linear predictor</strong>: <span class="math inline">\(\eta_n = \gamma ^ \top z_n = \alpha + \beta ^ \top x_n\)</span>. Then, a function <span class="math inline">\(F\)</span> is chosen that relates this index function to the unique parameter of the binomial distribution: <span class="math inline">\(\mu_n =F(\eta_n)\)</span>. Different choices of <span class="math inline">\(F\)</span> leads to different binomial models.</p>
<p><a href="#sec-func_form_binom"><span>Section&nbsp;10.1</span></a> will present the three most common choices for <span class="math inline">\(F\)</span> which result in the linear probability, the logit and the probit models. <a href="#sec-struct_binom"><span>Section&nbsp;10.2</span></a> will present two distinct structural models that can justify the use of these models. <a href="#sec-glm"><span>Section&nbsp;10.3</span></a> presents the generalized linear models from which the binomial model is a special case. <a href="#sec-binom_evaluation"><span>Section&nbsp;10.4</span></a> is devoted to the estimation, the evaluation and the testing of binomial models. <a href="#sec-endog_probit"><span>Section&nbsp;10.5</span></a> presents relevant estimators when some covariates are endogenous. Finally, <a href="#sec-ordered"><span>Section&nbsp;10.6</span></a> presents the ordered model.</p>
<section id="sec-func_form_binom" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="sec-func_form_binom">
<span class="header-section-number">10.1</span> Functional form and the linear-probability, probit and logit model</h2>
<p> The most obvious choice for <span class="math inline">\(F\)</span> is the identity function, so that <span class="math inline">\(\mu_n = \eta_n = \alpha + \beta ^ \top x_n\)</span>. Therefore, the parameter of the binomial distribution is assumed to be a linear function of the covariates. On the one hand, this choice has several interesting features. It is very simple to estimate, as it is a linear model and, moreover, it can be simply extended to IV estimation. As a linear model, <span class="math inline">\(\frac{\partial\mu_n}{\partial x_{kn}} = \beta_k\)</span>, so that the estimated parameters can be interpreted as the (constant) marginal effects of the corresponding covariate on the probability of success. On the other hand, it has two serious drawbacks. Firstly, the residuals are <span class="math inline">\(y_n - \hat{\mu}_n\)</span> but, as <span class="math inline">\(y_n\)</span> is either 0 or 1, the residuals are respectively <span class="math inline">\(- (\hat{\alpha}+ \hat{\beta} ^ \top x_n)\)</span> or <span class="math inline">\(1 - (\hat{\alpha} + \hat{\beta} ^ \top x_n)\)</span> and therefore depends on the values of <span class="math inline">\(x_n\)</span>. The linear-probability model, estimated by least-squares is therefore inefficient, as the residuals are heteroskedastic and the standard deviations reported by a least squares program are biased. As usual, the solution would be either to estimate the linear-probability model by GLS or to use heteroskedasticity-robust estimator for the covariance matrix of the estimators. Secondly, as the fitted probabilities of success are linear functions of the covariates, they are not bounded by 0 and 1 and, therefore, it is possible that the model will predict, for some observations, probabilities that would be either negative or greater than 1.</p>
<p>Therefore, it is customary to use a functional form <span class="math inline">\(F\)</span> which has the following properties:</p>
<ul>
<li>
<span class="math inline">\(F(z)\)</span> is increasing in <span class="math inline">\(z\)</span>,</li>
<li>
<span class="math inline">\(\lim_{z\rightarrow -\infty} F(z) = 0\)</span>,</li>
<li>
<span class="math inline">\(\lim_{z\rightarrow +\infty} F(z) = 1\)</span>.</li>
</ul>
<p>which are the features of any cumulative density function for continuous variables defined on the whole real line support. Two common choices are the normal (<span class="math inline">\(\Phi\)</span>) and the logistic (<span class="math inline">\(\Lambda\)</span>) distributions: </p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
\Phi(z) &amp;=&amp; \displaystyle \int_{-\infty} ^ z \phi(t) dt = \int_{-\infty} ^ z \frac{1}{\sqrt{2\pi}} e ^{-\frac{1}{2}t ^ 2} dt \\
\Lambda(z) &amp;=&amp; \displaystyle \frac{e^z}{1 + e ^ z}
\end{array}
\right.
\]</span></p>
<p>which lead respectively to the <strong>probit</strong> and <strong>logit</strong> models. The density function for the logistic distribution (obtained by taking the derivative of <span class="math inline">\(\Lambda\)</span>) is <span class="math inline">\(\lambda(z) = \frac{e^z}{(1 + e ^ z) ^ 2}\)</span>. Both density functions are symmetric around 0 and are “bell-shaped”, but they have two important differences, as illustrated in <a href="#fig-normal_logistic">Figure&nbsp;<span>10.1</span></a>:</p>
<ul>
<li>the variance of the standard normal distribution is 1 and is equal to <span class="math inline">\(\pi ^ 2/3\)</span> for the logistic distribution,</li>
<li>the logistic distribution has much heavier tails than the normal density.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-normal_logistic" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="binomial_files/figure-html/fig-normal_logistic-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.1: Logistic and normal densities</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As <span class="math inline">\(\mu_n=F(\eta_n)\)</span> (with <span class="math inline">\(\eta_n = \alpha + \beta ^ \top x_n\)</span>), the marginal effect of the k<sup>th</sup> covariate on the probability is:</p>
<p><span id="eq-meffect_binomial"><span class="math display">\[
\frac{\partial \mu_n}{\partial x_{nk}} = \beta_k f(\eta_n)
\tag{10.1}\]</span></span></p>
<p>where <span class="math inline">\(f\)</span> is the first derivative of <span class="math inline">\(F\)</span>, which is respectively, for the probit and logit models, <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\lambda\)</span>, the normal and logistic densities. Therefore, the marginal effect is obtained by multiplying the coefficient by <span class="math inline">\(f(\eta_n)\)</span> which depends on the value of the covariates for a given observation. Therefore, the marginal effect is observation-dependent, but the ratio of two marginal effects for two covariates is not, as it is obviously, from <a href="#eq-meffect_binomial">Equation&nbsp;<span>10.1</span></a>, equal to the ratio of the two corresponding coefficients. As the coefficient of proportionality is the normal/logistic density, the maximum marginal effect is for <span class="math inline">\(\eta_n = 0\)</span>, which results in a probability of success of 0.5. The corresponding values of the densities are 0.4 and 0.25 for the normal and logistic densities. Therefore, a rule of thumb to interpret coefficients is to multiply them respectively by 0.4 and 0.25 for the probit and logit model to get an estimation of the maximum marginal effect.</p>
<p>The coefficients of the logit and probit can therefore not be compared. This is due to the fact that they are scaled differently, as the standard deviation of the logistic distribution is <span class="math inline">\(\pi/\sqrt{3} \approx 1.81\)</span>, compared to 1 for the normal distribution. Therefore, it would be tempting to multiply the probit coefficients by 1.81 to compare them to the logit coefficients, but <span class="citation" data-cites="AMEM:81">Amemiya (<a href="#ref-AMEM:81" role="doc-biblioref">1981</a>)</span> showed that, empirically, the value of 1.6 performs better. </p>
<p> As an example, we consider the data set used by <span class="citation" data-cites="HORO:93">Horowitz (<a href="#ref-HORO:93" role="doc-biblioref">1993</a>)</span> which concerns the transport mode chosen for work trips by a sample of 842 individuals in Washington DC in the late sixties. The response <code>mode</code> is 1 for car and 0 for transit. The covariates are the in- and out-vehicle times (<code>ivtime</code> and <code>ovtime</code>) and the cost differences between car and transit. Therefore, a positive value indicates that car trip is longer/more expensive than the corresponding trip using public transit. We multiply the cost by 8.42 to obtain dollars in 2022 (the CPI for 2022 is 842 with a 100 base in 1967). The generalized cost of a trip is the sum of the monetary cost and the value of the time spent in the transport. We use two-thirds of the minimum hourly wage (about $1.4 in the US in the late sixties, which is about $8 in dollars of 2022) to valuate an hour of transport: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mode_choice</span> <span class="op">&lt;-</span> <span class="va">mode_choice</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>cost <span class="op">=</span> <span class="va">cost</span> <span class="op">*</span> <span class="fl">8.42</span>,</span>
<span>           gcost <span class="op">=</span> <span class="op">(</span><span class="va">ivtime</span> <span class="op">+</span> <span class="va">ovtime</span><span class="op">)</span> <span class="op">*</span> <span class="fl">8</span> <span class="op">+</span> <span class="va">cost</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To fit the three models, we use the <code><a href="https://rdrr.io/pkg/micsr/man/binomreg.html">micsr::binomreg</a></code> function, which has a <code>link</code> argument which enables to estimate the three models. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lp_m</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, <span class="va">mode_choice</span>, link <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span></span>
<span><span class="va">pt_m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lp_m</span>, link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span></span>
<span><span class="va">lt_m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lp_m</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="fu">gaze</span><span class="op">(</span><span class="va">lp_m</span><span class="op">)</span></span>
<span><span class="co">##       Estimate Std. Error z-value Pr(&gt;|z|)</span></span>
<span><span class="co">## gcost  0.02255    0.00236    9.58   &lt;2e-16</span></span>
<span><span class="fu">gaze</span><span class="op">(</span><span class="va">pt_m</span><span class="op">)</span></span>
<span><span class="co">##       Estimate Std. Error z-value Pr(&gt;|z|)</span></span>
<span><span class="co">## gcost   0.1129     0.0128    8.79   &lt;2e-16</span></span>
<span><span class="fu">gaze</span><span class="op">(</span><span class="va">lt_m</span><span class="op">)</span></span>
<span><span class="co">##       Estimate Std. Error z-value Pr(&gt;|z|)</span></span>
<span><span class="co">## gcost   0.2112     0.0248    8.52   &lt;2e-16</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">

</div>
<p>The coefficient of <code>gcost</code> for the linear-probability model is 0.0226, which means that a one dollar increase of the generalized cost differential will increase the probability of using the car by 2.26 percentage points. If we use the previously described rule of thumb to multiply the probit/logit coefficients by 0.4/0.25 in order to have an upper limit for the marginal effect, we get 5.28 and 4.51 percentage points, which are much higher values than for the linear probability model. This is because the coefficient of the linear model estimates the marginal effect at the sample mean. In our sample, the mean value of the covariate is 2.9. To get comparable marginal effects for the probit/logit models, we should first compute <span class="math inline">\(\hat{\alpha} + \hat{\beta} \bar{x}\)</span> (1.15 and 2 respectively for the probit and logit models) and use these values with the relevant densities (<span class="math inline">\(\phi(1.15) = 0.206\)</span> and <span class="math inline">\(\lambda(2) = 0.105\)</span>). At the sample mean, the marginal effects are then 0.023 and 0.022 and are therefore very close to the linear probability model coefficient. The scatterplot and the fitted probability curves are presented o in <a href="#fig-fitprob">Figure&nbsp;<span>10.2</span></a>. <!-- Note the use of `geom_jitter` so that an a small random vertical --> <!-- distance is added to every point.  --></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fitprob" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="binomial_files/figure-html/fig-fitprob-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.2: Fitted probabilities</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The fitted probabilities are given by a straight line for the linear probability model and by an S curve for the probit and logit models. These last two curves are very similar except for low values of the covariate. Note also that at the sample mean (<span class="math inline">\(x = 2.9\)</span>), the slopes of the three curves are very similar. This illustrates the fact that the three models result in similar marginal effects around the mean value of the covariate. The linear probability model is <span class="math inline">\(\hat{\mu} = 0.774 + 0.023 \times x\)</span>. Therefore, <span class="math inline">\(\hat{\mu}&lt;0\)</span> for <span class="math inline">\(x &lt; - 0.774 / 0.023 = - 34.33\)</span> and <span class="math inline">\(\hat{\mu}&gt;1\)</span> for <span class="math inline">\(x &gt; (1 - 0.774) / 0.023 = 10.007\)</span>. In this sample, there are no observations for which <span class="math inline">\(\hat{\mu} &lt; 0\)</span> but, for 83 out of 842 observations, <span class="math inline">\(\hat{\mu} &gt; 1\)</span>. Finally, the ratio of the logit and probit coefficients is <span class="math inline">\(0.211 / 0.211 = 1.871\)</span>, which is a bit larger than the value of 1.6 suggested by <span class="citation" data-cites="AMEM:81">Amemiya (<a href="#ref-AMEM:81" role="doc-biblioref">1981</a>)</span>. </p>
<p>We now consider a second data set called <code>airbnb</code>, used by <span class="citation" data-cites="EDEL:LUCA:SVIR:17">Edelman, Luca, and Svirsky (<a href="#ref-EDEL:LUCA:SVIR:17" role="doc-biblioref">2017</a>)</span>. The aim of their study is to analyze the presence of racial discrimination on the Airbnb platform. The authors create guest accounts that differ by the first name chosen. More specifically, the race of the applicant is suggested by the choice of the first name, either a “white” (Emily, Sarah, Greg) or an “African American” (Lakisha or Kareem) first name. The response is acceptance and is 1 if the host gave a positive response and 0 otherwise. In our simplified example, we use only three covariates, guest’s race suggested by the first name <code>guest_race</code>, the price <code>price</code> (in logs) and <code>city</code>, the cities where the experience took place (Baltimore, Dallas, Los Angeles, St.&nbsp;Louis and Washington, DC). Note that the mean of the response is <span class="math inline">\(0.45\)</span> which is a distinctive feature of this data set compared to the previous one. As the mean value of the probability of success is close to 50% we can expect that the rule of the thumb which consists of multiplying the logit/probit coefficients by 0.25/0.4 would give an estimated value for the marginal effect close to the one directly obtained in the linear probability model. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">airbnb</span> <span class="op">&lt;-</span> <span class="va">airbnb</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>acceptance <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">acceptance</span> <span class="op">==</span> <span class="st">"no"</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span> <span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">price</span><span class="op">)</span>, <span class="op">!</span> <span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">city</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">lp_a</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">acceptance</span> <span class="op">~</span> <span class="va">guest_race</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">price</span><span class="op">)</span> <span class="op">+</span> <span class="va">city</span>, </span>
<span>                 <span class="va">airbnb</span>, link <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span></span>
<span><span class="va">pt_a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lp_a</span>, link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span></span>
<span><span class="va">lt_a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lp_a</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To summarize the results, we print in <a href="#tbl-compabb">Table&nbsp;<span>10.1</span></a> the coefficients of the linear probability model, those of the logit multiplied by 0.25, those of the probit multiplied by 0.4 and the ratio of the logit and the probit coefficients.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-compabb" class="anchored">
<table class="table table-sm table-striped">
<caption>Table&nbsp;10.1: Comparison of the coefficients for the Airbnb data set</caption>
<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">linear</th>
<th style="text-align: right;">probit</th>
<th style="text-align: right;">logit</th>
<th style="text-align: right;">logit / probit</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.708</td>
<td style="text-align: right;">0.214</td>
<td style="text-align: right;">0.215</td>
<td style="text-align: right;">1.604</td>
</tr>
<tr class="even">
<td style="text-align: left;">guest_raceblack</td>
<td style="text-align: right;">-0.084</td>
<td style="text-align: right;">-0.085</td>
<td style="text-align: right;">-0.085</td>
<td style="text-align: right;">1.602</td>
</tr>
<tr class="odd">
<td style="text-align: left;">log(price)</td>
<td style="text-align: right;">-0.045</td>
<td style="text-align: right;">-0.047</td>
<td style="text-align: right;">-0.047</td>
<td style="text-align: right;">1.603</td>
</tr>
<tr class="even">
<td style="text-align: left;">cityDallas</td>
<td style="text-align: right;">0.023</td>
<td style="text-align: right;">0.023</td>
<td style="text-align: right;">0.023</td>
<td style="text-align: right;">1.593</td>
</tr>
<tr class="odd">
<td style="text-align: left;">cityLos-Angeles</td>
<td style="text-align: right;">0.015</td>
<td style="text-align: right;">0.016</td>
<td style="text-align: right;">0.016</td>
<td style="text-align: right;">1.590</td>
</tr>
<tr class="even">
<td style="text-align: left;">citySt-Louis</td>
<td style="text-align: right;">0.010</td>
<td style="text-align: right;">0.010</td>
<td style="text-align: right;">0.010</td>
<td style="text-align: right;">1.573</td>
</tr>
<tr class="odd">
<td style="text-align: left;">cityWashington</td>
<td style="text-align: right;">-0.037</td>
<td style="text-align: right;">-0.037</td>
<td style="text-align: right;">-0.037</td>
<td style="text-align: right;">1.611</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>With this rescaling, the three models give similar results. For a 100% increase of the price, the probability of acceptance reduces by 4.16 percentage points. The estimated marginal effect for black guests is about <span class="math inline">\(-8.5\)</span> percentage points. However, computing a derivative is not relevant in this case as the covariate is a dummy. We should therefore better compute the difference between the probabilities of acceptance, everything other being equal, which means here for a given price of the property and for the reference city, which is Baltimore. The average price being equal to $182 in our sample, we have, for the probit model: <span class="math inline">\(\Phi(0.497 - 0.213 - 0.107 \times \ln 182) - \Phi(0.497 - 0.213 - 0.107 \times \ln 182) = -0.084\)</span> and for the logit model: <span class="math inline">\(\Lambda(0.796 - 0.341 - 0.171 \times\ln 182) - \Lambda(0.796 - 0.171\times\ln 182) = -0.084\)</span>, which means that, at least in this example, the previous computation of the derivative gives an extremely accurate approximation of the effect of this dummy covariate. Finally, note that the ratio of the logit and probit coefficients is very close to the value of 1.6 advocated by <span class="citation" data-cites="AMEM:81">Amemiya (<a href="#ref-AMEM:81" role="doc-biblioref">1981</a>)</span>. </p>
<div style="page-break-after: always;"></div>
</section><section id="sec-struct_binom" class="level2" data-number="10.2"><h2 data-number="10.2" class="anchored" data-anchor-id="sec-struct_binom">
<span class="header-section-number">10.2</span> Structural models for binomial responses</h2>
<p>Two structural models have been proposed to give a theoretical foundation to the probit/logit models. Without loss of generality, we’ll present these two models for the case where there is a unique covariate.</p>
<section id="sec-latent_variable" class="level3"><h3 class="anchored" data-anchor-id="sec-latent_variable">Latent variable and index function</h3>
<p> We observe that <span class="math inline">\(y\)</span> is equal to 0 or 1, but we now assume that this values is related to a latent continuous variable (called <span class="math inline">\(y^*\)</span>) which is unobserved. <span class="math inline">\(y=1\)</span> will result for “high” values of <span class="math inline">\(y ^ *\)</span> and <span class="math inline">\(y=0\)</span> for low values of <span class="math inline">\(y ^ *\)</span>. More specifically we’ll assume that the observation rule is:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y = 0 &amp; \mbox{if } &amp; y ^ * \leq \psi \\
y = 1 &amp; \mbox{if } &amp; y ^ * &gt; \psi \\
\end{array}
\right.
\]</span></p>
<p>where <span class="math inline">\(\psi\)</span> is an unknown threshold. Now assume that the value of <span class="math inline">\(y^ *\)</span> is partly explained by an observable covariate <span class="math inline">\(x\)</span>, the unexplained part being modelized by a random error <span class="math inline">\(\epsilon\)</span>. We then have: <span class="math inline">\(y ^ * = \alpha + \beta x + \epsilon\)</span>, so that the observation rule becomes:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y = 0 &amp; \mbox{if } &amp; \epsilon \leq \psi - \alpha - \beta x\\
y = 1 &amp; \mbox{if } &amp; \epsilon &gt; \psi - \alpha - \beta x \\
\end{array}
\right.
\]</span> This observation rule depends on <span class="math inline">\(\psi - \alpha\)</span> and not on the separate values of <span class="math inline">\(\psi\)</span> and <span class="math inline">\(\alpha\)</span>. Therefore, <span class="math inline">\(\psi\)</span> can be set to any arbitrary value, for example 0. Then, the probability of success is: <span class="math inline">\(1 - F(-\alpha - \beta x)\)</span> where <span class="math inline">\(F\)</span> is the cumulative density function of <span class="math inline">\(\epsilon\)</span>. For example, if <span class="math inline">\(\epsilon \sim \mathcal{N} (0, \sigma)\)</span>, <span class="math inline">\(\mbox{P}(y = 1 \mid x) = 1 - \Phi(-(\alpha - \beta x) / \sigma)\)</span>. We can see from this expression that only <span class="math inline">\(\alpha / \sigma\)</span> and <span class="math inline">\(\beta / \sigma\)</span> can be identified, so that, <span class="math inline">\(\sigma\)</span> can be set to any arbitrary value, for example 1. Moreover, by the symmetry of the normal distribution, we have <span class="math inline">\(1 - \Phi(-z) = \Phi(z)\)</span>, so that the probability of success becomes <span class="math inline">\(F(y = 1 \mid x) = \Phi(\alpha +\beta ^\top x)\)</span>, which defines the probit model. Assuming that the distribution of <span class="math inline">\(\epsilon\)</span> is logistic, we have a probability of success equal to <span class="math inline">\(1 - \Lambda(- \alpha-\beta x)\)</span> which reduces, as the logistic distribution is also symmetric, to: <span class="math inline">\(F(y = 1 \mid x) = \Lambda(\alpha + \beta x) = e^{\alpha + \beta x} / (1 + e ^ {\alpha + \beta x})\)</span>. </p>
</section><section id="sec-rum_binomial" class="level3"><h3 class="anchored" data-anchor-id="sec-rum_binomial">Random utility model</h3>
<p> Consider now that we can define a utility function for the two alternatives that correspond to the two values of the binomial response. As an example, <span class="math inline">\(y\)</span> equals 1 or 0 if car or public transit is chosen, and the only covariate <span class="math inline">\(x\)</span> is the generalized cost. The utility of choosing a transport mode doesn’t depend only on the generalized cost, but also on some other unobserved variables. The effect of these variables are modelized as the realization of a random variable <span class="math inline">\(\epsilon\)</span>. We can therefore define the following random utility functions:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
U_0 &amp;=&amp; \alpha_0 + \beta x_0 + \epsilon_0 \\
U_1 &amp;=&amp; \alpha_1 + \beta x_1 + \epsilon_1
\end{array}
\right.
\]</span> </p>
<p>where <span class="math inline">\(\beta\)</span> is the marginal utility of $1. The choice of the individual is deterministic. They will choose the car if the utility of this mode is greater than the utility of public transit. Therefore, we have the following observation rule:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y = 0 &amp; \mbox{if } &amp; \epsilon_1 - \epsilon_0 \leq - (\alpha_1 - \alpha_0) - \beta (x_1 - x_0)\\
y = 1 &amp; \mbox{if } &amp; \epsilon_1 - \epsilon_0 &gt; - (\alpha_1 - \alpha_0) - \beta (x_1 - x_0)\\
\end{array}
\right.
\]</span></p>
<p>Denoting <span class="math inline">\(\epsilon = \epsilon_1 - \epsilon_0\)</span> the error difference, <span class="math inline">\(\alpha = \alpha_1 - \alpha_0\)</span> and <span class="math inline">\(x = x_1 - x_0\)</span> the difference of generalized cost for the two modes, we have:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
y = 0 &amp; \mbox{if } &amp; \epsilon \leq  - (\alpha + \beta x)\\
y = 1 &amp; \mbox{if } &amp; \epsilon &gt; - (\alpha + \beta x)\\
\end{array}
\right.
\]</span></p>
<p>The probability of “success” (here choosing the car) is therefore <span class="math inline">\(\mbox{P}(y = 1 \mid x) = 1 - F(- \alpha - \beta x)\)</span>, with <span class="math inline">\(F\)</span> as the cumulative density of <span class="math inline">\(\epsilon\)</span>. If the distribution is symmetric, this probability reduces once again to <span class="math inline">\(\mbox{P}(y = 1 \mid x) = F(\alpha + \beta x)\)</span>, and the probit or logit models are obtained by choosing either the normal or the logistic distribution. </p>
</section></section><section id="sec-glm" class="level2" data-number="10.3"><h2 data-number="10.3" class="anchored" data-anchor-id="sec-glm">
<span class="header-section-number">10.3</span> Binomial model as a generalized linear model</h2>
<p> The estimation of binomial models with <strong>R</strong> is performed using the <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm</a></code> function, which stands for a <strong>generalized linear model</strong>. It is therefore important to have at least some basic knowledge about generalized linear models to understand the output of the fitted models.</p>
<section id="generalized-linear-models" class="level3"><h3 class="anchored" data-anchor-id="generalized-linear-models">Generalized linear models</h3>
<p>The generalized linear models (<strong>GLM</strong>) are a wide family of models that are intended to extend the linear model. These models have the following components:</p>
<ul>
<li>a <em>random component</em> which specifies the distribution of the response, as a member of the exponential family, and in particular the expected value <span class="math inline">\(\mbox{E}(y) = \mu\)</span>,</li>
<li>a <em>systematic component</em>: some covariates <span class="math inline">\(x_1, x_2, \ldots x_m\)</span> produce a linear predictor <span class="math inline">\(\eta_n = \alpha + \beta ^ \top x_n\)</span>,</li>
<li>the <em>link</em> function <span class="math inline">\(g\)</span> which specifies the relation between the random and the systematic components: <span class="math inline">\(\eta = g(\mu)\)</span>.</li>
</ul>
<p>The exponential family is defined by the following density function:</p>
<p><span id="eq-density_glm"><span class="math display">\[
f(y;\theta,\phi) = e ^ {\displaystyle\left(y\theta - b(\theta)\right)/\phi + c(y, \phi)}
\tag{10.2}\]</span></span></p>
<p><span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> being respectively a position and a scale parameter. Linear models are actually a specific case of generalized linear models with a normal distribution and an identity link. We have in this case the following density function:</p>
<p><span class="math display">\[
\phi(y;\mu, \sigma) = \frac{1}{\sqrt{2\pi}\sigma} e ^ {-\frac{1}{2}\frac{(y - \mu)^2}{\sigma ^ 2}}=
e^{\frac{y\mu - 0.5 \mu ^ 2}{\sigma ^ 2}- 0.5 y ^ 2 / \sigma ^ 2 - 0.5 \ln(2\pi\sigma ^ 2)}
\]</span></p>
<p>which is a member of the exponential family with <span class="math inline">\(\theta = \mu\)</span>, <span class="math inline">\(\phi = \sigma^ 2\)</span>, <span class="math inline">\(b(\theta) = 0.5 \theta ^ 2\)</span> and <span class="math inline">\(c(y, \phi) = - 0.5(y ^ 2 / \phi + \ln(2\pi\phi))\)</span>. The first two derivatives of <a href="#eq-density_glm">Equation&nbsp;<span>10.2</span></a> with respect to <span class="math inline">\(\theta\)</span> are:</p>
<p><span class="math display">\[
\left\{
\begin{array}{ccl}
\displaystyle\frac{\partial l}{\partial \theta} &amp;=&amp; \displaystyle\frac{1}{\phi}(y - b'(\theta))\\
\displaystyle\frac{\partial ^ 2 l}{\partial \theta ^ 2} &amp;=&amp; \displaystyle-\frac{1}{\phi}b''(\theta)
\end{array}
\right.
\]</span></p>
<p>As <span class="math inline">\(\mbox{E}\left(\frac{\partial l}{\partial \theta}\right) = 0\)</span>, we have <span class="math inline">\(\mbox{E}(y)=b'(\theta)\)</span>. Moreover, by the information matrix equality: <span class="math inline">\(\mbox{E}\left(\frac{\partial^2 l}{\partial \theta ^ 2}\right) + \mbox{E}\left(\frac{\partial l}{\partial \theta} ^ 2\right) = 0\)</span>, so that <span class="math inline">\(\mbox{V}(y) = \phi b''(\theta)\)</span>.</p>
<p>Going back to the normal (or gaussian) model with an identity link, we have, for a given set of estimates (which leads to the <strong>proposed model</strong>): <span class="math inline">\(\hat{\mu}_n = \hat{\eta}_n = \hat{\alpha} + \hat{\beta} ^ \top x_n\)</span> and the log-likelihood function is:</p>
<p><span class="math display">\[
\ln L(y, \hat{\mu}) = - \frac{N}{2}\ln(2 \pi + \sigma ^ 2) - \frac{1}{2\sigma ^2} \sum_{n=1} ^ N (y_n - \hat{\mu}_n) ^ 2
\]</span> </p>
<p>For a hypothetical “perfect” or <strong>saturated model</strong> with a perfect fit, we would have <span class="math inline">\(\hat{\mu}_n = y_n\)</span>, so that the log-likelihood would be <span class="math inline">\(- \frac{N}{2}\ln(2 \pi + \sigma ^ 2)\)</span>. Minus two times the difference of these two values of the log likelihood function is called the <strong>scaled deviance</strong> of the proposed model: </p>
<p><span class="math display">\[
D^*(y;\hat\mu) = \sum_{n=1} ^ N\frac{(y_n - \hat{\mu}_n) ^ 2}{\sigma ^ 2}
\]</span> </p>
<p>and the deviance is obtained by multiplying the scaled deviance by <span class="math inline">\(\sigma ^ 2\)</span> (or more generally by the scale parameter <span class="math inline">\(\phi\)</span>):</p>
<p><span class="math display">\[
D(y; \hat{\mu}) = \sum_{n=1} ^ N(y_n - \hat{\mu}_n) ^ 2
\]</span></p>
<p>which is simply, for the linear model, the sum of square residuals. For the binomial model, the probability mass function is given by the probability of success <span class="math inline">\(\mu\)</span> if <span class="math inline">\(y = 1\)</span> and by the probability of failure <span class="math inline">\(1 - \mu\)</span> if <span class="math inline">\(y=0\)</span>. This probability can be compactly written as <span class="math inline">\(\mu ^ y (1 - \mu) ^ {1 - y}\)</span> or as:</p>
<p><span class="math display">\[
f(y;\mu) = e ^ {y \ln \mu + (1 - y) \ln(1 - \mu)}=e ^ {y \ln \frac{\mu}{1 - \mu} + \ln(1 - \mu)}=
e^{y\theta - \ln (1 + e ^ \theta)}
\]</span></p>
<p>which is a member of the exponential family with: <span class="math inline">\(\theta = \ln\frac{\mu}{1 -\mu}\)</span>, <span class="math inline">\(b(\theta) = \ln(1 + e ^ \theta)\)</span>, <span class="math inline">\(c(\theta,y) = 0\)</span> and <span class="math inline">\(\phi=1\)</span>. The model is fully characterized once the link is specified. For the logit model, we have <span class="math inline">\(\mu = \frac{e ^ \eta}{1+e ^ \eta}\)</span>, so that <span class="math inline">\(\eta = \ln \frac{\mu}{1 - \mu} = g(\mu)\)</span>. We then have <span class="math inline">\(\theta = \eta\)</span>, so that the logit link is called the <strong>canonical</strong> link for binomial models<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. As the density for the binomial model returns a probability, the log-likelihood for the saturated model is zero. Therefore, the deviance is:</p>
<p><span id="eq-deviance_binomial"><span class="math display">\[
D(y;\hat{\mu}) = 2 \sum_{n=1} ^ N \left(y_n \ln \hat{\mu}_n + (1 - y_n) \ln(1 - \hat{\mu}_n)\right)
\tag{10.3}\]</span></span></p>
<p> The <strong>null model</strong> is a model with only an intercept. In this case, <span class="math inline">\(\hat{\mu}_n = \hat{\mu}_0\)</span> and the maximum likelihood estimator of <span class="math inline">\(\mu_0\)</span> is <span class="math inline">\(\sum_{n=1} ^ N y_n / N\)</span>, i.e., the share of success in the sample. The deviance of this model is called the <strong>null deviance</strong>. An alternative to the deviance as a measure of the fit of the model is the <strong>generalized Pearson statistic</strong>, defined as: </p>
<p><span id="eq-pearson_statistic"><span class="math display">\[
X ^ 2 = \sum_{n=1} ^ N \frac{(y_n - \hat{\mu}_n) ^ 2}{\mbox{V}(\hat{\mu}_n)}=
\sum_{n=1} ^ N \frac{(y_n - \hat{\mu}_n) ^ 2}{\hat{\mu}_n(1 - \hat{\mu}_n)}
\tag{10.4}\]</span></span></p>
<!--  Both $D$ and $X ^2$ have an asymptotic $\chi -->
<!-- ^ 2$ distribution. -->
<p>In the linear model, residuals have several interesting properties:</p>
<ul>
<li>they are homoskedastic (or at least they may be homoskedastic if the variance of the conditional distribution of the response is constant),</li>
<li>they have an intuitive meaning, as they are the difference between the actual and the fitted values of the response, the latter being an estimate of the conditional mean of the response,</li>
<li>they are related to the value of the objective function, which is the sum of square residuals.</li>
</ul>
<p> The most obvious definition of the residuals for binomial models is the <strong>response residuals</strong>, which are simply the difference between the response and the prediction of the model (the fitted probability of success <span class="math inline">\(\hat{\mu}\)</span>). However, these residuals (<span class="math inline">\(y_n - \hat{\mu}_n\)</span>) are necessarily heteroskedastic, as the variance of <span class="math inline">\(y_n\)</span> is <span class="math inline">\(\mu_n(1 - \mu_n)\)</span>. Scaling the response residuals by their standard deviation leads to <strong>Pearson’s residuals</strong>: <span class="math inline">\((y_n - \hat{\mu}_n) / \sqrt{\hat{\mu}_n(1 - \hat{\mu}_n)}\)</span>. The sum of squares of Pearson’s residuals is the generalized Pearson statistic given by <a href="#eq-pearson_statistic">Equation&nbsp;<span>10.4</span></a>. The <strong>deviance residuals</strong> are such that the sum of their squares equals the deviance statistic <span class="math inline">\(D\)</span>. They are therefore defined by:</p>
<p><span class="math display">\[(2 y_n - 1) \sqrt{2}\sqrt{y_n \ln \hat{\mu}_n + (1 - y_n) \ln (1 - \hat{\mu}_n)}\]</span></p>
<p>the term <span class="math inline">\(2 y_n - 1\)</span> gives a positive sign for the residuals of observations for which <span class="math inline">\(y_n = 1\)</span> and a negative sign for <span class="math inline">\(y_n = 0\)</span>, as for the two other types of residuals. </p>
</section><section id="estimation-with-statsglm" class="level3"><h3 class="anchored" data-anchor-id="estimation-with-statsglm">Estimation with <code>stats::glm</code>
</h3>
<p>The estimation of probit/logit models is performed using <code>glm</code>. The interface of <code>glm</code> is very similar to <code>lm</code>, but it has a supplementary argument called <code>family</code> which indicates the distribution of the response.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> The family argument can be either a character string or a function. In the latter case, an argument called <code>link</code> can be specified, which indicates how the linear predictor <span class="math inline">\(\eta_n=\alpha + \beta ^ \top x_n\)</span> is related to the parameter of the distribution <span class="math inline">\(\mu_n\)</span> . If we use <code>family = binomial(link = "probit")</code>, then <span class="math inline">\(\mu_n = \Phi(\eta_n)\)</span>. The default choice is <code>"logit"</code> (the canonical link), so that the logit model can be obtained using either: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lgt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, data <span class="op">=</span> <span class="va">mode_choice</span>, </span>
<span>           family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">'logit'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, data <span class="op">=</span> <span class="va">mode_choice</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, data <span class="op">=</span> <span class="va">mode_choice</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, data <span class="op">=</span> <span class="va">mode_choice</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Remember that, while estimating a generalized linear model, three models are considered:</p>
<ul>
<li>the saturated model, for which there is one parameter for every observation and a perfect fit; therefore the log-likelihood, the deviance and the number of degrees of freedom are 0,</li>
<li>the null model, with only one estimated coefficient and <span class="math inline">\(N-1\)</span> degrees of freedom,</li>
<li>the proposed model, with <span class="math inline">\(K+1\)</span> estimated parameters, and therefore <span class="math inline">\(N - K - 1\)</span> degrees of freedom.</li>
</ul>
<p>A call to <code>glm</code> results in an object of class <code>glm</code> which inherits from class <code>lm</code>. As for <code>lm</code>, the <code>summary</code> method computes detailed results for the model and, if not saved in an object, these results are printed:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lgt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = mode ~ gcost, family = binomial(link = "logit"), 
    data = mode_choice)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   1.3905     0.0998   13.94   &lt;2e-16 ***
gcost         0.2112     0.0248    8.52   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 741.33  on 841  degrees of freedom
Residual deviance: 647.39  on 840  degrees of freedom
AIC: 651.4

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
<p>The output indicates the deviance of the null and the proposed model, along with their respective degrees of freedom (<span class="math inline">\(N - 1 = 841\)</span> and <span class="math inline">\(N - K - 1 = 840\)</span>). The latter is called the <strong>residual deviance</strong>. This information is elements of the object returned by <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm</a></code> and can be extracted directly:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lgt</span><span class="op">$</span><span class="va">deviance</span></span>
<span><span class="va">lgt</span><span class="op">$</span><span class="va">null.deviance</span></span>
<span><span class="va">lgt</span><span class="op">$</span><span class="va">df.residual</span></span>
<span><span class="va">lgt</span><span class="op">$</span><span class="va">df.null</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>or, for the fitted model, using the corresponding functions: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/deviance.html">deviance</a></span><span class="op">(</span><span class="va">lgt</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/df.residual.html">df.residual</a></span><span class="op">(</span><span class="va">lgt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can check that the null deviance can be obtained by fitting a model with only an intercept: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lgt</span>, <span class="va">.</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">deviance</span></span>
<span><span class="co">## [1] 741.3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The residuals can be extracted from the fitted model using <code>resid</code>. The <code>resid</code> method for <code>glm</code> objects has a <code>type</code> argument which can be equal to <code>"response"</code>, <code>"pearson"</code> and <code>"deviance"</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">lgt</span>, <span class="st">"response"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##        1        2        3        4        5        6 </span></span>
<span><span class="co">##  0.03651 -0.55944  0.23718 -0.66782  0.04603 -0.80629</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">lgt</span>, <span class="st">"pearson"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##       1       2       3       4       5       6 </span></span>
<span><span class="co">##  0.1947 -1.1269  0.5576 -1.4179  0.2197 -2.0402</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">lgt</span>, <span class="st">"deviance"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##       1       2       3       4       5       6 </span></span>
<span><span class="co">##  0.2728 -1.2804  0.7358 -1.4846  0.3070 -1.8118</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The fitted values of the model can be expressed on the scale of the linear predictor or the response. They are available in the returned object as <code>linear.predictors</code> and <code>fitted.values</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lgt</span><span class="op">$</span><span class="va">linear.predictors</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##      1      2      3      4      5      6 </span></span>
<span><span class="co">## 3.2729 0.2389 1.1682 0.6983 3.0313 1.4261</span></span>
<span><span class="va">lgt</span><span class="op">$</span><span class="va">fitted.values</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##      1      2      3      4      5      6 </span></span>
<span><span class="co">## 0.9635 0.5594 0.7628 0.6678 0.9540 0.8063</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The latter can also be obtained using the <code>fitted</code> function: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">lgt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>predict</code> method returns by default the fitted values but can also compute the predicted values for a new data frame. For example, if the difference of generalized cost is increased by 10%: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mode_choice2</span> <span class="op">&lt;-</span> <span class="va">mode_choice</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>gcost2 <span class="op">=</span> <span class="va">gcost</span> <span class="op">*</span> <span class="fl">1.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The predictions can be computed in the scale of the linear predictors or of the response by setting the <code>type</code> argument to <code>"link"</code> (the default) or <code>"response"</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lgt</span>, newdata <span class="op">=</span> <span class="va">mode_choice2</span>, type <span class="op">=</span> <span class="st">"link"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##      1      2      3      4      5      6 </span></span>
<span><span class="co">## 3.2729 0.2389 1.1682 0.6983 3.0313 1.4261</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lgt</span>, newdata <span class="op">=</span> <span class="va">mode_choice2</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">head</span></span>
<span><span class="co">##      1      2      3      4      5      6 </span></span>
<span><span class="co">## 0.9635 0.5594 0.7628 0.6678 0.9540 0.8063</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section><section id="sec-binom_evaluation" class="level2" data-number="10.4"><h2 data-number="10.4" class="anchored" data-anchor-id="sec-binom_evaluation">
<span class="header-section-number">10.4</span> Model estimation, evaluation and testing</h2>
<section id="sec-estimation_binomial" class="level3"><h3 class="anchored" data-anchor-id="sec-estimation_binomial">Estimation</h3>
<p>The <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm</a></code> function uses an iterative weighted least squares method to fit all the flavors of GLM’s models. However, probit and logit models are usually estimated by maximum likelihood. With <span class="math inline">\(\eta_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n\)</span> the linear predictor, the individual contribution to the likelihood is <span class="math inline">\(F(\eta_n)\)</span> if <span class="math inline">\(y_n = 1\)</span> and <span class="math inline">\(1 - F(\eta_n)\)</span> if <span class="math inline">\(y_n = 0\)</span>. <!-- Defining $q_n = --> <!-- 2 y_n -1$ (which equals -1/+1 for y=0/1), it can also be compactly --> <!-- written as: $F(q_n \eta_n)$ if the chosen distribution is --> <!-- symmetric.  --> The log-likelihood is then:</p>
<p><span class="math display">\[
\ln L = \sum_{n=1} ^ N y_n \ln F(\eta_n) + (1 - y_n) \ln (1 - F(\eta_n)
\]</span></p>
<p>The first-order condition for a maximum is that the vector of the first derivatives:</p>
<p><span id="eq-gradbinom"><span class="math display">\[
\frac{\partial \ln L}{\partial \gamma} = \sum_{n=1} ^ N \frac{y_n}{F(\eta_n)}f(\eta_n)z_n -
\frac{1 - y_n}{1 - F(\eta_n)}f(\eta_n)z_n=
\sum_{n=1} ^ N \frac{y_n - F_n}{F_n\left(1 - F_n\right)}f_n z_n =0
\tag{10.5}\]</span></span></p>
<p>is zero, where we defined for convenience <span class="math inline">\(F_n = F(\eta_n)\)</span> and <span class="math inline">\(f_n = f(\eta_n)\)</span>.</p>
<p> <span class="math inline">\(\psi_n = \frac{y_n - F_n}{F_n\left(1 - F_n\right)}f_n\)</span> is called the <strong>generalized residual</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Generalized residuals have the same property as standard residuals in the linear regression model, they are orthogonal to all the covariates, and they sum to 0 if the regression contains an intercept. The hessian matrix of the second derivatives is:</p>
<p><span id="eq-hessbinom"><span class="math display">\[
\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top} =
- \sum_{n = 1} ^ N \left(\frac{y_n (1 - F_n) ^ 2 + (1 - y_n) F_n ^ 2}{F_n ^ 2 (1 - F_n) ^ 2} f_n ^ 2 -
\frac{y_n - F_n}{F_n(1 - F_n)} f_n'\right) z_n z_n^\top
\tag{10.6}\]</span></span></p>
<p>with <span class="math inline">\(f'_n\)</span> the derivative of <span class="math inline">\(f_n\)</span>. Taking the expectation, we obtain a much simpler expression: as <span class="math inline">\(E(y_n) = F_n\)</span>, the second term in brackets disappears and the first one simplifies to:</p>
<p><span id="eq-infobinom"><span class="math display">\[
\mbox{E} \left(\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top}\right) =
- \sum_{n = 1} ^ N \frac{f_n ^ 2}{F_n (1 - F_n)}
z_n z_n^\top
\tag{10.7}\]</span></span></p>
<p>For the logit model, the density is: <span class="math inline">\(\lambda_n = e ^ {\eta_n} / (1 + e ^ {\eta_n}) ^ 2 = \Lambda_n (1 - \Lambda_n)\)</span> and <a href="#eq-gradbinom">Equation&nbsp;<span>10.5</span></a> reduces to:</p>
<p><span class="math display">\[
\frac{\partial \ln L}{\partial \gamma} =
\sum_{n=1} ^ N \left(y_n - \Lambda_n\right)z_n = 0
\]</span></p>
<p>This expression is particularly appealing as the generalized residual <span class="math inline">\(y_n - \Lambda_n\)</span> is the response residual. Moreover, the expression of the matrix of second derivatives is particularly simple: </p>
<p><span class="math display">\[
\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top} =
- \sum_{n=1} ^ N \lambda_n z_n z_n ^ \top =
- \sum_{n=1} ^ N \Lambda_n (1 - \Lambda_n) z_n z_n ^ \top
\]</span></p>
<p>and is equal to its expectation, as it doesn’t depend on <span class="math inline">\(y\)</span>. For the probit model, the vector of response residuals (<span class="math inline">\(y_n - \Phi_n\)</span>) is not orthogonal to the covariates. Moreover, the formula of the hessian is rather complicated and depends on <span class="math inline">\(y\)</span>. However, its expectation (<a href="#eq-infobinom">Equation&nbsp;<span>10.7</span></a>) can be expressed compactly in terms of the inverse mills ratio, defined by: <span class="math inline">\(r(z) = \phi(z) / \Phi(z)\)</span>. Noting that <span class="math inline">\(\phi(z) / (1 - \Phi(z)) = \phi(-z) / \Phi(-z) = r(-z)\)</span> by symmetry of the normal distribution, <a href="#eq-infobinom">Equation&nbsp;<span>10.7</span></a> simplifies to:</p>
<p><span id="eq-infoprobit"><span class="math display">\[
\mbox{E} \left(\frac{\partial ^ 2 \ln L}{\partial \beta \partial \beta ^ \top}\right) =
- \sum_{n = 1} ^ N r(\eta_n) r(- \eta_n)z_n z_n^\top
\tag{10.8}\]</span></span></p>
<p>The generalized residuals are:</p>
<p><span id="eq-gen_resid_probit"><span class="math display">\[
\psi_n = \frac{\phi_n (y_n - \Phi_n)}{\Phi_n (1 - \Phi_n)}
\tag{10.9}\]</span></span></p>
<p>and they are related to the latent variable <span class="math inline">\(y^*\)</span> used in <a href="#sec-latent_variable"><span>Section&nbsp;10.2.1</span></a>. Remember that <span class="math inline">\(y_n ^ * = \mu_n + \epsilon_n\)</span>, with <span class="math inline">\(\mu_n = \alpha + \beta ^ \top x_n\)</span> and <span class="math inline">\(\epsilon_n \sim \mathcal{N}(0, \sigma)\)</span>. Then, considering the latent variable, the residual can be defined as <span class="math inline">\(\hat{\epsilon}_n = y_n ^ * - \hat{\mu}_n\)</span>. This residual can’t be computed because <span class="math inline">\(y_n ^ *\)</span> is unobserved, we only observe <span class="math inline">\(y_n = 1\)</span> if <span class="math inline">\(y_n ^ * &gt; 0\)</span> and <span class="math inline">\(y_n = 0\)</span> if <span class="math inline">\(y_n ^ * \leq 0\)</span>. However, its expectation can be computed. For <span class="math inline">\(y_n = 1\)</span>:</p>
<p><span class="math display">\[
\mbox{E}(\hat{\epsilon}\mid x, y^* &gt; 0) = \frac{\int_{0} ^ {+\infty} y^*\phi(y^* - \hat{\mu}) dy^*}{\int_{0} ^ {+\infty}\phi(y^* - \hat{\mu})dy^*} - \hat{\mu} =
\frac{\int_{-\hat{\mu}} ^ {+\infty} (\hat{\mu} + v)\phi(v) dv}{\int_{-\hat{\mu}} ^ {+\infty}\phi(v)dv} - \hat{\mu} = \frac{\phi(\hat{\mu})}{\Phi(\hat{\mu})}
\]</span> Similarly, <span class="math inline">\(\mbox{E}(\hat{\epsilon}\mid x, y^* \leq 0) = -\frac{\phi(\hat{\mu})}{1 - \Phi(\hat{\mu})}\)</span>, so that: <span class="math display">\[
\mbox{E}(\hat{\epsilon}_n\mid x_n) = y_n \mbox{E}(\hat{\epsilon}_n\mid x_n, y_n ^* &gt; 0) + (1 - y_n)  \mbox{E}(\hat{\epsilon}_n\mid x_n, y_n ^* \leq 0) = \frac{\phi(\hat{\mu}_n)(y_n - \Phi(\hat{\mu}_n))}{\Phi(\hat{\mu}_n)(1 - \Phi(\hat{\mu}_n))}
\]</span></p>
<p>which is the generalized residual defined in <a href="#eq-gen_resid_probit">Equation&nbsp;<span>10.9</span></a>. </p>
<p> The three estimators of the covariance matrix of the estimators can be used. The outer product of the gradient estimator is based on <a href="#eq-gradbinom">Equation&nbsp;<span>10.5</span></a>:</p>
<p><span class="math display">\[
\hat{V}_G(\hat{\gamma}) = \sum_{n = 1} ^ N \left(\frac{y_n - F_n}{F_n (1 - F_n)}f_n\right) ^ 2 z_n z_n^ \top
\]</span></p>
<p>The hessian based estimator is obtained by taking the inverse of the opposite of the hessian given by <a href="#eq-hessbinom">Equation&nbsp;<span>10.6</span></a>. Finally the information-based estimator is obtained by taking the inverse of the opposite of the matrix given by <a href="#eq-infobinom">Equation&nbsp;<span>10.7</span></a>:</p>
<p><span class="math display">\[
\hat{V}_I(\hat{\gamma}) = \left(\sum_{n = 1} ^ N \frac{f_n ^ 2}{F_n (1 - F_n)}
z_n z_n^\top\right) ^ {-1}
\]</span> As the hessian for the logit model doesn’t depend on <span class="math inline">\(y\)</span>, the last two estimators are the same for this model. We consider as an example two variants of the mode choice model: the first uses as distinct covariate the monetary cost, in- and out-vehicle time; the second uses as unique covariate the generalized cost. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lgt_unconst</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">cost</span> <span class="op">+</span> <span class="va">ivtime</span> <span class="op">+</span> <span class="va">ovtime</span>, </span>
<span>                        data <span class="op">=</span> <span class="va">mode_choice</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="va">lgt_const</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span>, data <span class="op">=</span> <span class="va">mode_choice</span>, link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="va">pbt_unconst</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lgt_unconst</span>, link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span></span>
<span><span class="va">pbt_const</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">lgt_const</span>, link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-binom_const_unconst" class="anchored">

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Table&nbsp;10.2:  Logit and probit models for the mode choice data set </caption>
 <thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1"></th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">logit</div></th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">probit</div></th>
</tr>
<tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> unconstrained </th>
   <th style="text-align:center;"> constrained </th>
   <th style="text-align:center;"> unconstrained  </th>
   <th style="text-align:center;"> constrained  </th>
  </tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> (Intercept) </td>
   <td style="text-align:center;"> 1.062 </td>
   <td style="text-align:center;"> 1.390 </td>
   <td style="text-align:center;"> 0.664 </td>
   <td style="text-align:center;"> 0.821 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.195) </td>
   <td style="text-align:center;"> (0.100) </td>
   <td style="text-align:center;"> (0.110) </td>
   <td style="text-align:center;"> (0.056) </td>
  </tr>
<tr>
<td style="text-align:left;"> cost </td>
   <td style="text-align:center;"> 0.156 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.086 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.036) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.020) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> ivtime </td>
   <td style="text-align:center;"> 0.545 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.308 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.455) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.248) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> ovtime </td>
   <td style="text-align:center;"> 4.760 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 2.380 </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.958) </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.494) </td>
   <td style="text-align:center;">  </td>
  </tr>
<tr>
<td style="text-align:left;"> gcost </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.211 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.113 </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.025) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.013) </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 842 </td>
   <td style="text-align:center;"> 842 </td>
   <td style="text-align:center;"> 842 </td>
   <td style="text-align:center;"> 842 </td>
  </tr>
<tr>
<td style="text-align:left;"> AIC </td>
   <td style="text-align:center;"> 642.6 </td>
   <td style="text-align:center;"> 651.4 </td>
   <td style="text-align:center;"> 645.5 </td>
   <td style="text-align:center;"> 652.5 </td>
  </tr>
<tr>
<td style="text-align:left;"> BIC </td>
   <td style="text-align:center;"> 661.6 </td>
   <td style="text-align:center;"> 660.9 </td>
   <td style="text-align:center;"> 664.5 </td>
   <td style="text-align:center;"> 662.0 </td>
  </tr>
<tr>
<td style="text-align:left;"> Log.Lik. </td>
   <td style="text-align:center;"> −317.322 </td>
   <td style="text-align:center;"> −323.694 </td>
   <td style="text-align:center;"> −318.769 </td>
   <td style="text-align:center;"> −324.270 </td>
  </tr>
<tr>
<td style="text-align:left;"> Deviance </td>
   <td style="text-align:center;"> 634.64 </td>
   <td style="text-align:center;"> 647.39 </td>
   <td style="text-align:center;"> 637.54 </td>
   <td style="text-align:center;"> 648.54 </td>
  </tr>
<tr>
<td style="text-align:left;"> Deviance Null </td>
   <td style="text-align:center;"> 741.33 </td>
   <td style="text-align:center;"> 741.33 </td>
   <td style="text-align:center;"> 741.33 </td>
   <td style="text-align:center;"> 741.33 </td>
  </tr>
</tbody>
</table>
</div>
</div>
</div>
<p>We present in <a href="#tbl-binom_const_unconst">Table&nbsp;<span>10.2</span></a> the results of the logit and probit models. By default, the standard deviations are computed using the information-based estimation of the covariance matrix of the estimates. The hessian and the outer-product of the gradient estimators are obtained by setting the <code>vcov</code> argument of <code>vcov</code> or of <code>summary</code> to respectively <code>"hessian"</code> or <code>"opg"</code>. For example, to get the gradient-based estimator of the covariance matrix: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, vcov <span class="op">=</span> <span class="st">"opg"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code><a href="https://rdrr.io/pkg/micsr/man/stder.html">micsr::stder</a></code> function enables to compute the different flavors of the estimated standard errors, which are obtained by taking the square roots of the diagonal elements of the covariance matrix: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, vcov <span class="op">=</span> <span class="st">"opg"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">diag</span> <span class="op">%&gt;%</span> <span class="va">sqrt</span></span>
<span><span class="co">## (Intercept)        cost      ivtime      ovtime </span></span>
<span><span class="co">##     0.11392     0.02111     0.32552     0.47637</span></span>
<span><span class="fu">stder</span><span class="op">(</span><span class="va">pbt_unconst</span>, vcov <span class="op">=</span> <span class="st">"opg"</span><span class="op">)</span></span>
<span><span class="co">## (Intercept)        cost      ivtime      ovtime </span></span>
<span><span class="co">##     0.11392     0.02111     0.32552     0.47637</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The sandwich estimator is obtained using the <strong>micsr</strong>’s method for <code><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">sandwich::vcovHC</a></code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">sandwich</span><span class="fu">::</span><span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">pbt_unconst</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">diag</span> <span class="op">%&gt;%</span> <span class="va">sqrt</span></span>
<span><span class="co">## (Intercept)        cost      ivtime      ovtime </span></span>
<span><span class="co">##     0.10864     0.01863     0.18973     0.54202</span></span>
<span><span class="fu">stder</span><span class="op">(</span><span class="va">pbt_unconst</span>, vcov <span class="op">=</span> <span class="va">vcovHC</span><span class="op">)</span></span>
<span><span class="co">## (Intercept)        cost      ivtime      ovtime </span></span>
<span><span class="co">##     0.10864     0.01863     0.18973     0.54202</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The four estimators of the standard errors are presented in <a href="#tbl-tabestd">Table&nbsp;<span>10.3</span></a> for the unconstrained probit model. The first three give very similar estimates. The sandwich estimator gives slightly different results, especially a larger value for out-vehicle time and a smaller value for in-vehicle time. </p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-tabestd" class="anchored">
<table class="table table-sm table-striped">
<caption>Table&nbsp;10.3: Estimation of the standard deviations of the estimates</caption>
<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">information</th>
<th style="text-align: right;">hessian</th>
<th style="text-align: right;">gradient</th>
<th style="text-align: right;">sandwich</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.1092</td>
<td style="text-align: right;">0.1100</td>
<td style="text-align: right;">0.1139</td>
<td style="text-align: right;">0.1086</td>
</tr>
<tr class="even">
<td style="text-align: left;">cost</td>
<td style="text-align: right;">0.0195</td>
<td style="text-align: right;">0.0198</td>
<td style="text-align: right;">0.0211</td>
<td style="text-align: right;">0.0186</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ivtime</td>
<td style="text-align: right;">0.2382</td>
<td style="text-align: right;">0.2483</td>
<td style="text-align: right;">0.3255</td>
<td style="text-align: right;">0.1897</td>
</tr>
<tr class="even">
<td style="text-align: left;">ovtime</td>
<td style="text-align: right;">0.4952</td>
<td style="text-align: right;">0.4938</td>
<td style="text-align: right;">0.4764</td>
<td style="text-align: right;">0.5420</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section><section id="evaluation" class="level3"><h3 class="anchored" data-anchor-id="evaluation">Evaluation</h3>
<p>Once several models are estimated, the evaluation and the selection process of one of them is based on several indicators. The first indicator is the value of the objective function, which is the log-likelihood. Closely related to the log-likelihood is the deviance, which is the opposite of twice the log-likelihood. Both measures are reported in <a href="#tbl-binom_const_unconst">Table&nbsp;<span>10.2</span></a>. These measures favor lightly the logit models compared to the probit models and indicate an important difference between the constrained and unconstrained model. However, the comparison between the constrained and unconstrained models is spurious, because adding further covariates, even if they are irrelevant, necessarily increases the fit of the model. Therefore, we need indicators that penalize highly parametrized models. The two most popular indicators are the Akaike and the Bayes information criteria (<strong>AIC</strong> and <strong>BIC</strong>) which are respectively defined by <span class="math inline">\(\mbox{AIC} = - 2 \ln L + 2 K\)</span> and <span class="math inline">\(\mbox{BIC} = - 2 \ln L + K \ln N\)</span>. They are therefore obtained by augmenting the deviance by a term which is a multiple of the number of fitted parameters: 2 times for the AIC and <span class="math inline">\(\ln N\)</span> times for the BIC. The rule being to select the model for which the statistic is lower, we can see from <a href="#tbl-binom_const_unconst">Table&nbsp;<span>10.2</span></a> that the AIC leads to the choice of the unconstrained model, and the BIC leads to the choice of the constrained model. This is because the penalization in the BIC is higher, as <span class="math inline">\(\ln 842 = 6.7\)</span>. These statistics can be extracted from the fitted model using the <code>logLik</code>, <code>deviance</code>, <code>BIC</code> and <code>AIC</code> methods for <code>micsr</code> objects, for example: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">pbt_unconst</span><span class="op">)</span></span>
<span><span class="co">## [1] 645.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>logLik</code> method for <code>micsr</code> objects has a <code>type</code> argument which enables to extract the value for the proposed model (<code>type = "mode"</code>, the default), the null model or the saturated model: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_unconst</span><span class="op">)</span></span>
<span><span class="co">## 'log Lik.' -318.8 (df=4)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"model"</span><span class="op">)</span></span>
<span><span class="co">## 'log Lik.' -318.8 (df=4)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"null"</span><span class="op">)</span></span>
<span><span class="co">## 'log Lik.' -370.7 (df=1)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"saturated"</span><span class="op">)</span></span>
<span><span class="co">## 'log Lik.' 0 (df=842)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> In linear model, a popular indicator of the quality of a model is the coefficient of determination, called R<sup>2</sup>. For linear models: <span class="math inline">\(\sum (y_n - \bar{y}) ^ 2 = \sum (\hat{y}_n - \bar{y}) ^ 2 + \sum \hat{\epsilon}_n ^ 2\)</span> because the vectors of fitted values and residuals are orthogonal. The R<sup>2</sup> can therefore be defined using three equivalent formulas:<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><span id="eq-rsqlin"><span class="math display">\[
R ^ 2 = \frac{\sum (\hat{y}_n - \bar{y}) ^ 2}{\sum (y_n - \bar{y}) ^
2} = 1 - \frac{\sum \hat{\epsilon}_n^2}{\sum (y_n - \bar{y}) ^ 2} =
\hat{\rho}_{y,\hat{y}} ^ 2
\tag{10.10}\]</span></span></p>
<p>The first formula is particularly appealing, as it indicates the share of the variance of the response that is explained by the model: it is therefore bounded by 0 and 1. It is 0 if the model has no explanatory power, which means that the fit is equivalent to the null model, i.e., the model with no covariates. It is one for a “perfect” model, i.e., a model for which the vector of residuals is 0.</p>
<p>The three formulas are not equivalent for binomial models and, therefore, there is no unambiguous formula for the R<sup>2</sup> for these models. A lot of different formulas have been proposed in the literature.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> The <strong>micsr</strong> package provides an <code>rsq</code> function which has a type argument. By setting <code>type</code> to <code>"ess"</code>, <code>"rss"</code> and <code>"cor"</code>, we get the three versions of the R<sup>2</sup> described in <a href="#eq-rsqlin">Equation&nbsp;<span>10.10</span></a>. The <code>"rss"</code> version is often called the Efron’s R<sup>2</sup><span class="citation" data-cites="EFRO:78">(<a href="#ref-EFRO:78" role="doc-biblioref">Efron 1978</a>)</span> and was previously proposed by <span class="citation" data-cites="LAVE:70">Lave (<a href="#ref-LAVE:70" role="doc-biblioref">1970</a>)</span>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"ess"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.1164</span></span>
<span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"rss"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.1336</span></span>
<span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"cor"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.1342</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As seen in <a href="maximum_likelihood.html#sec-pseudo_r2_ml"><span>Section&nbsp;5.3.1.2</span></a>, in the linear model, the R<sup>2</sup> is related to statistics that test the hypothesis that all the coefficients of the model except the intercept are 0. This leads to pseudo-R<sup>2</sup> that are obtained using any of the three classical tests statistic: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"wald"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.08751</span></span>
<span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"lr"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.116</span></span>
<span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"score"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.1111</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="citation" data-cites="TJUR:09">Tjur (<a href="#ref-TJUR:09" role="doc-biblioref">2009</a>)</span> proposed an R<sup>2</sup> that he called the coefficient of discrimination. This coefficient is the difference between the probability of success for the subsample for which <span class="math inline">\(y=1\)</span> and the subsample for which <span class="math inline">\(y=0\)</span>. Tjur’s measure is interestingly related to the ESS, the RSS and the correlation measure of the R<sup>2</sup>. More precisely:</p>
<p><span class="math display">\[
R ^ 2 = \frac{1}{2}\left(R ^ 2_{\mbox{ess}} + R ^ 2_{\mbox{rss}}\right) =
\sqrt{R ^ 2_{\mbox{ess}} R ^ 2_{\mbox{cor}}}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"tjur"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.125</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It summarizes the difference in the distribution of the fitted values for the two subsamples defined by <span class="math inline">\(y=1/0\)</span>. The <code>plot</code> method for <code>binomreg</code> objects draws these two distributions as an histogram and indicates the average fit for the two groups by a dot on the horizontal axis. Tjur’s R<sup>2</sup> is then simply the distance between these two points. For the probit unconstrained model of mode choice, the result is represented in <a href="#fig-histbinom">Figure&nbsp;<span>10.3</span></a> and the same plot is presented for the <code>airbnb</code> data set in <a href="#fig-histairbnb">Figure&nbsp;<span>10.4</span></a>.</p>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-histbinom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="binomial_files/figure-html/fig-histbinom-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.3: Histogram of the distribution of the fitted values for the probit mode choice model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-histairbnb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="binomial_files/figure-html/fig-histairbnb-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.4: Histogram of the distribution of the fitted values for the Airbnb probit model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-histairbnb">Figure&nbsp;<span>10.4</span></a> reveals a very poor fit, as the two points are very close. This can be checked by computing the R<sup>2</sup>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pt_a</span>, type <span class="op">=</span> <span class="st">"tjur"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.0127</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="citation" data-cites="ESTR:98">Estrella (<a href="#ref-ESTR:98" role="doc-biblioref">1998</a>)</span> proposed a <span class="math inline">\(R^2\)</span> based on the likelihood ratio statistic comparing the proposed model and the null model, for which only one parameter is estimated. The average likelihood ratio statistic is:</p>
<p><span class="math display">\[
A_{LR} = \frac{2}{N} \left(\ln L - \ln L_0\right)
\]</span></p>
<div style="page-break-after: always;"></div>
<p>If the model has no explanatory power, <span class="math inline">\(\ln L = \ln L_0\)</span> so that the minimum value of <span class="math inline">\(A_{LR}\)</span> is 0. For the saturated model, <span class="math inline">\(L = 1\)</span>, so that the maximum value of <span class="math inline">\(A_{LR}\)</span> is <span class="math inline">\(B = - \frac{2}{N} \ln L_0\)</span>. The proposed <span class="math inline">\(R ^ 2\)</span> follows the following differential equation:</p>
<p><span class="math display">\[
\frac{d R^ 2}{1 - d R ^ 2} = \frac{d A}{1 - A/B}
\]</span></p>
<p>which means that the relative change of the <span class="math inline">\(R ^ 2\)</span> should be equal to the relative change of the average likelihood ratio. The solution to this differential equation is: <span class="math inline">\(1 - (1 - A/B) ^ B\)</span>, so that the <span class="math inline">\(R ^ 2\)</span> is:</p>
<p><span class="math display">\[
R ^ 2 = 1 - \left(\frac{\ln L}{\ln L_0}\right) ^ {-\frac{2}{N} \ln L_0}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"estrella"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.1244</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="citation" data-cites="MCFA:73">McFadden (<a href="#ref-MCFA:73" role="doc-biblioref">1973</a>)</span> proposed the very popular pseudo-R<sup>2</sup>:</p>
<p><span class="math display">\[
R ^ 2 = 1 - \frac{\ln L_0}{\ln L}
\]</span> </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"mcfadden"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.14</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="citation" data-cites="MCKE:ZAVO:75">McKelvey and Zavoina (<a href="#ref-MCKE:ZAVO:75" role="doc-biblioref">1975</a>)</span> proposed a R<sup>2</sup> based on the latent variable. Denoting <span class="math inline">\(\hat{y}_n ^* = \hat{\alpha}+\hat{\beta} ^ \top x_n\)</span> as the fitted values and <span class="math inline">\(\bar{y}^*\)</span> as the sample mean, the explained sum of squares is: <span class="math inline">\(\sum (\hat{y}_n ^ * - \bar{y}^ *) ^ 2\)</span> and the residuals sum of squares is not estimated, but its expected value is <span class="math inline">\(N\)</span> times the variance of the errors, which is 1 for a probit and <span class="math inline">\(\pi ^ 2 / 3\)</span> for a logit. The R<sup>2</sup> is then obtained by dividing the explained sum of squares by the sum of the explained sum of squares and either <span class="math inline">\(N\)</span> or <span class="math inline">\(N\pi ^ 2 / 3\)</span> respectively for the probit and logit models. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rsq</span><span class="op">(</span><span class="va">pbt_unconst</span>, type <span class="op">=</span> <span class="st">"mckel_zavo"</span><span class="op">)</span></span>
<span><span class="co">## [1] 0.2726</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</section><section id="testing" class="level3"><h3 class="anchored" data-anchor-id="testing">Testing</h3>
<section id="tests-of-nested-models" class="level4"><h4 class="anchored" data-anchor-id="tests-of-nested-models">Tests of nested models</h4>
<p>To test nested models, the three tests described in <a href="multiple_regression.html#sec-three_tests"><span>Section&nbsp;3.6.3</span></a> and <a href="maximum_likelihood.html#sec-three_tests_ml"><span>Section&nbsp;5.3.1</span></a> are available. In <a href="#sec-func_form_binom"><span>Section&nbsp;10.1</span></a>, we estimated a model with the generalized cost as a unique covariate, which was computed as: <span class="math inline">\(g_n = c_n + 8(i_n + o_n)\)</span>, where <span class="math inline">\(c\)</span>, <span class="math inline">\(i\)</span>, and <span class="math inline">\(o\)</span> are the differences in monetary cost, in-vehicle time and out-vehicle time, based on the hypothesis that time value was $8 per hour. The unconstrained model is:</p>
<p><span class="math display">\[
P(y_n = 1) = \Phi(\alpha + \beta_c c_n + \beta_i i_n + \beta_o o_n)
\]</span></p>
<p>The constrained model implies the two following hypotheses: <span class="math inline">\(H_O: \beta_o = \beta_i = 8 \beta_c\)</span>. It is more convenient to rewrite the model so that, under H<sub>0</sub>, a subset of the parameters are 0:</p>
<p><span class="math display">\[
\begin{array}{rcl}
P(y_n = 1) &amp;=&amp; \Phi\left(\alpha + \beta_c \left(c_n + 8 (i_n +
o_n)\right) + (\beta_i - 8\beta_c)i_n + (\beta_o - 8 \beta_c)
o_n\right)\\
&amp;=&amp; \Phi(\alpha + \beta_c g_n + \beta_i'i_n + \beta_o'o_n)
\end{array}
\]</span></p>
<p>where <span class="math inline">\(\beta_i' = (\beta_i - 8\beta_c)\)</span> and <span class="math inline">\(\beta_o = (\beta_o - 8\beta_c)\)</span> are the reduced form parameters of the binomial regression with the generalized cost, the in-vehicle and out-vehicle time as covariates. With this parametrization, the set of hypotheses is simply <span class="math inline">\(\beta_i' = \beta_o' = 0\)</span>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pbt_unconst2</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">mode</span> <span class="op">~</span> <span class="va">gcost</span> <span class="op">+</span> <span class="va">ivtime</span> <span class="op">+</span> <span class="va">ovtime</span>, </span>
<span>                         data <span class="op">=</span> <span class="va">mode_choice</span>, link <span class="op">=</span> <span class="st">"probit"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> Tests can be computed using several functions in the <strong>lmtest</strong> package <span class="citation" data-cites="ZEIL:HOTH:02">(<a href="#ref-ZEIL:HOTH:02" role="doc-biblioref">Zeileis and Hothorn 2002</a>)</span>. The likelihood ratio test can easily be computed “by hand”, as it is twice the difference of the log-likelihood functions of the unconstrained and constrained models: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_unconst</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">pbt_const</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## [1] 11</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>but <code><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lmtest::lrtest</a></code> is a convenient function which computes the statistic and the probability value:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lrtest</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, <span class="va">pbt_const</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 11.002, df: 2, pval = 0.004</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p></p>
<p> The Wald test can be computed using either <code><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">lmtest::waldtest</a></code> or <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">car::linearHypothesis</a></code>. <code><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">lmtest::waldtest</a></code> provides two possible syntaxes: two fitted models, as <code><a href="https://rdrr.io/pkg/lmtest/man/lrtest.html">lmtest::lrtest</a></code> or the fitted unconstrained model and a formula describing the constrained model. <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">car::linearHypothesis</a></code>, already described in <a href="multiple_regression.html#sec-wald_test_example"><span>Section&nbsp;3.6.4.1</span></a>, uses a character vector to indicate the hypothesis: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">pbt_unconst2</span>, <span class="va">pbt_const</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 10.987, df: 2, pval = 0.004</span></span>
<span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/waldtest.html">waldtest</a></span><span class="op">(</span><span class="va">pbt_unconst2</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">ivtime</span> <span class="op">-</span> <span class="va">ovtime</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 10.987, df: 2, pval = 0.004</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">pbt_unconst</span>, </span>
<span>                      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ivtime = 8 * cost"</span>, <span class="st">"ovtime = 8 * cost"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 10.987, df: 2, pval = 0.004</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> Finally, score tests are provided by the <code><a href="https://rdrr.io/pkg/micsr/man/scoretest.html">micsr::scoretest</a></code> function. Its first argument is the constrained fitted model and the second one a formula that describes the unconstrained model: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">scoretest</span><span class="op">(</span><span class="va">pbt_const</span> , <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">ivtime</span> <span class="op">+</span> <span class="va">ovtime</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 10.231, df: 2, pval = 0.006</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> The three statistics are very close and the joint hypothesis is rejected at the 1% level.</p>
</section><section id="sec-cond_moment_binomial" class="level4"><h4 class="anchored" data-anchor-id="sec-cond_moment_binomial">Conditional moment test</h4>
<p> The conditional moment tests have been presented in <a href="maximum_likelihood.html#sec-ml_cond_moment_test"><span>Section&nbsp;5.3.2</span></a> and the relevant moments are given by <a href="maximum_likelihood.html#eq-emp_moments_homosc">Equation&nbsp;<span>5.44</span></a> (for the heteroskedasticity test), <a href="maximum_likelihood.html#eq-emp_moments_normal">Equation&nbsp;<span>5.43</span></a> (for the normal test) and <a href="maximum_likelihood.html#eq-emp_moments_omit_var">Equation&nbsp;<span>5.45</span></a> (for the omitted variable test). The empirical moments use the powers (up to 4) of the residuals. As the residuals are unobserved, <span class="math inline">\(\epsilon_n ^ k\)</span> is replaced by their expectations, i.e., by the uncentered moments of the residuals:</p>
<p><span id="eq-moments_errors"><span class="math display">\[
m_k = \mbox{E}(\epsilon_n ^ k \mid x_n) = (1-y_n) \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) + y_n \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * &gt; 0)
\tag{10.11}\]</span></span></p>
<p>For the probit model, the first four moments of the truncated normal distribution should be computed. A recursive formula for the moments of a normal variable <span class="math inline">\(x \sim \mathcal{N}(\eta, \sigma)\)</span> with <span class="math inline">\(l\leq x \leq u\)</span> is:<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p><span id="eq-moments_normal_trunc"><span class="math display">\[
m_k = (k-1)\sigma ^ 2 m_{k-2} + \eta m_{k-1} - \sigma \frac{u ^ {k-1}\phi\left(\frac{u-\eta}{\sigma}\right) - l ^ {k-1}\phi\left(\frac{l-\eta}{\sigma}\right)}
{\Phi\left(\frac{u-\eta}{\sigma}\right) - \Phi\left(\frac{l-\eta}{\sigma}\right)}
\tag{10.12}\]</span></span></p>
<p>with <span class="math inline">\(m_{-1} = 0\)</span> and <span class="math inline">\(m_{0} = 1\)</span>. For a residual of the probit model, we have <span class="math inline">\(\eta = 0\)</span> and <span class="math inline">\(\sigma = 1\)</span> and the truncature is <span class="math inline">\(-\mu_n\)</span>. We then obtain, for <span class="math inline">\(y_n^* \leq 0\)</span> (<span class="math inline">\(l = - \infty\)</span> and <span class="math inline">\(u = -\mu_n\)</span>) and <span class="math inline">\(y_n ^ * &gt; 0\)</span> (<span class="math inline">\(l = - \mu_n\)</span> and <span class="math inline">\(u = +\infty\)</span>):</p>
<p><span class="math display">\[
\left\{
\begin{array}{rclrcl}
\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) &amp;=&amp; (k - 1)  m_{k-2} - (- \mu_n) ^ {k-1} \frac{\phi(\mu_n / \sigma)}{1-\Phi(\mu_n / \sigma)} \\
\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * &gt; 0) &amp;=&amp; (k - 1)  m_{k-2} + (- \mu_n) ^ {k-1} \frac{\phi(\mu_n / \sigma)}{\Phi(\mu_n / \sigma)} \\
\end{array}
\right.
\]</span></p>
<p>Using <a href="#eq-moments_errors">Equation&nbsp;<span>10.11</span></a>, the recursive formula for the k<sup>th</sup> moment of <span class="math inline">\(\epsilon\)</span> is simply:</p>
<p><span class="math display">\[
m_k = (k-1) m_{k-2} + (-\mu_n)^{k-1}\frac{(y_n - \Phi(\mu_n / \sigma))\phi(\mu_n / \sigma)}{\Phi(\mu_n / \sigma)(1 - \Phi(\mu_n / \sigma))} = (k-1)m_{k-2} + (-\mu) ^ {k - 1} \psi_n
\]</span></p>
<p>where <span class="math inline">\(\psi_n\)</span> is the generalized residual defined by <a href="#eq-gen_resid_probit">Equation&nbsp;<span>10.9</span></a>.</p>
<!-- $$ -->
<!-- \begin{array}{ccccc} -->
<!-- k & \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0)  & \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * > 0) & \mbox{E}(\epsilon_n ^ k \mid x_n) & \mbox{moment} \\ -->
<!-- 1 & - r_{n0} & r_{n1} & r_n & \sum_n r_n w_n\\ -->
<!-- 2 & 1 + \mu_n r_{n0} & 1 - \mu_n r_{n1} & 1 - \mu_n r & - \sum_n \mu_n r_n w_n\\ -->
<!-- 3 & - (2 + \mu_n ^ 2) r_{n0} & (2 + \mu_n ^ 2) r_{n1} & (2 + \mu_n ^ 2) r & \sum_n \mu_n ^ 2 r_n\\ -->
<!-- 4 & 3 + (3 \mu_n + \mu_n ^ 3)r_{n0} & 3 - (3 \mu_n + \mu_n ^ 3)r_{n1} & 3 - (3 \mu_n + \mu_n ^ 3)r & - \sum_n \mu_n ^ 3 r_n -->
<!-- \end{array} -->
<!-- $$ -->
<p>The omitted variable test uses the first moment, the homoskedasticity test the second and the normality test the third and fourth. The moments of <span class="math inline">\(\epsilon_n\)</span>, the theoretical moments for the three hypotheses and their empirical counterparts are presented in the following table:<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p><span id="eq-table_moments_probit"><span class="math display">\[
\begin{array}{clcccc}\hline
k &amp; \mbox{hypothesis} &amp; \mbox{E}(\epsilon_n ^ k \mid x_n) &amp; \mbox{theor. moment} &amp; \mbox{emp. moment} \\ \hline
1 &amp; \mbox{omit. var.} &amp; \psi_n &amp; \mbox{E}(\epsilon_n w_n\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \psi_n w_n\\
2 &amp; \mbox{homosc.} &amp; 1 - \mu_n \psi_n &amp; \mbox{E}((\epsilon_n^2-1) w_n\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \mu_n \psi_n w_n\\
3 &amp; \mbox{asymetry} &amp;  (2 + \mu_n ^ 2) \psi_n &amp;\mbox{E}(\epsilon_n^3\mid x_n) = 0 &amp;  \frac{1}{N}\sum_n \mu_n ^ 2 \psi_n\\
4 &amp; \mbox{kurtosis} &amp; 3 - (3 \mu_n + \mu_n ^ 3)\psi_n &amp; \mbox{E}(\epsilon_n^4 - 3\mid x_n) = 0 &amp; \frac{1}{N} \sum_n \mu_n ^ 3 \psi_n \\\hline
\end{array}
\tag{10.13}\]</span></span></p>
<div style="page-break-after: always;"></div>
<p>The <code>miscr::cmtest</code> function computes the conditional moment test; the first argument is a fitted model the second one is <code>test</code> which can be equal to <code>"normality"</code>, <code>"reset"</code> (for tests for omitted variables) or <code>"heterosc"</code>. The two joint hypothesis corresponding to the normality hypothesis can be tested one by one by setting <code>test</code> either to <code>"skewness"</code> or <code>"kurtosis"</code>. For the homoskedasticity tests, the set of variables can be selected using the <code>heter_cov</code> argument. By default, all the covariates used in the model are selected. By default, tests are performed using the hessian, but the outer product of the gradient form of the test can be computed by setting <code>opg</code> to <code>TRUE</code>. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">cmtest</span><span class="op">(</span><span class="va">pbt_unconst</span>, test <span class="op">=</span> <span class="st">"normality"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 4.700, df: 2, pval = 0.095</span></span>
<span><span class="fu">cmtest</span><span class="op">(</span><span class="va">pbt_unconst</span>, test <span class="op">=</span> <span class="st">"heterosc"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 4.129, df: 3, pval = 0.248</span></span>
<span><span class="fu">cmtest</span><span class="op">(</span><span class="va">pbt_unconst</span>, test <span class="op">=</span> <span class="st">"reset"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 3.218, df: 2, pval = 0.200</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our probit model seems to be correctly specified, as the three hypotheses are not rejected. </p>
</section></section></section><section id="sec-endog_probit" class="level2" data-number="10.5"><h2 data-number="10.5" class="anchored" data-anchor-id="sec-endog_probit">
<span class="header-section-number">10.5</span> Endogeneity</h2>
<p> We now consider the case where some of the covariates are endogenous. In a linear model, the solution is to use an instrumental variable estimator, which can be estimated using the 2SLS approach and therefore by using only the <code>lm</code> function. We treat in this section the case where the response is binomial, and we consider that the realization of <span class="math inline">\(y\)</span> is related to the value of a latent variable <span class="math inline">\(y_n ^ *\)</span>, with the usual observation rule: (<span class="math inline">\(y = 0\)</span> if <span class="math inline">\(y^* \leq 0\)</span> and <span class="math inline">\(y = 1\)</span> if <span class="math inline">\(y^*&gt;0\)</span>). <span class="math inline">\(y^*\)</span> is a linear function of a set of <span class="math inline">\(K_1\)</span> exogenous (<span class="math inline">\(x_1\)</span>) and <span class="math inline">\(G\)</span> endogenous (<span class="math inline">\(e\)</span>) covariates:</p>
<p><span class="math display">\[
y_n ^ * = \alpha + \beta ^ \top x_{1n} + \delta ^ \top e_n + \epsilon_n = \gamma ^ \top
z_n + \epsilon_n
\]</span> with <span class="math inline">\(\gamma ^ \top = (\alpha, \beta ^ \top, \delta ^ \top)\)</span> and <span class="math inline">\(z_n ^ \top = (1, x_{1n} ^ \top, e_n ^ \top)\)</span>.</p>
<p>The reduced form equation for each endogenous variable is:</p>
<p><span class="math display">\[
e_{gn} = \pi_g ^ \top w_n + \nu_{gn}
\]</span></p>
<p>where <span class="math inline">\(w_n^\top = (1, x_{1n} ^ \top, x_{2n} ^ \top)\)</span>, <span class="math inline">\(x_{2n}\)</span> being a vector of <span class="math inline">\(K_2\)</span> external instruments. It is assumed that <span class="math inline">\(K_2 \geq G\)</span>. The joint distribution of <span class="math inline">\(y_n^*\)</span> and <span class="math inline">\(w_n\)</span> is normal:</p>
<p><span class="math display">\[
\left(\begin{array}{c} y^* \\ e \end{array}\right) \sim N \left(
\left(\begin{array}{c} \gamma ^ \top z_n  \\ \Pi w_n
\end{array}\right) ;
\left(
\begin{array}{cc} \sigma_\epsilon ^ 2 &amp; \sigma_{\epsilon\nu} ^ \top \\ \sigma_{\epsilon\nu} &amp;
\Sigma_\nu \end{array}
\right)
\right)
\]</span></p>
<p>where <span class="math inline">\(\Pi\)</span> is an <span class="math inline">\((K_1+K_2+1) \times G\)</span> matrix with the <span class="math inline">\(g\)</span><sup>th</sup> line equal to <span class="math inline">\(\pi_g ^ \top\)</span>, <span class="math inline">\(\Sigma_\nu\)</span> is the <span class="math inline">\(G\times G\)</span> matrix of covariance of <span class="math inline">\(\nu\)</span> and <span class="math inline">\(\sigma_{\epsilon\nu}\)</span> is a vector of length <span class="math inline">\(G\)</span> containing the covariances between <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\nu\)</span>. Conditional on <span class="math inline">\(w_n\)</span>, the distribution of <span class="math inline">\(y_n ^ *\)</span> is also normal:</p>
<p><span id="eq-ycond"><span class="math display">\[
y_n ^ * \mid e_n \sim N \left(\gamma ^ \top z_n + \sigma_{\epsilon\nu}
^ \top \Sigma_\nu ^ {-1}(e_n - \Pi w_n), \sigma_\epsilon ^ 2 -
\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}\right)
\tag{10.14}\]</span></span></p>
<p>Let <span class="math inline">\(\rho = \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}\)</span> and <span class="math inline">\(\sigma ^ 2 = \sigma_\epsilon ^ 2 - \sigma_{\epsilon\nu} ^ \top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}\)</span>. The conditional mean of <span class="math inline">\(y^*_n\)</span> is then <span class="math inline">\(\theta ^ \top u_n\)</span>, with <span class="math inline">\(\theta ^ \top = (\gamma ^ \top, \rho ^ \top)\)</span> and <span class="math inline">\(u_n ^ \top = (z_n ^ \top, \nu_n ^ \top)\)</span> and its conditional variance is <span class="math inline">\(\sigma ^ 2\)</span>.</p>
<section id="maximum-likelihood-estimation" class="level3"><h3 class="anchored" data-anchor-id="maximum-likelihood-estimation">Maximum likelihood estimation</h3>
<p>The joint density of <span class="math inline">\(y_n^*\)</span> and <span class="math inline">\(e_n\)</span> can be written as the product of the conditional density of <span class="math inline">\(y_n^*\)</span> and the marginal density of <span class="math inline">\(e_n\)</span>, which is multivariate normal:</p>
<p><span id="eq-marg_density_w"><span class="math display">\[
\ln g(e_n) = - \frac{1}{2}
\left(G \ln 2\pi + \ln \mid \Sigma_\nu \mid + \nu_n ^ \top \Sigma_\nu
^ {-1} \nu_n\right)
\tag{10.15}\]</span></span></p>
<p>We consider here the case where <span class="math inline">\(y_n ^ *\)</span> is not observed, but only its sign. Therefore, we observe <span class="math inline">\(y_n\)</span> equal to 0 or 1, or <span class="math inline">\(q_n = 2 y_n - 1\)</span> equal to <span class="math inline">\(-1\)</span> or <span class="math inline">\(+1\)</span>. The log-likelihood is then <span class="math inline">\(\ln L = \sum_{n=1} ^ N \ln g(e_n) + \ln f(y_n \mid e_n)\)</span>, where <span class="math inline">\(g(e)\)</span> is given by <a href="#eq-marg_density_w">Equation&nbsp;<span>10.15</span></a> and:</p>
<p><span id="eq-cond_density_y_star"><span class="math display">\[
f(y_n \mid d_n) = \Phi\left(q_n\frac{\theta ^ \top u_n}{\sigma} \right) =
\Phi\left(q_n\frac{\gamma ^ \top z_n + \sigma_{\epsilon\nu}
^ \top \Sigma_\nu ^ {-1}(e_n - \Pi w_n)}{\sqrt{\sigma_\epsilon ^ 2 -
\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}}}\right)
\tag{10.16}\]</span></span></p>
<p>The computation of the estimator is simplified by the use of the Cholesky decomposition of <span class="math inline">\(\Sigma_\nu ^ {-1}\)</span>, i.e., by considering the upper triangular matrix <span class="math inline">\(C\)</span> such that <span class="math inline">\(C^\top C= \Sigma_\nu ^ {-1}\)</span>. Then, the determinant of <span class="math inline">\(\Sigma_\nu ^ {-1}\)</span> is simply the product of the squares of the diagonal elements of <span class="math inline">\(C\)</span>. Therefore, <span class="math inline">\(\ln \mid \Sigma_\nu ^ {-1} \mid = 2 \sum_g \ln C_{gg}\)</span> and <span class="math inline">\(\ln \mid \Sigma_\nu \mid = - 2 \sum_g \ln C_{gg}\)</span>. Denoting <span class="math inline">\(\Pi ^ * = C \Pi\)</span>, <span class="math inline">\(w_n^* = C w_n\)</span> and <span class="math inline">\(\rho ^ * = C \sigma_{\epsilon\nu}\)</span> we have : <span class="math inline">\(\theta ^ \top u_n = \gamma ^ \top z_n + \rho ^ {* \top} (e_n^* - \Pi ^ * w_n)\)</span> and <span class="math inline">\(\sigma ^ 2 = \sigma_\epsilon ^ 2 - \rho ^{*\top} \rho ^ *\)</span>. The marginal density of <span class="math inline">\(e_n\)</span> and the conditional density of <span class="math inline">\(y_n\)</span> are then:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rcl}
\ln g(e_n) &amp;=&amp; -
\frac{1}{2} G \ln 2\pi + \sum_{g = 1} ^ G  \ln C_{gg} -
\frac{1}{2} (e_n ^ * - \Pi ^ * w_n) ^ \top (e_n ^ * - \Pi ^ * w_n) \\
\ln f(y_n \mid e_n) &amp;=&amp; \Phi\left((2 y_n - 1) \frac{\gamma ^ \top z_n + \rho ^ {*
\top} (e_n^* - \Pi ^ * w_n)}
{\sqrt{\sigma_\epsilon ^ 2 - \rho ^{*\top} \rho ^ *}}\right)
\end{array}
\right.
\]</span> The maximum likelihood estimator is then obtained by maximizing the log-likelihood function <span class="math inline">\(\ln L = \sum_{n=1} ^ N \left(\ln g(e_n) + \ln f(y_n \mid e_n)\right)\)</span> with respect to <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(\rho ^*\)</span>, <span class="math inline">\(\Pi ^ *\)</span> and <span class="math inline">\(C\)</span>. <span class="math inline">\(\sigma_\epsilon\)</span> is not identified and can be set to 1.</p>
</section><section id="two-step-estimator" class="level3"><h3 class="anchored" data-anchor-id="two-step-estimator">Two-step estimator</h3>
<p> From <a href="#eq-ycond">Equation&nbsp;<span>10.14</span></a>, we have <span class="math inline">\(y_n ^ * \sim N \left(\gamma ^ \top z_n + \rho ^ \top \nu_n, \sigma^2\right)\)</span>. If <span class="math inline">\(y_n ^ *\)</span> and <span class="math inline">\(\nu_n\)</span> were observed, the model could be consistently estimated by regressing <span class="math inline">\(y_n ^ *\)</span> on <span class="math inline">\(z_n\)</span> and <span class="math inline">\(\nu_n\)</span>. <span class="math inline">\(\nu_n\)</span> is actually unknown, but it can be consistently estimated using the estimation of <span class="math inline">\(\hat{\Pi}\)</span> obtained by maximizing <span class="math inline">\(\sum_{n=1} ^ N \ln g(e_n)\)</span>. This is a seemingly unrelated regression problem, and it is well known that, for the special case where the set of covariates is the same for all the equations, the estimator can be obtained using OLS independently on each equation. From this first step, we obtain <span class="math inline">\(\hat{\nu}_n = e_n - \hat{\Pi} w_n\)</span> and, in the second step, <span class="math inline">\(\hat{\gamma}\)</span> and <span class="math inline">\(\hat{\rho}\)</span> are obtained by regressing <span class="math inline">\(y_n ^*\)</span> on <span class="math inline">\(z_n\)</span> and <span class="math inline">\(\hat{\nu}_n\)</span>.</p>
<div style="page-break-after: always;"></div>
<p>Regressing <span class="math inline">\(y_n ^ *\)</span> on a vector of 1, <span class="math inline">\(x_{1n}\)</span>, <span class="math inline">\(e_n\)</span> and <span class="math inline">\(\hat{\nu}_n\)</span> is one way to obtain the instrumental variable estimator. This approach (called <strong>control function</strong>) is identical to the 2SLS estimator but provides supplementary estimates (<span class="math inline">\(\hat{\rho}\)</span> associated with <span class="math inline">\(\hat{\nu}_n\)</span>) that can be used to test the hypothesis of exogeneity. If <span class="math inline">\(G = 1\)</span>, the test can be performed using the Student statistic. If <span class="math inline">\(G &gt; 1\)</span>, the joint hypothesis that <span class="math inline">\(\rho= 0\)</span> can be tested using a Wald test, the statistic being a <span class="math inline">\(\chi ^ 2\)</span> with <span class="math inline">\(G\)</span> degrees of freedom under the null hypothesis of exogeneity.</p>
<p>This two-step instrumental variable estimator and test has been extended for the case where <span class="math inline">\(y_n ^*\)</span> is only partially observed by <span class="citation" data-cites="SMIT:BLUN:86">Smith and Blundell (<a href="#ref-SMIT:BLUN:86" role="doc-biblioref">1986</a>)</span> and <span class="citation" data-cites="RIVE:VUON:88">Rivers and Vuong (<a href="#ref-RIVE:VUON:88" role="doc-biblioref">1988</a>)</span> (respectively for the tobit and the probit models). It can be computed as follows:</p>
<ul>
<li>compute the OLS estimator of <span class="math inline">\(\pi_g\)</span> for the G endogenous variables and retrieve the residuals <span class="math inline">\(\hat{\nu}_{gn}\)</span>,</li>
<li>estimate <span class="math inline">\(\theta ^ \top = (\gamma ^ \top, \rho^\top)\)</span> using a probit model with <span class="math inline">\(z_n\)</span>, and <span class="math inline">\(\hat{\nu}_n\)</span> as covariates,</li>
<li>test the hypothesis that <span class="math inline">\(\rho = 0\)</span>.</li>
</ul>
<p>As it is customary for two-step estimators, the covariance matrix returned by the probit model is inconsistent because it doesn’t take into account the fact that <span class="math inline">\(\nu_n\)</span> is unknown and is replaced by a consistent estimator. Denoting <span class="math inline">\(\pi = \mbox{vec} \,\Pi\)</span>, the first-order approximation of the vector of scores is:</p>
<p><span class="math display">\[
\frac{\partial \ln L}{\partial \theta}(\hat{\theta}, \hat{\pi}) \approx
\frac{\partial \ln L}{\partial \theta} +
\frac{\partial \ln^2 L}{\partial \theta \partial \theta ^
\top}\times (\hat{\theta} - \theta) +
\frac{\partial \ln^2 L}{\partial \theta \partial \pi ^
\top}\times (\hat{\pi} - \pi)
\]</span></p>
<p>Taking expectation and solving for <span class="math inline">\(\hat{\theta} - \theta\)</span>, we get:</p>
<!-- $$ -->
<!-- i_n = \theta ^ \top z_n + \rho ^ \top \hat{v}_n = \theta ^ \top u_n -->
<!-- $$ -->
<p><span class="math display">\[
\hat{\theta} - \theta = \mbox{E}\left(- \frac{\partial ^ 2 \ln L}{\partial
\theta \partial \theta ^ \top}\right)^{-1} \left(\frac{\partial \ln L}{\partial
\theta} +
\mbox{E}\left(\frac{\partial ^ 2 \ln L}{\partial
\theta \partial\pi ^ \top}\right) (\hat{\pi} - \pi)\right)
= A ^ {-1}\left(\frac{\partial \ln L}{\partial
\theta} + B (\hat{\pi} - \pi)\right)
\]</span></p>
<p>As the two terms in the brackets are uncorrelated and using the information matrix equality, we get:</p>
<p><span class="math display">\[
\hat{V}({\hat{\theta}}) = A ^ {-1} + A ^ {-1} B \hat{V}(\hat{\pi}) B ^
\top A ^ {-1}
\]</span></p>
<p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> contain the second derivatives of the individual contribution to the log-likelihood function for the probit model. These are, defining: <span class="math inline">\(\eta_n = \gamma ^ \top z_n + \rho \hat{\nu}_n\)</span> and <span class="math inline">\(r_n = \phi(\eta_n) / (1 - \Phi(\eta_n))\)</span>:</p>
<p><span class="math display">\[
\frac{\partial ^ 2\ln l_n}{\partial \eta_n \partial \eta_n ^ \top} = -
r_n \left(r_n + \eta_n \right) = - \psi_n
\]</span></p>
<p>More precisely, <span class="math inline">\(A = \sum_{n=1} ^ N \psi_ n \hat{u}_n \hat{u}_n ^ \top\)</span> and <span class="math inline">\(B = \sum_{n=1} ^ N \rho ^ \top \otimes \psi_n \hat{u}_n w_n ^ \top\)</span> or, defining <span class="math inline">\(\Psi\)</span> a diagonal matrix of dimension <span class="math inline">\(N\)</span> containing <span class="math inline">\(\psi_n\)</span>: <span class="math inline">\(A = \hat{U} ^ \top \Psi \hat{U}\)</span> and <span class="math inline">\(B = \hat{U} ^ \top \Psi W\)</span>, with <span class="math inline">\(\hat{U}\)</span> the <span class="math inline">\(N\times (K_1 + 2 G + 1)\)</span> matrix with rows <span class="math inline">\((1, x_{1n} ^ \top, e_n ^ \top, \hat{\nu}_n ^\top)\)</span> and <span class="math inline">\(W\)</span> the <span class="math inline">\(N\times (K_1 + K_2 + 1)\)</span> matrix with rows <span class="math inline">\(w_n^\top = (1, x_{1n} ^ \top, x_{2n} ^ \top)\)</span>. As <span class="math inline">\(\hat{V}(\hat{\pi})\)</span> is the variance of the SUR estimator with identical covariates, <span class="math inline">\(\hat{V}(\hat{\pi}) = \hat{\Sigma}_\nu \otimes (W ^ \top W) ^ {-1}\)</span> and the expression further simplifies to:</p>
<p><span class="math display">\[
\hat{V}(\hat{\theta}) =
(\hat{U} ^ \top \Psi \hat{U}) ^ {-1} +
(\hat{\rho} ^ \top \hat{\Sigma} \hat{\rho})\times
(\hat{U} ^ \top \Psi \hat{U}) ^ {-1} (\hat{U} ^  \top \Psi W) (W ^ \top W) ^ {-1} (W ^  \top \Psi \hat{U}) (\hat{U} ^ \top \Psi \hat{U}) ^ {-1}
\]</span></p>
<p><span class="citation" data-cites="SMIT:BLUN:86">Smith and Blundell (<a href="#ref-SMIT:BLUN:86" role="doc-biblioref">1986</a>)</span> proposed an endogeneity test based on the two-step estimator. As for the linear instrumental variable estimator, it is a Wald test that <span class="math inline">\(\rho = 0\)</span>, but it uses the simple probit estimation of the covariance matrix. </p>
</section><section id="minimum-chi-2-estimator" class="level3"><h3 class="anchored" data-anchor-id="minimum-chi-2-estimator">Minimum <span class="math inline">\(\chi ^ 2\)</span> estimator</h3>
<p> </p>
<p><span class="citation" data-cites="NEWE:87">Newey (<a href="#ref-NEWE:87" role="doc-biblioref">1987</a>)</span> argued that the minimum chi-square estimator <span class="citation" data-cites="AMEM:78">(<a href="#ref-AMEM:78" role="doc-biblioref">Amemiya 1978</a>’s)</span> can be used in this context and is more efficient than the two-step estimator. This estimator is computed in five steps:</p>
<ol type="1">
<li>compute the OLS estimator of <span class="math inline">\(\pi_g\)</span> for the <span class="math inline">\(G\)</span> endogenous variables and compute the fitted values <span class="math inline">\(\hat{d}_{gn}\)</span> and the residuals <span class="math inline">\(\hat{\nu}_{gn}\)</span> of these regressions,</li>
<li>using a probit regress <span class="math inline">\(y\)</span> on the whole set of exogenous variables <span class="math inline">\(w_n ^ \top = (1, x_{n1} ^ \top, x_{n2} ^ \top)\)</span> and on the previously computed residuals <span class="math inline">\(\hat{\nu}_{gn}\)</span>. Save the coefficients of <span class="math inline">\(v_n\)</span> (<span class="math inline">\(\hat{\alpha}\)</span>), of <span class="math inline">\(\hat{\nu}_n\)</span> (<span class="math inline">\(\hat{\lambda}\)</span>) and the part of the covariance matrix that corresponds to <span class="math inline">\(\alpha\)</span> <span class="math inline">\(\hat{\Sigma}_{1}\)</span>,</li>
<li>using a probit, regress <span class="math inline">\(y\)</span> on <span class="math inline">\(\hat{u}_n^\top = (1, x_1^\top, \hat{\nu}_n ^ \top)\)</span> and on the fitted values <span class="math inline">\(\hat{d}_{gn}\)</span> computed on the first step; save the coefficients of the fitted values <span class="math inline">\(\hat{\delta}\)</span> and compute <span class="math inline">\(\hat{\rho} = \hat{\lambda} - \hat{\delta}\)</span>,</li>
<li>regress <span class="math inline">\(\hat{\rho} ^ \top e_n\)</span> on the whole set of exogenous variables <span class="math inline">\(w_n\)</span>, save the covariance matrix <span class="math inline">\(\hat{\Sigma}_{2}\)</span> and compute <span class="math inline">\(\hat{\Omega} = \hat{\Sigma}_1 + \hat{\Sigma}_2\)</span>,</li>
<li>compute the minimum <span class="math inline">\(\chi^2\)</span> estimator <span class="math inline">\(\hat{\gamma}\)</span> and its variance <span class="math inline">\(\hat{V}(\hat{\gamma})\)</span>:</li>
</ol>
<p><span class="math display">\[
\hat{V}(\hat{\gamma}) = (Z^\top W) (W^\top W) ^ {-1} \hat{\Omega} ^
  {-1} (W^\top W) ^ {-1} (W ^ \top Z)
\]</span></p>
<p><span class="math display">\[\hat{\gamma}
  = \hat{V}(\hat{\gamma}) (Z^\top W) (W^\top W) ^ {-1} \hat{\Omega} ^ {-1}
\]</span></p>
<p> </p>
</section><section id="application" class="level3"><h3 class="anchored" data-anchor-id="application">Application</h3>
<p><span class="citation" data-cites="ADKI:CART:SIMP:07">Adkins, Carter, and Simpson (<a href="#ref-ADKI:CART:SIMP:07" role="doc-biblioref">2007</a>)</span> and <span class="citation" data-cites="ADKI:12">Adkins (<a href="#ref-ADKI:12" role="doc-biblioref">2012</a>)</span> analyzed the effect of managerial incentives on the use of foreign-exchange derivatives for hedging by U.S. bank holding companies, for the 1996-2000 period. The dependent variable <code>federiv</code> is 1 if the bank uses foreign-exchange derivatives.</p>
<p>The first set of covariates concerns ownership. When managers have a higher ownership position in the bank, their behavior is more in line with the preferences of shareholders, and they therefore have an incentive to take risk: the logarithm of the percentage of total shares outstanding that are owned by officers and directors (<code>linsown</code>) should therefore have a negative effect on the probability of using foreign-exchange derivatives. However, incentives provided by regulation may dominate the expected incentive relation and lead to a negative effect on the probability. On the contrary, institutional blockholders have imperfect information and, therefore, the logarithm of the percentage of total shares outstanding that are owned by all institutional investors (<code>linstown</code>) should have a negative effect on the probability of using foreign-exchange derivatives.</p>
<p>The second set of covariates concerns CEO compensation. Value of option awards (<code>optval</code>) should induce managers to take more risk and therefore should have a negative effect on the probability. On the contrary, cash bonus (<code>bonus</code>) may increase the probability of hedging in order to decrease variability in the firm’s cash flows.</p>
<p>The other covariates are the leverage (<code>eqrat</code>), the logarithm of total assets (<code>ltass</code>), the return on equity (<code>roe</code>), the market to book ratio (<code>mktbt</code>), the foreign to total interest income ratio (<code>perfor</code>), a derivative dealer activity dummy (<code>dealdum</code>), dividends paid (<code>div</code>) and the year from 1996 to 2000 (<code>year</code>).</p>
<p>Three covariates are suspected to be endogenous: the leverage (<code>eqrat</code>), the option awards <code>optval</code> and the bonus, (<code>bonus</code>). The external instruments are the number of employees (<code>no_emp</code>), of subsidiaries (<code>no_subs</code>) and of officies (<code>no_off</code>), the CEO age (<code>ceo_age</code>), the 12 month maturity mismatch (<code>gap</code>) and the ratio of cash flow to total assets (<code>cfa</code>).</p>
<p>The instrumental variable probit estimator is obtained using <code>binomreg</code> with <code>link = "probit"</code> and a two-part formula, containing the covariates and the instruments. The method argument (the default <code>"ml"</code>, <code>"twosteps"</code> and <code>"min"</code>) indicates the estimation method. The results for the three estimators are presented in <a href="#tbl-resbank">Table&nbsp;<span>10.4</span></a>. To save place, we only present the coefficients for the covariates of main interest. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">form</span> <span class="op">&lt;-</span> <span class="va">federiv</span> <span class="op">~</span> <span class="va">eqrat</span> <span class="op">+</span> <span class="va">optval</span> <span class="op">+</span> <span class="va">bonus</span> <span class="op">+</span> <span class="va">ltass</span> <span class="op">+</span> </span>
<span>                      <span class="va">linsown</span> <span class="op">+</span> <span class="va">linstown</span> <span class="op">+</span> <span class="va">roe</span> <span class="op">+</span> <span class="va">mktbk</span> <span class="op">+</span> </span>
<span>                      <span class="va">perfor</span> <span class="op">+</span> <span class="va">dealdum</span> <span class="op">+</span> <span class="va">div</span> <span class="op">+</span> <span class="va">year</span> <span class="op">|</span></span>
<span>                        <span class="va">.</span> <span class="op">-</span> <span class="va">eqrat</span> <span class="op">-</span> <span class="va">bonus</span> <span class="op">-</span> <span class="va">optval</span> <span class="op">+</span> <span class="va">no_emp</span> <span class="op">+</span> </span>
<span>                      <span class="va">no_subs</span> <span class="op">+</span> <span class="va">no_off</span> <span class="op">+</span> <span class="va">ceo_age</span> <span class="op">+</span> <span class="va">gap</span> <span class="op">+</span> <span class="va">cfa</span></span>
<span><span class="va">bank_msq</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">form</span>, data <span class="op">=</span> <span class="va">federiv</span>, link <span class="op">=</span> <span class="st">"probit"</span>,</span>
<span>                    method <span class="op">=</span> <span class="st">"minchisq"</span><span class="op">)</span></span>
<span><span class="va">bank_ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">bank_msq</span>, method <span class="op">=</span> <span class="st">"ml"</span><span class="op">)</span></span>
<span><span class="va">bank_2st</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">bank_msq</span>, method <span class="op">=</span> <span class="st">"twosteps"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-resbank" class="anchored">

<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Table&nbsp;10.4:  IV probit models for the bank data set </caption>
 <thead><tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> minchisq </th>
   <th style="text-align:center;"> two-step </th>
   <th style="text-align:center;"> ML </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:left;"> linsown </td>
   <td style="text-align:center;"> 0.259 </td>
   <td style="text-align:center;"> 0.257 </td>
   <td style="text-align:center;"> 0.145 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.116) </td>
   <td style="text-align:center;"> (0.116) </td>
   <td style="text-align:center;"> (0.062) </td>
  </tr>
<tr>
<td style="text-align:left;"> linstown </td>
   <td style="text-align:center;"> 0.370 </td>
   <td style="text-align:center;"> 0.372 </td>
   <td style="text-align:center;"> 0.202 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.135) </td>
   <td style="text-align:center;"> (0.135) </td>
   <td style="text-align:center;"> (0.106) </td>
  </tr>
<tr>
<td style="text-align:left;"> eqrat </td>
   <td style="text-align:center;"> 21.775 </td>
   <td style="text-align:center;"> 21.825 </td>
   <td style="text-align:center;"> 12.491 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (13.386) </td>
   <td style="text-align:center;"> (13.424) </td>
   <td style="text-align:center;"> (5.354) </td>
  </tr>
<tr>
<td style="text-align:left;"> optval </td>
   <td style="text-align:center;"> −0.088 </td>
   <td style="text-align:center;"> −0.087 </td>
   <td style="text-align:center;"> −0.051 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.053) </td>
   <td style="text-align:center;"> (0.053) </td>
   <td style="text-align:center;"> (0.017) </td>
  </tr>
<tr>
<td style="text-align:left;"> bonus </td>
   <td style="text-align:center;"> 1.757 </td>
   <td style="text-align:center;"> 1.735 </td>
   <td style="text-align:center;"> 1.018 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.888) </td>
   <td style="text-align:center;"> (0.888) </td>
   <td style="text-align:center;"> (0.187) </td>
  </tr>
<tr>
<td style="text-align:left;"> rho_eqrat </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −25.506 </td>
   <td style="text-align:center;"> −0.224 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (13.835) </td>
   <td style="text-align:center;"> (0.087) </td>
  </tr>
<tr>
<td style="text-align:left;"> rho_optval </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.096 </td>
   <td style="text-align:center;"> 0.347 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.049) </td>
   <td style="text-align:center;"> (0.075) </td>
  </tr>
<tr>
<td style="text-align:left;"> rho_bonus </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −1.672 </td>
   <td style="text-align:center;"> −0.730 </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.875) </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.140) </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 794 </td>
   <td style="text-align:center;"> 794 </td>
   <td style="text-align:center;"> 794 </td>
  </tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The coefficients of <code>linstown</code>, <code>bonus</code> and <code>optval</code> have the expected sign. <code>linsown</code> has a positive sign, which must be driven by the strength of the regulatory constraints. Note that the standard deviations are much smaller for the highly parametrized ML estimator, compared to the two-step and the minimum <span class="math inline">\(\chi^2\)</span> estimator.</p>
<p>To perform the endogeneity test, we first estimate the two-step estimator with the probit estimator of the covariance matrix of the coefficients. This is performed by setting the supplementary argument <code>robust</code> to <code>FALSE</code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">bank_2s_nr</span> <span class="op">&lt;-</span> <span class="fu">binomreg</span><span class="op">(</span><span class="va">form</span>, data <span class="op">=</span> <span class="va">federiv</span>, link <span class="op">=</span> <span class="st">"probit"</span>, </span>
<span>                       method <span class="op">=</span> <span class="st">"twosteps"</span>, robust <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, a Wald test that <span class="math inline">\(\rho = 0\)</span> can be performed, using for example <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">car::linearHypothesis</a></code>: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">bank_2s_nr</span> <span class="op">%&gt;%</span> <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"rho_eqrat = 0"</span>, </span>
<span>                                       <span class="st">"rho_optval = 0"</span>, </span>
<span>                                       <span class="st">"rho_bonus = 0"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## Chisq = 7.547, df: 3, pval = 0.056</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>or more simply using the <code>miscsr::endogtest</code> function: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">endogtest</span><span class="op">(</span><span class="va">form</span>, <span class="va">federiv</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="va">gaze</span></span>
<span><span class="co">## chisq = 7.547, df: 3, pval = 0.056</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The hypothesis of no endogeneity is rejected at the 10%, but not at the 5% level.</p>
<!-- ```{r } -->
<!-- #| eval: false -->
<!-- #| include: false -->
<!-- #' @rdname get_predict -->
<!-- #' @export -->
<!-- get_predict.micsr <- function(model, -->
<!--                               newdata = insight::get_data(model), -->
<!--                               vcov = NULL, -->
<!--                               conf_level = 0.95, -->
<!--                               type = "response", -->
<!--                                ...) { -->
<!--     out <- stats::predict(model, what = type, newdata = newdata) -->
<!--     out <- data.frame(rowid = seq_len(length(out)), predicted = out) -->
<!--     return(out) -->
<!-- } -->
<!-- ``` -->
</section></section><section id="sec-ordered" class="level2" data-number="10.6"><h2 data-number="10.6" class="anchored" data-anchor-id="sec-ordered">
<span class="header-section-number">10.6</span> Ordered models</h2>
<p> An ordered model is a model for which the response can take <span class="math inline">\(J\)</span> distinct values (with <span class="math inline">\(J&gt;2\)</span>). The construction of the model is very similar to the one of the binomial model. We consider, as in <a href="#sec-latent_variable"><span>Section&nbsp;10.2.1</span></a>, a latent variable equal to the sum of a linear combination of the covariates and an error:</p>
<p><span class="math display">\[
y^* = \alpha + \beta^\top x + \epsilon
\]</span></p>
<p>Denoting <span class="math inline">\(\mu = (\mu_0, \mu_1, \mu_1, \ldots, \mu_{J})\)</span> a vector of parameters, with <span class="math inline">\(\mu_0 = -\infty\)</span> and <span class="math inline">\(\mu_{J}= +\infty\)</span>, the rule of observation for the different values of <span class="math inline">\(y\)</span> is then:</p>
<p><span class="math display">\[
\left\{
\begin{array}{rclcclccc}
y &amp;=&amp; 1 &amp;  \Leftrightarrow &amp; \mu_0 &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_1 \\
y &amp;=&amp; 2 &amp;  \Leftrightarrow &amp; \mu_1 &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_2 \\
&amp;\vdots &amp;  &amp; \vdots &amp;&amp; \vdots &amp; &amp; \vdots\\
y &amp;=&amp; J-1 &amp;  \Leftrightarrow &amp; \mu_{J-2} &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_{J-1} \\
y &amp;=&amp; J &amp;  \Leftrightarrow &amp; \mu_{J-1} &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_{J}\\
\end{array}
\right.
\]</span></p>
<p>For <span class="math inline">\(y = 1\)</span>, subtracting <span class="math inline">\(\alpha\)</span> from the three terms of the inequality, we get: <span class="math inline">\(\mu_0 - \alpha \leq \beta ^ \top x + \epsilon \leq \mu_1 - \alpha\)</span>. Therefore, the observation rule doesn’t depend on <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\alpha\)</span>, but on <span class="math inline">\(\mu_0-\alpha\)</span> and <span class="math inline">\(\mu_1 - \alpha\)</span>. Therefore, <span class="math inline">\(\mu_0\)</span>, <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\alpha\)</span> are not identified and, for example, <span class="math inline">\(\alpha\)</span> can be set to 0. The same reasoning applies to the other values of <span class="math inline">\(y\)</span>. Denoting <span class="math inline">\(F\)</span> the cumulative density of <span class="math inline">\(\epsilon\)</span>, the probability for a given value <span class="math inline">\(j\)</span> of <span class="math inline">\(y\)</span> is:</p>
<p><span class="math display">\[
\mbox{P}(y_n=j)=F(\mu_{j} - \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)
\]</span></p>
<p>The probabilities are represented in <a href="#fig-ordered1">Figure&nbsp;<span>10.5</span></a> for <span class="math inline">\(J = 3\)</span> by the areas under the density curve of <span class="math inline">\(\epsilon\)</span> between two consecutive values of <span class="math inline">\(\mu_j - \beta ^ \top x\)</span> (with <span class="math inline">\(\mu_0 = -\infty\)</span> and <span class="math inline">\(\mu_3 = + \infty\)</span>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ordered1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/ordered1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.5: Probabilities for an ordered model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Consider now an increase of a covariate <span class="math inline">\(x_k\)</span> and suppose that the associated coefficient <span class="math inline">\(\beta_k\)</span> is positive. Then, all the values of <span class="math inline">\(\mu_j - \beta^ \top x\)</span> decrease by the same amount <span class="math inline">\(-\beta_k \Delta x_k\)</span>. The new probabilities are represented in <a href="#fig-ordered2">Figure&nbsp;<span>10.6</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ordered2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./tikz/fig/ordered2.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;10.6: Marginal effects for an ordered model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The dashed area represents an increase of the probability that <span class="math inline">\(y = 2\)</span> and a reduction of the probability that <span class="math inline">\(y = 1\)</span>, and the dotted area a reduction of the probability that <span class="math inline">\(y = 2\)</span> and an increase of the probability that <span class="math inline">\(y = 3\)</span>. Therefore, the marginal effect of <span class="math inline">\(x_k\)</span> is positive for <span class="math inline">\(\mbox{P}(y = 3)\)</span>, negative for <span class="math inline">\(\mbox{P}(y = 1)\)</span> and ambiguous for <span class="math inline">\(\mbox{P}(y = 2)\)</span>. For small changes of <span class="math inline">\(x_k\)</span> the dashed and dotted areas are proportional to the densities for the two limits of the range of <span class="math inline">\(\epsilon\)</span> for which <span class="math inline">\(y = 2\)</span>. Therefore <span class="math inline">\(\mbox{P}(y = 2)\)</span> increases if the density for the lower limit (<span class="math inline">\(\mu_1 - \beta ^ \top x\)</span>) is greater than the density for the upper limit (<span class="math inline">\(\mu_2 - \beta ^ \top x\)</span>), which is the case here, and decrease otherwise. More generally, when <span class="math inline">\(y\)</span> takes <span class="math inline">\(J\)</span> values, the effect on the probabilities is unambiguous only for <span class="math inline">\(\mbox{P}(y = 1)\)</span> and <span class="math inline">\(\mbox{P}(y = J)\)</span>. The probability of the outcome can be written compactly using the <span class="math inline">\(\mathbf{1}(x)\)</span> function which equals 1 if <span class="math inline">\(x\)</span> is true and 0 otherwise:</p>
<p><span id="eq-probord"><span class="math display">\[
  \mbox{P}(y_n)=\sum_{j=1}^J \mathbf{1}(y_n = j)\left[F(\mu_{j} - \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)\right]
\tag{10.17}\]</span></span></p>
<p>For a sample of size <span class="math inline">\(N\)</span>, the log-likelihood function is obtained by summing the logarithms of <a href="#eq-probord">Equation&nbsp;<span>10.17</span></a> for all the observations:</p>
<p><span class="math display">\[
\ln L = \sum_{n=1}^{N} \sum_{j = 1}^J\mathbf{1}(y_n = j)\ln \left[F(\mu_j -
  \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)\right]
\]</span></p>
<p>As for the binomial model, the most common choices for the distribution of <span class="math inline">\(\epsilon\)</span> are the normal and the logistic distributions, which lead respectively to the ordered probit and logit models.</p>
<p>As an example, we consider the article of <span class="citation" data-cites="ABIA:MODY:05">Abiad and Mody (<a href="#ref-ABIA:MODY:05" role="doc-biblioref">2005</a>)</span> who study the determinants of financial reform. The data set, called <code>fin_reform</code>, is a panel of 35 countries for 24 years (from 1973 to 1996). The variable of interest <code>fli</code> is an index of financial liberalization, which takes integer values from 0 to 18. Denote <span class="math inline">\(I_{nt}\)</span> the value of this variable for country <span class="math inline">\(n\)</span> on year <span class="math inline">\(t\)</span> divided by 18, so that <span class="math inline">\(I_{nt}\)</span> equal to 0 or to 1 indicates respectively no and perfect financial liberalization. It is assumed that the yearly variation of the index is given by the following equation, denoting <span class="math inline">\(I^*_{nt}\)</span> the desired value of <span class="math inline">\(I_{nt}\)</span>:</p>
<p><span class="math display">\[
\Delta I_{nt} = \alpha(I ^ *_{nt} - I_{n(t-1)}) + \epsilon_{nt}
\]</span> <span class="math inline">\(I^*\)</span> is unobserved and is supposed to be equal to 1, so that the target is perfect financial liberalization. <span class="math inline">\(\alpha\)</span> is an adjustment factor and is supposed to be equal to <span class="math inline">\(\alpha = \theta I_{n(t-1)}\)</span>, so that the resistance to reform is a function of the state of liberalization. We then have:</p>
<p><span class="math display">\[
\Delta I_{nt} = \theta I_{n(t-1)}(1 - I_{n(t-1)}) + \epsilon_{nt}
\]</span></p>
<p>The response is therefore the change in the index and the main covariate is <code>indxl</code> <span class="math inline">\(\times\)</span> <code>(1 - indxl)</code> where <code>indxl</code> is the lagged value of the index on the 0-1 scale. The computation of these variables are presented below; note the use of the <code>lag</code> function on the data frame grouped by <code>country</code>. This ensures that the lag value for the first year (1973) for the second country (Australia) is <code>NA</code> and not the value of the first country (Argentina) for the last year (1996). </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fin_reform</span> <span class="op">&lt;-</span> <span class="va">fin_reform</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">group_by</span><span class="op">(</span><span class="va">country</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>dindx <span class="op">=</span> <span class="va">fli</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">fli</span><span class="op">)</span>,</span>
<span>           indx <span class="op">=</span> <span class="va">fli</span> <span class="op">/</span> <span class="fl">18</span>,</span>
<span>           indxl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">indx</span><span class="op">)</span>,</span>
<span>           rhs1 <span class="op">=</span> <span class="va">indxl</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">indxl</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="va">ungroup</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The authors test the possibility of regional diffusion: countries within a region would then be induced to catch up with the highest level of liberalization observed within the region. Therefore, they introduce a covariate which is equal to the difference between the previous value of the index and the maximum value in the group of country: </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">g</span> <span class="op">&lt;-</span> <span class="va">fin_reform</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">region</span>, <span class="va">year</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span>max_indxl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">indxl</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">fin_reform</span> <span class="op">&lt;-</span> <span class="va">fin_reform</span> <span class="op">%&gt;%</span> <span class="fu">left_join</span><span class="op">(</span><span class="va">g</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>catchup <span class="op">=</span> <span class="va">max_indxl</span> <span class="op">-</span> <span class="va">indxl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Other covariates are the political orientation of the government (<code>pol</code>, a factor with levels <code>center</code>, <code>left</code> and <code>right</code>) and dummies for first year of office (<code>dum_1yofc</code>), for balance of payments and bank crises in the first two previous years (<code>dum_bop</code> and <code>dum_bank</code>) and for recession <code>recession</code> (growth rate <code>gdpg</code> negative) and high inflation <code>hinfl</code> (inflation rate <code>infl</code> greater than 50%). The relevant dummies are computed below:<br></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fin_reform</span> <span class="op">&lt;-</span> <span class="va">fin_reform</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu">mutate</span><span class="op">(</span>dum_bop <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">bop</span> <span class="op">|</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bop</span><span class="op">)</span> <span class="op">|</span> <span class="op">(</span><span class="op">!</span> <span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bop</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">&amp;</span> </span>
<span>                                                <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bop</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>           dum_bank <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">bank</span> <span class="op">|</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bank</span><span class="op">)</span> <span class="op">|</span> <span class="op">(</span><span class="op">!</span> <span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bank</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">&amp;</span> </span>
<span>                                                   <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="va">bank</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>           dum_1yofc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">yofc</span><span class="op">)</span> <span class="op">&amp;</span> <span class="va">yofc</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>           recession <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">gdpg</span> <span class="op">&lt;=</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>           hinfl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">infl</span> <span class="op">&gt;</span> <span class="fl">50</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ordered models can be fitted using <code><a href="https://rdrr.io/pkg/MASS/man/polr.html">MASS::polr</a></code>, which has a <code>method</code> argument similar to the <code>link</code> argument of the <code>binomial</code> function used as a <code>family</code> argument in <code>glm</code>. It can be set to <code>logistic</code> (called <code>logit</code> for binomial) , <code>probit</code>, <code>loglog</code>, <code>cloglog</code> and <code>cauchy</code>. As for binomial models, <code>probit</code> and <code>logit</code> are by far the most used links. Another implementation of the ordered model is <code><a href="https://rdrr.io/pkg/micsr/man/ordreg.html">micsr::ordreg</a></code>. <a href="#tbl-ordfinreform">Table&nbsp;<span>10.5</span></a> presents the three specifications presented by <span class="citation" data-cites="ABIA:MODY:05">Abiad and Mody (<a href="#ref-ABIA:MODY:05" role="doc-biblioref">2005</a>)</span>, table 7, page 78. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mass1</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/polr.html">polr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">dindx</span><span class="op">)</span> <span class="op">~</span> <span class="va">rhs1</span> <span class="op">+</span> <span class="va">catchup</span>, <span class="va">fin_reform</span>, </span>
<span>                    method <span class="op">=</span> <span class="st">"logistic"</span><span class="op">)</span></span>
<span><span class="va">mod1</span> <span class="op">&lt;-</span> <span class="fu">ordreg</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">dindx</span><span class="op">)</span> <span class="op">~</span> <span class="va">rhs1</span> <span class="op">+</span> <span class="va">catchup</span>, <span class="va">fin_reform</span>, </span>
<span>               link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="va">mod2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">mod1</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">dum_bop</span> <span class="op">+</span> <span class="va">dum_bank</span> <span class="op">+</span> <span class="va">recession</span> <span class="op">+</span> <span class="va">hinfl</span><span class="op">)</span></span>
<span><span class="va">mod3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">mod2</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">dum_1yofc</span> <span class="op">+</span> <span class="va">imf</span> <span class="op">+</span> <span class="va">usint</span> <span class="op">+</span> <span class="va">pol</span> <span class="op">+</span> <span class="va">open</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-ordfinreform" class="anchored">

<table style="NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;" class="table">
<caption>Table&nbsp;10.5:  Ordered logit models for the financial reform data set </caption>
 <thead><tr>
<th style="text-align:left;">   </th>
   <th style="text-align:center;"> &nbsp;(1) </th>
   <th style="text-align:center;"> &nbsp;&nbsp;(2) </th>
   <th style="text-align:center;"> &nbsp;&nbsp;(3) </th>
  </tr></thead>
<tbody>
<tr>
<td style="text-align:left;"> rhs1 </td>
   <td style="text-align:center;"> 4.001*** </td>
   <td style="text-align:center;"> 4.652*** </td>
   <td style="text-align:center;"> 4.188*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (1.008) </td>
   <td style="text-align:center;"> (1.031) </td>
   <td style="text-align:center;"> (1.048) </td>
  </tr>
<tr>
<td style="text-align:left;"> catchup </td>
   <td style="text-align:center;"> 0.842** </td>
   <td style="text-align:center;"> 0.897** </td>
   <td style="text-align:center;"> 0.993** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;"> (0.310) </td>
   <td style="text-align:center;"> (0.321) </td>
   <td style="text-align:center;"> (0.353) </td>
  </tr>
<tr>
<td style="text-align:left;"> dum_bop </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.526** </td>
   <td style="text-align:center;"> 0.439* </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.183) </td>
   <td style="text-align:center;"> (0.187) </td>
  </tr>
<tr>
<td style="text-align:left;"> dum_bank </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −1.025*** </td>
   <td style="text-align:center;"> −0.993*** </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.279) </td>
   <td style="text-align:center;"> (0.280) </td>
  </tr>
<tr>
<td style="text-align:left;"> recession </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.071 </td>
   <td style="text-align:center;"> −0.056 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.260) </td>
   <td style="text-align:center;"> (0.262) </td>
  </tr>
<tr>
<td style="text-align:left;"> hinfl </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.161 </td>
   <td style="text-align:center;"> −0.264 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.298) </td>
   <td style="text-align:center;"> (0.307) </td>
  </tr>
<tr>
<td style="text-align:left;"> dum_1yofc </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.194 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.208) </td>
  </tr>
<tr>
<td style="text-align:left;"> imf </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.326+ </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.195) </td>
  </tr>
<tr>
<td style="text-align:left;"> usint </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.066+ </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.034) </td>
  </tr>
<tr>
<td style="text-align:left;"> polleft </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.242 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.239) </td>
  </tr>
<tr>
<td style="text-align:left;"> polright </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 0.169 </td>
  </tr>
<tr>
<td style="text-align:left;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> (0.208) </td>
  </tr>
<tr>
<td style="text-align:left;"> open </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> −0.001 </td>
  </tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px">  </td>
   <td style="text-align:center;box-shadow: 0px 1.5px"> (0.002) </td>
  </tr>
<tr>
<td style="text-align:left;"> Num.Obs. </td>
   <td style="text-align:center;"> 805 </td>
   <td style="text-align:center;"> 805 </td>
   <td style="text-align:center;"> 805 </td>
  </tr>
<tr>
<td style="text-align:left;"> AIC </td>
   <td style="text-align:center;"> 1555.3 </td>
   <td style="text-align:center;"> 1542.1 </td>
   <td style="text-align:center;"> 1544.4 </td>
  </tr>
<tr>
<td style="text-align:left;"> BIC </td>
   <td style="text-align:center;"> 1625.7 </td>
   <td style="text-align:center;"> 1631.2 </td>
   <td style="text-align:center;"> 1661.7 </td>
  </tr>
<tr>
<td style="text-align:left;"> Log.Lik. </td>
   <td style="text-align:center;"> −762.662 </td>
   <td style="text-align:center;"> −752.052 </td>
   <td style="text-align:center;"> −747.202 </td>
  </tr>
</tbody>
<tfoot><tr><td style="padding: 0; " colspan="100%">
<sup></sup> + p </td></tr></tfoot>
</table>
</div>
</div>
</div>
<p>The first column presents the result of the model with the resistance to reform and the diffusion covariates which have both of the expected signs and are significant. In the second column, the shocks covariates are added, and only the balance of payments and the bank crisis dummies are significant. Finally, in the third column, the political and economic structure covariates are added, but none of them are significant. </p>
<p></p>
<!-- ## Bivariate probit -->
<!-- The methods previously described rest on the hypothesis that the -->
<!-- endogenous variables are normally distributed. They are therefore -->
<!-- irrelevant in the common case where the endogenous variable is -->
<!-- binary. In this situation, the bivariate probit model is -->
<!-- appropriate. Denote $y_j$ and $x_j$ the two responses and the two sets -->
<!-- of covariates. For the two responses, define $y_j^* = \beta_j ^ \top -->
<!-- x_j + \epsilon_j$ a latent variable. $(y_1 = 0, y_2 = 0)$ is then -->
<!-- observed if $(y_1 ^ * < 0, y_2 ^ * < 0)$ or $(\epsilon_1 < - \beta_1 ^ -->
<!-- \top x_1, \epsilon_2 < - \beta_2 ^ \top x_2)$. Assuming that the joint -->
<!-- distribution of $(\epsilon_1, \epsilon_2)$ is normal with a -->
<!-- coefficient of correlation $\rho$, the probability that $(y_1 = 0, y_2 -->
<!-- = 0)$ is given by the cummulative bivariate density function: -->
<!-- $$ -->
<!-- \mbox{P}(y_1 = 1, y_2 = 1) = \Phi_b(\beta_1 ^ \top x_1, \beta_2 ^ \top x_2, \rho) -->
<!-- $$ -->
<!-- @GREE:18 showed that the general formula for the probability is: -->
<!-- $$ -->
<!-- \Phi_b(q_1 \beta_1 ^ \top x_1, q_2 \beta_2 ^ \top x_2, q_1 q_2 \rho) -->
<!-- $$ -->
<!-- The log-likelihood function is then: -->
<!-- $$ -->
<!-- \ln L = \sum_{n=1} ^ N \ln \Phi_b(q_{n1} \beta_1 ^ \top x_{n1}, q_{n2} \beta_2 ^ \top x_{n2}, q_{n1} q_{n2} \rho) -->
<!-- $$ -->
<!-- This general model can deal with the case of endogenous dependant -->
<!-- variable if, for example, $y_1$ is one element of $x_2$. -->
<!-- ```{r } -->
<!-- pins <- bivprobit(doctor | privateins ~ size + smsa + age + sex + educ + log(wage) | -->
<!--                       . -privateins + pluriloc + nbemp, private_ins) -->
<!-- #pins <- bivprobit(doctor | privateins ~ privateins + size + smsa + age + sex + educ + log(wage) | -->
<!-- #                      . - privateins + pluriloc + nbemp, private_ins) -->
<!-- ``` -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-ABIA:MODY:05" class="csl-entry" role="doc-biblioentry">
Abiad, Abdul, and Ashoka Mody. 2005. <span>“Financial Reform: What Shakes It? What Shapes It?”</span> <em>American Economic Review</em> 95 (1): 66–88. <a href="https://doi.org/10.1257/0002828053828699">https://doi.org/10.1257/0002828053828699</a>.
</div>
<div id="ref-ADKI:12" class="csl-entry" role="doc-biblioentry">
Adkins, Lee C. 2012. <span>“Testing Parameter Significance in Instrumental Variables Probit Estimators: Some Simulation.”</span> <em>Journal of Statistical Computation and Simulation</em> 82: 1415–36. <a href="https://api.semanticscholar.org/CorpusID:18158285">https://api.semanticscholar.org/CorpusID:18158285</a>.
</div>
<div id="ref-ADKI:CART:SIMP:07" class="csl-entry" role="doc-biblioentry">
Adkins, Lee C., David A. Carter, and W. Gary Simpson. 2007. <span>“<span>Managerial Incentives And The Use Of Foreign‐Exchange Derivatives By Banks</span>.”</span> <em>Journal of Financial Research</em> 30 (3): 399–413. <a href="https://doi.org/10.1111/j.1475-6803.2007.">https://doi.org/10.1111/j.1475-6803.2007.</a>
</div>
<div id="ref-AMEM:78" class="csl-entry" role="doc-biblioentry">
Amemiya, Takeshi. 1978. <span>“The Estimation of a Simultaneous Equation Generalized Probit Model.”</span> <em>Econometrica</em> 46 (5): 1193–1205. <a href="https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:5:p:1193-1205">https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:5:p:1193-1205</a>.
</div>
<div id="ref-AMEM:81" class="csl-entry" role="doc-biblioentry">
———. 1981. <span>“<span>Qualitative Response Models: A Survey</span>.”</span> <em>Journal of Economic Literature</em> 19 (4): 1483–1536. <a href="https://ideas.repec.org/a/aea/jeclit/v19y1981i4p1483-1536.html">https://ideas.repec.org/a/aea/jeclit/v19y1981i4p1483-1536.html</a>.
</div>
<div id="ref-EDEL:LUCA:SVIR:17" class="csl-entry" role="doc-biblioentry">
Edelman, Benjamin, Michael Luca, and Dan Svirsky. 2017. <span>“Racial Discrimination in the Sharing Economy: Evidence from a Field Experiment.”</span> <em>American Economic Journal: Applied Economics</em> 9 (2): 1–22. <a href="https://doi.org/10.1257/app.20160213">https://doi.org/10.1257/app.20160213</a>.
</div>
<div id="ref-EFRO:78" class="csl-entry" role="doc-biblioentry">
Efron, Bradley. 1978. <span>“Regression and ANOVA with Zero-One Data: Measures of Residual Variation.”</span> <em>Journal of the American Statistical Association</em> 73 (361): 113–21. <a href="http://www.jstor.org/stable/2286531">http://www.jstor.org/stable/2286531</a>.
</div>
<div id="ref-ESTR:98" class="csl-entry" role="doc-biblioentry">
Estrella, Arturo. 1998. <span>“A New Measure of Fit for Equations with Dichotomous Dependent Variables.”</span> <em>Journal of Business &amp; Economic Statistics</em> 16 (2): 198–205.
</div>
<div id="ref-GOUR:MONF:RENA:TROG:87" class="csl-entry" role="doc-biblioentry">
Gourieroux, Christian, Alain Monfort, Eric Renault, and Alain Trognon. 1987. <span>“Generalised Residuals.”</span> <em>Journal of Econometrics</em> 34 (1): 5–32. <a href="https://doi.org/10.1016/0304-4076(87)90065-0">https://doi.org/10.1016/0304-4076(87)90065-0</a>.
</div>
<div id="ref-HORO:93" class="csl-entry" role="doc-biblioentry">
Horowitz, Joel L. 1993. <span>“Semiparametric Estimation of a Work-Trip Mode Choice Model.”</span> <em>Journal of Econometrics</em> 58 (1-2): 49–70. <a href="https://EconPapers.repec.org/RePEc:eee:econom:v:58:y:1993:i:1-2:p:49-70">https://EconPapers.repec.org/RePEc:eee:econom:v:58:y:1993:i:1-2:p:49-70</a>.
</div>
<div id="ref-LAVE:70" class="csl-entry" role="doc-biblioentry">
Lave, Charles A. 1970. <span>“The Demand for Urban Mass Transportation.”</span> <em>The Review of Economics and Statistics</em> 52 (3): 320–23. <a href="http://www.jstor.org/stable/1926301">http://www.jstor.org/stable/1926301</a>.
</div>
<div id="ref-MAGE:90" class="csl-entry" role="doc-biblioentry">
Magee, Lonnie. 1990. <span>“R2 Measures Based on Wald and Likelihood Ratio Joint Significance Tests.”</span> <em>The American Statistician</em> 44 (3): 250–53. <a href="http://www.jstor.org/stable/2685352">http://www.jstor.org/stable/2685352</a>.
</div>
<div id="ref-MCCU:NELD:89" class="csl-entry" role="doc-biblioentry">
McCullagh, P., and J. A. Nelder. 1989. <em>Generalized Linear Models</em>. 2nd ed. London: Chapman; Hall.
</div>
<div id="ref-MCFA:73" class="csl-entry" role="doc-biblioentry">
McFadden, Daniel. 1973. <span>“Conditional Logit Analysis of Qualitative Choice Behaviour.”</span> In <em>Frontiers in Econometrics</em>, edited by P. Zarembka, 105–42. Academic Press New York.
</div>
<div id="ref-MCKE:ZAVO:75" class="csl-entry" role="doc-biblioentry">
McKelvey, Richard D., and William Zavoina. 1975. <span>“A Statistical Model for the Analysis of Ordinal Level Dependent Variables.”</span> <em>The Journal of Mathematical Sociology</em> 4 (1): 103–20. <a href="https://doi.org/10.1080/0022250X.1975.9989847">https://doi.org/10.1080/0022250X.1975.9989847</a>.
</div>
<div id="ref-NEWE:87" class="csl-entry" role="doc-biblioentry">
Newey, Whitney K. 1987. <span>“Efficient Estimation of Limited Dependent Variable Models with Endogenous Explanatory Variables.”</span> <em>Journal of Econometrics</em> 36 (3): 231–50. <a href="https://doi.org/10.1016/0304-4076(87)90001-7">https://doi.org/10.1016/0304-4076(87)90001-7</a>.
</div>
<div id="ref-RIVE:VUON:88" class="csl-entry" role="doc-biblioentry">
Rivers, Douglas, and Quang H. Vuong. 1988. <span>“Limited Information Estimators and Exogeneity Tests for Simultaneous Probit Models.”</span> <em>Journal of Econometrics</em> 39 (3): 347–66. <a href="https://EconPapers.repec.org/RePEc:eee:econom:v:39:y:1988:i:3:p:347-366">https://EconPapers.repec.org/RePEc:eee:econom:v:39:y:1988:i:3:p:347-366</a>.
</div>
<div id="ref-SMIT:BLUN:86" class="csl-entry" role="doc-biblioentry">
Smith, Richard J., and Richard W. Blundell. 1986. <span>“An Exogeneity Test for a Simultaneous Equation Tobit Model with an Application to Labor Supply.”</span> <em>Econometrica</em> 54 (3): 679–85. <a href="http://www.jstor.org/stable/1911314">http://www.jstor.org/stable/1911314</a>.
</div>
<div id="ref-TJUR:09" class="csl-entry" role="doc-biblioentry">
Tjur, Tue. 2009. <span>“Coefficients of Determination in Logistic Regression Models—a New Proposal: The Coefficient of Discrimination.”</span> <em>The American Statistician</em> 63 (4): 366–72. <a href="http://www.jstor.org/stable/25652317">http://www.jstor.org/stable/25652317</a>.
</div>
<div id="ref-VEAL:ZIMM:96" class="csl-entry" role="doc-biblioentry">
Veall, Michael R., and Klaus F. Zimmermann. 1996. <span>“Pseudo-R2 Measures for Some Common Limited Dependent Variable Models.”</span> <em>Journal of Economic Surveys</em> 10 (3): 241–59. <a href="https://doi.org/10.1111/j.1467-6419.1996.tb00013.x">https://doi.org/10.1111/j.1467-6419.1996.tb00013.x</a>.
</div>
<div id="ref-WIND:95" class="csl-entry" role="doc-biblioentry">
Windmeijer, Frank. 1995. <span>“Goodness-of-Fit Measures in Binary Choice Models.”</span> <em>Econometric Reviews</em> 14 (February): 101–16. <a href="https://doi.org/10.1080/07474939508800306">https://doi.org/10.1080/07474939508800306</a>.
</div>
<div id="ref-ZEIL:HOTH:02" class="csl-entry" role="doc-biblioentry">
Zeileis, Achim, and Torsten Hothorn. 2002. <span>“Diagnostic Checking in Regression Relationships.”</span> <em>R News</em> 2 (3): 7–10. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>For every member of the exponential family, there is one canonical link, see <span class="citation" data-cites="MCCU:NELD:89">McCullagh and Nelder (<a href="#ref-MCCU:NELD:89" role="doc-biblioref">1989</a>)</span>, page 30.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that <code>family</code> is the second argument of <code>glm</code>, and <code>data</code> is the third.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="GOUR:MONF:RENA:TROG:87">Gourieroux et al. (<a href="#ref-GOUR:MONF:RENA:TROG:87" role="doc-biblioref">1987</a>)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>See <a href="simple_regression.html#sec-vardecomp_R2"><span>Section&nbsp;1.4.3</span></a>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Useful surveys are <span class="citation" data-cites="MAGE:90">Magee (<a href="#ref-MAGE:90" role="doc-biblioref">1990</a>)</span>, <span class="citation" data-cites="WIND:95">Windmeijer (<a href="#ref-WIND:95" role="doc-biblioref">1995</a>)</span> and <span class="citation" data-cites="VEAL:ZIMM:96">Veall and Zimmermann (<a href="#ref-VEAL:ZIMM:96" role="doc-biblioref">1996</a>)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Unpublished note by Eric Orjebin, 2014, founded on the Wikipedia page entitled “Truncated normal distribution”.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Note that the empirical moments simplify because <span class="math inline">\(\sum_n \psi_n = 0\)</span> and <span class="math inline">\(\sum_n \psi_n \mu_n = 0\)</span>, see <a href="#eq-gradbinom">Equation&nbsp;<span>10.5</span></a>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../special_responses.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Special responses</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/tobit.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Censored and truncated models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb42" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Binomial models {#sec-binomial}</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup_binomial</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"../_commonR.R"</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>Binomial responses can take only two mutually</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>exclusive values that can be, without loss of generality coded as 1</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>and 0. Common examples are transport mode choice (car vs. public</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>transit), working force participation for women, union membership,</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>etc.</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>For this kind of responses, the statistical distribution is obviously a binomial distribution with one trial. This is a major difference with the estimators that will be reviewed in the other chapters of this part, for which assuming a distribution function for the response is a crucial choice. Denoting 1 as "a success" and 0 as "a fail", this distribution</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>is fully characterized by a unique parameter, $\mu$, which is the</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>probability of success and is also the expected value of the variable,</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>as: $\mbox{E}(y) = (1 - \mu) \times 0 + \mu \times 1 = \mu$.</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>The variance of the distribution is:</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>$\mbox{V}(y) = (1 - \mu) (0-\mu) ^ 2+ \mu (1-\mu) ^ 2 = \mu(1-\mu)$.</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>It is therefore inversely U-shaped, has a maximum for $\mu = 0.5$ (with a value of 0.25) and is symmetric around this value. As $\mu$ tends</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>to 0 or to 1, the variance of $y$ obviously tends to 0 as almost all the</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>values in a given sample will be either equal to 0 or 1. </span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{index function}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{linear predictor}</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>To get a regression model for a binomial response, we first define an **index function**, also called the **linear predictor**: $\eta_n = \gamma ^ \top z_n = \alpha + \beta ^ \top x_n$. Then, a function $F$ is chosen that relates this index function to the unique parameter of the binomial distribution: $\mu_n =F(\eta_n)$. Different choices of $F$ leads to different binomial models. </span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>@sec-func_form_binom will present the three most common choices for $F$</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>which result in the linear probability, the logit and the probit models. @sec-struct_binom will present two distinct structural models that</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>can justify the use of these models. @sec-glm presents the generalized linear models from which the binomial model is a special case. @sec-binom_evaluation is devoted to the estimation, the evaluation and the testing of binomial models. @sec-endog_probit presents relevant estimators when some covariates are endogenous. Finally, @sec-ordered presents the ordered model.</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Functional form and the linear-probability, probit and logit model {#sec-func_form_binom}</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{linear probability model}</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>The most obvious choice for $F$ is the identity function, so that</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>$\mu_n = \eta_n = \alpha + \beta ^ \top x_n$. Therefore, the parameter of the binomial </span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>distribution is assumed to be a linear function of the covariates. </span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>On the one hand, this choice has several interesting features. It is</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>very simple to estimate, as it is a linear model and, moreover,</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>it can be simply extended to IV estimation. As a linear model, $\frac{\partial\mu_n}{\partial x_{kn}} = \beta_k$, so that the estimated parameters can be interpreted as the (constant) marginal effects of the corresponding  covariate on the probability of success.</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>On the other hand, it has two serious drawbacks. Firstly, the</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>residuals are $y_n - \hat{\mu}_n$ but, as $y_n$ is either 0</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>or 1, the residuals are respectively $- (\hat{\alpha}+ \hat{\beta} ^ \top x_n)$ or</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>$1 - (\hat{\alpha} + \hat{\beta} ^ \top x_n)$ and therefore depends on the values of</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>$x_n$. The linear-probability model, estimated by least-squares is</span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>therefore inefficient, as the residuals are heteroskedastic and the standard deviations reported by a least</span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>squares program are biased. As usual, the solution would be either to</span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>estimate the linear-probability model by GLS or to use heteroskedasticity-robust estimator for the</span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>covariance matrix of the estimators. Secondly, as the fitted</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a>probabilities of success are linear functions of the covariates, they</span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a>are not bounded by 0 and 1 and, therefore, it is possible that the</span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a>model will predict, for some observations, probabilities that would be</span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>either negative or greater than 1.</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>Therefore, it is customary to use a functional form $F$ which has the</span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>following properties:</span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$F(z)$ is increasing in $z$,</span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\lim_{z\rightarrow -\infty} F(z) = 0$,</span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\lim_{z\rightarrow +\infty} F(z) = 1$.</span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>which are the features of any cumulative density function for</span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a>continuous variables defined on the whole real line support. Two common choices are the normal ($\Phi$) and the logistic ($\Lambda$) distributions:</span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{probit|(}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{logit|(}</span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>\Phi(z) &amp;=&amp; \displaystyle \int_{-\infty} ^ z \phi(t) dt = \int_{-\infty} ^ z \frac{1}{\sqrt{2\pi}} e ^{-\frac{1}{2}t ^ 2} dt <span class="sc">\\</span></span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>\Lambda(z) &amp;=&amp; \displaystyle \frac{e^z}{1 + e ^ z}</span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>which lead respectively to the **probit** and **logit** models. The</span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a>density function for the logistic distribution (obtained by taking the derivative of $\Lambda$) is $\lambda(z) = \frac{e^z}{(1 + e ^ z) ^</span>
<span id="cb42-76"><a href="#cb42-76" aria-hidden="true" tabindex="-1"></a>2}$. Both density functions are symmetric around 0 and are</span>
<span id="cb42-77"><a href="#cb42-77" aria-hidden="true" tabindex="-1"></a>"bell-shaped", but they have two important differences, as illustrated in @fig-normal_logistic:</span>
<span id="cb42-78"><a href="#cb42-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-79"><a href="#cb42-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the variance of the standard normal distribution is 1 and is equal</span>
<span id="cb42-80"><a href="#cb42-80" aria-hidden="true" tabindex="-1"></a>  to $\pi ^ 2/3$ for the logistic distribution,</span>
<span id="cb42-81"><a href="#cb42-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the logistic distribution has much heavier tails than the normal density.</span>
<span id="cb42-82"><a href="#cb42-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-85"><a href="#cb42-85" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-86"><a href="#cb42-86" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-normal_logistic</span></span>
<span id="cb42-87"><a href="#cb42-87" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Logistic and normal densities"</span></span>
<span id="cb42-88"><a href="#cb42-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-89"><a href="#cb42-89" aria-hidden="true" tabindex="-1"></a>datas <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>, .<span class="dv">1</span>), <span class="at">normal =</span> <span class="fu">dnorm</span>(x), <span class="at">logistic =</span> <span class="fu">dlogis</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb42-90"><a href="#cb42-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span> x)</span>
<span id="cb42-91"><a href="#cb42-91" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(datas, <span class="fu">aes</span>(x, value, <span class="at">linetype =</span> name)) <span class="sc">+</span> </span>
<span id="cb42-92"><a href="#cb42-92" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb42-93"><a href="#cb42-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">linetype =</span> <span class="st">"Distribution"</span>)</span>
<span id="cb42-94"><a href="#cb42-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-95"><a href="#cb42-95" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-96"><a href="#cb42-96" aria-hidden="true" tabindex="-1"></a>As $\mu_n=F(\eta_n)$ (with $\eta_n = \alpha + \beta ^ \top x_n$), the marginal effect of the k^th^ covariate on the probability is:</span>
<span id="cb42-97"><a href="#cb42-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-98"><a href="#cb42-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-99"><a href="#cb42-99" aria-hidden="true" tabindex="-1"></a>\frac{\partial \mu_n}{\partial x_{nk}} = \beta_k f(\eta_n)</span>
<span id="cb42-100"><a href="#cb42-100" aria-hidden="true" tabindex="-1"></a>$$ {#eq-meffect_binomial}</span>
<span id="cb42-101"><a href="#cb42-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-102"><a href="#cb42-102" aria-hidden="true" tabindex="-1"></a>where $f$ is the first derivative of $F$, which is respectively, for the probit and logit models, </span>
<span id="cb42-103"><a href="#cb42-103" aria-hidden="true" tabindex="-1"></a>$\phi$ and $\lambda$, the normal and logistic densities. Therefore, the marginal effect is obtained</span>
<span id="cb42-104"><a href="#cb42-104" aria-hidden="true" tabindex="-1"></a>by multiplying the coefficient by $f(\eta_n)$ which depends on</span>
<span id="cb42-105"><a href="#cb42-105" aria-hidden="true" tabindex="-1"></a>the value of the covariates for a given observation. Therefore, the</span>
<span id="cb42-106"><a href="#cb42-106" aria-hidden="true" tabindex="-1"></a>marginal effect is observation-dependent, but the ratio of two</span>
<span id="cb42-107"><a href="#cb42-107" aria-hidden="true" tabindex="-1"></a>marginal effects for two covariates is not, as it is obviously, from @eq-meffect_binomial, equal</span>
<span id="cb42-108"><a href="#cb42-108" aria-hidden="true" tabindex="-1"></a>to the ratio of the two corresponding coefficients. As the coefficient of</span>
<span id="cb42-109"><a href="#cb42-109" aria-hidden="true" tabindex="-1"></a>proportionality is the normal/logistic density, the maximum marginal effect is for</span>
<span id="cb42-110"><a href="#cb42-110" aria-hidden="true" tabindex="-1"></a>$\eta_n = 0$, which results in a probability of success of</span>
<span id="cb42-111"><a href="#cb42-111" aria-hidden="true" tabindex="-1"></a>0.5. The corresponding values of the densities are 0.4 and 0.25 for</span>
<span id="cb42-112"><a href="#cb42-112" aria-hidden="true" tabindex="-1"></a>the normal and logistic densities. Therefore, a rule of thumb to</span>
<span id="cb42-113"><a href="#cb42-113" aria-hidden="true" tabindex="-1"></a>interpret coefficients is to multiply them respectively by 0.4 and</span>
<span id="cb42-114"><a href="#cb42-114" aria-hidden="true" tabindex="-1"></a>0.25 for the probit and logit model to get an estimation of the</span>
<span id="cb42-115"><a href="#cb42-115" aria-hidden="true" tabindex="-1"></a>maximum marginal effect. </span>
<span id="cb42-116"><a href="#cb42-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-117"><a href="#cb42-117" aria-hidden="true" tabindex="-1"></a>The coefficients of the logit and probit can therefore not be</span>
<span id="cb42-118"><a href="#cb42-118" aria-hidden="true" tabindex="-1"></a>compared. This is due to the fact that they are scaled differently, as</span>
<span id="cb42-119"><a href="#cb42-119" aria-hidden="true" tabindex="-1"></a>the standard deviation of the logistic distribution is $\pi/\sqrt{3}</span>
<span id="cb42-120"><a href="#cb42-120" aria-hidden="true" tabindex="-1"></a>\approx 1.81$, compared to 1 for the normal distribution. Therefore,</span>
<span id="cb42-121"><a href="#cb42-121" aria-hidden="true" tabindex="-1"></a>it would be tempting to multiply the probit coefficients by 1.81 to</span>
<span id="cb42-122"><a href="#cb42-122" aria-hidden="true" tabindex="-1"></a>compare them to the logit coefficients, but @AMEM:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Amemiya} showed that,</span>
<span id="cb42-123"><a href="#cb42-123" aria-hidden="true" tabindex="-1"></a>empirically, the value of 1.6 performs better.</span>
<span id="cb42-124"><a href="#cb42-124" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}</span>
<span id="cb42-125"><a href="#cb42-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-126"><a href="#cb42-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-127"><a href="#cb42-127" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-128"><a href="#cb42-128" aria-hidden="true" tabindex="-1"></a><span class="co"># source bls cpi 2022 842 (base 100 en 1967)</span></span>
<span id="cb42-129"><a href="#cb42-129" aria-hidden="true" tabindex="-1"></a><span class="co"># salaire minimum 1.5</span></span>
<span id="cb42-130"><a href="#cb42-130" aria-hidden="true" tabindex="-1"></a>mode_choice <span class="ot">&lt;-</span> mode_choice <span class="sc">%&gt;%</span></span>
<span id="cb42-131"><a href="#cb42-131" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">ivtime =</span> ivtime <span class="sc">/</span> <span class="dv">60</span>, <span class="at">ovtime =</span> ovtime <span class="sc">/</span> <span class="dv">60</span>, <span class="at">cost =</span> cost <span class="sc">/</span> <span class="dv">100</span>)</span>
<span id="cb42-132"><a href="#cb42-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-133"><a href="#cb42-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-134"><a href="#cb42-134" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{probit|)}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{logit|)}</span>
<span id="cb42-135"><a href="#cb42-135" aria-hidden="true" tabindex="-1"></a>\idxdata{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-136"><a href="#cb42-136" aria-hidden="true" tabindex="-1"></a>As an example, we consider the data set used by @HORO:93\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Horowitz} which</span>
<span id="cb42-137"><a href="#cb42-137" aria-hidden="true" tabindex="-1"></a>concerns the transport mode chosen for work trips by a sample of 842 individuals in</span>
<span id="cb42-138"><a href="#cb42-138" aria-hidden="true" tabindex="-1"></a>Washington DC in the late sixties. The response <span class="in">`mode`</span> is 1 for car and 0</span>
<span id="cb42-139"><a href="#cb42-139" aria-hidden="true" tabindex="-1"></a>for transit. The covariates are the in- and out-vehicle times</span>
<span id="cb42-140"><a href="#cb42-140" aria-hidden="true" tabindex="-1"></a>(<span class="in">`ivtime`</span> and <span class="in">`ovtime`</span>) and the cost differences between car and</span>
<span id="cb42-141"><a href="#cb42-141" aria-hidden="true" tabindex="-1"></a>transit. Therefore, a positive value indicates that car trip is</span>
<span id="cb42-142"><a href="#cb42-142" aria-hidden="true" tabindex="-1"></a>longer/more expensive than the corresponding trip using public</span>
<span id="cb42-143"><a href="#cb42-143" aria-hidden="true" tabindex="-1"></a>transit. We multiply the cost by 8.42 to obtain dollars in 2022 (the CPI for</span>
<span id="cb42-144"><a href="#cb42-144" aria-hidden="true" tabindex="-1"></a>2022 is 842 with a 100 base in 1967).</span>
<span id="cb42-145"><a href="#cb42-145" aria-hidden="true" tabindex="-1"></a>The generalized cost of a trip is the sum of the monetary cost and the</span>
<span id="cb42-146"><a href="#cb42-146" aria-hidden="true" tabindex="-1"></a>value of the time spent in the transport. We use two-thirds of the minimum</span>
<span id="cb42-147"><a href="#cb42-147" aria-hidden="true" tabindex="-1"></a>hourly wage (about $1.4 in the US in the late sixties, which is about $8 in dollars of 2022) to valuate an hour of transport:</span>
<span id="cb42-148"><a href="#cb42-148" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}</span>
<span id="cb42-149"><a href="#cb42-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-150"><a href="#cb42-150" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-151"><a href="#cb42-151" aria-hidden="true" tabindex="-1"></a>mode_choice <span class="ot">&lt;-</span> mode_choice <span class="sc">%&gt;%</span></span>
<span id="cb42-152"><a href="#cb42-152" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">cost =</span> cost <span class="sc">*</span> <span class="fl">8.42</span>,</span>
<span id="cb42-153"><a href="#cb42-153" aria-hidden="true" tabindex="-1"></a>           <span class="at">gcost =</span> (ivtime <span class="sc">+</span> ovtime) <span class="sc">*</span> <span class="dv">8</span> <span class="sc">+</span> cost)</span>
<span id="cb42-154"><a href="#cb42-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-155"><a href="#cb42-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-156"><a href="#cb42-156" aria-hidden="true" tabindex="-1"></a>To fit the three models, we use the <span class="in">`micsr::binomreg`</span> function, which</span>
<span id="cb42-157"><a href="#cb42-157" aria-hidden="true" tabindex="-1"></a>has a <span class="in">`link`</span> argument which enables to estimate the three models.</span>
<span id="cb42-158"><a href="#cb42-158" aria-hidden="true" tabindex="-1"></a>\idxfun{binomreg}{micsr}\idxfun{update}{stats}\idxfun{gaze}{micsr}</span>
<span id="cb42-159"><a href="#cb42-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-160"><a href="#cb42-160" aria-hidden="true" tabindex="-1"></a><span class="in">```{r collapse = TRUE}</span></span>
<span id="cb42-161"><a href="#cb42-161" aria-hidden="true" tabindex="-1"></a>lp_m <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> gcost, mode_choice, <span class="at">link =</span> <span class="st">"identity"</span>)</span>
<span id="cb42-162"><a href="#cb42-162" aria-hidden="true" tabindex="-1"></a>pt_m <span class="ot">&lt;-</span> <span class="fu">update</span>(lp_m, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-163"><a href="#cb42-163" aria-hidden="true" tabindex="-1"></a>lt_m <span class="ot">&lt;-</span> <span class="fu">update</span>(lp_m, <span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb42-164"><a href="#cb42-164" aria-hidden="true" tabindex="-1"></a><span class="fu">gaze</span>(lp_m)</span>
<span id="cb42-165"><a href="#cb42-165" aria-hidden="true" tabindex="-1"></a><span class="fu">gaze</span>(pt_m)</span>
<span id="cb42-166"><a href="#cb42-166" aria-hidden="true" tabindex="-1"></a><span class="fu">gaze</span>(lt_m)</span>
<span id="cb42-167"><a href="#cb42-167" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-168"><a href="#cb42-168" aria-hidden="true" tabindex="-1"></a>\idxfun{coef}{stats}</span>
<span id="cb42-169"><a href="#cb42-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-170"><a href="#cb42-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-171"><a href="#cb42-171" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-172"><a href="#cb42-172" aria-hidden="true" tabindex="-1"></a>mef_lp <span class="ot">&lt;-</span> <span class="fu">coef</span>(lp_m)[<span class="st">"gcost"</span>]</span>
<span id="cb42-173"><a href="#cb42-173" aria-hidden="true" tabindex="-1"></a>mef_pt <span class="ot">&lt;-</span> <span class="fu">coef</span>(pt_m)[<span class="st">"gcost"</span>] <span class="sc">*</span> <span class="fl">0.4</span></span>
<span id="cb42-174"><a href="#cb42-174" aria-hidden="true" tabindex="-1"></a>mef_lt <span class="ot">&lt;-</span> <span class="fu">coef</span>(lt_m)[<span class="st">"gcost"</span>] <span class="sc">*</span> <span class="fl">0.25</span></span>
<span id="cb42-175"><a href="#cb42-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-176"><a href="#cb42-176" aria-hidden="true" tabindex="-1"></a>\idxfun{coef}{stats}</span>
<span id="cb42-177"><a href="#cb42-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-178"><a href="#cb42-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r include = FALSE}</span></span>
<span id="cb42-179"><a href="#cb42-179" aria-hidden="true" tabindex="-1"></a>xb <span class="ot">&lt;-</span> <span class="fu">mean</span>(mode_choice<span class="sc">$</span>gcost)</span>
<span id="cb42-180"><a href="#cb42-180" aria-hidden="true" tabindex="-1"></a>lpb_pt <span class="ot">&lt;-</span> <span class="fu">coef</span>(pt_m)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(pt_m)[<span class="dv">2</span>] <span class="sc">*</span> xb</span>
<span id="cb42-181"><a href="#cb42-181" aria-hidden="true" tabindex="-1"></a>lpb_lt <span class="ot">&lt;-</span> <span class="fu">coef</span>(lt_m)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(lt_m)[<span class="dv">2</span>] <span class="sc">*</span> xb</span>
<span id="cb42-182"><a href="#cb42-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-183"><a href="#cb42-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-184"><a href="#cb42-184" aria-hidden="true" tabindex="-1"></a>The coefficient of <span class="in">`gcost`</span> for the linear-probability model is </span>
<span id="cb42-185"><a href="#cb42-185" aria-hidden="true" tabindex="-1"></a><span class="in">`r round(mef_lp, 4)`</span>, which means that a one dollar increase of</span>
<span id="cb42-186"><a href="#cb42-186" aria-hidden="true" tabindex="-1"></a>the generalized cost differential will increase the probability of using the car</span>
<span id="cb42-187"><a href="#cb42-187" aria-hidden="true" tabindex="-1"></a>by <span class="in">`r round(mef_lp * 100, 2)`</span> percentage points.</span>
<span id="cb42-188"><a href="#cb42-188" aria-hidden="true" tabindex="-1"></a>If we use the previously described rule of thumb to multiply the</span>
<span id="cb42-189"><a href="#cb42-189" aria-hidden="true" tabindex="-1"></a>probit/logit coefficients by 0.4/0.25 in order to have an upper limit</span>
<span id="cb42-190"><a href="#cb42-190" aria-hidden="true" tabindex="-1"></a>for the marginal effect, we get <span class="in">`r round(mef_lt * 100, 2)`</span></span>
<span id="cb42-191"><a href="#cb42-191" aria-hidden="true" tabindex="-1"></a>and <span class="in">`r round(mef_pt * 100, 2)`</span> percentage points,</span>
<span id="cb42-192"><a href="#cb42-192" aria-hidden="true" tabindex="-1"></a>which are much higher values than for the linear probability model.</span>
<span id="cb42-193"><a href="#cb42-193" aria-hidden="true" tabindex="-1"></a>This is because the coefficient of the linear model estimates the</span>
<span id="cb42-194"><a href="#cb42-194" aria-hidden="true" tabindex="-1"></a>marginal effect at the sample mean. In our sample, the mean value of</span>
<span id="cb42-195"><a href="#cb42-195" aria-hidden="true" tabindex="-1"></a>the covariate is <span class="in">`r round(xb, 2)`</span>. To get</span>
<span id="cb42-196"><a href="#cb42-196" aria-hidden="true" tabindex="-1"></a>comparable marginal effects for the probit/logit models, we should first</span>
<span id="cb42-197"><a href="#cb42-197" aria-hidden="true" tabindex="-1"></a>compute $\hat{\alpha} + \hat{\beta} \bar{x}$ (<span class="in">`r round(lpb_pt, 2)`</span> and <span class="in">`r round(lpb_lt, 2)`</span> respectively for the</span>
<span id="cb42-198"><a href="#cb42-198" aria-hidden="true" tabindex="-1"></a>probit and logit models) and use these values with the relevant densities ($\phi(<span class="in">`r round(lpb_pt, 2)`</span>) = <span class="in">`r round(dnorm(lpb_pt), 3)`</span>$ and $\lambda(<span class="in">`r round(lpb_lt, 2)`</span>) =  <span class="in">`r round(dlogis(lpb_lt), 3)`</span>$). </span>
<span id="cb42-199"><a href="#cb42-199" aria-hidden="true" tabindex="-1"></a>At the sample mean, the marginal effects are then <span class="in">`r round(dnorm(lpb_pt) * coef(pt_m)[2], 3)`</span>  and </span>
<span id="cb42-200"><a href="#cb42-200" aria-hidden="true" tabindex="-1"></a><span class="in">`r round(dlogis(lpb_lt) * coef(lt_m)[2], 3)`</span></span>
<span id="cb42-201"><a href="#cb42-201" aria-hidden="true" tabindex="-1"></a>and are therefore very close to the linear probability model coefficient.</span>
<span id="cb42-202"><a href="#cb42-202" aria-hidden="true" tabindex="-1"></a>The scatterplot and the fitted probability curves are presented o</span>
<span id="cb42-203"><a href="#cb42-203" aria-hidden="true" tabindex="-1"></a>in @fig-fitprob. </span>
<span id="cb42-204"><a href="#cb42-204" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Note the use of `geom_jitter` so that an a small random vertical --&gt;</span></span>
<span id="cb42-205"><a href="#cb42-205" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- distance is added to every point.  --&gt;</span></span>
<span id="cb42-206"><a href="#cb42-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-207"><a href="#cb42-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-208"><a href="#cb42-208" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-fitprob</span></span>
<span id="cb42-209"><a href="#cb42-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig.cap: "Fitted probabilities"</span></span>
<span id="cb42-210"><a href="#cb42-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-211"><a href="#cb42-211" aria-hidden="true" tabindex="-1"></a>mode_choice <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(gcost, mode)) <span class="sc">+</span></span>
<span id="cb42-212"><a href="#cb42-212" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">size =</span> <span class="fl">0.2</span>, <span class="at">height =</span> <span class="fl">0.02</span>) <span class="sc">+</span></span>
<span id="cb42-213"><a href="#cb42-213" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">coef</span>(lp_m)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(lp_m)[<span class="dv">2</span>] <span class="sc">*</span> x, </span>
<span id="cb42-214"><a href="#cb42-214" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"linear"</span>)) <span class="sc">+</span> </span>
<span id="cb42-215"><a href="#cb42-215" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">pnorm</span>(<span class="fu">coef</span>(pt_m)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(pt_m)[<span class="dv">2</span>] <span class="sc">*</span> x), </span>
<span id="cb42-216"><a href="#cb42-216" aria-hidden="true" tabindex="-1"></a>                                          <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"probit"</span>)) <span class="sc">+</span> </span>
<span id="cb42-217"><a href="#cb42-217" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">plogis</span>(<span class="fu">coef</span>(lt_m)[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">coef</span>(lt_m)[<span class="dv">2</span>] <span class="sc">*</span> x), </span>
<span id="cb42-218"><a href="#cb42-218" aria-hidden="true" tabindex="-1"></a>                                           <span class="fu">aes</span>(<span class="at">linetype =</span> <span class="st">"logit"</span>)) <span class="sc">+</span> </span>
<span id="cb42-219"><a href="#cb42-219" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb42-220"><a href="#cb42-220" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-221"><a href="#cb42-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-222"><a href="#cb42-222" aria-hidden="true" tabindex="-1"></a>The fitted probabilities are given by</span>
<span id="cb42-223"><a href="#cb42-223" aria-hidden="true" tabindex="-1"></a>a straight line for the linear probability model and by an S curve for</span>
<span id="cb42-224"><a href="#cb42-224" aria-hidden="true" tabindex="-1"></a>the probit and logit models. These last two curves are very similar</span>
<span id="cb42-225"><a href="#cb42-225" aria-hidden="true" tabindex="-1"></a>except for low values of the covariate. Note also that at the sample</span>
<span id="cb42-226"><a href="#cb42-226" aria-hidden="true" tabindex="-1"></a>mean ($x = <span class="in">`r round(xb, 2)`</span>$), the slopes of the three curves are very similar. This illustrates the fact that the three models result in similar marginal</span>
<span id="cb42-227"><a href="#cb42-227" aria-hidden="true" tabindex="-1"></a>effects around the mean value of the covariate. </span>
<span id="cb42-228"><a href="#cb42-228" aria-hidden="true" tabindex="-1"></a>The linear probability model is $\hat{\mu} = <span class="in">`r round(coef(lp_m)[1], 3)`</span> +  <span class="in">`r round(coef(lp_m)[2], 3)`</span> \times</span>
<span id="cb42-229"><a href="#cb42-229" aria-hidden="true" tabindex="-1"></a>x$. Therefore, $\hat{\mu}&lt;0$ for </span>
<span id="cb42-230"><a href="#cb42-230" aria-hidden="true" tabindex="-1"></a>$x &lt; - <span class="in">`r round(coef(lp_m)[1], 3)`</span> /  <span class="in">`r round(coef(lp_m)[2], 3)`</span> = - <span class="in">`r round(coef(lp_m)[1] / coef(lp_m)[2], 2)`</span>$ and</span>
<span id="cb42-231"><a href="#cb42-231" aria-hidden="true" tabindex="-1"></a>$\hat{\mu}&gt;1$ for </span>
<span id="cb42-232"><a href="#cb42-232" aria-hidden="true" tabindex="-1"></a>$x &gt; (1 -  <span class="in">`r round(coef(lp_m)[1], 3)`</span>) /  <span class="in">`r round(coef(lp_m)[2], 3)`</span> =  <span class="in">`r round((1 - coef(lp_m)[1]) / coef(lp_m)[2], 3)`</span>$. In this sample,</span>
<span id="cb42-233"><a href="#cb42-233" aria-hidden="true" tabindex="-1"></a>there are no observations for which $\hat{\mu} &lt; 0$ but, for 83 out of</span>
<span id="cb42-234"><a href="#cb42-234" aria-hidden="true" tabindex="-1"></a>842 observations, $\hat{\mu} &gt; 1$.</span>
<span id="cb42-235"><a href="#cb42-235" aria-hidden="true" tabindex="-1"></a>Finally, the ratio of the logit and probit coefficients is</span>
<span id="cb42-236"><a href="#cb42-236" aria-hidden="true" tabindex="-1"></a>$<span class="in">`r round(coef(lt_m)[2], 3)`</span> /</span>
<span id="cb42-237"><a href="#cb42-237" aria-hidden="true" tabindex="-1"></a><span class="in">`r round(coef(lt_m)[2], 3)`</span> = </span>
<span id="cb42-238"><a href="#cb42-238" aria-hidden="true" tabindex="-1"></a><span class="in">`r round(coef(lt_m)[2] / coef(pt_m)[2], 3)`</span>$, </span>
<span id="cb42-239"><a href="#cb42-239" aria-hidden="true" tabindex="-1"></a>which is a bit larger than the value of 1.6 suggested by @AMEM:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Amemiya}.</span>
<span id="cb42-240"><a href="#cb42-240" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{airbnb}{micsr.data}</span>
<span id="cb42-241"><a href="#cb42-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-242"><a href="#cb42-242" aria-hidden="true" tabindex="-1"></a>We now consider a second data set called <span class="in">`airbnb`</span>, used by</span>
<span id="cb42-243"><a href="#cb42-243" aria-hidden="true" tabindex="-1"></a>@EDEL:LUCA:SVIR:17\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Edelman}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Luca}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Svirsky}. The aim of their study is to analyze the presence</span>
<span id="cb42-244"><a href="#cb42-244" aria-hidden="true" tabindex="-1"></a>of racial discrimination on the Airbnb platform. The authors create</span>
<span id="cb42-245"><a href="#cb42-245" aria-hidden="true" tabindex="-1"></a>guest accounts that differ by the first name chosen. More</span>
<span id="cb42-246"><a href="#cb42-246" aria-hidden="true" tabindex="-1"></a>specifically, the race of the applicant is suggested by the choice of</span>
<span id="cb42-247"><a href="#cb42-247" aria-hidden="true" tabindex="-1"></a>the first name, either a "white" (Emily, Sarah, Greg) or an</span>
<span id="cb42-248"><a href="#cb42-248" aria-hidden="true" tabindex="-1"></a>"African American" (Lakisha or Kareem) first name. The response is</span>
<span id="cb42-249"><a href="#cb42-249" aria-hidden="true" tabindex="-1"></a>acceptance and is 1 if the host gave a positive response and 0</span>
<span id="cb42-250"><a href="#cb42-250" aria-hidden="true" tabindex="-1"></a>otherwise. In our simplified example, we use only three covariates,</span>
<span id="cb42-251"><a href="#cb42-251" aria-hidden="true" tabindex="-1"></a>guest's race suggested by the first name <span class="in">`guest_race`</span>, the price</span>
<span id="cb42-252"><a href="#cb42-252" aria-hidden="true" tabindex="-1"></a><span class="in">`price`</span> (in logs) and <span class="in">`city`</span>, the cities where the experience took place (Baltimore, Dallas, Los Angeles, St. Louis and Washington, DC). Note that the mean of</span>
<span id="cb42-253"><a href="#cb42-253" aria-hidden="true" tabindex="-1"></a>the response is $0.45$ which is a distinctive feature of this data set</span>
<span id="cb42-254"><a href="#cb42-254" aria-hidden="true" tabindex="-1"></a>compared to the previous one. As the mean value of the probability of</span>
<span id="cb42-255"><a href="#cb42-255" aria-hidden="true" tabindex="-1"></a>success is close to 50% we can expect that the rule of the thumb which</span>
<span id="cb42-256"><a href="#cb42-256" aria-hidden="true" tabindex="-1"></a>consists of multiplying the logit/probit coefficients by 0.25/0.4 would</span>
<span id="cb42-257"><a href="#cb42-257" aria-hidden="true" tabindex="-1"></a>give an estimated value for the marginal effect close to the one</span>
<span id="cb42-258"><a href="#cb42-258" aria-hidden="true" tabindex="-1"></a>directly obtained in the linear probability model.</span>
<span id="cb42-259"><a href="#cb42-259" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{is.na}{base}\idxfun{binomreg}{micsr}\idxfun{update}{stats}</span>
<span id="cb42-260"><a href="#cb42-260" aria-hidden="true" tabindex="-1"></a>\idxfun{filter}{dplyr}\idxfun{ifelse}{base}</span>
<span id="cb42-261"><a href="#cb42-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-262"><a href="#cb42-262" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-263"><a href="#cb42-263" aria-hidden="true" tabindex="-1"></a>airbnb <span class="ot">&lt;-</span> airbnb <span class="sc">%&gt;%</span></span>
<span id="cb42-264"><a href="#cb42-264" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">acceptance =</span> <span class="fu">ifelse</span>(acceptance <span class="sc">==</span> <span class="st">"no"</span>, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb42-265"><a href="#cb42-265" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(<span class="sc">!</span> <span class="fu">is.na</span>(price), <span class="sc">!</span> <span class="fu">is.na</span>(city))</span>
<span id="cb42-266"><a href="#cb42-266" aria-hidden="true" tabindex="-1"></a>lp_a <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(acceptance <span class="sc">~</span> guest_race <span class="sc">+</span> <span class="fu">log</span>(price) <span class="sc">+</span> city, </span>
<span id="cb42-267"><a href="#cb42-267" aria-hidden="true" tabindex="-1"></a>                 airbnb, <span class="at">link =</span> <span class="st">"identity"</span>)</span>
<span id="cb42-268"><a href="#cb42-268" aria-hidden="true" tabindex="-1"></a>pt_a <span class="ot">&lt;-</span> <span class="fu">update</span>(lp_a, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-269"><a href="#cb42-269" aria-hidden="true" tabindex="-1"></a>lt_a <span class="ot">&lt;-</span> <span class="fu">update</span>(lp_a, <span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb42-270"><a href="#cb42-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb42-271"><a href="#cb42-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-272"><a href="#cb42-272" aria-hidden="true" tabindex="-1"></a>To summarize the results, we print in @tbl-compabb the</span>
<span id="cb42-273"><a href="#cb42-273" aria-hidden="true" tabindex="-1"></a>coefficients of the linear probability model, those of the logit</span>
<span id="cb42-274"><a href="#cb42-274" aria-hidden="true" tabindex="-1"></a>multiplied by 0.25, those of the probit multiplied by 0.4 and the</span>
<span id="cb42-275"><a href="#cb42-275" aria-hidden="true" tabindex="-1"></a>ratio of the logit and the probit coefficients.</span>
<span id="cb42-276"><a href="#cb42-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-277"><a href="#cb42-277" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-278"><a href="#cb42-278" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-compabb</span></span>
<span id="cb42-279"><a href="#cb42-279" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-280"><a href="#cb42-280" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Comparison of the coefficients for the Airbnb data set"</span></span>
<span id="cb42-281"><a href="#cb42-281" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">linear =</span> <span class="fu">coef</span>(lp_a), </span>
<span id="cb42-282"><a href="#cb42-282" aria-hidden="true" tabindex="-1"></a>       <span class="at">probit =</span> <span class="fu">coef</span>(pt_a) <span class="sc">*</span> <span class="fl">0.4</span>,</span>
<span id="cb42-283"><a href="#cb42-283" aria-hidden="true" tabindex="-1"></a>       <span class="at">logit =</span> <span class="fu">coef</span>(lt_a) <span class="sc">*</span> <span class="fl">0.25</span>,</span>
<span id="cb42-284"><a href="#cb42-284" aria-hidden="true" tabindex="-1"></a>       <span class="st">`</span><span class="at">logit / probit</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">coef</span>(lt_a) <span class="sc">/</span> <span class="fu">coef</span>(pt_a)) <span class="sc">%&gt;%</span></span>
<span id="cb42-285"><a href="#cb42-285" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_column</span>(<span class="st">" "</span> <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">coef</span>(lt_a)), <span class="at">.before =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb42-286"><a href="#cb42-286" aria-hidden="true" tabindex="-1"></a>    knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb42-287"><a href="#cb42-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-288"><a href="#cb42-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-289"><a href="#cb42-289" aria-hidden="true" tabindex="-1"></a>With this rescaling, the three models give similar results. For a</span>
<span id="cb42-290"><a href="#cb42-290" aria-hidden="true" tabindex="-1"></a>100% increase of the price, the probability of acceptance reduces by</span>
<span id="cb42-291"><a href="#cb42-291" aria-hidden="true" tabindex="-1"></a>4.16 percentage points. The estimated marginal effect for black</span>
<span id="cb42-292"><a href="#cb42-292" aria-hidden="true" tabindex="-1"></a>guests is about $-8.5$ percentage points. However, computing a</span>
<span id="cb42-293"><a href="#cb42-293" aria-hidden="true" tabindex="-1"></a>derivative is not relevant in this case as the covariate is a</span>
<span id="cb42-294"><a href="#cb42-294" aria-hidden="true" tabindex="-1"></a>dummy. We should therefore better compute the difference between the</span>
<span id="cb42-295"><a href="#cb42-295" aria-hidden="true" tabindex="-1"></a>probabilities of acceptance, everything other being equal, which means here</span>
<span id="cb42-296"><a href="#cb42-296" aria-hidden="true" tabindex="-1"></a>for a given price of the property and for the reference city, which is Baltimore. The average price being equal to</span>
<span id="cb42-297"><a href="#cb42-297" aria-hidden="true" tabindex="-1"></a>$182 in our sample, we have, for the probit model: $\Phi(0.497 -</span>
<span id="cb42-298"><a href="#cb42-298" aria-hidden="true" tabindex="-1"></a>0.213 - 0.107 \times \ln 182) - \Phi(0.497 - 0.213 - 0.107 \times \ln 182) = -0.084$</span>
<span id="cb42-299"><a href="#cb42-299" aria-hidden="true" tabindex="-1"></a>and for the logit model: $\Lambda(0.796 - 0.341 - 0.171 \times\ln 182) -</span>
<span id="cb42-300"><a href="#cb42-300" aria-hidden="true" tabindex="-1"></a>\Lambda(0.796 - 0.171\times\ln 182) = -0.084$, which means that, at least in</span>
<span id="cb42-301"><a href="#cb42-301" aria-hidden="true" tabindex="-1"></a>this example, the previous computation of the derivative gives an</span>
<span id="cb42-302"><a href="#cb42-302" aria-hidden="true" tabindex="-1"></a>extremely accurate approximation of the effect of this dummy</span>
<span id="cb42-303"><a href="#cb42-303" aria-hidden="true" tabindex="-1"></a>covariate. Finally, note that the ratio of the logit and probit</span>
<span id="cb42-304"><a href="#cb42-304" aria-hidden="true" tabindex="-1"></a>coefficients is very close to the value of 1.6 advocated by</span>
<span id="cb42-305"><a href="#cb42-305" aria-hidden="true" tabindex="-1"></a>@AMEM:81\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Amemiya}.</span>
<span id="cb42-306"><a href="#cb42-306" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{airbnb}{micsr.data}</span>
<span id="cb42-307"><a href="#cb42-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-308"><a href="#cb42-308" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb42-309"><a href="#cb42-309" aria-hidden="true" tabindex="-1"></a><span class="fu">## Structural models for binomial responses {#sec-struct_binom}</span></span>
<span id="cb42-310"><a href="#cb42-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-311"><a href="#cb42-311" aria-hidden="true" tabindex="-1"></a>Two structural models have been proposed to give a theoretical</span>
<span id="cb42-312"><a href="#cb42-312" aria-hidden="true" tabindex="-1"></a>foundation to the probit/logit models. Without loss of generality, we'll present these two models for the case where there is a unique covariate.</span>
<span id="cb42-313"><a href="#cb42-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-314"><a href="#cb42-314" aria-hidden="true" tabindex="-1"></a><span class="fu">### Latent variable and index function {#sec-latent_variable}</span></span>
<span id="cb42-315"><a href="#cb42-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-316"><a href="#cb42-316" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{latent variable|(}</span>
<span id="cb42-317"><a href="#cb42-317" aria-hidden="true" tabindex="-1"></a>We observe that $y$ is equal to 0 or 1, but we now assume that this</span>
<span id="cb42-318"><a href="#cb42-318" aria-hidden="true" tabindex="-1"></a>values is related to a latent continuous variable (called $y^*$) which</span>
<span id="cb42-319"><a href="#cb42-319" aria-hidden="true" tabindex="-1"></a>is unobserved. $y=1$ will result for "high" values of $y ^ *$ and</span>
<span id="cb42-320"><a href="#cb42-320" aria-hidden="true" tabindex="-1"></a>$y=0$ for low values of $y ^ *$. More specifically we'll assume that</span>
<span id="cb42-321"><a href="#cb42-321" aria-hidden="true" tabindex="-1"></a>the observation rule is:</span>
<span id="cb42-322"><a href="#cb42-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-323"><a href="#cb42-323" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-324"><a href="#cb42-324" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-325"><a href="#cb42-325" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-326"><a href="#cb42-326" aria-hidden="true" tabindex="-1"></a>y = 0 &amp; \mbox{if } &amp; y ^ * \leq \psi <span class="sc">\\</span></span>
<span id="cb42-327"><a href="#cb42-327" aria-hidden="true" tabindex="-1"></a>y = 1 &amp; \mbox{if } &amp; y ^ * &gt; \psi <span class="sc">\\</span></span>
<span id="cb42-328"><a href="#cb42-328" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-329"><a href="#cb42-329" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-330"><a href="#cb42-330" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-331"><a href="#cb42-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-332"><a href="#cb42-332" aria-hidden="true" tabindex="-1"></a>where $\psi$ is an unknown threshold. Now assume that the value of $y^ *$ is partly explained by an observable covariate $x$, the</span>
<span id="cb42-333"><a href="#cb42-333" aria-hidden="true" tabindex="-1"></a>unexplained part being modelized by a random error $\epsilon$. We then</span>
<span id="cb42-334"><a href="#cb42-334" aria-hidden="true" tabindex="-1"></a>have: $y ^ * = \alpha + \beta x + \epsilon$, so that the observation</span>
<span id="cb42-335"><a href="#cb42-335" aria-hidden="true" tabindex="-1"></a>rule becomes:</span>
<span id="cb42-336"><a href="#cb42-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-337"><a href="#cb42-337" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-338"><a href="#cb42-338" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-339"><a href="#cb42-339" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-340"><a href="#cb42-340" aria-hidden="true" tabindex="-1"></a>y = 0 &amp; \mbox{if } &amp; \epsilon \leq \psi - \alpha - \beta x<span class="sc">\\</span></span>
<span id="cb42-341"><a href="#cb42-341" aria-hidden="true" tabindex="-1"></a>y = 1 &amp; \mbox{if } &amp; \epsilon &gt; \psi - \alpha - \beta x <span class="sc">\\</span></span>
<span id="cb42-342"><a href="#cb42-342" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-343"><a href="#cb42-343" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-344"><a href="#cb42-344" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-345"><a href="#cb42-345" aria-hidden="true" tabindex="-1"></a>This observation rule depends on $\psi - \alpha$ and not on the separate values of $\psi$ and $\alpha$. </span>
<span id="cb42-346"><a href="#cb42-346" aria-hidden="true" tabindex="-1"></a>Therefore, $\psi$ can be set to</span>
<span id="cb42-347"><a href="#cb42-347" aria-hidden="true" tabindex="-1"></a>any arbitrary value, for example 0. Then, the probability of success</span>
<span id="cb42-348"><a href="#cb42-348" aria-hidden="true" tabindex="-1"></a>is: $1 - F(-\alpha - \beta x)$ where $F$ is the cumulative density</span>
<span id="cb42-349"><a href="#cb42-349" aria-hidden="true" tabindex="-1"></a>function of $\epsilon$. For example, if $\epsilon \sim \mathcal{N} (0, \sigma)$,</span>
<span id="cb42-350"><a href="#cb42-350" aria-hidden="true" tabindex="-1"></a>$\mbox{P}(y = 1 \mid x) = 1 - \Phi(-(\alpha - \beta x) / \sigma)$. We can</span>
<span id="cb42-351"><a href="#cb42-351" aria-hidden="true" tabindex="-1"></a>see from this expression that only $\alpha / \sigma$ and $\beta / \sigma$ can be identified,</span>
<span id="cb42-352"><a href="#cb42-352" aria-hidden="true" tabindex="-1"></a>so that, $\sigma$ can be set to any arbitrary value, for</span>
<span id="cb42-353"><a href="#cb42-353" aria-hidden="true" tabindex="-1"></a>example 1. Moreover, by the symmetry of the normal distribution, we</span>
<span id="cb42-354"><a href="#cb42-354" aria-hidden="true" tabindex="-1"></a>have $1 - \Phi(-z) = \Phi(z)$, so that the probability of success</span>
<span id="cb42-355"><a href="#cb42-355" aria-hidden="true" tabindex="-1"></a>becomes $F(y = 1 \mid x) = \Phi(\alpha +\beta ^\top x)$, which defines the</span>
<span id="cb42-356"><a href="#cb42-356" aria-hidden="true" tabindex="-1"></a>probit model.</span>
<span id="cb42-357"><a href="#cb42-357" aria-hidden="true" tabindex="-1"></a>Assuming that the distribution of $\epsilon$ is logistic, we have a</span>
<span id="cb42-358"><a href="#cb42-358" aria-hidden="true" tabindex="-1"></a>probability of success equal to $1 - \Lambda(- \alpha-\beta  x)$ which</span>
<span id="cb42-359"><a href="#cb42-359" aria-hidden="true" tabindex="-1"></a>reduces, as the logistic distribution is also symmetric, to: $F(y = 1</span>
<span id="cb42-360"><a href="#cb42-360" aria-hidden="true" tabindex="-1"></a>\mid x) = \Lambda(\alpha + \beta x) = e^{\alpha + \beta x} / (1 + e ^</span>
<span id="cb42-361"><a href="#cb42-361" aria-hidden="true" tabindex="-1"></a>{\alpha + \beta x})$.</span>
<span id="cb42-362"><a href="#cb42-362" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{latent variable|)}</span>
<span id="cb42-363"><a href="#cb42-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-364"><a href="#cb42-364" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random utility model {#sec-rum_binomial}</span></span>
<span id="cb42-365"><a href="#cb42-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-366"><a href="#cb42-366" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random utility model|(}</span>
<span id="cb42-367"><a href="#cb42-367" aria-hidden="true" tabindex="-1"></a>Consider now that we can define a utility function for the two</span>
<span id="cb42-368"><a href="#cb42-368" aria-hidden="true" tabindex="-1"></a>alternatives that correspond to the two values of the binomial</span>
<span id="cb42-369"><a href="#cb42-369" aria-hidden="true" tabindex="-1"></a>response. As an example, $y$ equals 1 or 0 if car or public transit</span>
<span id="cb42-370"><a href="#cb42-370" aria-hidden="true" tabindex="-1"></a>is chosen, and the only covariate $x$ is the generalized cost. The</span>
<span id="cb42-371"><a href="#cb42-371" aria-hidden="true" tabindex="-1"></a>utility of choosing a transport mode doesn't depend only on the</span>
<span id="cb42-372"><a href="#cb42-372" aria-hidden="true" tabindex="-1"></a>generalized cost, but also on some other unobserved variables. The</span>
<span id="cb42-373"><a href="#cb42-373" aria-hidden="true" tabindex="-1"></a>effect of these variables are modelized as the realization of a random</span>
<span id="cb42-374"><a href="#cb42-374" aria-hidden="true" tabindex="-1"></a>variable $\epsilon$. We can therefore define the following random</span>
<span id="cb42-375"><a href="#cb42-375" aria-hidden="true" tabindex="-1"></a>utility functions:</span>
<span id="cb42-376"><a href="#cb42-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-377"><a href="#cb42-377" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-378"><a href="#cb42-378" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-379"><a href="#cb42-379" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-380"><a href="#cb42-380" aria-hidden="true" tabindex="-1"></a>U_0 &amp;=&amp; \alpha_0 + \beta x_0 + \epsilon_0 <span class="sc">\\</span></span>
<span id="cb42-381"><a href="#cb42-381" aria-hidden="true" tabindex="-1"></a>U_1 &amp;=&amp; \alpha_1 + \beta x_1 + \epsilon_1</span>
<span id="cb42-382"><a href="#cb42-382" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-383"><a href="#cb42-383" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-384"><a href="#cb42-384" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-385"><a href="#cb42-385" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb42-386"><a href="#cb42-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-387"><a href="#cb42-387" aria-hidden="true" tabindex="-1"></a>where $\beta$ is the marginal utility of $1. The choice of the</span>
<span id="cb42-388"><a href="#cb42-388" aria-hidden="true" tabindex="-1"></a>individual is deterministic. They will choose the car if the utility of</span>
<span id="cb42-389"><a href="#cb42-389" aria-hidden="true" tabindex="-1"></a>this mode is greater than the utility of public transit. Therefore, we</span>
<span id="cb42-390"><a href="#cb42-390" aria-hidden="true" tabindex="-1"></a>have the following observation rule:</span>
<span id="cb42-391"><a href="#cb42-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-392"><a href="#cb42-392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-393"><a href="#cb42-393" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-394"><a href="#cb42-394" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-395"><a href="#cb42-395" aria-hidden="true" tabindex="-1"></a>y = 0 &amp; \mbox{if } &amp; \epsilon_1 - \epsilon_0 \leq - (\alpha_1 - \alpha_0) - \beta (x_1 - x_0)<span class="sc">\\</span></span>
<span id="cb42-396"><a href="#cb42-396" aria-hidden="true" tabindex="-1"></a>y = 1 &amp; \mbox{if } &amp; \epsilon_1 - \epsilon_0 &gt; - (\alpha_1 - \alpha_0) - \beta (x_1 - x_0)<span class="sc">\\</span></span>
<span id="cb42-397"><a href="#cb42-397" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-398"><a href="#cb42-398" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-399"><a href="#cb42-399" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-400"><a href="#cb42-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-401"><a href="#cb42-401" aria-hidden="true" tabindex="-1"></a>Denoting $\epsilon = \epsilon_1 - \epsilon_0$ the error difference,</span>
<span id="cb42-402"><a href="#cb42-402" aria-hidden="true" tabindex="-1"></a>$\alpha = \alpha_1 - \alpha_0$ and $x = x_1 - x_0$ the difference of</span>
<span id="cb42-403"><a href="#cb42-403" aria-hidden="true" tabindex="-1"></a>generalized cost for the two modes, we have:</span>
<span id="cb42-404"><a href="#cb42-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-405"><a href="#cb42-405" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-406"><a href="#cb42-406" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-407"><a href="#cb42-407" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-408"><a href="#cb42-408" aria-hidden="true" tabindex="-1"></a>y = 0 &amp; \mbox{if } &amp; \epsilon \leq  - (\alpha + \beta x)<span class="sc">\\</span></span>
<span id="cb42-409"><a href="#cb42-409" aria-hidden="true" tabindex="-1"></a>y = 1 &amp; \mbox{if } &amp; \epsilon &gt; - (\alpha + \beta x)<span class="sc">\\</span></span>
<span id="cb42-410"><a href="#cb42-410" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-411"><a href="#cb42-411" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-412"><a href="#cb42-412" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-413"><a href="#cb42-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-414"><a href="#cb42-414" aria-hidden="true" tabindex="-1"></a>The probability of "success" (here choosing the car) is therefore</span>
<span id="cb42-415"><a href="#cb42-415" aria-hidden="true" tabindex="-1"></a>$\mbox{P}(y = 1 \mid x) = 1 - F(- \alpha - \beta x)$, with $F$ as the</span>
<span id="cb42-416"><a href="#cb42-416" aria-hidden="true" tabindex="-1"></a>cumulative density of $\epsilon$. If the distribution is symmetric,</span>
<span id="cb42-417"><a href="#cb42-417" aria-hidden="true" tabindex="-1"></a>this probability reduces once again to $\mbox{P}(y = 1 \mid x) =</span>
<span id="cb42-418"><a href="#cb42-418" aria-hidden="true" tabindex="-1"></a>F(\alpha + \beta x)$, and the probit or logit models are obtained by</span>
<span id="cb42-419"><a href="#cb42-419" aria-hidden="true" tabindex="-1"></a>choosing either the normal or the logistic distribution. </span>
<span id="cb42-420"><a href="#cb42-420" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{random utility model|)}</span>
<span id="cb42-421"><a href="#cb42-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-422"><a href="#cb42-422" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binomial model as a generalized linear model {#sec-glm}</span></span>
<span id="cb42-423"><a href="#cb42-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-424"><a href="#cb42-424" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized linear model|(}</span>
<span id="cb42-425"><a href="#cb42-425" aria-hidden="true" tabindex="-1"></a>\idxfun{glm}{stats}</span>
<span id="cb42-426"><a href="#cb42-426" aria-hidden="true" tabindex="-1"></a>The estimation of binomial models with **R** is performed using the</span>
<span id="cb42-427"><a href="#cb42-427" aria-hidden="true" tabindex="-1"></a><span class="in">`stats::glm`</span> function, which stands for a **generalized linear model**. It</span>
<span id="cb42-428"><a href="#cb42-428" aria-hidden="true" tabindex="-1"></a>is therefore important to have at least some basic knowledge about</span>
<span id="cb42-429"><a href="#cb42-429" aria-hidden="true" tabindex="-1"></a>generalized linear models to understand the output of the fitted models. </span>
<span id="cb42-430"><a href="#cb42-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-431"><a href="#cb42-431" aria-hidden="true" tabindex="-1"></a><span class="fu">### Generalized linear models</span></span>
<span id="cb42-432"><a href="#cb42-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-433"><a href="#cb42-433" aria-hidden="true" tabindex="-1"></a>The generalized linear models (**GLM**) are a wide family of</span>
<span id="cb42-434"><a href="#cb42-434" aria-hidden="true" tabindex="-1"></a>models that are intended to extend the linear model. These models have the following</span>
<span id="cb42-435"><a href="#cb42-435" aria-hidden="true" tabindex="-1"></a>components:</span>
<span id="cb42-436"><a href="#cb42-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-437"><a href="#cb42-437" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a *random component* which specifies the distribution of the</span>
<span id="cb42-438"><a href="#cb42-438" aria-hidden="true" tabindex="-1"></a>  response, as a member of the exponential family, and in particular the expected value $\mbox{E}(y) = \mu$,</span>
<span id="cb42-439"><a href="#cb42-439" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a *systematic component*: some covariates $x_1, x_2, \ldots x_m$</span>
<span id="cb42-440"><a href="#cb42-440" aria-hidden="true" tabindex="-1"></a>  produce a linear predictor $\eta_n = \alpha + \beta ^ \top x_n$,</span>
<span id="cb42-441"><a href="#cb42-441" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the *link* function $g$ which specifies the relation between the random</span>
<span id="cb42-442"><a href="#cb42-442" aria-hidden="true" tabindex="-1"></a>  and the systematic components: $\eta = g(\mu)$.\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{link}</span>
<span id="cb42-443"><a href="#cb42-443" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-444"><a href="#cb42-444" aria-hidden="true" tabindex="-1"></a>The exponential family is defined by the following density function:</span>
<span id="cb42-445"><a href="#cb42-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-446"><a href="#cb42-446" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-447"><a href="#cb42-447" aria-hidden="true" tabindex="-1"></a>f(y;\theta,\phi) = e ^ {\displaystyle\left(y\theta - b(\theta)\right)/\phi + c(y, \phi)}</span>
<span id="cb42-448"><a href="#cb42-448" aria-hidden="true" tabindex="-1"></a>$$ {#eq-density_glm}</span>
<span id="cb42-449"><a href="#cb42-449" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-450"><a href="#cb42-450" aria-hidden="true" tabindex="-1"></a>$\theta$ and $\phi$ being respectively a position and a scale</span>
<span id="cb42-451"><a href="#cb42-451" aria-hidden="true" tabindex="-1"></a>parameter.  Linear models are actually a specific case of generalized linear models with a normal distribution and an identity link. We have in this case the following density function:</span>
<span id="cb42-452"><a href="#cb42-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-453"><a href="#cb42-453" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-454"><a href="#cb42-454" aria-hidden="true" tabindex="-1"></a>\phi(y;\mu, \sigma) = \frac{1}{\sqrt{2\pi}\sigma} e ^ {-\frac{1}{2}\frac{(y - \mu)^2}{\sigma ^ 2}}=</span>
<span id="cb42-455"><a href="#cb42-455" aria-hidden="true" tabindex="-1"></a>e^{\frac{y\mu - 0.5 \mu ^ 2}{\sigma ^ 2}- 0.5 y ^ 2 / \sigma ^ 2 - 0.5 \ln(2\pi\sigma ^ 2)}</span>
<span id="cb42-456"><a href="#cb42-456" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-457"><a href="#cb42-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-458"><a href="#cb42-458" aria-hidden="true" tabindex="-1"></a>which is a member of the exponential</span>
<span id="cb42-459"><a href="#cb42-459" aria-hidden="true" tabindex="-1"></a>family with $\theta = \mu$, $\phi = \sigma^ 2$, $b(\theta) = 0.5</span>
<span id="cb42-460"><a href="#cb42-460" aria-hidden="true" tabindex="-1"></a>\theta ^ 2$ and $c(y, \phi) = - 0.5(y ^ 2 /</span>
<span id="cb42-461"><a href="#cb42-461" aria-hidden="true" tabindex="-1"></a>\phi + \ln(2\pi\phi))$. The first two derivatives of @eq-density_glm with respect to $\theta$ are:</span>
<span id="cb42-462"><a href="#cb42-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-463"><a href="#cb42-463" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-464"><a href="#cb42-464" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-465"><a href="#cb42-465" aria-hidden="true" tabindex="-1"></a>\begin{array}{ccl}</span>
<span id="cb42-466"><a href="#cb42-466" aria-hidden="true" tabindex="-1"></a>\displaystyle\frac{\partial l}{\partial \theta} &amp;=&amp; \displaystyle\frac{1}{\phi}(y - b'(\theta))<span class="sc">\\</span></span>
<span id="cb42-467"><a href="#cb42-467" aria-hidden="true" tabindex="-1"></a>\displaystyle\frac{\partial ^ 2 l}{\partial \theta ^ 2} &amp;=&amp; \displaystyle-\frac{1}{\phi}b''(\theta)</span>
<span id="cb42-468"><a href="#cb42-468" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-469"><a href="#cb42-469" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-470"><a href="#cb42-470" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-471"><a href="#cb42-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-472"><a href="#cb42-472" aria-hidden="true" tabindex="-1"></a>As $\mbox{E}\left(\frac{\partial l}{\partial \theta}\right) = 0$, we</span>
<span id="cb42-473"><a href="#cb42-473" aria-hidden="true" tabindex="-1"></a>have $\mbox{E}(y)=b'(\theta)$. Moreover, by the information matrix equality:</span>
<span id="cb42-474"><a href="#cb42-474" aria-hidden="true" tabindex="-1"></a>$\mbox{E}\left(\frac{\partial^2 l}{\partial \theta ^ 2}\right) +</span>
<span id="cb42-475"><a href="#cb42-475" aria-hidden="true" tabindex="-1"></a>\mbox{E}\left(\frac{\partial l}{\partial \theta} ^ 2\right) = 0$, so that </span>
<span id="cb42-476"><a href="#cb42-476" aria-hidden="true" tabindex="-1"></a>$\mbox{V}(y) = \phi b''(\theta)$.</span>
<span id="cb42-477"><a href="#cb42-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-478"><a href="#cb42-478" aria-hidden="true" tabindex="-1"></a>Going back to the normal (or gaussian) model with an identity link, we have, for a given set of estimates (which leads to the **proposed model**): $\hat{\mu}_n = \hat{\eta}_n = \hat{\alpha} + \hat{\beta} ^ \top x_n$ and the log-likelihood function is:</span>
<span id="cb42-479"><a href="#cb42-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-480"><a href="#cb42-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-481"><a href="#cb42-481" aria-hidden="true" tabindex="-1"></a>\ln L(y, \hat{\mu}) = - \frac{N}{2}\ln(2 \pi + \sigma ^ 2) - \frac{1}{2\sigma ^2} \sum_{n=1} ^ N (y_n - \hat{\mu}_n) ^ 2</span>
<span id="cb42-482"><a href="#cb42-482" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-483"><a href="#cb42-483" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{saturated model}</span>
<span id="cb42-484"><a href="#cb42-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-485"><a href="#cb42-485" aria-hidden="true" tabindex="-1"></a>For a hypothetical "perfect" or **saturated model** with a perfect fit, we would have $\hat{\mu}_n = y_n$, so that the log-likelihood would be $- \frac{N}{2}\ln(2 \pi + \sigma ^ 2)$.</span>
<span id="cb42-486"><a href="#cb42-486" aria-hidden="true" tabindex="-1"></a>Minus two times the difference of these two values of the log likelihood function is called</span>
<span id="cb42-487"><a href="#cb42-487" aria-hidden="true" tabindex="-1"></a>the **scaled deviance** of the proposed model:</span>
<span id="cb42-488"><a href="#cb42-488" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{deviance!scaled}</span>
<span id="cb42-489"><a href="#cb42-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-490"><a href="#cb42-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-491"><a href="#cb42-491" aria-hidden="true" tabindex="-1"></a>D^*(y;\hat\mu) = \sum_{n=1} ^ N\frac{(y_n - \hat{\mu}_n) ^ 2}{\sigma ^ 2}</span>
<span id="cb42-492"><a href="#cb42-492" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-493"><a href="#cb42-493" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{deviance}</span>
<span id="cb42-494"><a href="#cb42-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-495"><a href="#cb42-495" aria-hidden="true" tabindex="-1"></a>and the deviance is obtained by multiplying the scaled deviance by</span>
<span id="cb42-496"><a href="#cb42-496" aria-hidden="true" tabindex="-1"></a>$\sigma ^ 2$ (or more generally by the scale parameter $\phi$):</span>
<span id="cb42-497"><a href="#cb42-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-498"><a href="#cb42-498" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-499"><a href="#cb42-499" aria-hidden="true" tabindex="-1"></a>D(y; \hat{\mu}) = \sum_{n=1} ^ N(y_n - \hat{\mu}_n) ^ 2</span>
<span id="cb42-500"><a href="#cb42-500" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-501"><a href="#cb42-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-502"><a href="#cb42-502" aria-hidden="true" tabindex="-1"></a>which is simply, for the linear model, the sum of square residuals.</span>
<span id="cb42-503"><a href="#cb42-503" aria-hidden="true" tabindex="-1"></a>For the binomial model, the probability mass function is given by the probability of success $\mu$ if $y = 1$ and by the probability of failure $1 - \mu$ if $y=0$. This probability can be compactly written as $\mu ^ y (1 - \mu) ^ {1 - y}$ or as:</span>
<span id="cb42-504"><a href="#cb42-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-505"><a href="#cb42-505" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-506"><a href="#cb42-506" aria-hidden="true" tabindex="-1"></a>f(y;\mu) = e ^ {y \ln \mu + (1 - y) \ln(1 - \mu)}=e ^ {y \ln \frac{\mu}{1 - \mu} + \ln(1 - \mu)}=</span>
<span id="cb42-507"><a href="#cb42-507" aria-hidden="true" tabindex="-1"></a>e^{y\theta - \ln (1 + e ^ \theta)}</span>
<span id="cb42-508"><a href="#cb42-508" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-509"><a href="#cb42-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-510"><a href="#cb42-510" aria-hidden="true" tabindex="-1"></a>which is a member of the exponential family with: $\theta =</span>
<span id="cb42-511"><a href="#cb42-511" aria-hidden="true" tabindex="-1"></a>\ln\frac{\mu}{1 -\mu}$, $b(\theta) = \ln(1 + e ^ \theta)$,</span>
<span id="cb42-512"><a href="#cb42-512" aria-hidden="true" tabindex="-1"></a>$c(\theta,y) = 0$ and $\phi=1$. The model is fully characterized once the link is specified. For</span>
<span id="cb42-513"><a href="#cb42-513" aria-hidden="true" tabindex="-1"></a>the logit model, we have $\mu = \frac{e ^ \eta}{1+e ^ \eta}$, so that</span>
<span id="cb42-514"><a href="#cb42-514" aria-hidden="true" tabindex="-1"></a>$\eta = \ln \frac{\mu}{1 - \mu} = g(\mu)$. We then have $\theta =</span>
<span id="cb42-515"><a href="#cb42-515" aria-hidden="true" tabindex="-1"></a>\eta$, so that the logit link is called the **canonical** link for</span>
<span id="cb42-516"><a href="#cb42-516" aria-hidden="true" tabindex="-1"></a>binomial models^[For every member of the exponential family, there is</span>
<span id="cb42-517"><a href="#cb42-517" aria-hidden="true" tabindex="-1"></a>one canonical link, see @MCCU:NELD:89, page 30.\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McCullagh}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Nelder}].</span>
<span id="cb42-518"><a href="#cb42-518" aria-hidden="true" tabindex="-1"></a>As the density for the binomial model returns a probability, the</span>
<span id="cb42-519"><a href="#cb42-519" aria-hidden="true" tabindex="-1"></a>log-likelihood for the saturated model is zero. Therefore, the</span>
<span id="cb42-520"><a href="#cb42-520" aria-hidden="true" tabindex="-1"></a>deviance is:\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{deviance!binomial model}</span>
<span id="cb42-521"><a href="#cb42-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-522"><a href="#cb42-522" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-523"><a href="#cb42-523" aria-hidden="true" tabindex="-1"></a>D(y;\hat{\mu}) = 2 \sum_{n=1} ^ N \left(y_n \ln \hat{\mu}_n + (1 - y_n) \ln(1 - \hat{\mu}_n)\right)</span>
<span id="cb42-524"><a href="#cb42-524" aria-hidden="true" tabindex="-1"></a>$$ {#eq-deviance_binomial}</span>
<span id="cb42-525"><a href="#cb42-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-526"><a href="#cb42-526" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{null model}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{deviance!null}</span>
<span id="cb42-527"><a href="#cb42-527" aria-hidden="true" tabindex="-1"></a>The **null model** is a model with only an intercept. In this case,</span>
<span id="cb42-528"><a href="#cb42-528" aria-hidden="true" tabindex="-1"></a>$\hat{\mu}_n = \hat{\mu}_0$ and the maximum likelihood estimator of</span>
<span id="cb42-529"><a href="#cb42-529" aria-hidden="true" tabindex="-1"></a>$\mu_0$ is $\sum_{n=1} ^ N y_n / N$, i.e., the share of success in the</span>
<span id="cb42-530"><a href="#cb42-530" aria-hidden="true" tabindex="-1"></a>sample. The deviance of this model is called the **null deviance**.</span>
<span id="cb42-531"><a href="#cb42-531" aria-hidden="true" tabindex="-1"></a>An alternative to the deviance as a measure of the fit of the model is the **generalized Pearson statistic**, defined as:</span>
<span id="cb42-532"><a href="#cb42-532" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Pearson statistic}</span>
<span id="cb42-533"><a href="#cb42-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-534"><a href="#cb42-534" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-535"><a href="#cb42-535" aria-hidden="true" tabindex="-1"></a>X ^ 2 = \sum_{n=1} ^ N \frac{(y_n - \hat{\mu}_n) ^ 2}{\mbox{V}(\hat{\mu}_n)}=</span>
<span id="cb42-536"><a href="#cb42-536" aria-hidden="true" tabindex="-1"></a>\sum_{n=1} ^ N \frac{(y_n - \hat{\mu}_n) ^ 2}{\hat{\mu}_n(1 - \hat{\mu}_n)}</span>
<span id="cb42-537"><a href="#cb42-537" aria-hidden="true" tabindex="-1"></a>$$ {#eq-pearson_statistic}</span>
<span id="cb42-538"><a href="#cb42-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-539"><a href="#cb42-539" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--  Both $D$ and $X ^2$ have an asymptotic $\chi --&gt;</span></span>
<span id="cb42-540"><a href="#cb42-540" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ^ 2$ distribution. --&gt;</span></span>
<span id="cb42-541"><a href="#cb42-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-542"><a href="#cb42-542" aria-hidden="true" tabindex="-1"></a>In the linear model, residuals have several interesting properties:</span>
<span id="cb42-543"><a href="#cb42-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-544"><a href="#cb42-544" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>they are homoskedastic (or at least they may be homoskedastic if the</span>
<span id="cb42-545"><a href="#cb42-545" aria-hidden="true" tabindex="-1"></a>  variance of the conditional distribution of the response is constant),</span>
<span id="cb42-546"><a href="#cb42-546" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>they have an intuitive meaning, as they are the difference between</span>
<span id="cb42-547"><a href="#cb42-547" aria-hidden="true" tabindex="-1"></a>  the actual and the fitted values of the response, the latter being an</span>
<span id="cb42-548"><a href="#cb42-548" aria-hidden="true" tabindex="-1"></a>  estimate of the conditional mean of the response,</span>
<span id="cb42-549"><a href="#cb42-549" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>they are related to the value of the objective function, which is</span>
<span id="cb42-550"><a href="#cb42-550" aria-hidden="true" tabindex="-1"></a>  the sum of square residuals.</span>
<span id="cb42-551"><a href="#cb42-551" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-552"><a href="#cb42-552" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!response}</span>
<span id="cb42-553"><a href="#cb42-553" aria-hidden="true" tabindex="-1"></a>The most obvious definition of the residuals for binomial</span>
<span id="cb42-554"><a href="#cb42-554" aria-hidden="true" tabindex="-1"></a>models is the **response residuals**, which are simply the difference</span>
<span id="cb42-555"><a href="#cb42-555" aria-hidden="true" tabindex="-1"></a>between the response and the prediction of the model (the</span>
<span id="cb42-556"><a href="#cb42-556" aria-hidden="true" tabindex="-1"></a>fitted probability of success $\hat{\mu}$). However, these residuals ($y_n - \hat{\mu}_n$)</span>
<span id="cb42-557"><a href="#cb42-557" aria-hidden="true" tabindex="-1"></a>are necessarily heteroskedastic, as the variance of $y_n$ is</span>
<span id="cb42-558"><a href="#cb42-558" aria-hidden="true" tabindex="-1"></a>$\mu_n(1 - \mu_n)$.</span>
<span id="cb42-559"><a href="#cb42-559" aria-hidden="true" tabindex="-1"></a>Scaling the response residuals by their standard deviation leads to</span>
<span id="cb42-560"><a href="#cb42-560" aria-hidden="true" tabindex="-1"></a>**Pearson's residuals**: $(y_n - \hat{\mu}_n) / \sqrt{\hat{\mu}_n(1 - \hat{\mu}_n)}$. The sum of squares of Pearson's residuals is the generalized</span>
<span id="cb42-561"><a href="#cb42-561" aria-hidden="true" tabindex="-1"></a>Pearson statistic given by @eq-pearson_statistic.\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!Pearson's}</span>
<span id="cb42-562"><a href="#cb42-562" aria-hidden="true" tabindex="-1"></a>The **deviance residuals** are such that the sum of their squares equals the</span>
<span id="cb42-563"><a href="#cb42-563" aria-hidden="true" tabindex="-1"></a>deviance statistic $D$. They are therefore defined by:\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!deviance}</span>
<span id="cb42-564"><a href="#cb42-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-565"><a href="#cb42-565" aria-hidden="true" tabindex="-1"></a>$$(2 y_n - 1) \sqrt{2}\sqrt{y_n \ln \hat{\mu}_n + (1 - y_n) \ln (1 - \hat{\mu}_n)}$$</span>
<span id="cb42-566"><a href="#cb42-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-567"><a href="#cb42-567" aria-hidden="true" tabindex="-1"></a>the term $2 y_n - 1$ gives a positive sign for the residuals of</span>
<span id="cb42-568"><a href="#cb42-568" aria-hidden="true" tabindex="-1"></a>observations for which $y_n = 1$ and a negative sign for $y_n = 0$, as</span>
<span id="cb42-569"><a href="#cb42-569" aria-hidden="true" tabindex="-1"></a>for the two other types of residuals.</span>
<span id="cb42-570"><a href="#cb42-570" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized linear model|)}</span>
<span id="cb42-571"><a href="#cb42-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-572"><a href="#cb42-572" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation with `stats::glm`</span></span>
<span id="cb42-573"><a href="#cb42-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-574"><a href="#cb42-574" aria-hidden="true" tabindex="-1"></a>The estimation of probit/logit models is performed using <span class="in">`glm`</span>. The</span>
<span id="cb42-575"><a href="#cb42-575" aria-hidden="true" tabindex="-1"></a>interface of <span class="in">`glm`</span> is very similar to <span class="in">`lm`</span>, but it has a supplementary</span>
<span id="cb42-576"><a href="#cb42-576" aria-hidden="true" tabindex="-1"></a>argument called <span class="in">`family`</span> which indicates the distribution of the</span>
<span id="cb42-577"><a href="#cb42-577" aria-hidden="true" tabindex="-1"></a>response.^<span class="co">[</span><span class="ot">Note that `family` is the second argument of `glm`, and `data` is the third.</span><span class="co">]</span> The family argument can be either a character string or a</span>
<span id="cb42-578"><a href="#cb42-578" aria-hidden="true" tabindex="-1"></a>function. In the latter case, an argument called <span class="in">`link`</span> can be</span>
<span id="cb42-579"><a href="#cb42-579" aria-hidden="true" tabindex="-1"></a>specified, which indicates how the linear predictor $\eta_n=\alpha + \beta ^ \top x_n$ is related to the parameter of the distribution $\mu_n$ . If we</span>
<span id="cb42-580"><a href="#cb42-580" aria-hidden="true" tabindex="-1"></a>use <span class="in">`family = binomial(link = "probit")`</span>, then $\mu_n = \Phi(\eta_n)$. The default choice is <span class="in">`"logit"`</span> (the canonical link), so that the logit model can be obtained using either:</span>
<span id="cb42-581"><a href="#cb42-581" aria-hidden="true" tabindex="-1"></a>\idxfun{glm}{stats}\idxfun{binomial}{stats}</span>
<span id="cb42-582"><a href="#cb42-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-583"><a href="#cb42-583" aria-hidden="true" tabindex="-1"></a><span class="in">```{r results = "hide"}</span></span>
<span id="cb42-584"><a href="#cb42-584" aria-hidden="true" tabindex="-1"></a>lgt <span class="ot">&lt;-</span> <span class="fu">glm</span>(mode <span class="sc">~</span> gcost, <span class="at">data =</span> mode_choice, </span>
<span id="cb42-585"><a href="#cb42-585" aria-hidden="true" tabindex="-1"></a>           <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">'logit'</span>))</span>
<span id="cb42-586"><a href="#cb42-586" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(mode <span class="sc">~</span> gcost, <span class="at">data =</span> mode_choice, <span class="at">family =</span> binomial)</span>
<span id="cb42-587"><a href="#cb42-587" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(mode <span class="sc">~</span> gcost, <span class="at">data =</span> mode_choice, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb42-588"><a href="#cb42-588" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(mode <span class="sc">~</span> gcost, <span class="at">data =</span> mode_choice, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb42-589"><a href="#cb42-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-590"><a href="#cb42-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-591"><a href="#cb42-591" aria-hidden="true" tabindex="-1"></a>Remember that, while estimating a generalized linear model, three models are considered: </span>
<span id="cb42-592"><a href="#cb42-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-593"><a href="#cb42-593" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the saturated model, for which there is one parameter for every</span>
<span id="cb42-594"><a href="#cb42-594" aria-hidden="true" tabindex="-1"></a>  observation and a perfect fit; therefore the log-likelihood, the</span>
<span id="cb42-595"><a href="#cb42-595" aria-hidden="true" tabindex="-1"></a>  deviance and the number of degrees of freedom are 0,</span>
<span id="cb42-596"><a href="#cb42-596" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the null model, with only one estimated coefficient and $N-1$ degrees of</span>
<span id="cb42-597"><a href="#cb42-597" aria-hidden="true" tabindex="-1"></a>  freedom,</span>
<span id="cb42-598"><a href="#cb42-598" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the proposed model, with $K+1$ estimated parameters, and therefore $N - K - 1$</span>
<span id="cb42-599"><a href="#cb42-599" aria-hidden="true" tabindex="-1"></a>  degrees of freedom. </span>
<span id="cb42-600"><a href="#cb42-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-601"><a href="#cb42-601" aria-hidden="true" tabindex="-1"></a>A call to <span class="in">`glm`</span> results in an object of class <span class="in">`glm`</span> which inherits from class <span class="in">`lm`</span>. As for <span class="in">`lm`</span>, the <span class="in">`summary`</span> method computes detailed results for the model and, if not saved in an object, these results are printed:</span>
<span id="cb42-602"><a href="#cb42-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-603"><a href="#cb42-603" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-604"><a href="#cb42-604" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lgt)</span>
<span id="cb42-605"><a href="#cb42-605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-606"><a href="#cb42-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-607"><a href="#cb42-607" aria-hidden="true" tabindex="-1"></a>The output indicates the deviance of the null and the proposed model,</span>
<span id="cb42-608"><a href="#cb42-608" aria-hidden="true" tabindex="-1"></a>along with their respective degrees of freedom ($N - 1 =</span>
<span id="cb42-609"><a href="#cb42-609" aria-hidden="true" tabindex="-1"></a>841$ and $N - K - 1 = 840$). The latter is called the **residual</span>
<span id="cb42-610"><a href="#cb42-610" aria-hidden="true" tabindex="-1"></a>deviance**. This information is elements of the object returned by</span>
<span id="cb42-611"><a href="#cb42-611" aria-hidden="true" tabindex="-1"></a><span class="in">`stats::glm`</span> and can be extracted directly:</span>
<span id="cb42-612"><a href="#cb42-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-613"><a href="#cb42-613" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-614"><a href="#cb42-614" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: false</span></span>
<span id="cb42-615"><a href="#cb42-615" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>deviance</span>
<span id="cb42-616"><a href="#cb42-616" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>null.deviance</span>
<span id="cb42-617"><a href="#cb42-617" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>df.residual</span>
<span id="cb42-618"><a href="#cb42-618" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>df.null</span>
<span id="cb42-619"><a href="#cb42-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-620"><a href="#cb42-620" aria-hidden="true" tabindex="-1"></a>or, for the fitted model, using the corresponding functions:</span>
<span id="cb42-621"><a href="#cb42-621" aria-hidden="true" tabindex="-1"></a>\idxfun{deviance}{stats}\idxfun{df.residual}{stats}</span>
<span id="cb42-622"><a href="#cb42-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-623"><a href="#cb42-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-624"><a href="#cb42-624" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: false</span></span>
<span id="cb42-625"><a href="#cb42-625" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(lgt)</span>
<span id="cb42-626"><a href="#cb42-626" aria-hidden="true" tabindex="-1"></a><span class="fu">df.residual</span>(lgt)</span>
<span id="cb42-627"><a href="#cb42-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-628"><a href="#cb42-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-629"><a href="#cb42-629" aria-hidden="true" tabindex="-1"></a>We can check that the null deviance can be obtained by</span>
<span id="cb42-630"><a href="#cb42-630" aria-hidden="true" tabindex="-1"></a>fitting a model with only an intercept:</span>
<span id="cb42-631"><a href="#cb42-631" aria-hidden="true" tabindex="-1"></a>\idxfun{update}{stats}</span>
<span id="cb42-632"><a href="#cb42-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-633"><a href="#cb42-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-634"><a href="#cb42-634" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-635"><a href="#cb42-635" aria-hidden="true" tabindex="-1"></a><span class="fu">update</span>(lgt, . <span class="sc">~</span> <span class="dv">1</span>)<span class="sc">$</span>deviance</span>
<span id="cb42-636"><a href="#cb42-636" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-637"><a href="#cb42-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-638"><a href="#cb42-638" aria-hidden="true" tabindex="-1"></a>The residuals can be extracted from the fitted model using</span>
<span id="cb42-639"><a href="#cb42-639" aria-hidden="true" tabindex="-1"></a><span class="in">`resid`</span>. The <span class="in">`resid`</span> method for <span class="in">`glm`</span> objects has a <span class="in">`type`</span> argument</span>
<span id="cb42-640"><a href="#cb42-640" aria-hidden="true" tabindex="-1"></a>which can be equal to <span class="in">`"response"`</span>, <span class="in">`"pearson"`</span> and <span class="in">`"deviance"`</span>.</span>
<span id="cb42-641"><a href="#cb42-641" aria-hidden="true" tabindex="-1"></a>\idxfun{resid}{stats}\idxfun{head}{utils}</span>
<span id="cb42-642"><a href="#cb42-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-643"><a href="#cb42-643" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-644"><a href="#cb42-644" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-645"><a href="#cb42-645" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(lgt, <span class="st">"response"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-646"><a href="#cb42-646" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(lgt, <span class="st">"pearson"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-647"><a href="#cb42-647" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(lgt, <span class="st">"deviance"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-648"><a href="#cb42-648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-649"><a href="#cb42-649" aria-hidden="true" tabindex="-1"></a>The fitted values of the model can be expressed on the scale of the</span>
<span id="cb42-650"><a href="#cb42-650" aria-hidden="true" tabindex="-1"></a>linear predictor or the response. They are available</span>
<span id="cb42-651"><a href="#cb42-651" aria-hidden="true" tabindex="-1"></a>in the returned object as <span class="in">`linear.predictors`</span> and <span class="in">`fitted.values`</span>:</span>
<span id="cb42-652"><a href="#cb42-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-653"><a href="#cb42-653" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-654"><a href="#cb42-654" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-655"><a href="#cb42-655" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>linear.predictors <span class="sc">%&gt;%</span> head</span>
<span id="cb42-656"><a href="#cb42-656" aria-hidden="true" tabindex="-1"></a>lgt<span class="sc">$</span>fitted.values <span class="sc">%&gt;%</span> head</span>
<span id="cb42-657"><a href="#cb42-657" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-658"><a href="#cb42-658" aria-hidden="true" tabindex="-1"></a>The latter can also be obtained using the <span class="in">`fitted`</span> function:</span>
<span id="cb42-659"><a href="#cb42-659" aria-hidden="true" tabindex="-1"></a>\idxfun{fitted}{stats}</span>
<span id="cb42-660"><a href="#cb42-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-661"><a href="#cb42-661" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-662"><a href="#cb42-662" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: 'hide'</span></span>
<span id="cb42-663"><a href="#cb42-663" aria-hidden="true" tabindex="-1"></a><span class="fu">fitted</span>(lgt)</span>
<span id="cb42-664"><a href="#cb42-664" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-665"><a href="#cb42-665" aria-hidden="true" tabindex="-1"></a>The <span class="in">`predict`</span> method returns by default the</span>
<span id="cb42-666"><a href="#cb42-666" aria-hidden="true" tabindex="-1"></a>fitted values but can also compute the predicted values for a new data</span>
<span id="cb42-667"><a href="#cb42-667" aria-hidden="true" tabindex="-1"></a>frame. For example, if the difference of generalized cost is increased</span>
<span id="cb42-668"><a href="#cb42-668" aria-hidden="true" tabindex="-1"></a>by 10%:</span>
<span id="cb42-669"><a href="#cb42-669" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}</span>
<span id="cb42-670"><a href="#cb42-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-671"><a href="#cb42-671" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-672"><a href="#cb42-672" aria-hidden="true" tabindex="-1"></a>mode_choice2 <span class="ot">&lt;-</span> mode_choice <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">gcost2 =</span> gcost <span class="sc">*</span> <span class="fl">1.1</span>)</span>
<span id="cb42-673"><a href="#cb42-673" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-674"><a href="#cb42-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-675"><a href="#cb42-675" aria-hidden="true" tabindex="-1"></a>The predictions can be computed in the scale of the linear predictors</span>
<span id="cb42-676"><a href="#cb42-676" aria-hidden="true" tabindex="-1"></a>or of the response by setting the <span class="in">`type`</span> argument to <span class="in">`"link"`</span> (the</span>
<span id="cb42-677"><a href="#cb42-677" aria-hidden="true" tabindex="-1"></a>default) or <span class="in">`"response"`</span>:</span>
<span id="cb42-678"><a href="#cb42-678" aria-hidden="true" tabindex="-1"></a>\idxfun{predict}{stats}\idxfun{head}{utils}</span>
<span id="cb42-679"><a href="#cb42-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-680"><a href="#cb42-680" aria-hidden="true" tabindex="-1"></a><span class="in">```{r collapse = TRUE}</span></span>
<span id="cb42-681"><a href="#cb42-681" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lgt, <span class="at">newdata =</span> mode_choice2, <span class="at">type =</span> <span class="st">"link"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-682"><a href="#cb42-682" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lgt, <span class="at">newdata =</span> mode_choice2, <span class="at">type =</span> <span class="st">"response"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-683"><a href="#cb42-683" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-684"><a href="#cb42-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-685"><a href="#cb42-685" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-686"><a href="#cb42-686" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-687"><a href="#cb42-687" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-688"><a href="#cb42-688" aria-hidden="true" tabindex="-1"></a><span class="co">#lw &lt;- read_csv("low_weight.csv")</span></span>
<span id="cb42-689"><a href="#cb42-689" aria-hidden="true" tabindex="-1"></a><span class="co">#lgt &lt;- glm(low ~ age + lwt + factor(race) + smoke, family = binomial, data = lw)</span></span>
<span id="cb42-690"><a href="#cb42-690" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.key2stats.com/data-set/view/1131</span></span>
<span id="cb42-691"><a href="#cb42-691" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-692"><a href="#cb42-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-693"><a href="#cb42-693" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model estimation, evaluation and testing {#sec-binom_evaluation}</span></span>
<span id="cb42-694"><a href="#cb42-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-695"><a href="#cb42-695" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation {#sec-estimation_binomial}</span></span>
<span id="cb42-696"><a href="#cb42-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-697"><a href="#cb42-697" aria-hidden="true" tabindex="-1"></a>The <span class="in">`stats::glm`</span> function uses an iterative weighted least</span>
<span id="cb42-698"><a href="#cb42-698" aria-hidden="true" tabindex="-1"></a>squares method to fit all the flavors of GLM's models. However, probit</span>
<span id="cb42-699"><a href="#cb42-699" aria-hidden="true" tabindex="-1"></a>and logit models are usually estimated by maximum likelihood. With $\eta_n = \alpha + \beta ^ \top x_n = \gamma ^ \top z_n$ the linear predictor, the</span>
<span id="cb42-700"><a href="#cb42-700" aria-hidden="true" tabindex="-1"></a>individual contribution to the likelihood is $F(\eta_n)$ if</span>
<span id="cb42-701"><a href="#cb42-701" aria-hidden="true" tabindex="-1"></a>$y_n = 1$ and $1 - F(\eta_n)$ if $y_n = 0$.</span>
<span id="cb42-702"><a href="#cb42-702" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Defining $q_n = --&gt;</span></span>
<span id="cb42-703"><a href="#cb42-703" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 2 y_n -1$ (which equals -1/+1 for y=0/1), it can also be compactly --&gt;</span></span>
<span id="cb42-704"><a href="#cb42-704" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- written as: $F(q_n \eta_n)$ if the chosen distribution is --&gt;</span></span>
<span id="cb42-705"><a href="#cb42-705" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- symmetric.  --&gt;</span></span>
<span id="cb42-706"><a href="#cb42-706" aria-hidden="true" tabindex="-1"></a>The log-likelihood is then:</span>
<span id="cb42-707"><a href="#cb42-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-708"><a href="#cb42-708" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-709"><a href="#cb42-709" aria-hidden="true" tabindex="-1"></a>\ln L = \sum_{n=1} ^ N y_n \ln F(\eta_n) + (1 - y_n) \ln (1 - F(\eta_n)</span>
<span id="cb42-710"><a href="#cb42-710" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-711"><a href="#cb42-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-712"><a href="#cb42-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-713"><a href="#cb42-713" aria-hidden="true" tabindex="-1"></a>The first-order condition for a maximum is that the vector of the first derivatives:</span>
<span id="cb42-714"><a href="#cb42-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-715"><a href="#cb42-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-716"><a href="#cb42-716" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-717"><a href="#cb42-717" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln L}{\partial \gamma} = \sum_{n=1} ^ N \frac{y_n}{F(\eta_n)}f(\eta_n)z_n - </span>
<span id="cb42-718"><a href="#cb42-718" aria-hidden="true" tabindex="-1"></a>\frac{1 - y_n}{1 - F(\eta_n)}f(\eta_n)z_n=</span>
<span id="cb42-719"><a href="#cb42-719" aria-hidden="true" tabindex="-1"></a>\sum_{n=1} ^ N \frac{y_n - F_n}{F_n\left(1 - F_n\right)}f_n z_n =0</span>
<span id="cb42-720"><a href="#cb42-720" aria-hidden="true" tabindex="-1"></a>$$ {#eq-gradbinom}</span>
<span id="cb42-721"><a href="#cb42-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-722"><a href="#cb42-722" aria-hidden="true" tabindex="-1"></a>is zero, where we defined for convenience $F_n = F(\eta_n)$</span>
<span id="cb42-723"><a href="#cb42-723" aria-hidden="true" tabindex="-1"></a>and $f_n = f(\eta_n)$.</span>
<span id="cb42-724"><a href="#cb42-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-725"><a href="#cb42-725" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized residuals!binomial model}</span>
<span id="cb42-726"><a href="#cb42-726" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized}</span>
<span id="cb42-727"><a href="#cb42-727" aria-hidden="true" tabindex="-1"></a>$\psi_n = \frac{y_n - F_n}{F_n\left(1 - F_n\right)}f_n$ is called the **generalized residual**^<span class="co">[</span><span class="ot">@GOUR:MONF:RENA:TROG:87\index[author]{Gourieroux}\index[author]{Monfort}\index[author]{Renault}\index[author]{Trognon}.</span><span class="co">]</span>. Generalized residuals have the same property as standard residuals in the linear regression model, they are orthogonal to all the covariates, and they sum to 0 if the regression contains an intercept. </span>
<span id="cb42-728"><a href="#cb42-728" aria-hidden="true" tabindex="-1"></a>The hessian matrix of the second derivatives is:</span>
<span id="cb42-729"><a href="#cb42-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-730"><a href="#cb42-730" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-731"><a href="#cb42-731" aria-hidden="true" tabindex="-1"></a>\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top} =</span>
<span id="cb42-732"><a href="#cb42-732" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\sum_{n = 1} ^ N \left(\frac{y_n (1 - F_n) ^ 2 + (1 - y_n) F_n ^ 2}{F_n ^ 2 (1 - F_n) ^ 2} f_n ^ 2 -</span>
<span id="cb42-733"><a href="#cb42-733" aria-hidden="true" tabindex="-1"></a>\frac{y_n - F_n}{F_n(1 - F_n)} f_n'\right) z_n z_n^\top</span>
<span id="cb42-734"><a href="#cb42-734" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hessbinom}</span>
<span id="cb42-735"><a href="#cb42-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-736"><a href="#cb42-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-737"><a href="#cb42-737" aria-hidden="true" tabindex="-1"></a>with $f'_n$ the derivative of $f_n$. Taking the expectation, we obtain a much simpler expression: as $E(y_n) = F_n$, the second term in brackets disappears and the first one simplifies to:</span>
<span id="cb42-738"><a href="#cb42-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-739"><a href="#cb42-739" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-740"><a href="#cb42-740" aria-hidden="true" tabindex="-1"></a>\mbox{E} \left(\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top}\right) =</span>
<span id="cb42-741"><a href="#cb42-741" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\sum_{n = 1} ^ N \frac{f_n ^ 2}{F_n (1 - F_n)}</span>
<span id="cb42-742"><a href="#cb42-742" aria-hidden="true" tabindex="-1"></a>z_n z_n^\top</span>
<span id="cb42-743"><a href="#cb42-743" aria-hidden="true" tabindex="-1"></a>$$ {#eq-infobinom}</span>
<span id="cb42-744"><a href="#cb42-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-745"><a href="#cb42-745" aria-hidden="true" tabindex="-1"></a>For the logit model, the density is: $\lambda_n = e ^ {\eta_n} / (1 + e ^</span>
<span id="cb42-746"><a href="#cb42-746" aria-hidden="true" tabindex="-1"></a>{\eta_n}) ^ 2 = \Lambda_n (1 - \Lambda_n)$ and @eq-gradbinom reduces to:</span>
<span id="cb42-747"><a href="#cb42-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-748"><a href="#cb42-748" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-749"><a href="#cb42-749" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln L}{\partial \gamma} = </span>
<span id="cb42-750"><a href="#cb42-750" aria-hidden="true" tabindex="-1"></a>\sum_{n=1} ^ N \left(y_n - \Lambda_n\right)z_n = 0</span>
<span id="cb42-751"><a href="#cb42-751" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-752"><a href="#cb42-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-753"><a href="#cb42-753" aria-hidden="true" tabindex="-1"></a>This expression is particularly appealing as the generalized residual $y_n - \Lambda_n$ is the response residual. Moreover, the expression of the matrix of second derivatives is particularly simple:</span>
<span id="cb42-754"><a href="#cb42-754" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!response}</span>
<span id="cb42-755"><a href="#cb42-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-756"><a href="#cb42-756" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-757"><a href="#cb42-757" aria-hidden="true" tabindex="-1"></a>\frac{\partial ^ 2 \ln L}{\partial \gamma \partial \gamma ^ \top} = </span>
<span id="cb42-758"><a href="#cb42-758" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\sum_{n=1} ^ N \lambda_n z_n z_n ^ \top = </span>
<span id="cb42-759"><a href="#cb42-759" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\sum_{n=1} ^ N \Lambda_n (1 - \Lambda_n) z_n z_n ^ \top</span>
<span id="cb42-760"><a href="#cb42-760" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-761"><a href="#cb42-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-762"><a href="#cb42-762" aria-hidden="true" tabindex="-1"></a>and is equal to its expectation, as it doesn't depend on $y$.</span>
<span id="cb42-763"><a href="#cb42-763" aria-hidden="true" tabindex="-1"></a>For the probit model, the vector of response residuals ($y_n - \Phi_n$) is</span>
<span id="cb42-764"><a href="#cb42-764" aria-hidden="true" tabindex="-1"></a>not orthogonal to the covariates. Moreover, the formula of the hessian</span>
<span id="cb42-765"><a href="#cb42-765" aria-hidden="true" tabindex="-1"></a>is rather complicated and depends on $y$. However, its expectation (@eq-infobinom) can be expressed compactly in terms of the inverse mills ratio\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{inverse mills ratio}, defined by:</span>
<span id="cb42-766"><a href="#cb42-766" aria-hidden="true" tabindex="-1"></a> $r(z) = \phi(z) / \Phi(z)$. Noting that $\phi(z) / (1 - \Phi(z)) = \phi(-z) / \Phi(-z) = r(-z)$ by symmetry of the normal distribution, @eq-infobinom simplifies to:</span>
<span id="cb42-767"><a href="#cb42-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-768"><a href="#cb42-768" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-769"><a href="#cb42-769" aria-hidden="true" tabindex="-1"></a>\mbox{E} \left(\frac{\partial ^ 2 \ln L}{\partial \beta \partial \beta ^ \top}\right) =</span>
<span id="cb42-770"><a href="#cb42-770" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\sum_{n = 1} ^ N r(\eta_n) r(- \eta_n)z_n z_n^\top</span>
<span id="cb42-771"><a href="#cb42-771" aria-hidden="true" tabindex="-1"></a>$$ {#eq-infoprobit}</span>
<span id="cb42-772"><a href="#cb42-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-773"><a href="#cb42-773" aria-hidden="true" tabindex="-1"></a>The generalized residuals are:\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized residuals}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized}</span>
<span id="cb42-774"><a href="#cb42-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-775"><a href="#cb42-775" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-776"><a href="#cb42-776" aria-hidden="true" tabindex="-1"></a>\psi_n = \frac{\phi_n (y_n - \Phi_n)}{\Phi_n (1 - \Phi_n)}</span>
<span id="cb42-777"><a href="#cb42-777" aria-hidden="true" tabindex="-1"></a>$$ {#eq-gen_resid_probit}</span>
<span id="cb42-778"><a href="#cb42-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-779"><a href="#cb42-779" aria-hidden="true" tabindex="-1"></a>and they are related to the latent variable $y^*$ used in @sec-latent_variable\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{latent variable}. Remember that $y_n ^ * = \mu_n + \epsilon_n$, with $\mu_n = \alpha + \beta ^ \top x_n$ and $\epsilon_n \sim \mathcal{N}(0, \sigma)$. Then, considering the latent variable, the residual can be defined as $\hat{\epsilon}_n = y_n ^ * - \hat{\mu}_n$. This residual can't be computed because $y_n ^ *$ is unobserved, we only observe $y_n = 1$ if $y_n ^ * &gt; 0$ and $y_n = 0$ if $y_n ^ * \leq 0$. However, its expectation can be computed. For $y_n = 1$:</span>
<span id="cb42-780"><a href="#cb42-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-781"><a href="#cb42-781" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-782"><a href="#cb42-782" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\hat{\epsilon}\mid x, y^* &gt; 0) = \frac{\int_{0} ^ {+\infty} y^*\phi(y^* - \hat{\mu}) dy^*}{\int_{0} ^ {+\infty}\phi(y^* - \hat{\mu})dy^*} - \hat{\mu} = </span>
<span id="cb42-783"><a href="#cb42-783" aria-hidden="true" tabindex="-1"></a>\frac{\int_{-\hat{\mu}} ^ {+\infty} (\hat{\mu} + v)\phi(v) dv}{\int_{-\hat{\mu}} ^ {+\infty}\phi(v)dv} - \hat{\mu} = \frac{\phi(\hat{\mu})}{\Phi(\hat{\mu})}</span>
<span id="cb42-784"><a href="#cb42-784" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-785"><a href="#cb42-785" aria-hidden="true" tabindex="-1"></a>Similarly, $\mbox{E}(\hat{\epsilon}\mid x, y^* \leq 0) = -\frac{\phi(\hat{\mu})}{1 - \Phi(\hat{\mu})}$, so that: </span>
<span id="cb42-786"><a href="#cb42-786" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-787"><a href="#cb42-787" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\hat{\epsilon}_n\mid x_n) = y_n \mbox{E}(\hat{\epsilon}_n\mid x_n, y_n ^* &gt; 0) + (1 - y_n)  \mbox{E}(\hat{\epsilon}_n\mid x_n, y_n ^* \leq 0) = \frac{\phi(\hat{\mu}_n)(y_n - \Phi(\hat{\mu}_n))}{\Phi(\hat{\mu}_n)(1 - \Phi(\hat{\mu}_n))}</span>
<span id="cb42-788"><a href="#cb42-788" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb42-789"><a href="#cb42-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-790"><a href="#cb42-790" aria-hidden="true" tabindex="-1"></a>which is the generalized residual defined in @eq-gen_resid_probit.</span>
<span id="cb42-791"><a href="#cb42-791" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{generalized residuals}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{residuals!generalized}</span>
<span id="cb42-792"><a href="#cb42-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-793"><a href="#cb42-793" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{covariance matrix!binomial model|(}</span>
<span id="cb42-794"><a href="#cb42-794" aria-hidden="true" tabindex="-1"></a>The three estimators of the covariance matrix of the estimators can be</span>
<span id="cb42-795"><a href="#cb42-795" aria-hidden="true" tabindex="-1"></a>used. The outer product of the gradient estimator is based on</span>
<span id="cb42-796"><a href="#cb42-796" aria-hidden="true" tabindex="-1"></a>@eq-gradbinom:</span>
<span id="cb42-797"><a href="#cb42-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-798"><a href="#cb42-798" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-799"><a href="#cb42-799" aria-hidden="true" tabindex="-1"></a>\hat{V}_G(\hat{\gamma}) = \sum_{n = 1} ^ N \left(\frac{y_n - F_n}{F_n (1 - F_n)}f_n\right) ^ 2 z_n z_n^ \top</span>
<span id="cb42-800"><a href="#cb42-800" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-801"><a href="#cb42-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-802"><a href="#cb42-802" aria-hidden="true" tabindex="-1"></a>The hessian based estimator is obtained by taking the inverse of the</span>
<span id="cb42-803"><a href="#cb42-803" aria-hidden="true" tabindex="-1"></a>opposite of the hessian given by @eq-hessbinom. Finally the</span>
<span id="cb42-804"><a href="#cb42-804" aria-hidden="true" tabindex="-1"></a>information-based estimator is obtained by taking the inverse of</span>
<span id="cb42-805"><a href="#cb42-805" aria-hidden="true" tabindex="-1"></a>the opposite of the matrix given by @eq-infobinom:</span>
<span id="cb42-806"><a href="#cb42-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-807"><a href="#cb42-807" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-808"><a href="#cb42-808" aria-hidden="true" tabindex="-1"></a>\hat{V}_I(\hat{\gamma}) = \left(\sum_{n = 1} ^ N \frac{f_n ^ 2}{F_n (1 - F_n)}</span>
<span id="cb42-809"><a href="#cb42-809" aria-hidden="true" tabindex="-1"></a>z_n z_n^\top\right) ^ {-1}</span>
<span id="cb42-810"><a href="#cb42-810" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-811"><a href="#cb42-811" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{covariance matrix estimation!binomial model|)}</span>
<span id="cb42-812"><a href="#cb42-812" aria-hidden="true" tabindex="-1"></a>As the hessian for the logit model doesn't depend on $y$, the last two estimators are the same for this model. We consider as an example two variants of the mode choice model: the first uses as distinct covariate the monetary cost, in- and out-vehicle time; the second uses as unique covariate the</span>
<span id="cb42-813"><a href="#cb42-813" aria-hidden="true" tabindex="-1"></a>generalized cost. </span>
<span id="cb42-814"><a href="#cb42-814" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-815"><a href="#cb42-815" aria-hidden="true" tabindex="-1"></a>\idxfun{binomreg}{micsr}\idxfun{update}{stats}</span>
<span id="cb42-816"><a href="#cb42-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-817"><a href="#cb42-817" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-818"><a href="#cb42-818" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: mcs</span></span>
<span id="cb42-819"><a href="#cb42-819" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-820"><a href="#cb42-820" aria-hidden="true" tabindex="-1"></a>lgt_unconst <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> cost <span class="sc">+</span> ivtime <span class="sc">+</span> ovtime, </span>
<span id="cb42-821"><a href="#cb42-821" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span> mode_choice, <span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb42-822"><a href="#cb42-822" aria-hidden="true" tabindex="-1"></a>lgt_const <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> gcost, <span class="at">data =</span> mode_choice, <span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb42-823"><a href="#cb42-823" aria-hidden="true" tabindex="-1"></a>pbt_unconst <span class="ot">&lt;-</span> <span class="fu">update</span>(lgt_unconst, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-824"><a href="#cb42-824" aria-hidden="true" tabindex="-1"></a>pbt_const <span class="ot">&lt;-</span> <span class="fu">update</span>(lgt_const, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-825"><a href="#cb42-825" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-826"><a href="#cb42-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-827"><a href="#cb42-827" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-828"><a href="#cb42-828" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-binom_const_unconst</span></span>
<span id="cb42-829"><a href="#cb42-829" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-830"><a href="#cb42-830" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Logit and probit models for the mode choice data set"</span></span>
<span id="cb42-831"><a href="#cb42-831" aria-hidden="true" tabindex="-1"></a>gm <span class="ot">&lt;-</span> modelsummary<span class="sc">::</span>gof_map</span>
<span id="cb42-832"><a href="#cb42-832" aria-hidden="true" tabindex="-1"></a>gm <span class="ot">&lt;-</span> gm <span class="sc">%&gt;%</span> </span>
<span id="cb42-833"><a href="#cb42-833" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">omit =</span> <span class="fu">ifelse</span>(raw <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"deviance"</span>, <span class="st">"null.deviance"</span>), </span>
<span id="cb42-834"><a href="#cb42-834" aria-hidden="true" tabindex="-1"></a>                       <span class="cn">FALSE</span>, omit))</span>
<span id="cb42-835"><a href="#cb42-835" aria-hidden="true" tabindex="-1"></a>modelsummary<span class="sc">::</span><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="at">unconstrained =</span> lgt_unconst,</span>
<span id="cb42-836"><a href="#cb42-836" aria-hidden="true" tabindex="-1"></a>                            <span class="at">constrained =</span> lgt_const,</span>
<span id="cb42-837"><a href="#cb42-837" aria-hidden="true" tabindex="-1"></a>                            <span class="at">unconstrained =</span> pbt_unconst,</span>
<span id="cb42-838"><a href="#cb42-838" aria-hidden="true" tabindex="-1"></a>                            <span class="at">constrained =</span> pbt_const), <span class="at">gof_map =</span> gm,</span>
<span id="cb42-839"><a href="#cb42-839" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output =</span> <span class="st">"kableExtra"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb42-840"><a href="#cb42-840" aria-hidden="true" tabindex="-1"></a>    kableExtra<span class="sc">::</span><span class="fu">add_header_above</span>(<span class="fu">c</span>(<span class="st">" "</span> <span class="ot">=</span> <span class="dv">1</span>, <span class="at">logit =</span> <span class="dv">2</span>, <span class="at">probit =</span> <span class="dv">2</span>))</span>
<span id="cb42-841"><a href="#cb42-841" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-842"><a href="#cb42-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-843"><a href="#cb42-843" aria-hidden="true" tabindex="-1"></a>We present in @tbl-binom_const_unconst the results of the</span>
<span id="cb42-844"><a href="#cb42-844" aria-hidden="true" tabindex="-1"></a>logit and probit models.</span>
<span id="cb42-845"><a href="#cb42-845" aria-hidden="true" tabindex="-1"></a>By default, the standard deviations are computed using the</span>
<span id="cb42-846"><a href="#cb42-846" aria-hidden="true" tabindex="-1"></a>information-based estimation of the covariance matrix of the</span>
<span id="cb42-847"><a href="#cb42-847" aria-hidden="true" tabindex="-1"></a>estimates. The hessian and the outer-product of the gradient</span>
<span id="cb42-848"><a href="#cb42-848" aria-hidden="true" tabindex="-1"></a>estimators are obtained by setting the <span class="in">`vcov`</span> argument of <span class="in">`vcov`</span> or of</span>
<span id="cb42-849"><a href="#cb42-849" aria-hidden="true" tabindex="-1"></a><span class="in">`summary`</span> to respectively <span class="in">`"hessian"`</span> or <span class="in">`"opg"`</span>. For example, to get the gradient-based estimator of the covariance matrix:</span>
<span id="cb42-850"><a href="#cb42-850" aria-hidden="true" tabindex="-1"></a>\idxfun{vcov}{stats}</span>
<span id="cb42-851"><a href="#cb42-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-854"><a href="#cb42-854" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-855"><a href="#cb42-855" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: false</span></span>
<span id="cb42-856"><a href="#cb42-856" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(pbt_unconst, <span class="at">vcov =</span> <span class="st">"opg"</span>)</span>
<span id="cb42-857"><a href="#cb42-857" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-858"><a href="#cb42-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-859"><a href="#cb42-859" aria-hidden="true" tabindex="-1"></a>The <span class="in">`micsr::stder`</span> function enables to compute the different flavors of the estimated standard errors, which are obtained by taking the square roots of the diagonal elements of the covariance matrix:</span>
<span id="cb42-860"><a href="#cb42-860" aria-hidden="true" tabindex="-1"></a>\idxfun{vcov}{stats}\idxfun{diag}{base}\idxfun{stder}{micsr}</span>
<span id="cb42-861"><a href="#cb42-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-864"><a href="#cb42-864" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-865"><a href="#cb42-865" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-866"><a href="#cb42-866" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(pbt_unconst, <span class="at">vcov =</span> <span class="st">"opg"</span>) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt</span>
<span id="cb42-867"><a href="#cb42-867" aria-hidden="true" tabindex="-1"></a><span class="fu">stder</span>(pbt_unconst, <span class="at">vcov =</span> <span class="st">"opg"</span>)</span>
<span id="cb42-868"><a href="#cb42-868" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-869"><a href="#cb42-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-870"><a href="#cb42-870" aria-hidden="true" tabindex="-1"></a>The sandwich estimator is obtained using the **micsr**'s method for <span class="in">`sandwich::vcovHC`</span>. </span>
<span id="cb42-871"><a href="#cb42-871" aria-hidden="true" tabindex="-1"></a>\idxfun{vcovHC}{sandwich}\idxfun{diag}{base}\idxfun{stder}{micsr}</span>
<span id="cb42-872"><a href="#cb42-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-875"><a href="#cb42-875" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-876"><a href="#cb42-876" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-877"><a href="#cb42-877" aria-hidden="true" tabindex="-1"></a>sandwich<span class="sc">::</span><span class="fu">vcovHC</span>(pbt_unconst) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt</span>
<span id="cb42-878"><a href="#cb42-878" aria-hidden="true" tabindex="-1"></a><span class="fu">stder</span>(pbt_unconst, <span class="at">vcov =</span> vcovHC)</span>
<span id="cb42-879"><a href="#cb42-879" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-880"><a href="#cb42-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-881"><a href="#cb42-881" aria-hidden="true" tabindex="-1"></a>The four estimators of the standard errors are presented in </span>
<span id="cb42-882"><a href="#cb42-882" aria-hidden="true" tabindex="-1"></a>@tbl-tabestd for the unconstrained probit model.</span>
<span id="cb42-883"><a href="#cb42-883" aria-hidden="true" tabindex="-1"></a>The first three give very similar estimates. The sandwich estimator gives slightly different results, especially a larger value for out-vehicle time and a smaller</span>
<span id="cb42-884"><a href="#cb42-884" aria-hidden="true" tabindex="-1"></a>value for in-vehicle time.</span>
<span id="cb42-885"><a href="#cb42-885" aria-hidden="true" tabindex="-1"></a>\idxfun{vcovHC}{sandwich}\idxfun{diag}{base}\idxfun{stder}{micsr}</span>
<span id="cb42-886"><a href="#cb42-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-887"><a href="#cb42-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-888"><a href="#cb42-888" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: estd</span></span>
<span id="cb42-889"><a href="#cb42-889" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-890"><a href="#cb42-890" aria-hidden="true" tabindex="-1"></a>sd_info <span class="ot">&lt;-</span> <span class="fu">vcov</span>(pbt_unconst) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt</span>
<span id="cb42-891"><a href="#cb42-891" aria-hidden="true" tabindex="-1"></a>sd_hessian <span class="ot">&lt;-</span> <span class="fu">vcov</span>(pbt_unconst, <span class="at">vcov =</span> <span class="st">"hessian"</span>) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt</span>
<span id="cb42-892"><a href="#cb42-892" aria-hidden="true" tabindex="-1"></a>sd_opg <span class="ot">&lt;-</span> <span class="fu">vcov</span>(pbt_unconst, <span class="at">vcov =</span> <span class="st">"opg"</span>) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt</span>
<span id="cb42-893"><a href="#cb42-893" aria-hidden="true" tabindex="-1"></a>sd_swh <span class="ot">&lt;-</span> <span class="fu">vcovHC</span>(pbt_unconst) <span class="sc">%&gt;%</span> diag <span class="sc">%&gt;%</span> sqrt <span class="sc">%&gt;%</span> .[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb42-894"><a href="#cb42-894" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-895"><a href="#cb42-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-896"><a href="#cb42-896" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-897"><a href="#cb42-897" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-tabestd</span></span>
<span id="cb42-898"><a href="#cb42-898" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: FALSE</span></span>
<span id="cb42-899"><a href="#cb42-899" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Estimation of the standard deviations of the estimates</span></span>
<span id="cb42-900"><a href="#cb42-900" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="st">" "</span> <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">coef</span>(pbt_unconst)),</span>
<span id="cb42-901"><a href="#cb42-901" aria-hidden="true" tabindex="-1"></a>       <span class="at">information =</span> sd_info, <span class="at">hessian =</span> sd_hessian,</span>
<span id="cb42-902"><a href="#cb42-902" aria-hidden="true" tabindex="-1"></a>       <span class="at">gradient =</span> sd_opg, <span class="at">sandwich =</span> sd_swh) <span class="sc">%&gt;%</span></span>
<span id="cb42-903"><a href="#cb42-903" aria-hidden="true" tabindex="-1"></a>    knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">booktabs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-904"><a href="#cb42-904" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-905"><a href="#cb42-905" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-906"><a href="#cb42-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-907"><a href="#cb42-907" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation</span></span>
<span id="cb42-908"><a href="#cb42-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-909"><a href="#cb42-909" aria-hidden="true" tabindex="-1"></a>Once several models are estimated, the evaluation and the selection</span>
<span id="cb42-910"><a href="#cb42-910" aria-hidden="true" tabindex="-1"></a>process of one of them is based on several indicators. The first indicator</span>
<span id="cb42-911"><a href="#cb42-911" aria-hidden="true" tabindex="-1"></a>is the value of the objective function, which is the</span>
<span id="cb42-912"><a href="#cb42-912" aria-hidden="true" tabindex="-1"></a>log-likelihood. Closely related to the log-likelihood is the deviance,\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{deviance}</span>
<span id="cb42-913"><a href="#cb42-913" aria-hidden="true" tabindex="-1"></a>which is the opposite of twice the log-likelihood. Both measures are</span>
<span id="cb42-914"><a href="#cb42-914" aria-hidden="true" tabindex="-1"></a>reported in @tbl-binom_const_unconst. These measures favor lightly the</span>
<span id="cb42-915"><a href="#cb42-915" aria-hidden="true" tabindex="-1"></a>logit models compared to the probit models and indicate an important</span>
<span id="cb42-916"><a href="#cb42-916" aria-hidden="true" tabindex="-1"></a>difference between the constrained and unconstrained</span>
<span id="cb42-917"><a href="#cb42-917" aria-hidden="true" tabindex="-1"></a>model. However, the comparison between the constrained and</span>
<span id="cb42-918"><a href="#cb42-918" aria-hidden="true" tabindex="-1"></a>unconstrained models is spurious, because adding further covariates,</span>
<span id="cb42-919"><a href="#cb42-919" aria-hidden="true" tabindex="-1"></a>even if they are irrelevant, necessarily increases the fit of the</span>
<span id="cb42-920"><a href="#cb42-920" aria-hidden="true" tabindex="-1"></a>model. Therefore, we need indicators that penalize highly parametrized</span>
<span id="cb42-921"><a href="#cb42-921" aria-hidden="true" tabindex="-1"></a>models. The two most popular indicators are the Akaike and the Bayes</span>
<span id="cb42-922"><a href="#cb42-922" aria-hidden="true" tabindex="-1"></a>information criteria (**AIC** and **BIC**) which are respectively defined by $\mbox{AIC}</span>
<span id="cb42-923"><a href="#cb42-923" aria-hidden="true" tabindex="-1"></a>= - 2 \ln L + 2 K$ and $\mbox{BIC} = - 2 \ln L + K \ln N$.</span>
<span id="cb42-924"><a href="#cb42-924" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Akaike information criteria}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Bayes information criteria}</span>
<span id="cb42-925"><a href="#cb42-925" aria-hidden="true" tabindex="-1"></a>They are therefore obtained by augmenting the deviance by a term which is a</span>
<span id="cb42-926"><a href="#cb42-926" aria-hidden="true" tabindex="-1"></a>multiple of the number of fitted parameters: 2 times for the AIC</span>
<span id="cb42-927"><a href="#cb42-927" aria-hidden="true" tabindex="-1"></a>and $\ln N$ times for the BIC. The rule being to select the model for which</span>
<span id="cb42-928"><a href="#cb42-928" aria-hidden="true" tabindex="-1"></a>the statistic is lower, we can see from @tbl-binom_const_unconst that the</span>
<span id="cb42-929"><a href="#cb42-929" aria-hidden="true" tabindex="-1"></a>AIC leads to the choice of the unconstrained model, and the BIC</span>
<span id="cb42-930"><a href="#cb42-930" aria-hidden="true" tabindex="-1"></a>leads to the choice of the constrained model. This is because the</span>
<span id="cb42-931"><a href="#cb42-931" aria-hidden="true" tabindex="-1"></a>penalization in the BIC is higher, as $\ln 842 = 6.7$. These</span>
<span id="cb42-932"><a href="#cb42-932" aria-hidden="true" tabindex="-1"></a>statistics can be extracted from the fitted model using the <span class="in">`logLik`</span>,</span>
<span id="cb42-933"><a href="#cb42-933" aria-hidden="true" tabindex="-1"></a><span class="in">`deviance`</span>, <span class="in">`BIC`</span> and <span class="in">`AIC`</span> methods for <span class="in">`micsr`</span> objects, for example:</span>
<span id="cb42-934"><a href="#cb42-934" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}\idxfun{AIC}{stats}</span>
<span id="cb42-935"><a href="#cb42-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-936"><a href="#cb42-936" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-937"><a href="#cb42-937" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-938"><a href="#cb42-938" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(pbt_unconst)</span>
<span id="cb42-939"><a href="#cb42-939" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-940"><a href="#cb42-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-941"><a href="#cb42-941" aria-hidden="true" tabindex="-1"></a>The <span class="in">`logLik`</span> method for <span class="in">`micsr`</span> objects has a <span class="in">`type`</span> argument which enables to extract the value for the proposed model (<span class="in">`type = "mode"`</span>, the default), the null model or the saturated model:</span>
<span id="cb42-942"><a href="#cb42-942" aria-hidden="true" tabindex="-1"></a>\idxfun{logLik}{stats}</span>
<span id="cb42-943"><a href="#cb42-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-946"><a href="#cb42-946" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-947"><a href="#cb42-947" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-948"><a href="#cb42-948" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(pbt_unconst)</span>
<span id="cb42-949"><a href="#cb42-949" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"model"</span>)</span>
<span id="cb42-950"><a href="#cb42-950" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"null"</span>)</span>
<span id="cb42-951"><a href="#cb42-951" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"saturated"</span>)</span>
<span id="cb42-952"><a href="#cb42-952" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-953"><a href="#cb42-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-954"><a href="#cb42-954" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{coefficient of determination!binomial model|(}</span>
<span id="cb42-955"><a href="#cb42-955" aria-hidden="true" tabindex="-1"></a>In linear model, a popular indicator of the quality of a model is the</span>
<span id="cb42-956"><a href="#cb42-956" aria-hidden="true" tabindex="-1"></a>coefficient of determination, called R^2^. For linear models: $\sum</span>
<span id="cb42-957"><a href="#cb42-957" aria-hidden="true" tabindex="-1"></a>(y_n - \bar{y}) ^ 2 = \sum (\hat{y}_n - \bar{y}) ^ 2 + \sum</span>
<span id="cb42-958"><a href="#cb42-958" aria-hidden="true" tabindex="-1"></a>\hat{\epsilon}_n ^ 2$ because the vectors of fitted values and</span>
<span id="cb42-959"><a href="#cb42-959" aria-hidden="true" tabindex="-1"></a>residuals are orthogonal. The R^2^ can therefore be defined using</span>
<span id="cb42-960"><a href="#cb42-960" aria-hidden="true" tabindex="-1"></a>three equivalent formulas:^<span class="co">[</span><span class="ot">See @sec-vardecomp_R2.</span><span class="co">]</span></span>
<span id="cb42-961"><a href="#cb42-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-962"><a href="#cb42-962" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-963"><a href="#cb42-963" aria-hidden="true" tabindex="-1"></a>R ^ 2 = \frac{\sum (\hat{y}_n - \bar{y}) ^ 2}{\sum (y_n - \bar{y}) ^</span>
<span id="cb42-964"><a href="#cb42-964" aria-hidden="true" tabindex="-1"></a>2} = 1 - \frac{\sum \hat{\epsilon}_n^2}{\sum (y_n - \bar{y}) ^ 2} =</span>
<span id="cb42-965"><a href="#cb42-965" aria-hidden="true" tabindex="-1"></a>\hat{\rho}_{y,\hat{y}} ^ 2</span>
<span id="cb42-966"><a href="#cb42-966" aria-hidden="true" tabindex="-1"></a>$$ {#eq-rsqlin}</span>
<span id="cb42-967"><a href="#cb42-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-968"><a href="#cb42-968" aria-hidden="true" tabindex="-1"></a>The first formula is particularly appealing, as it indicates the share</span>
<span id="cb42-969"><a href="#cb42-969" aria-hidden="true" tabindex="-1"></a>of the variance of the response that is explained by the model: it is</span>
<span id="cb42-970"><a href="#cb42-970" aria-hidden="true" tabindex="-1"></a>therefore bounded by 0 and 1. It is 0 if the model has no explanatory</span>
<span id="cb42-971"><a href="#cb42-971" aria-hidden="true" tabindex="-1"></a>power, which means that the fit is equivalent to the null model,</span>
<span id="cb42-972"><a href="#cb42-972" aria-hidden="true" tabindex="-1"></a>i.e., the model with no covariates. It is one for a "perfect" model, i.e., a</span>
<span id="cb42-973"><a href="#cb42-973" aria-hidden="true" tabindex="-1"></a>model for which the vector of residuals is 0.</span>
<span id="cb42-974"><a href="#cb42-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-975"><a href="#cb42-975" aria-hidden="true" tabindex="-1"></a>The three formulas are not equivalent for binomial models and,</span>
<span id="cb42-976"><a href="#cb42-976" aria-hidden="true" tabindex="-1"></a>therefore, there is no unambiguous formula for the R^2^ for these models. A lot of</span>
<span id="cb42-977"><a href="#cb42-977" aria-hidden="true" tabindex="-1"></a>different formulas have been proposed in the literature.^<span class="co">[</span><span class="ot">Useful surveys are @MAGE:90\index[author]{Magee}, @WIND:95\index[author]{Windmeijer} and @VEAL:ZIMM:96\index[author]{Veall}\index[author]{Zimmermann}.</span><span class="co">]</span> The **micsr**</span>
<span id="cb42-978"><a href="#cb42-978" aria-hidden="true" tabindex="-1"></a>package provides an <span class="in">`rsq`</span> function which has a type argument. By</span>
<span id="cb42-979"><a href="#cb42-979" aria-hidden="true" tabindex="-1"></a>setting <span class="in">`type`</span> to <span class="in">`"ess"`</span>, <span class="in">`"rss"`</span> and <span class="in">`"cor"`</span>, we get the three</span>
<span id="cb42-980"><a href="#cb42-980" aria-hidden="true" tabindex="-1"></a>versions of the R^2^ described in @eq-rsqlin. The <span class="in">`"rss"`</span> version is often called the Efron's R^2^ <span class="co">[</span><span class="ot">@EFRO:78</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Efron} and was previously proposed by @LAVE:70\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Lave}.</span>
<span id="cb42-981"><a href="#cb42-981" aria-hidden="true" tabindex="-1"></a>\idxfun{rsq}{micsr}</span>
<span id="cb42-982"><a href="#cb42-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-983"><a href="#cb42-983" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-984"><a href="#cb42-984" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-985"><a href="#cb42-985" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"ess"</span>)</span>
<span id="cb42-986"><a href="#cb42-986" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"rss"</span>)</span>
<span id="cb42-987"><a href="#cb42-987" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"cor"</span>)</span>
<span id="cb42-988"><a href="#cb42-988" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-989"><a href="#cb42-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-990"><a href="#cb42-990" aria-hidden="true" tabindex="-1"></a>As seen in @sec-pseudo_r2_ml, in the linear model, the R^2^ is related to statistics that</span>
<span id="cb42-991"><a href="#cb42-991" aria-hidden="true" tabindex="-1"></a>test the hypothesis that all the coefficients of the model except the</span>
<span id="cb42-992"><a href="#cb42-992" aria-hidden="true" tabindex="-1"></a>intercept are 0. This leads to pseudo-R^2^ that are obtained using any of the three classical tests statistic:</span>
<span id="cb42-993"><a href="#cb42-993" aria-hidden="true" tabindex="-1"></a>\idxfun{rsq}{micsr}</span>
<span id="cb42-994"><a href="#cb42-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-997"><a href="#cb42-997" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-998"><a href="#cb42-998" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-999"><a href="#cb42-999" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"wald"</span>)</span>
<span id="cb42-1000"><a href="#cb42-1000" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"lr"</span>)</span>
<span id="cb42-1001"><a href="#cb42-1001" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"score"</span>)</span>
<span id="cb42-1002"><a href="#cb42-1002" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1003"><a href="#cb42-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1004"><a href="#cb42-1004" aria-hidden="true" tabindex="-1"></a>@TJUR:09\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Tjur} proposed an R^2^ that he called the coefficient of</span>
<span id="cb42-1005"><a href="#cb42-1005" aria-hidden="true" tabindex="-1"></a>discrimination. This coefficient is the difference between the</span>
<span id="cb42-1006"><a href="#cb42-1006" aria-hidden="true" tabindex="-1"></a>probability of success for the subsample for which $y=1$ and the</span>
<span id="cb42-1007"><a href="#cb42-1007" aria-hidden="true" tabindex="-1"></a>subsample for which $y=0$. Tjur's measure is interestingly related to the</span>
<span id="cb42-1008"><a href="#cb42-1008" aria-hidden="true" tabindex="-1"></a>ESS, the RSS and the correlation measure of the R^2^. More precisely:</span>
<span id="cb42-1009"><a href="#cb42-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1010"><a href="#cb42-1010" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1011"><a href="#cb42-1011" aria-hidden="true" tabindex="-1"></a>R ^ 2 = \frac{1}{2}\left(R ^ 2_{\mbox{ess}} + R ^ 2_{\mbox{rss}}\right) = </span>
<span id="cb42-1012"><a href="#cb42-1012" aria-hidden="true" tabindex="-1"></a>\sqrt{R ^ 2_{\mbox{ess}} R ^ 2_{\mbox{cor}}}</span>
<span id="cb42-1013"><a href="#cb42-1013" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1014"><a href="#cb42-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1015"><a href="#cb42-1015" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1016"><a href="#cb42-1016" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1017"><a href="#cb42-1017" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"tjur"</span>)</span>
<span id="cb42-1018"><a href="#cb42-1018" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1019"><a href="#cb42-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1020"><a href="#cb42-1020" aria-hidden="true" tabindex="-1"></a>It summarizes the difference in the distribution of the fitted values</span>
<span id="cb42-1021"><a href="#cb42-1021" aria-hidden="true" tabindex="-1"></a>for the two subsamples defined by $y=1/0$. The <span class="in">`plot`</span> method for</span>
<span id="cb42-1022"><a href="#cb42-1022" aria-hidden="true" tabindex="-1"></a><span class="in">`binomreg`</span> objects draws these two distributions as an histogram and</span>
<span id="cb42-1023"><a href="#cb42-1023" aria-hidden="true" tabindex="-1"></a>indicates the average fit for the two groups by a dot on the</span>
<span id="cb42-1024"><a href="#cb42-1024" aria-hidden="true" tabindex="-1"></a>horizontal axis. Tjur's R^2^ is then simply the distance between these two</span>
<span id="cb42-1025"><a href="#cb42-1025" aria-hidden="true" tabindex="-1"></a>points. For the probit unconstrained model of mode choice, the result is</span>
<span id="cb42-1026"><a href="#cb42-1026" aria-hidden="true" tabindex="-1"></a>represented in @fig-histbinom and the same plot is presented for the <span class="in">`airbnb`</span> data set in @fig-histairbnb.</span>
<span id="cb42-1027"><a href="#cb42-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1028"><a href="#cb42-1028" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1029"><a href="#cb42-1029" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1030"><a href="#cb42-1030" aria-hidden="true" tabindex="-1"></a>plot.binomreg <span class="ot">&lt;-</span> <span class="cf">function</span>(x, ...){</span>
<span id="cb42-1031"><a href="#cb42-1031" aria-hidden="true" tabindex="-1"></a>    tb <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">y =</span> <span class="fu">model.response</span>(<span class="fu">model.frame</span>(x)), <span class="at">fit =</span> <span class="fu">fitted</span>(x))</span>
<span id="cb42-1032"><a href="#cb42-1032" aria-hidden="true" tabindex="-1"></a>    means <span class="ot">&lt;-</span> tb <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(y) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">fit =</span> <span class="fu">mean</span>(fit))</span>
<span id="cb42-1033"><a href="#cb42-1033" aria-hidden="true" tabindex="-1"></a>    tb <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> fit)) <span class="sc">+</span></span>
<span id="cb42-1034"><a href="#cb42-1034" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"white"</span>, <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.05</span>)) <span class="sc">+</span></span>
<span id="cb42-1035"><a href="#cb42-1035" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_point</span>(<span class="at">data =</span> means, <span class="fu">aes</span>(<span class="at">x =</span> fit, <span class="at">y =</span> <span class="dv">0</span>), <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span> </span>
<span id="cb42-1036"><a href="#cb42-1036" aria-hidden="true" tabindex="-1"></a>        <span class="fu">facet_wrap</span>(<span class="sc">~</span> y, <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb42-1037"><a href="#cb42-1037" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-1038"><a href="#cb42-1038" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-1039"><a href="#cb42-1039" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1040"><a href="#cb42-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1041"><a href="#cb42-1041" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1042"><a href="#cb42-1042" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1043"><a href="#cb42-1043" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-histbinom</span></span>
<span id="cb42-1044"><a href="#cb42-1044" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig.cap: "Histogram of the distribution of the fitted values for the probit mode choice model"</span></span>
<span id="cb42-1045"><a href="#cb42-1045" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pbt_unconst)</span>
<span id="cb42-1046"><a href="#cb42-1046" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1047"><a href="#cb42-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1048"><a href="#cb42-1048" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1049"><a href="#cb42-1049" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-histairbnb</span></span>
<span id="cb42-1050"><a href="#cb42-1050" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1051"><a href="#cb42-1051" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig.cap: "Histogram of the distribution of the fitted values for the Airbnb probit model"</span></span>
<span id="cb42-1052"><a href="#cb42-1052" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pt_a)</span>
<span id="cb42-1053"><a href="#cb42-1053" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1054"><a href="#cb42-1054" aria-hidden="true" tabindex="-1"></a>@fig-histairbnb reveals a very poor fit, as the two points are very close. This can be checked by computing the R^2^:</span>
<span id="cb42-1055"><a href="#cb42-1055" aria-hidden="true" tabindex="-1"></a>\idxfun{rsq}{micsr}</span>
<span id="cb42-1056"><a href="#cb42-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1057"><a href="#cb42-1057" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1058"><a href="#cb42-1058" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1059"><a href="#cb42-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pt_a, <span class="at">type =</span> <span class="st">"tjur"</span>)</span>
<span id="cb42-1060"><a href="#cb42-1060" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1061"><a href="#cb42-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1062"><a href="#cb42-1062" aria-hidden="true" tabindex="-1"></a>@ESTR:98\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Estrella} proposed a $R^2$ based on the likelihood ratio statistic comparing  the proposed model and</span>
<span id="cb42-1063"><a href="#cb42-1063" aria-hidden="true" tabindex="-1"></a>the null model, for which only one parameter is estimated. </span>
<span id="cb42-1064"><a href="#cb42-1064" aria-hidden="true" tabindex="-1"></a>The average likelihood ratio statistic is:</span>
<span id="cb42-1065"><a href="#cb42-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1066"><a href="#cb42-1066" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1067"><a href="#cb42-1067" aria-hidden="true" tabindex="-1"></a>A_{LR} = \frac{2}{N} \left(\ln L - \ln L_0\right)</span>
<span id="cb42-1068"><a href="#cb42-1068" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1069"><a href="#cb42-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1070"><a href="#cb42-1070" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb42-1071"><a href="#cb42-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1072"><a href="#cb42-1072" aria-hidden="true" tabindex="-1"></a>If the model has no explanatory power, $\ln L = \ln L_0$ so that the</span>
<span id="cb42-1073"><a href="#cb42-1073" aria-hidden="true" tabindex="-1"></a>minimum value of $A_{LR}$ is 0. For the saturated model, $L</span>
<span id="cb42-1074"><a href="#cb42-1074" aria-hidden="true" tabindex="-1"></a>= 1$, so that the maximum value of $A_{LR}$ is $B = - \frac{2}{N} \ln</span>
<span id="cb42-1075"><a href="#cb42-1075" aria-hidden="true" tabindex="-1"></a>L_0$. The proposed $R ^ 2$ follows the following differential equation:</span>
<span id="cb42-1076"><a href="#cb42-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1077"><a href="#cb42-1077" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1078"><a href="#cb42-1078" aria-hidden="true" tabindex="-1"></a>\frac{d R^ 2}{1 - d R ^ 2} = \frac{d A}{1 - A/B}</span>
<span id="cb42-1079"><a href="#cb42-1079" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1080"><a href="#cb42-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1081"><a href="#cb42-1081" aria-hidden="true" tabindex="-1"></a>which means that the relative change of the $R ^ 2$ should be equal to</span>
<span id="cb42-1082"><a href="#cb42-1082" aria-hidden="true" tabindex="-1"></a>the relative change of the average likelihood ratio. The solution to</span>
<span id="cb42-1083"><a href="#cb42-1083" aria-hidden="true" tabindex="-1"></a>this differential equation is: $1 - (1 - A/B) ^ B$, so that the $R ^ 2$</span>
<span id="cb42-1084"><a href="#cb42-1084" aria-hidden="true" tabindex="-1"></a>is:</span>
<span id="cb42-1085"><a href="#cb42-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1086"><a href="#cb42-1086" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1087"><a href="#cb42-1087" aria-hidden="true" tabindex="-1"></a>R ^ 2 = 1 - \left(\frac{\ln L}{\ln L_0}\right) ^ {-\frac{2}{N} \ln L_0}</span>
<span id="cb42-1088"><a href="#cb42-1088" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1089"><a href="#cb42-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1090"><a href="#cb42-1090" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1091"><a href="#cb42-1091" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1092"><a href="#cb42-1092" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"estrella"</span>)</span>
<span id="cb42-1093"><a href="#cb42-1093" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1094"><a href="#cb42-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1095"><a href="#cb42-1095" aria-hidden="true" tabindex="-1"></a>@MCFA:73\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McFadden} proposed the very popular pseudo-R^2^:</span>
<span id="cb42-1096"><a href="#cb42-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1097"><a href="#cb42-1097" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1098"><a href="#cb42-1098" aria-hidden="true" tabindex="-1"></a>R ^ 2 = 1 - \frac{\ln L_0}{\ln L}</span>
<span id="cb42-1099"><a href="#cb42-1099" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1100"><a href="#cb42-1100" aria-hidden="true" tabindex="-1"></a>\idxfun{rsq}{micsr}</span>
<span id="cb42-1101"><a href="#cb42-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1102"><a href="#cb42-1102" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1103"><a href="#cb42-1103" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1104"><a href="#cb42-1104" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"mcfadden"</span>)</span>
<span id="cb42-1105"><a href="#cb42-1105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1106"><a href="#cb42-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1107"><a href="#cb42-1107" aria-hidden="true" tabindex="-1"></a>@MCKE:ZAVO:75\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{McKelvey}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Zavoina} proposed a R^2^ based on the latent variable. Denoting</span>
<span id="cb42-1108"><a href="#cb42-1108" aria-hidden="true" tabindex="-1"></a>$\hat{y}_n ^* = \hat{\alpha}+\hat{\beta} ^ \top x_n$ as the fitted values and</span>
<span id="cb42-1109"><a href="#cb42-1109" aria-hidden="true" tabindex="-1"></a>$\bar{y}^*$ as the sample mean, the explained sum of squares is:</span>
<span id="cb42-1110"><a href="#cb42-1110" aria-hidden="true" tabindex="-1"></a>$\sum (\hat{y}_n ^ * - \bar{y}^ *) ^ 2$ and the residuals sum of</span>
<span id="cb42-1111"><a href="#cb42-1111" aria-hidden="true" tabindex="-1"></a>squares is not estimated, but its expected value is $N$ times the variance of the errors, which</span>
<span id="cb42-1112"><a href="#cb42-1112" aria-hidden="true" tabindex="-1"></a>is 1 for a probit and $\pi ^ 2 / 3$ for a logit. The R^2^ is then</span>
<span id="cb42-1113"><a href="#cb42-1113" aria-hidden="true" tabindex="-1"></a>obtained by dividing the explained sum of squares by the sum of the</span>
<span id="cb42-1114"><a href="#cb42-1114" aria-hidden="true" tabindex="-1"></a>explained sum of squares and either $N$ or $N\pi ^ 2 / 3$ respectively for the probit and logit models. </span>
<span id="cb42-1115"><a href="#cb42-1115" aria-hidden="true" tabindex="-1"></a>\idxfun{rsq}{micsr}</span>
<span id="cb42-1116"><a href="#cb42-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1117"><a href="#cb42-1117" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1118"><a href="#cb42-1118" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1119"><a href="#cb42-1119" aria-hidden="true" tabindex="-1"></a><span class="fu">rsq</span>(pbt_unconst, <span class="at">type =</span> <span class="st">"mckel_zavo"</span>)</span>
<span id="cb42-1120"><a href="#cb42-1120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1121"><a href="#cb42-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1122"><a href="#cb42-1122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1123"><a href="#cb42-1123" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-1124"><a href="#cb42-1124" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-1125"><a href="#cb42-1125" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">glm</span>(mode <span class="sc">~</span> cost <span class="sc">+</span> ivtime <span class="sc">+</span> ovtime, <span class="at">data =</span> mode_choice, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">'probit'</span>))</span>
<span id="cb42-1126"><a href="#cb42-1126" aria-hidden="true" tabindex="-1"></a>DescTools<span class="sc">::</span><span class="fu">PseudoR2</span>(z, <span class="st">"all"</span>)</span>
<span id="cb42-1127"><a href="#cb42-1127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1128"><a href="#cb42-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1129"><a href="#cb42-1129" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{coefficient of determination!binomial model|)}</span>
<span id="cb42-1130"><a href="#cb42-1130" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-1131"><a href="#cb42-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1132"><a href="#cb42-1132" aria-hidden="true" tabindex="-1"></a><span class="fu">### Testing</span></span>
<span id="cb42-1133"><a href="#cb42-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1134"><a href="#cb42-1134" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Tests of nested models</span></span>
<span id="cb42-1135"><a href="#cb42-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1136"><a href="#cb42-1136" aria-hidden="true" tabindex="-1"></a>To test nested models, the three tests described</span>
<span id="cb42-1137"><a href="#cb42-1137" aria-hidden="true" tabindex="-1"></a>in @sec-three_tests and @sec-three_tests_ml are available. </span>
<span id="cb42-1138"><a href="#cb42-1138" aria-hidden="true" tabindex="-1"></a>In @sec-func_form_binom, we estimated a model with the generalized cost as a unique covariate, which was computed as: $g_n = c_n + 8(i_n + o_n)$, where $c$, $i$, and $o$ are the differences in monetary cost,</span>
<span id="cb42-1139"><a href="#cb42-1139" aria-hidden="true" tabindex="-1"></a>in-vehicle time and out-vehicle time,</span>
<span id="cb42-1140"><a href="#cb42-1140" aria-hidden="true" tabindex="-1"></a>based on the hypothesis that time value was $8 per hour. </span>
<span id="cb42-1141"><a href="#cb42-1141" aria-hidden="true" tabindex="-1"></a>The unconstrained model is:</span>
<span id="cb42-1142"><a href="#cb42-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1143"><a href="#cb42-1143" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1144"><a href="#cb42-1144" aria-hidden="true" tabindex="-1"></a>P(y_n = 1) = \Phi(\alpha + \beta_c c_n + \beta_i i_n + \beta_o o_n)</span>
<span id="cb42-1145"><a href="#cb42-1145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1146"><a href="#cb42-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1147"><a href="#cb42-1147" aria-hidden="true" tabindex="-1"></a>The constrained model implies the two following hypotheses: $H_O: \beta_o = \beta_i =</span>
<span id="cb42-1148"><a href="#cb42-1148" aria-hidden="true" tabindex="-1"></a>8 \beta_c$. It is more convenient to rewrite the model so</span>
<span id="cb42-1149"><a href="#cb42-1149" aria-hidden="true" tabindex="-1"></a>that, under H~0~, a subset of the parameters are 0:</span>
<span id="cb42-1150"><a href="#cb42-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1151"><a href="#cb42-1151" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb42-1152"><a href="#cb42-1152" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-1153"><a href="#cb42-1153" aria-hidden="true" tabindex="-1"></a>P(y_n = 1) &amp;=&amp; \Phi\left(\alpha + \beta_c \left(c_n + 8 (i_n +</span>
<span id="cb42-1154"><a href="#cb42-1154" aria-hidden="true" tabindex="-1"></a>o_n)\right) + (\beta_i - 8\beta_c)i_n + (\beta_o - 8 \beta_c)</span>
<span id="cb42-1155"><a href="#cb42-1155" aria-hidden="true" tabindex="-1"></a>o_n\right)<span class="sc">\\</span></span>
<span id="cb42-1156"><a href="#cb42-1156" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \Phi(\alpha + \beta_c g_n + \beta_i'i_n + \beta_o'o_n) </span>
<span id="cb42-1157"><a href="#cb42-1157" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-1158"><a href="#cb42-1158" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1159"><a href="#cb42-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1160"><a href="#cb42-1160" aria-hidden="true" tabindex="-1"></a>where $\beta_i' = (\beta_i - 8\beta_c)$ and $\beta_o = (\beta_o -</span>
<span id="cb42-1161"><a href="#cb42-1161" aria-hidden="true" tabindex="-1"></a>8\beta_c)$ are the reduced form parameters of the binomial</span>
<span id="cb42-1162"><a href="#cb42-1162" aria-hidden="true" tabindex="-1"></a>regression with the generalized cost, the in-vehicle and out-vehicle time as</span>
<span id="cb42-1163"><a href="#cb42-1163" aria-hidden="true" tabindex="-1"></a>covariates. With this parametrization, the set of hypotheses is simply</span>
<span id="cb42-1164"><a href="#cb42-1164" aria-hidden="true" tabindex="-1"></a>$\beta_i' = \beta_o' = 0$.</span>
<span id="cb42-1165"><a href="#cb42-1165" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-1166"><a href="#cb42-1166" aria-hidden="true" tabindex="-1"></a>\idxfun{binomreg}{micsr}</span>
<span id="cb42-1167"><a href="#cb42-1167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1168"><a href="#cb42-1168" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1169"><a href="#cb42-1169" aria-hidden="true" tabindex="-1"></a>pbt_unconst2 <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> gcost <span class="sc">+</span> ivtime <span class="sc">+</span> ovtime, </span>
<span id="cb42-1170"><a href="#cb42-1170" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> mode_choice, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-1171"><a href="#cb42-1171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1172"><a href="#cb42-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1173"><a href="#cb42-1173" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{likelihood ratio test!binomial|(}</span>
<span id="cb42-1174"><a href="#cb42-1174" aria-hidden="true" tabindex="-1"></a>Tests can be computed using several functions in the **lmtest** package <span class="co">[</span><span class="ot">@ZEIL:HOTH:02</span><span class="co">]</span>\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Zeileis}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Hothorn}.</span>
<span id="cb42-1175"><a href="#cb42-1175" aria-hidden="true" tabindex="-1"></a>The likelihood ratio test can easily be computed "by hand", as it is twice the difference of the log-likelihood functions of the unconstrained and constrained models:</span>
<span id="cb42-1176"><a href="#cb42-1176" aria-hidden="true" tabindex="-1"></a>\idxfun{as.numeric}{base}\idxfun{logLik}{stats}</span>
<span id="cb42-1177"><a href="#cb42-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1180"><a href="#cb42-1180" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1181"><a href="#cb42-1181" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1182"><a href="#cb42-1182" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(pbt_unconst) <span class="sc">-</span> <span class="fu">logLik</span>(pbt_const)))</span>
<span id="cb42-1183"><a href="#cb42-1183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1184"><a href="#cb42-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1185"><a href="#cb42-1185" aria-hidden="true" tabindex="-1"></a>but <span class="in">`lmtest::lrtest`</span> is a convenient function which computes the statistic and the probability value:</span>
<span id="cb42-1186"><a href="#cb42-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1187"><a href="#cb42-1187" aria-hidden="true" tabindex="-1"></a>\idxfun{lrtest}{lmtest}\idxfun{gaze}{micsr}</span>
<span id="cb42-1190"><a href="#cb42-1190" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1191"><a href="#cb42-1191" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1192"><a href="#cb42-1192" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">lrtest</span>(pbt_unconst, pbt_const) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1193"><a href="#cb42-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1194"><a href="#cb42-1194" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{likelihood ratio test!binomial|)}</span>
<span id="cb42-1195"><a href="#cb42-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1196"><a href="#cb42-1196" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Wald test!binomial|(}</span>
<span id="cb42-1197"><a href="#cb42-1197" aria-hidden="true" tabindex="-1"></a>The Wald test can be computed using either <span class="in">`lmtest::waldtest`</span> or <span class="in">`car::linearHypothesis`</span>. <span class="in">`lmtest::waldtest`</span> provides two possible syntaxes: two fitted models, as <span class="in">`lmtest::lrtest`</span> or the fitted unconstrained model and a formula describing the constrained model. <span class="in">`car::linearHypothesis`</span>, already described in @sec-wald_test_example, uses a character vector to indicate the hypothesis:</span>
<span id="cb42-1198"><a href="#cb42-1198" aria-hidden="true" tabindex="-1"></a>\idxfun{waldtest}{lmtest}\idxfun{car}{linearHypothesis}\idxfun{gaze}{micsr}</span>
<span id="cb42-1199"><a href="#cb42-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1202"><a href="#cb42-1202" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1203"><a href="#cb42-1203" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1204"><a href="#cb42-1204" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">waldtest</span>(pbt_unconst2, pbt_const) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1205"><a href="#cb42-1205" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">waldtest</span>(pbt_unconst2, . <span class="sc">~</span> . <span class="sc">-</span> ivtime <span class="sc">-</span> ovtime) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1206"><a href="#cb42-1206" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(pbt_unconst, </span>
<span id="cb42-1207"><a href="#cb42-1207" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">c</span>(<span class="st">"ivtime = 8 * cost"</span>, <span class="st">"ovtime = 8 * cost"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb42-1208"><a href="#cb42-1208" aria-hidden="true" tabindex="-1"></a>  gaze</span>
<span id="cb42-1209"><a href="#cb42-1209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1210"><a href="#cb42-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1211"><a href="#cb42-1211" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{Wald test!binomial|)}\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{score test!binomial|(}</span>
<span id="cb42-1212"><a href="#cb42-1212" aria-hidden="true" tabindex="-1"></a>Finally, score tests are provided by the <span class="in">`micsr::scoretest`</span> function. Its first argument is the constrained fitted model and the second one a formula that describes the unconstrained model:</span>
<span id="cb42-1213"><a href="#cb42-1213" aria-hidden="true" tabindex="-1"></a>\idxfun{scoretest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb42-1214"><a href="#cb42-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1215"><a href="#cb42-1215" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1216"><a href="#cb42-1216" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1217"><a href="#cb42-1217" aria-hidden="true" tabindex="-1"></a><span class="fu">scoretest</span>(pbt_const , . <span class="sc">~</span> . <span class="sc">+</span> ivtime <span class="sc">+</span> ovtime) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1218"><a href="#cb42-1218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1219"><a href="#cb42-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1220"><a href="#cb42-1220" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{score test!binomial|)}</span>
<span id="cb42-1221"><a href="#cb42-1221" aria-hidden="true" tabindex="-1"></a>The three statistics are very close and the joint hypothesis is rejected at the 1% level.</span>
<span id="cb42-1222"><a href="#cb42-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1223"><a href="#cb42-1223" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1224"><a href="#cb42-1224" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-1225"><a href="#cb42-1225" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-1226"><a href="#cb42-1226" aria-hidden="true" tabindex="-1"></a>counts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">18</span>,<span class="dv">17</span>,<span class="dv">15</span>,<span class="dv">20</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">25</span>,<span class="dv">13</span>,<span class="dv">12</span>)</span>
<span id="cb42-1227"><a href="#cb42-1227" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> <span class="fu">gl</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">9</span>)</span>
<span id="cb42-1228"><a href="#cb42-1228" aria-hidden="true" tabindex="-1"></a>treatment <span class="ot">&lt;-</span> <span class="fu">gl</span>(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb42-1229"><a href="#cb42-1229" aria-hidden="true" tabindex="-1"></a>glm.D93 <span class="ot">&lt;-</span> <span class="fu">glm</span>(counts <span class="sc">~</span> outcome <span class="sc">+</span> treatment, <span class="at">family=</span><span class="fu">quasipoisson</span>())</span>
<span id="cb42-1230"><a href="#cb42-1230" aria-hidden="true" tabindex="-1"></a>glm.D93<span class="sc">$</span>resid</span>
<span id="cb42-1231"><a href="#cb42-1231" aria-hidden="true" tabindex="-1"></a><span class="co">#working</span></span>
<span id="cb42-1232"><a href="#cb42-1232" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(glm.D93,<span class="at">type=</span><span class="st">"working"</span>)</span>
<span id="cb42-1233"><a href="#cb42-1233" aria-hidden="true" tabindex="-1"></a>(counts <span class="sc">-</span> glm.D93<span class="sc">$</span>fitted.values)<span class="sc">/</span><span class="fu">exp</span>(glm.D93<span class="sc">$</span>linear)</span>
<span id="cb42-1234"><a href="#cb42-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1235"><a href="#cb42-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1236"><a href="#cb42-1236" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1237"><a href="#cb42-1237" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-1238"><a href="#cb42-1238" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-1239"><a href="#cb42-1239" aria-hidden="true" tabindex="-1"></a>za <span class="ot">&lt;-</span> <span class="fu">glm</span>(acceptance <span class="sc">~</span> <span class="fu">log</span>(price) <span class="sc">+</span> guest_race, airbnb, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">'probit'</span>))</span>
<span id="cb42-1240"><a href="#cb42-1240" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(za, <span class="st">"response"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-1241"><a href="#cb42-1241" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">model.response</span>(<span class="fu">model.frame</span>(za))</span>
<span id="cb42-1242"><a href="#cb42-1242" aria-hidden="true" tabindex="-1"></a>hy <span class="ot">&lt;-</span> <span class="fu">fitted</span>(za)</span>
<span id="cb42-1243"><a href="#cb42-1243" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(y <span class="sc">-</span> hy)</span>
<span id="cb42-1244"><a href="#cb42-1244" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(za, <span class="st">"pearson"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-1245"><a href="#cb42-1245" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>((y <span class="sc">-</span> hy) <span class="sc">/</span> <span class="fu">sqrt</span>(hy <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> hy)))</span>
<span id="cb42-1246"><a href="#cb42-1246" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(za, <span class="st">"working"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-1247"><a href="#cb42-1247" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>((y <span class="sc">-</span> hy) <span class="sc">/</span> hy)</span>
<span id="cb42-1248"><a href="#cb42-1248" aria-hidden="true" tabindex="-1"></a><span class="fu">resid</span>(za, <span class="st">"deviance"</span>) <span class="sc">%&gt;%</span> head</span>
<span id="cb42-1249"><a href="#cb42-1249" aria-hidden="true" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> y <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb42-1250"><a href="#cb42-1250" aria-hidden="true" tabindex="-1"></a>dev_res <span class="ot">&lt;-</span> q <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pnorm</span>( q <span class="sc">*</span>  za<span class="sc">$</span>linear.predictor, <span class="at">log.p =</span> <span class="cn">TRUE</span>))</span>
<span id="cb42-1251"><a href="#cb42-1251" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dev_res)</span>
<span id="cb42-1252"><a href="#cb42-1252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1253"><a href="#cb42-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1254"><a href="#cb42-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1255"><a href="#cb42-1255" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1256"><a href="#cb42-1256" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-1257"><a href="#cb42-1257" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-1258"><a href="#cb42-1258" aria-hidden="true" tabindex="-1"></a>smic <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb42-1259"><a href="#cb42-1259" aria-hidden="true" tabindex="-1"></a>mc <span class="ot">&lt;-</span> mode_choice <span class="sc">%&gt;%</span></span>
<span id="cb42-1260"><a href="#cb42-1260" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">cost =</span> cost <span class="sc">*</span> <span class="fl">8.42</span> <span class="sc">/</span> <span class="dv">100</span>,</span>
<span id="cb42-1261"><a href="#cb42-1261" aria-hidden="true" tabindex="-1"></a>           <span class="at">ovtime =</span> ovtime <span class="sc">/</span> <span class="dv">60</span>,</span>
<span id="cb42-1262"><a href="#cb42-1262" aria-hidden="true" tabindex="-1"></a>           <span class="at">ivtime =</span> ivtime <span class="sc">/</span> <span class="dv">60</span>,</span>
<span id="cb42-1263"><a href="#cb42-1263" aria-hidden="true" tabindex="-1"></a>           <span class="at">gcost =</span> smic <span class="sc">*</span> (ovtime <span class="sc">+</span> ivtime) <span class="sc">+</span> cost</span>
<span id="cb42-1264"><a href="#cb42-1264" aria-hidden="true" tabindex="-1"></a>           )</span>
<span id="cb42-1265"><a href="#cb42-1265" aria-hidden="true" tabindex="-1"></a>const <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> gcost, mc, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-1266"><a href="#cb42-1266" aria-hidden="true" tabindex="-1"></a>unconst <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(mode <span class="sc">~</span> cost <span class="sc">+</span> ivtime <span class="sc">+</span> ovtime, mc, <span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb42-1267"><a href="#cb42-1267" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">lrtest</span>(unconst, const)</span>
<span id="cb42-1268"><a href="#cb42-1268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1269"><a href="#cb42-1269" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-1270"><a href="#cb42-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1271"><a href="#cb42-1271" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Conditional moment test {#sec-cond_moment_binomial}</span></span>
<span id="cb42-1272"><a href="#cb42-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1273"><a href="#cb42-1273" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{conditional moment test!binomial|(}</span>
<span id="cb42-1274"><a href="#cb42-1274" aria-hidden="true" tabindex="-1"></a>The conditional moment tests have been presented in @sec-ml_cond_moment_test and the relevant moments are given by  @eq-emp_moments_homosc (for the heteroskedasticity test), @eq-emp_moments_normal (for the normal test) and @eq-emp_moments_omit_var (for the omitted variable test). The empirical moments use the powers (up to 4) of the residuals. As the residuals are unobserved, $\epsilon_n ^ k$ is replaced by their expectations, i.e., by the uncentered moments of the residuals:</span>
<span id="cb42-1275"><a href="#cb42-1275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1276"><a href="#cb42-1276" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1277"><a href="#cb42-1277" aria-hidden="true" tabindex="-1"></a>m_k = \mbox{E}(\epsilon_n ^ k \mid x_n) = (1-y_n) \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) + y_n \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * &gt; 0)</span>
<span id="cb42-1278"><a href="#cb42-1278" aria-hidden="true" tabindex="-1"></a>$$ {#eq-moments_errors}</span>
<span id="cb42-1279"><a href="#cb42-1279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1280"><a href="#cb42-1280" aria-hidden="true" tabindex="-1"></a>For the probit model, the first four moments of the truncated normal distribution should be computed. A recursive formula for the moments of a normal variable $x \sim \mathcal{N}(\eta, \sigma)$ with $l\leq x \leq u$ is:^<span class="co">[</span><span class="ot">Unpublished note by Eric Orjebin, 2014, founded on the Wikipedia page entitled "Truncated normal distribution".</span><span class="co">]</span></span>
<span id="cb42-1281"><a href="#cb42-1281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1282"><a href="#cb42-1282" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1283"><a href="#cb42-1283" aria-hidden="true" tabindex="-1"></a>m_k = (k-1)\sigma ^ 2 m_{k-2} + \eta m_{k-1} - \sigma \frac{u ^ {k-1}\phi\left(\frac{u-\eta}{\sigma}\right) - l ^ {k-1}\phi\left(\frac{l-\eta}{\sigma}\right)}</span>
<span id="cb42-1284"><a href="#cb42-1284" aria-hidden="true" tabindex="-1"></a>{\Phi\left(\frac{u-\eta}{\sigma}\right) - \Phi\left(\frac{l-\eta}{\sigma}\right)}</span>
<span id="cb42-1285"><a href="#cb42-1285" aria-hidden="true" tabindex="-1"></a>$$ {#eq-moments_normal_trunc}</span>
<span id="cb42-1286"><a href="#cb42-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1287"><a href="#cb42-1287" aria-hidden="true" tabindex="-1"></a>with $m_{-1} = 0$ and $m_{0} = 1$. </span>
<span id="cb42-1288"><a href="#cb42-1288" aria-hidden="true" tabindex="-1"></a>For a residual of the probit model, we have $\eta = 0$ and $\sigma = 1$ and the truncature is $-\mu_n$. We then obtain, for $y_n^* \leq 0$ ($l = - \infty$ and $u = -\mu_n$) and $y_n ^ * &gt; 0$ ($l = - \mu_n$ and $u = +\infty$):</span>
<span id="cb42-1289"><a href="#cb42-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1290"><a href="#cb42-1290" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1291"><a href="#cb42-1291" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-1292"><a href="#cb42-1292" aria-hidden="true" tabindex="-1"></a>\begin{array}{rclrcl}</span>
<span id="cb42-1293"><a href="#cb42-1293" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0) &amp;=&amp; (k - 1)  m_{k-2} - (- \mu_n) ^ {k-1} \frac{\phi(\mu_n / \sigma)}{1-\Phi(\mu_n / \sigma)} <span class="sc">\\</span></span>
<span id="cb42-1294"><a href="#cb42-1294" aria-hidden="true" tabindex="-1"></a>\mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * &gt; 0) &amp;=&amp; (k - 1)  m_{k-2} + (- \mu_n) ^ {k-1} \frac{\phi(\mu_n / \sigma)}{\Phi(\mu_n / \sigma)} <span class="sc">\\</span></span>
<span id="cb42-1295"><a href="#cb42-1295" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-1296"><a href="#cb42-1296" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-1297"><a href="#cb42-1297" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1298"><a href="#cb42-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1299"><a href="#cb42-1299" aria-hidden="true" tabindex="-1"></a>Using @eq-moments_errors, the recursive formula for the k^th^ moment of $\epsilon$ is simply:</span>
<span id="cb42-1300"><a href="#cb42-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1301"><a href="#cb42-1301" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1302"><a href="#cb42-1302" aria-hidden="true" tabindex="-1"></a>m_k = (k-1) m_{k-2} + (-\mu_n)^{k-1}\frac{(y_n - \Phi(\mu_n / \sigma))\phi(\mu_n / \sigma)}{\Phi(\mu_n / \sigma)(1 - \Phi(\mu_n / \sigma))} = (k-1)m_{k-2} + (-\mu) ^ {k - 1} \psi_n</span>
<span id="cb42-1303"><a href="#cb42-1303" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1304"><a href="#cb42-1304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1305"><a href="#cb42-1305" aria-hidden="true" tabindex="-1"></a>where $\psi_n$ is the generalized residual defined by @eq-gen_resid_probit. </span>
<span id="cb42-1306"><a href="#cb42-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1307"><a href="#cb42-1307" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1308"><a href="#cb42-1308" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{array}{ccccc} --&gt;</span></span>
<span id="cb42-1309"><a href="#cb42-1309" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- k &amp; \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * \leq 0)  &amp; \mbox{E}(\epsilon_n ^ k \mid x_n, y_n ^ * &gt; 0) &amp; \mbox{E}(\epsilon_n ^ k \mid x_n) &amp; \mbox{moment} \\ --&gt;</span></span>
<span id="cb42-1310"><a href="#cb42-1310" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 1 &amp; - r_{n0} &amp; r_{n1} &amp; r_n &amp; \sum_n r_n w_n\\ --&gt;</span></span>
<span id="cb42-1311"><a href="#cb42-1311" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 2 &amp; 1 + \mu_n r_{n0} &amp; 1 - \mu_n r_{n1} &amp; 1 - \mu_n r &amp; - \sum_n \mu_n r_n w_n\\ --&gt;</span></span>
<span id="cb42-1312"><a href="#cb42-1312" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 3 &amp; - (2 + \mu_n ^ 2) r_{n0} &amp; (2 + \mu_n ^ 2) r_{n1} &amp; (2 + \mu_n ^ 2) r &amp; \sum_n \mu_n ^ 2 r_n\\ --&gt;</span></span>
<span id="cb42-1313"><a href="#cb42-1313" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 4 &amp; 3 + (3 \mu_n + \mu_n ^ 3)r_{n0} &amp; 3 - (3 \mu_n + \mu_n ^ 3)r_{n1} &amp; 3 - (3 \mu_n + \mu_n ^ 3)r &amp; - \sum_n \mu_n ^ 3 r_n --&gt;</span></span>
<span id="cb42-1314"><a href="#cb42-1314" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{array} --&gt;</span></span>
<span id="cb42-1315"><a href="#cb42-1315" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1316"><a href="#cb42-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1317"><a href="#cb42-1317" aria-hidden="true" tabindex="-1"></a>The omitted variable test uses the first moment, the homoskedasticity test the second and the normality test the third and fourth. The moments of $\epsilon_n$, the theoretical moments for the three hypotheses and their empirical counterparts are presented in the following table:^<span class="co">[</span><span class="ot">Note that the empirical moments simplify because $\sum_n \psi_n = 0$ and $\sum_n \psi_n \mu_n = 0$, see @eq-gradbinom.</span><span class="co">]</span></span>
<span id="cb42-1318"><a href="#cb42-1318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1319"><a href="#cb42-1319" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1320"><a href="#cb42-1320" aria-hidden="true" tabindex="-1"></a>\begin{array}{clcccc}\hline</span>
<span id="cb42-1321"><a href="#cb42-1321" aria-hidden="true" tabindex="-1"></a>k &amp; \mbox{hypothesis} &amp; \mbox{E}(\epsilon_n ^ k \mid x_n) &amp; \mbox{theor. moment} &amp; \mbox{emp. moment} <span class="sc">\\</span> \hline</span>
<span id="cb42-1322"><a href="#cb42-1322" aria-hidden="true" tabindex="-1"></a>1 &amp; \mbox{omit. var.} &amp; \psi_n &amp; \mbox{E}(\epsilon_n w_n\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \psi_n w_n<span class="sc">\\</span></span>
<span id="cb42-1323"><a href="#cb42-1323" aria-hidden="true" tabindex="-1"></a>2 &amp; \mbox{homosc.} &amp; 1 - \mu_n \psi_n &amp; \mbox{E}((\epsilon_n^2-1) w_n\mid x_n) = 0 &amp; \frac{1}{N}\sum_n \mu_n \psi_n w_n<span class="sc">\\</span></span>
<span id="cb42-1324"><a href="#cb42-1324" aria-hidden="true" tabindex="-1"></a>3 &amp; \mbox{asymetry} &amp;  (2 + \mu_n ^ 2) \psi_n &amp;\mbox{E}(\epsilon_n^3\mid x_n) = 0 &amp;  \frac{1}{N}\sum_n \mu_n ^ 2 \psi_n<span class="sc">\\</span></span>
<span id="cb42-1325"><a href="#cb42-1325" aria-hidden="true" tabindex="-1"></a>4 &amp; \mbox{kurtosis} &amp; 3 - (3 \mu_n + \mu_n ^ 3)\psi_n &amp; \mbox{E}(\epsilon_n^4 - 3\mid x_n) = 0 &amp; \frac{1}{N} \sum_n \mu_n ^ 3 \psi_n <span class="sc">\\</span>\hline</span>
<span id="cb42-1326"><a href="#cb42-1326" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-1327"><a href="#cb42-1327" aria-hidden="true" tabindex="-1"></a>$$ {#eq-table_moments_probit}</span>
<span id="cb42-1328"><a href="#cb42-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1329"><a href="#cb42-1329" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb42-1330"><a href="#cb42-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1331"><a href="#cb42-1331" aria-hidden="true" tabindex="-1"></a>The <span class="in">`miscr::cmtest`</span> function computes the conditional moment test; the first argument is a fitted model the second one is <span class="in">`test`</span> which can be equal to <span class="in">`"normality"`</span>, <span class="in">`"reset"`</span> (for tests for omitted variables) or <span class="in">`"heterosc"`</span>. The two joint hypothesis corresponding to the normality hypothesis can be tested one by one by setting <span class="in">`test`</span> either to <span class="in">`"skewness"`</span> or <span class="in">`"kurtosis"`</span>. For the homoskedasticity tests, the set of variables can be selected using the <span class="in">`heter_cov`</span> argument. By default, all the covariates used in the model are selected. By default, tests are performed using the hessian, but the outer product of the gradient form of the test can be computed by setting <span class="in">`opg`</span> to <span class="in">`TRUE`</span>.</span>
<span id="cb42-1332"><a href="#cb42-1332" aria-hidden="true" tabindex="-1"></a>\idxfun{cmtest}{micsr}\idxfun{gaze}{micsr}\idxdata{mode<span class="sc">\_</span>choice}{micsr.data}</span>
<span id="cb42-1333"><a href="#cb42-1333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1336"><a href="#cb42-1336" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1337"><a href="#cb42-1337" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1338"><a href="#cb42-1338" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(pbt_unconst, <span class="at">test =</span> <span class="st">"normality"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1339"><a href="#cb42-1339" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(pbt_unconst, <span class="at">test =</span> <span class="st">"heterosc"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1340"><a href="#cb42-1340" aria-hidden="true" tabindex="-1"></a><span class="fu">cmtest</span>(pbt_unconst, <span class="at">test =</span> <span class="st">"reset"</span>) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1341"><a href="#cb42-1341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1342"><a href="#cb42-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1343"><a href="#cb42-1343" aria-hidden="true" tabindex="-1"></a>Our probit model seems to be correctly specified, as the three hypotheses are not rejected.</span>
<span id="cb42-1344"><a href="#cb42-1344" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{conditional moment test!binomial|)}</span>
<span id="cb42-1345"><a href="#cb42-1345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1346"><a href="#cb42-1346" aria-hidden="true" tabindex="-1"></a><span class="fu">## Endogeneity {#sec-endog_probit}</span></span>
<span id="cb42-1347"><a href="#cb42-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1348"><a href="#cb42-1348" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{endogeneity!probit|(}</span>
<span id="cb42-1349"><a href="#cb42-1349" aria-hidden="true" tabindex="-1"></a>We now consider the case where some of the covariates are endogenous. In a linear model, the solution is to use an instrumental variable estimator, which can be estimated using the 2SLS approach and therefore by using only the <span class="in">`lm`</span> function. We treat in this section the case where the response is binomial, and we consider that the realization of $y$ is related to the value of a latent variable $y_n ^ *$, with the usual observation rule: ($y = 0$ if $y^* \leq 0$ and $y = 1$ if $y^*&gt;0$). $y^*$ is a linear function of a set of $K_1$ exogenous ($x_1$) and $G$ endogenous ($e$) covariates:</span>
<span id="cb42-1350"><a href="#cb42-1350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1351"><a href="#cb42-1351" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1352"><a href="#cb42-1352" aria-hidden="true" tabindex="-1"></a>y_n ^ * = \alpha + \beta ^ \top x_{1n} + \delta ^ \top e_n + \epsilon_n = \gamma ^ \top</span>
<span id="cb42-1353"><a href="#cb42-1353" aria-hidden="true" tabindex="-1"></a>z_n + \epsilon_n</span>
<span id="cb42-1354"><a href="#cb42-1354" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1355"><a href="#cb42-1355" aria-hidden="true" tabindex="-1"></a>with $\gamma ^ \top = (\alpha, \beta ^ \top, \delta ^ \top)$ and $z_n ^ \top = (1, x_{1n} ^ \top, e_n ^ \top)$.</span>
<span id="cb42-1356"><a href="#cb42-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1357"><a href="#cb42-1357" aria-hidden="true" tabindex="-1"></a>The reduced form equation for each endogenous variable is:</span>
<span id="cb42-1358"><a href="#cb42-1358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1359"><a href="#cb42-1359" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1360"><a href="#cb42-1360" aria-hidden="true" tabindex="-1"></a>e_{gn} = \pi_g ^ \top w_n + \nu_{gn}</span>
<span id="cb42-1361"><a href="#cb42-1361" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1362"><a href="#cb42-1362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1363"><a href="#cb42-1363" aria-hidden="true" tabindex="-1"></a>where $w_n^\top = (1, x_{1n} ^ \top, x_{2n} ^ \top)$, $x_{2n}$ being a</span>
<span id="cb42-1364"><a href="#cb42-1364" aria-hidden="true" tabindex="-1"></a>vector of $K_2$ external instruments. It is assumed that $K_2 \geq G$.</span>
<span id="cb42-1365"><a href="#cb42-1365" aria-hidden="true" tabindex="-1"></a>The joint distribution of $y_n^*$ and $w_n$ is normal:</span>
<span id="cb42-1366"><a href="#cb42-1366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1367"><a href="#cb42-1367" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1368"><a href="#cb42-1368" aria-hidden="true" tabindex="-1"></a>\left(\begin{array}{c} y^* <span class="sc">\\</span> e \end{array}\right) \sim N \left(</span>
<span id="cb42-1369"><a href="#cb42-1369" aria-hidden="true" tabindex="-1"></a>\left(\begin{array}{c} \gamma ^ \top z_n  <span class="sc">\\</span> \Pi w_n</span>
<span id="cb42-1370"><a href="#cb42-1370" aria-hidden="true" tabindex="-1"></a>\end{array}\right) ;</span>
<span id="cb42-1371"><a href="#cb42-1371" aria-hidden="true" tabindex="-1"></a>\left(</span>
<span id="cb42-1372"><a href="#cb42-1372" aria-hidden="true" tabindex="-1"></a>\begin{array}{cc} \sigma_\epsilon ^ 2 &amp; \sigma_{\epsilon\nu} ^ \top <span class="sc">\\</span> \sigma_{\epsilon\nu} &amp;</span>
<span id="cb42-1373"><a href="#cb42-1373" aria-hidden="true" tabindex="-1"></a>\Sigma_\nu \end{array}</span>
<span id="cb42-1374"><a href="#cb42-1374" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb42-1375"><a href="#cb42-1375" aria-hidden="true" tabindex="-1"></a>\right)</span>
<span id="cb42-1376"><a href="#cb42-1376" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1377"><a href="#cb42-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1378"><a href="#cb42-1378" aria-hidden="true" tabindex="-1"></a>where $\Pi$ is an $(K_1+K_2+1) \times G$ matrix with the $g$^th^ line equal to</span>
<span id="cb42-1379"><a href="#cb42-1379" aria-hidden="true" tabindex="-1"></a>$\pi_g ^ \top$, $\Sigma_\nu$ is the $G\times G$ matrix of covariance</span>
<span id="cb42-1380"><a href="#cb42-1380" aria-hidden="true" tabindex="-1"></a>of $\nu$ and $\sigma_{\epsilon\nu}$ is a vector of length $G$ containing</span>
<span id="cb42-1381"><a href="#cb42-1381" aria-hidden="true" tabindex="-1"></a>the covariances between $\epsilon$ and $\nu$.</span>
<span id="cb42-1382"><a href="#cb42-1382" aria-hidden="true" tabindex="-1"></a>Conditional on $w_n$, the distribution of $y_n ^ *$ is also normal:</span>
<span id="cb42-1383"><a href="#cb42-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1384"><a href="#cb42-1384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1385"><a href="#cb42-1385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1386"><a href="#cb42-1386" aria-hidden="true" tabindex="-1"></a>y_n ^ * \mid e_n \sim N \left(\gamma ^ \top z_n + \sigma_{\epsilon\nu}</span>
<span id="cb42-1387"><a href="#cb42-1387" aria-hidden="true" tabindex="-1"></a>^ \top \Sigma_\nu ^ {-1}(e_n - \Pi w_n), \sigma_\epsilon ^ 2 -</span>
<span id="cb42-1388"><a href="#cb42-1388" aria-hidden="true" tabindex="-1"></a>\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}\right)</span>
<span id="cb42-1389"><a href="#cb42-1389" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ycond}</span>
<span id="cb42-1390"><a href="#cb42-1390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1391"><a href="#cb42-1391" aria-hidden="true" tabindex="-1"></a>Let $\rho = \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}$ and $\sigma ^ 2 = \sigma_\epsilon ^ 2 - \sigma_{\epsilon\nu} ^ \top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}$. The conditional mean of $y^*_n$ is then $\theta ^ \top u_n$, with $\theta ^ \top = (\gamma ^ \top, \rho ^ \top)$ and $u_n ^ \top = (z_n ^ \top, \nu_n ^ \top)$ and its conditional variance is $\sigma ^ 2$.</span>
<span id="cb42-1392"><a href="#cb42-1392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1393"><a href="#cb42-1393" aria-hidden="true" tabindex="-1"></a><span class="fu">### Maximum likelihood estimation</span></span>
<span id="cb42-1394"><a href="#cb42-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1395"><a href="#cb42-1395" aria-hidden="true" tabindex="-1"></a>The joint density of $y_n^*$ and $e_n$ can be written as the product of</span>
<span id="cb42-1396"><a href="#cb42-1396" aria-hidden="true" tabindex="-1"></a>the conditional density of $y_n^*$ and the</span>
<span id="cb42-1397"><a href="#cb42-1397" aria-hidden="true" tabindex="-1"></a>marginal density of $e_n$, which is multivariate normal:</span>
<span id="cb42-1398"><a href="#cb42-1398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1399"><a href="#cb42-1399" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1400"><a href="#cb42-1400" aria-hidden="true" tabindex="-1"></a>\ln g(e_n) = - \frac{1}{2}</span>
<span id="cb42-1401"><a href="#cb42-1401" aria-hidden="true" tabindex="-1"></a>\left(G \ln 2\pi + \ln \mid \Sigma_\nu \mid + \nu_n ^ \top \Sigma_\nu</span>
<span id="cb42-1402"><a href="#cb42-1402" aria-hidden="true" tabindex="-1"></a>^ {-1} \nu_n\right)</span>
<span id="cb42-1403"><a href="#cb42-1403" aria-hidden="true" tabindex="-1"></a>$$ {#eq-marg_density_w}</span>
<span id="cb42-1404"><a href="#cb42-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1405"><a href="#cb42-1405" aria-hidden="true" tabindex="-1"></a>We consider here the case where $y_n ^ *$ is not observed, but only its sign. Therefore, we observe $y_n$ equal to 0 or 1, or $q_n = 2 y_n - 1$ equal to $-1$ or $+1$. The log-likelihood is then $\ln L = \sum_{n=1} ^ N \ln g(e_n) + \ln f(y_n \mid e_n)$, where $g(e)$ is given by @eq-marg_density_w and:</span>
<span id="cb42-1406"><a href="#cb42-1406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1407"><a href="#cb42-1407" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1408"><a href="#cb42-1408" aria-hidden="true" tabindex="-1"></a>f(y_n \mid d_n) = \Phi\left(q_n\frac{\theta ^ \top u_n}{\sigma} \right) = </span>
<span id="cb42-1409"><a href="#cb42-1409" aria-hidden="true" tabindex="-1"></a>\Phi\left(q_n\frac{\gamma ^ \top z_n + \sigma_{\epsilon\nu}</span>
<span id="cb42-1410"><a href="#cb42-1410" aria-hidden="true" tabindex="-1"></a>^ \top \Sigma_\nu ^ {-1}(e_n - \Pi w_n)}{\sqrt{\sigma_\epsilon ^ 2 -</span>
<span id="cb42-1411"><a href="#cb42-1411" aria-hidden="true" tabindex="-1"></a>\sigma_{\epsilon\nu} ^\top \Sigma_\nu ^ {-1} \sigma_{\epsilon\nu}}}\right)</span>
<span id="cb42-1412"><a href="#cb42-1412" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_density_y_star}</span>
<span id="cb42-1413"><a href="#cb42-1413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1414"><a href="#cb42-1414" aria-hidden="true" tabindex="-1"></a>The computation of the estimator is simplified by the use of the Cholesky decomposition of $\Sigma_\nu ^ {-1}$, i.e., by considering the upper triangular matrix $C$ such that $C^\top C= \Sigma_\nu ^ {-1}$. Then, the determinant of $\Sigma_\nu ^ {-1}$ is simply the product of the squares of the diagonal elements of $C$. Therefore, $\ln \mid \Sigma_\nu ^ {-1} \mid = 2 \sum_g \ln C_{gg}$ and $\ln \mid \Sigma_\nu \mid = - 2 \sum_g \ln C_{gg}$.</span>
<span id="cb42-1415"><a href="#cb42-1415" aria-hidden="true" tabindex="-1"></a>Denoting $\Pi ^ * = C \Pi$, $w_n^* = C w_n$ and $\rho ^ * = C \sigma_{\epsilon\nu}$ we have : </span>
<span id="cb42-1416"><a href="#cb42-1416" aria-hidden="true" tabindex="-1"></a>$\theta ^ \top u_n = \gamma ^ \top z_n + \rho ^ {* \top} (e_n^* - \Pi ^ * w_n)$ and $\sigma ^ 2 = \sigma_\epsilon ^ 2 - \rho ^{*\top} \rho ^ *$.</span>
<span id="cb42-1417"><a href="#cb42-1417" aria-hidden="true" tabindex="-1"></a>The marginal density of $e_n$ and the conditional density of $y_n$ are then:</span>
<span id="cb42-1418"><a href="#cb42-1418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1419"><a href="#cb42-1419" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1420"><a href="#cb42-1420" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-1421"><a href="#cb42-1421" aria-hidden="true" tabindex="-1"></a>\begin{array}{rcl}</span>
<span id="cb42-1422"><a href="#cb42-1422" aria-hidden="true" tabindex="-1"></a>\ln g(e_n) &amp;=&amp; - </span>
<span id="cb42-1423"><a href="#cb42-1423" aria-hidden="true" tabindex="-1"></a>\frac{1}{2} G \ln 2\pi + \sum_{g = 1} ^ G  \ln C_{gg} - </span>
<span id="cb42-1424"><a href="#cb42-1424" aria-hidden="true" tabindex="-1"></a>\frac{1}{2} (e_n ^ * - \Pi ^ * w_n) ^ \top (e_n ^ * - \Pi ^ * w_n) <span class="sc">\\</span></span>
<span id="cb42-1425"><a href="#cb42-1425" aria-hidden="true" tabindex="-1"></a>\ln f(y_n \mid e_n) &amp;=&amp; \Phi\left((2 y_n - 1) \frac{\gamma ^ \top z_n + \rho ^ {*</span>
<span id="cb42-1426"><a href="#cb42-1426" aria-hidden="true" tabindex="-1"></a>\top} (e_n^* - \Pi ^ * w_n)}</span>
<span id="cb42-1427"><a href="#cb42-1427" aria-hidden="true" tabindex="-1"></a>{\sqrt{\sigma_\epsilon ^ 2 - \rho ^{*\top} \rho ^ *}}\right)</span>
<span id="cb42-1428"><a href="#cb42-1428" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-1429"><a href="#cb42-1429" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-1430"><a href="#cb42-1430" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1431"><a href="#cb42-1431" aria-hidden="true" tabindex="-1"></a>The maximum likelihood estimator is then obtained by maximizing the</span>
<span id="cb42-1432"><a href="#cb42-1432" aria-hidden="true" tabindex="-1"></a>log-likelihood function $\ln L = \sum_{n=1} ^ N \left(\ln g(e_n) + \ln f(y_n \mid e_n)\right)$ with respect to $\gamma$, $\rho ^*$, $\Pi ^ *$ and $C$. $\sigma_\epsilon$ is not identified and can be set to 1.</span>
<span id="cb42-1433"><a href="#cb42-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1434"><a href="#cb42-1434" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two-step estimator</span></span>
<span id="cb42-1435"><a href="#cb42-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1436"><a href="#cb42-1436" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!binomial model|(}</span>
<span id="cb42-1437"><a href="#cb42-1437" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{binomial model!two-step estimator|(}</span>
<span id="cb42-1438"><a href="#cb42-1438" aria-hidden="true" tabindex="-1"></a>From @eq-ycond, we have $y_n ^ * \sim N \left(\gamma ^ \top z_n + \rho ^ \top \nu_n, \sigma^2\right)$. If $y_n ^ *$ and $\nu_n$ were observed, the model could be consistently estimated by regressing $y_n ^ *$ on $z_n$ and $\nu_n$. $\nu_n$ is actually</span>
<span id="cb42-1439"><a href="#cb42-1439" aria-hidden="true" tabindex="-1"></a>unknown, but it can be consistently estimated using the estimation of</span>
<span id="cb42-1440"><a href="#cb42-1440" aria-hidden="true" tabindex="-1"></a>$\hat{\Pi}$ obtained by maximizing $\sum_{n=1} ^ N \ln g(e_n)$. This is a</span>
<span id="cb42-1441"><a href="#cb42-1441" aria-hidden="true" tabindex="-1"></a>seemingly unrelated regression problem, and it is well known that, for</span>
<span id="cb42-1442"><a href="#cb42-1442" aria-hidden="true" tabindex="-1"></a>the special case where the set of covariates is the same for all the</span>
<span id="cb42-1443"><a href="#cb42-1443" aria-hidden="true" tabindex="-1"></a>equations, the estimator can be obtained using OLS independently on</span>
<span id="cb42-1444"><a href="#cb42-1444" aria-hidden="true" tabindex="-1"></a>each equation. From this first step, we obtain $\hat{\nu}_n = e_n - \hat{\Pi} w_n$ and, in the second step, $\hat{\gamma}$ and $\hat{\rho}$  are obtained by regressing $y_n ^*$  on $z_n$ and $\hat{\nu}_n$.</span>
<span id="cb42-1445"><a href="#cb42-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1446"><a href="#cb42-1446" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb42-1447"><a href="#cb42-1447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1448"><a href="#cb42-1448" aria-hidden="true" tabindex="-1"></a>Regressing $y_n ^ *$ on a vector of 1, $x_{1n}$, $e_n$ and</span>
<span id="cb42-1449"><a href="#cb42-1449" aria-hidden="true" tabindex="-1"></a>$\hat{\nu}_n$ is one way to obtain the instrumental variable</span>
<span id="cb42-1450"><a href="#cb42-1450" aria-hidden="true" tabindex="-1"></a>estimator. This approach (called **control function**) is identical to</span>
<span id="cb42-1451"><a href="#cb42-1451" aria-hidden="true" tabindex="-1"></a>the 2SLS estimator but provides supplementary estimates</span>
<span id="cb42-1452"><a href="#cb42-1452" aria-hidden="true" tabindex="-1"></a>($\hat{\rho}$ associated with $\hat{\nu}_n$) that can be used to test the hypothesis of exogeneity. If $G = 1$, the test can be performed using the Student</span>
<span id="cb42-1453"><a href="#cb42-1453" aria-hidden="true" tabindex="-1"></a>statistic. If $G &gt; 1$, the joint hypothesis that $\rho= 0$ can be</span>
<span id="cb42-1454"><a href="#cb42-1454" aria-hidden="true" tabindex="-1"></a>tested using a Wald test, the statistic being a $\chi ^ 2$ with $G$</span>
<span id="cb42-1455"><a href="#cb42-1455" aria-hidden="true" tabindex="-1"></a>degrees of freedom under the null hypothesis of exogeneity.</span>
<span id="cb42-1456"><a href="#cb42-1456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1457"><a href="#cb42-1457" aria-hidden="true" tabindex="-1"></a>This two-step instrumental variable estimator and test has been extended for</span>
<span id="cb42-1458"><a href="#cb42-1458" aria-hidden="true" tabindex="-1"></a>the case where $y_n ^*$ is only partially observed by @SMIT:BLUN:86\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Smith}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Blundell} and</span>
<span id="cb42-1459"><a href="#cb42-1459" aria-hidden="true" tabindex="-1"></a>@RIVE:VUON:88\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Rivers}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Vuong} (respectively for the tobit and the probit models). It can be computed as follows:</span>
<span id="cb42-1460"><a href="#cb42-1460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1461"><a href="#cb42-1461" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>compute the OLS estimator of $\pi_g$ for the G endogenous variables</span>
<span id="cb42-1462"><a href="#cb42-1462" aria-hidden="true" tabindex="-1"></a>  and retrieve the residuals $\hat{\nu}_{gn}$,</span>
<span id="cb42-1463"><a href="#cb42-1463" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>estimate $\theta ^ \top = (\gamma ^ \top, \rho^\top)$ using a</span>
<span id="cb42-1464"><a href="#cb42-1464" aria-hidden="true" tabindex="-1"></a>  probit model with $z_n$, and $\hat{\nu}_n$ as covariates,</span>
<span id="cb42-1465"><a href="#cb42-1465" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>test the hypothesis that $\rho = 0$.</span>
<span id="cb42-1466"><a href="#cb42-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1467"><a href="#cb42-1467" aria-hidden="true" tabindex="-1"></a>As it is customary for two-step estimators, the covariance matrix</span>
<span id="cb42-1468"><a href="#cb42-1468" aria-hidden="true" tabindex="-1"></a>returned by the probit model is inconsistent</span>
<span id="cb42-1469"><a href="#cb42-1469" aria-hidden="true" tabindex="-1"></a>because it doesn't take into account the fact that $\nu_n$ is unknown</span>
<span id="cb42-1470"><a href="#cb42-1470" aria-hidden="true" tabindex="-1"></a>and is replaced by a consistent estimator. Denoting $\pi = \mbox{vec} \,\Pi$, the first-order approximation of the vector of scores is:</span>
<span id="cb42-1471"><a href="#cb42-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1472"><a href="#cb42-1472" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1473"><a href="#cb42-1473" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln L}{\partial \theta}(\hat{\theta}, \hat{\pi}) \approx</span>
<span id="cb42-1474"><a href="#cb42-1474" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln L}{\partial \theta} + </span>
<span id="cb42-1475"><a href="#cb42-1475" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln^2 L}{\partial \theta \partial \theta ^</span>
<span id="cb42-1476"><a href="#cb42-1476" aria-hidden="true" tabindex="-1"></a>\top}\times (\hat{\theta} - \theta) + </span>
<span id="cb42-1477"><a href="#cb42-1477" aria-hidden="true" tabindex="-1"></a>\frac{\partial \ln^2 L}{\partial \theta \partial \pi ^</span>
<span id="cb42-1478"><a href="#cb42-1478" aria-hidden="true" tabindex="-1"></a>\top}\times (\hat{\pi} - \pi)</span>
<span id="cb42-1479"><a href="#cb42-1479" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1480"><a href="#cb42-1480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1481"><a href="#cb42-1481" aria-hidden="true" tabindex="-1"></a>Taking expectation and solving for $\hat{\theta} - \theta$, we get:</span>
<span id="cb42-1482"><a href="#cb42-1482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1483"><a href="#cb42-1483" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1484"><a href="#cb42-1484" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- i_n = \theta ^ \top z_n + \rho ^ \top \hat{v}_n = \theta ^ \top u_n --&gt;</span></span>
<span id="cb42-1485"><a href="#cb42-1485" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1486"><a href="#cb42-1486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1487"><a href="#cb42-1487" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1488"><a href="#cb42-1488" aria-hidden="true" tabindex="-1"></a>\hat{\theta} - \theta = \mbox{E}\left(- \frac{\partial ^ 2 \ln L}{\partial</span>
<span id="cb42-1489"><a href="#cb42-1489" aria-hidden="true" tabindex="-1"></a>\theta \partial \theta ^ \top}\right)^{-1} \left(\frac{\partial \ln L}{\partial</span>
<span id="cb42-1490"><a href="#cb42-1490" aria-hidden="true" tabindex="-1"></a>\theta} + </span>
<span id="cb42-1491"><a href="#cb42-1491" aria-hidden="true" tabindex="-1"></a>\mbox{E}\left(\frac{\partial ^ 2 \ln L}{\partial</span>
<span id="cb42-1492"><a href="#cb42-1492" aria-hidden="true" tabindex="-1"></a>\theta \partial\pi ^ \top}\right) (\hat{\pi} - \pi)\right)</span>
<span id="cb42-1493"><a href="#cb42-1493" aria-hidden="true" tabindex="-1"></a>= A ^ {-1}\left(\frac{\partial \ln L}{\partial</span>
<span id="cb42-1494"><a href="#cb42-1494" aria-hidden="true" tabindex="-1"></a>\theta} + B (\hat{\pi} - \pi)\right)</span>
<span id="cb42-1495"><a href="#cb42-1495" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1496"><a href="#cb42-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1497"><a href="#cb42-1497" aria-hidden="true" tabindex="-1"></a>As the two terms in the brackets are uncorrelated and using the</span>
<span id="cb42-1498"><a href="#cb42-1498" aria-hidden="true" tabindex="-1"></a>information matrix equality, we get:</span>
<span id="cb42-1499"><a href="#cb42-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1500"><a href="#cb42-1500" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1501"><a href="#cb42-1501" aria-hidden="true" tabindex="-1"></a>\hat{V}({\hat{\theta}}) = A ^ {-1} + A ^ {-1} B \hat{V}(\hat{\pi}) B ^</span>
<span id="cb42-1502"><a href="#cb42-1502" aria-hidden="true" tabindex="-1"></a>\top A ^ {-1}</span>
<span id="cb42-1503"><a href="#cb42-1503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1504"><a href="#cb42-1504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1505"><a href="#cb42-1505" aria-hidden="true" tabindex="-1"></a>$A$ and $B$ contain the second derivatives of the individual</span>
<span id="cb42-1506"><a href="#cb42-1506" aria-hidden="true" tabindex="-1"></a>contribution to the log-likelihood function for the probit model. These are, defining: $\eta_n = \gamma ^ \top z_n + \rho \hat{\nu}_n$ and $r_n = \phi(\eta_n) / (1 - \Phi(\eta_n))$:</span>
<span id="cb42-1507"><a href="#cb42-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1508"><a href="#cb42-1508" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1509"><a href="#cb42-1509" aria-hidden="true" tabindex="-1"></a>\frac{\partial ^ 2\ln l_n}{\partial \eta_n \partial \eta_n ^ \top} = -</span>
<span id="cb42-1510"><a href="#cb42-1510" aria-hidden="true" tabindex="-1"></a>r_n \left(r_n + \eta_n \right) = - \psi_n</span>
<span id="cb42-1511"><a href="#cb42-1511" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1512"><a href="#cb42-1512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1513"><a href="#cb42-1513" aria-hidden="true" tabindex="-1"></a>More precisely, $A = \sum_{n=1} ^ N \psi_ n \hat{u}_n \hat{u}_n ^ \top$ and $B = \sum_{n=1} ^ N \rho ^ \top \otimes \psi_n \hat{u}_n w_n ^ \top$ or, defining $\Psi$ a diagonal matrix of dimension $N$  containing $\psi_n$: $A = \hat{U} ^ \top \Psi \hat{U}$ and $B = \hat{U} ^ \top \Psi W$, with</span>
<span id="cb42-1514"><a href="#cb42-1514" aria-hidden="true" tabindex="-1"></a>$\hat{U}$ the $N\times (K_1 + 2 G + 1)$ matrix with rows $(1, x_{1n} ^ \top, e_n ^ \top, \hat{\nu}_n ^\top)$ and $W$ the $N\times (K_1 + K_2 + 1)$ matrix with rows $w_n^\top = (1, x_{1n} ^ \top, x_{2n} ^ \top)$.</span>
<span id="cb42-1515"><a href="#cb42-1515" aria-hidden="true" tabindex="-1"></a>As $\hat{V}(\hat{\pi})$ is the variance of the SUR estimator with identical covariates, $\hat{V}(\hat{\pi}) = \hat{\Sigma}_\nu \otimes (W ^ \top W) ^ {-1}$ and the expression further simplifies to:</span>
<span id="cb42-1516"><a href="#cb42-1516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1517"><a href="#cb42-1517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1518"><a href="#cb42-1518" aria-hidden="true" tabindex="-1"></a>\hat{V}(\hat{\theta}) = </span>
<span id="cb42-1519"><a href="#cb42-1519" aria-hidden="true" tabindex="-1"></a>(\hat{U} ^ \top \Psi \hat{U}) ^ {-1} + </span>
<span id="cb42-1520"><a href="#cb42-1520" aria-hidden="true" tabindex="-1"></a>(\hat{\rho} ^ \top \hat{\Sigma} \hat{\rho})\times</span>
<span id="cb42-1521"><a href="#cb42-1521" aria-hidden="true" tabindex="-1"></a>(\hat{U} ^ \top \Psi \hat{U}) ^ {-1} (\hat{U} ^  \top \Psi W) (W ^ \top W) ^ {-1} (W ^  \top \Psi \hat{U}) (\hat{U} ^ \top \Psi \hat{U}) ^ {-1}</span>
<span id="cb42-1522"><a href="#cb42-1522" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1523"><a href="#cb42-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1524"><a href="#cb42-1524" aria-hidden="true" tabindex="-1"></a>@SMIT:BLUN:86\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Smith}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Blundell} proposed an endogeneity test based on the two-step estimator. As for the linear instrumental variable estimator, it is a Wald test that $\rho = 0$, but it uses the simple probit estimation of the covariance matrix.</span>
<span id="cb42-1525"><a href="#cb42-1525" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{two-step estimator!binomial model|)}</span>
<span id="cb42-1526"><a href="#cb42-1526" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{binomial model!two-step estimator|)}</span>
<span id="cb42-1527"><a href="#cb42-1527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1528"><a href="#cb42-1528" aria-hidden="true" tabindex="-1"></a><span class="fu">### Minimum $\chi ^ 2$ estimator</span></span>
<span id="cb42-1529"><a href="#cb42-1529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1530"><a href="#cb42-1530" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{minimum chi-squared estimator!binomial model|(}</span>
<span id="cb42-1531"><a href="#cb42-1531" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{binomial model!minimum chi-squared estimator|(}</span>
<span id="cb42-1532"><a href="#cb42-1532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1533"><a href="#cb42-1533" aria-hidden="true" tabindex="-1"></a>@NEWE:87\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Newey} argued that the minimum</span>
<span id="cb42-1534"><a href="#cb42-1534" aria-hidden="true" tabindex="-1"></a>chi-square estimator <span class="co">[</span><span class="ot">@AMEM:78's\index[author]{Amemiya}</span><span class="co">]</span> can be used in this context and is more efficient than the two-step estimator. This estimator is computed in five steps:</span>
<span id="cb42-1535"><a href="#cb42-1535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1536"><a href="#cb42-1536" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>compute the OLS estimator of $\pi_g$ for the $G$ endogenous variables</span>
<span id="cb42-1537"><a href="#cb42-1537" aria-hidden="true" tabindex="-1"></a>  and compute the fitted values $\hat{d}_{gn}$ and the residuals</span>
<span id="cb42-1538"><a href="#cb42-1538" aria-hidden="true" tabindex="-1"></a>  $\hat{\nu}_{gn}$ of these regressions,</span>
<span id="cb42-1539"><a href="#cb42-1539" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>using a probit regress $y$ on the whole set of exogenous</span>
<span id="cb42-1540"><a href="#cb42-1540" aria-hidden="true" tabindex="-1"></a>  variables $w_n ^ \top = (1, x_{n1} ^ \top, x_{n2} ^ \top)$ and on the previously computed residuals</span>
<span id="cb42-1541"><a href="#cb42-1541" aria-hidden="true" tabindex="-1"></a>  $\hat{\nu}_{gn}$. Save the coefficients of $v_n$ ($\hat{\alpha}$), of</span>
<span id="cb42-1542"><a href="#cb42-1542" aria-hidden="true" tabindex="-1"></a>  $\hat{\nu}_n$ ($\hat{\lambda}$) and the part of the covariance matrix</span>
<span id="cb42-1543"><a href="#cb42-1543" aria-hidden="true" tabindex="-1"></a>  that corresponds to $\alpha$  $\hat{\Sigma}_{1}$,</span>
<span id="cb42-1544"><a href="#cb42-1544" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>using a probit, regress $y$ on </span>
<span id="cb42-1545"><a href="#cb42-1545" aria-hidden="true" tabindex="-1"></a>  $\hat{u}_n^\top = (1, x_1^\top, \hat{\nu}_n ^ \top)$ and on the fitted values $\hat{d}_{gn}$ computed on the first step; save the coefficients of the fitted values $\hat{\delta}$ and compute $\hat{\rho} = \hat{\lambda} - \hat{\delta}$,</span>
<span id="cb42-1546"><a href="#cb42-1546" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>regress $\hat{\rho} ^ \top e_n$ on the whole set of exogenous</span>
<span id="cb42-1547"><a href="#cb42-1547" aria-hidden="true" tabindex="-1"></a>  variables $w_n$, save the covariance matrix $\hat{\Sigma}_{2}$ and</span>
<span id="cb42-1548"><a href="#cb42-1548" aria-hidden="true" tabindex="-1"></a>  compute $\hat{\Omega} = \hat{\Sigma}_1 + \hat{\Sigma}_2$,</span>
<span id="cb42-1549"><a href="#cb42-1549" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>compute the minimum $\chi^2$ estimator $\hat{\gamma}$ and</span>
<span id="cb42-1550"><a href="#cb42-1550" aria-hidden="true" tabindex="-1"></a>  its variance $\hat{V}(\hat{\gamma})$:</span>
<span id="cb42-1551"><a href="#cb42-1551" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-1552"><a href="#cb42-1552" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1553"><a href="#cb42-1553" aria-hidden="true" tabindex="-1"></a>\hat{V}(\hat{\gamma}) = (Z^\top W) (W^\top W) ^ {-1} \hat{\Omega} ^</span>
<span id="cb42-1554"><a href="#cb42-1554" aria-hidden="true" tabindex="-1"></a>  {-1} (W^\top W) ^ {-1} (W ^ \top Z)</span>
<span id="cb42-1555"><a href="#cb42-1555" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1556"><a href="#cb42-1556" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb42-1557"><a href="#cb42-1557" aria-hidden="true" tabindex="-1"></a>$$\hat{\gamma}</span>
<span id="cb42-1558"><a href="#cb42-1558" aria-hidden="true" tabindex="-1"></a>  = \hat{V}(\hat{\gamma}) (Z^\top W) (W^\top W) ^ {-1} \hat{\Omega} ^ {-1}</span>
<span id="cb42-1559"><a href="#cb42-1559" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1560"><a href="#cb42-1560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1561"><a href="#cb42-1561" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{binomial model!minimum chi-squared estimator|)}</span>
<span id="cb42-1562"><a href="#cb42-1562" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{minimum chi-squared estimator!binomial model|)}</span>
<span id="cb42-1563"><a href="#cb42-1563" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{endogeneity!probit|)}</span>
<span id="cb42-1564"><a href="#cb42-1564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1565"><a href="#cb42-1565" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application</span></span>
<span id="cb42-1566"><a href="#cb42-1566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1567"><a href="#cb42-1567" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{federiv}{micsr}</span>
<span id="cb42-1568"><a href="#cb42-1568" aria-hidden="true" tabindex="-1"></a>@ADKI:CART:SIMP:07\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Adkins}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Carter}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Simpson} and @ADKI:12\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Adkins} analyzed the effect of managerial incentives on the use of foreign-exchange derivatives for hedging by U.S. bank holding companies, for the 1996-2000 period. The dependent variable <span class="in">`federiv`</span> is 1 if the bank uses foreign-exchange derivatives.</span>
<span id="cb42-1569"><a href="#cb42-1569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1570"><a href="#cb42-1570" aria-hidden="true" tabindex="-1"></a>The first set of covariates concerns ownership. When managers have a higher ownership position in the bank, their behavior is more in line with the preferences of shareholders, and they therefore have an incentive to take risk: the logarithm of the percentage of total shares outstanding that are owned by officers and directors (<span class="in">`linsown`</span>) should therefore have a negative effect on the probability of using foreign-exchange derivatives. However, incentives provided by regulation may dominate the expected incentive relation and lead to a negative effect on the probability. On the contrary, institutional blockholders have imperfect information and, therefore, the logarithm of the percentage of total shares outstanding that are owned by all institutional investors (<span class="in">`linstown`</span>) should have a negative effect on the probability of using foreign-exchange derivatives. </span>
<span id="cb42-1571"><a href="#cb42-1571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1572"><a href="#cb42-1572" aria-hidden="true" tabindex="-1"></a>The second set of covariates concerns CEO compensation. Value of option awards (<span class="in">`optval`</span>) should induce managers to take more risk and therefore should have a negative effect on the probability. On the contrary, cash bonus (<span class="in">`bonus`</span>) may increase the probability of hedging in order to decrease variability in the firm's cash flows.</span>
<span id="cb42-1573"><a href="#cb42-1573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1574"><a href="#cb42-1574" aria-hidden="true" tabindex="-1"></a>The other covariates are the leverage (<span class="in">`eqrat`</span>), the logarithm of total assets (<span class="in">`ltass`</span>),  the return on equity (<span class="in">`roe`</span>), the market to book ratio (<span class="in">`mktbt`</span>), the foreign to total interest income ratio (<span class="in">`perfor`</span>), a derivative dealer activity dummy (<span class="in">`dealdum`</span>), dividends paid (<span class="in">`div`</span>) and the year from 1996 to 2000 (<span class="in">`year`</span>). </span>
<span id="cb42-1575"><a href="#cb42-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1576"><a href="#cb42-1576" aria-hidden="true" tabindex="-1"></a>Three covariates are suspected to be endogenous: the leverage (<span class="in">`eqrat`</span>), the option awards <span class="in">`optval`</span> and the bonus, (<span class="in">`bonus`</span>). The external instruments are the number of employees (<span class="in">`no_emp`</span>), of subsidiaries (<span class="in">`no_subs`</span>) and of officies (<span class="in">`no_off`</span>), the CEO age (<span class="in">`ceo_age`</span>), the 12 month maturity mismatch (<span class="in">`gap`</span>) and the ratio of cash flow to total assets (<span class="in">`cfa`</span>). </span>
<span id="cb42-1577"><a href="#cb42-1577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1578"><a href="#cb42-1578" aria-hidden="true" tabindex="-1"></a>The instrumental variable probit estimator is obtained using <span class="in">`binomreg`</span> with <span class="in">`link = "probit"`</span> and a two-part formula, containing the covariates and the instruments. The method argument (the default <span class="in">`"ml"`</span>, <span class="in">`"twosteps"`</span> and <span class="in">`"min"`</span>) indicates the estimation method. The results for the three estimators are presented in @tbl-resbank. To save place, we only present the coefficients for the covariates of main interest.</span>
<span id="cb42-1579"><a href="#cb42-1579" aria-hidden="true" tabindex="-1"></a>\idxfun{binomreg}{micsr}\idxfun{update}{stats}</span>
<span id="cb42-1580"><a href="#cb42-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1581"><a href="#cb42-1581" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1582"><a href="#cb42-1582" aria-hidden="true" tabindex="-1"></a>form <span class="ot">&lt;-</span> federiv <span class="sc">~</span> eqrat <span class="sc">+</span> optval <span class="sc">+</span> bonus <span class="sc">+</span> ltass <span class="sc">+</span> </span>
<span id="cb42-1583"><a href="#cb42-1583" aria-hidden="true" tabindex="-1"></a>                      linsown <span class="sc">+</span> linstown <span class="sc">+</span> roe <span class="sc">+</span> mktbk <span class="sc">+</span> </span>
<span id="cb42-1584"><a href="#cb42-1584" aria-hidden="true" tabindex="-1"></a>                      perfor <span class="sc">+</span> dealdum <span class="sc">+</span> div <span class="sc">+</span> year <span class="sc">|</span></span>
<span id="cb42-1585"><a href="#cb42-1585" aria-hidden="true" tabindex="-1"></a>                        . <span class="sc">-</span> eqrat <span class="sc">-</span> bonus <span class="sc">-</span> optval <span class="sc">+</span> no_emp <span class="sc">+</span> </span>
<span id="cb42-1586"><a href="#cb42-1586" aria-hidden="true" tabindex="-1"></a>                      no_subs <span class="sc">+</span> no_off <span class="sc">+</span> ceo_age <span class="sc">+</span> gap <span class="sc">+</span> cfa</span>
<span id="cb42-1587"><a href="#cb42-1587" aria-hidden="true" tabindex="-1"></a>bank_msq <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(form, <span class="at">data =</span> federiv, <span class="at">link =</span> <span class="st">"probit"</span>,</span>
<span id="cb42-1588"><a href="#cb42-1588" aria-hidden="true" tabindex="-1"></a>                    <span class="at">method =</span> <span class="st">"minchisq"</span>)</span>
<span id="cb42-1589"><a href="#cb42-1589" aria-hidden="true" tabindex="-1"></a>bank_ml <span class="ot">&lt;-</span> <span class="fu">update</span>(bank_msq, <span class="at">method =</span> <span class="st">"ml"</span>)</span>
<span id="cb42-1590"><a href="#cb42-1590" aria-hidden="true" tabindex="-1"></a>bank_2st <span class="ot">&lt;-</span> <span class="fu">update</span>(bank_msq, <span class="at">method =</span> <span class="st">"twosteps"</span>)</span>
<span id="cb42-1591"><a href="#cb42-1591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1592"><a href="#cb42-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1593"><a href="#cb42-1593" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1594"><a href="#cb42-1594" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-resbank</span></span>
<span id="cb42-1595"><a href="#cb42-1595" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1596"><a href="#cb42-1596" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-1597"><a href="#cb42-1597" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "IV probit models for the bank data set"</span></span>
<span id="cb42-1598"><a href="#cb42-1598" aria-hidden="true" tabindex="-1"></a>modelsummary<span class="sc">::</span><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="st">"minchisq"</span> <span class="ot">=</span> bank_msq, <span class="st">"two-step"</span> <span class="ot">=</span> bank_2st, <span class="st">"ML"</span> <span class="ot">=</span> bank_ml),</span>
<span id="cb42-1599"><a href="#cb42-1599" aria-hidden="true" tabindex="-1"></a>                       <span class="at">coef_omit =</span> (<span class="st">"year|Intercept|ltass|roe|mktbk|perfor|dealdum|div"</span>),</span>
<span id="cb42-1600"><a href="#cb42-1600" aria-hidden="true" tabindex="-1"></a>                       <span class="at">gof_omit =</span> <span class="st">"AIC|BIC|Log.Lik."</span>,</span>
<span id="cb42-1601"><a href="#cb42-1601" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output =</span> <span class="st">"kableExtra"</span>)</span>
<span id="cb42-1602"><a href="#cb42-1602" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1603"><a href="#cb42-1603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1604"><a href="#cb42-1604" aria-hidden="true" tabindex="-1"></a>The coefficients of <span class="in">`linstown`</span>, <span class="in">`bonus`</span> and <span class="in">`optval`</span> have the expected sign. <span class="in">`linsown`</span> has a positive sign, which must be driven by the strength of the regulatory constraints. Note that the standard deviations are much smaller for the highly parametrized ML estimator, compared to the two-step and the minimum $\chi^2$ estimator.</span>
<span id="cb42-1605"><a href="#cb42-1605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1606"><a href="#cb42-1606" aria-hidden="true" tabindex="-1"></a>To perform the endogeneity test, we first estimate the two-step estimator with the probit estimator of the covariance matrix of the coefficients. This is performed by setting the supplementary argument <span class="in">`robust`</span> to <span class="in">`FALSE`</span>:</span>
<span id="cb42-1607"><a href="#cb42-1607" aria-hidden="true" tabindex="-1"></a>\idxfun{binomreg}{micsr}</span>
<span id="cb42-1608"><a href="#cb42-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1611"><a href="#cb42-1611" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1612"><a href="#cb42-1612" aria-hidden="true" tabindex="-1"></a>bank_2s_nr <span class="ot">&lt;-</span> <span class="fu">binomreg</span>(form, <span class="at">data =</span> federiv, <span class="at">link =</span> <span class="st">"probit"</span>, </span>
<span id="cb42-1613"><a href="#cb42-1613" aria-hidden="true" tabindex="-1"></a>                       <span class="at">method =</span> <span class="st">"twosteps"</span>, <span class="at">robust =</span> <span class="cn">FALSE</span>)</span>
<span id="cb42-1614"><a href="#cb42-1614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1615"><a href="#cb42-1615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1616"><a href="#cb42-1616" aria-hidden="true" tabindex="-1"></a>Then, a Wald test that $\rho = 0$ can be performed, using for example <span class="in">`car::linearHypothesis`</span>:</span>
<span id="cb42-1617"><a href="#cb42-1617" aria-hidden="true" tabindex="-1"></a>\idxfun{linearHypothesis}{car}</span>
<span id="cb42-1618"><a href="#cb42-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1621"><a href="#cb42-1621" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1622"><a href="#cb42-1622" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1623"><a href="#cb42-1623" aria-hidden="true" tabindex="-1"></a>bank_2s_nr <span class="sc">%&gt;%</span> car<span class="sc">::</span><span class="fu">linearHypothesis</span>(<span class="fu">c</span>(<span class="st">"rho_eqrat = 0"</span>, </span>
<span id="cb42-1624"><a href="#cb42-1624" aria-hidden="true" tabindex="-1"></a>                                       <span class="st">"rho_optval = 0"</span>, </span>
<span id="cb42-1625"><a href="#cb42-1625" aria-hidden="true" tabindex="-1"></a>                                       <span class="st">"rho_bonus = 0"</span>)) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1626"><a href="#cb42-1626" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1627"><a href="#cb42-1627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1628"><a href="#cb42-1628" aria-hidden="true" tabindex="-1"></a>or more simply using the <span class="in">`miscsr::endogtest`</span> function:</span>
<span id="cb42-1629"><a href="#cb42-1629" aria-hidden="true" tabindex="-1"></a>\idxfun{endogtest}{micsr}\idxfun{gaze}{micsr}</span>
<span id="cb42-1630"><a href="#cb42-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1633"><a href="#cb42-1633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1634"><a href="#cb42-1634" aria-hidden="true" tabindex="-1"></a><span class="co">#| collapse: true</span></span>
<span id="cb42-1635"><a href="#cb42-1635" aria-hidden="true" tabindex="-1"></a><span class="fu">endogtest</span>(form, federiv) <span class="sc">%&gt;%</span> gaze</span>
<span id="cb42-1636"><a href="#cb42-1636" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1637"><a href="#cb42-1637" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{federiv}{micsr}</span>
<span id="cb42-1638"><a href="#cb42-1638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1639"><a href="#cb42-1639" aria-hidden="true" tabindex="-1"></a>The hypothesis of no endogeneity is rejected at the 10%, but not at the 5% level.</span>
<span id="cb42-1640"><a href="#cb42-1640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1641"><a href="#cb42-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1642"><a href="#cb42-1642" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r } --&gt;</span></span>
<span id="cb42-1643"><a href="#cb42-1643" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #| eval: false --&gt;</span></span>
<span id="cb42-1644"><a href="#cb42-1644" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #| include: false --&gt;</span></span>
<span id="cb42-1645"><a href="#cb42-1645" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #' @rdname get_predict --&gt;</span></span>
<span id="cb42-1646"><a href="#cb42-1646" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #' @export --&gt;</span></span>
<span id="cb42-1647"><a href="#cb42-1647" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- get_predict.micsr &lt;- function(model, --&gt;</span></span>
<span id="cb42-1648"><a href="#cb42-1648" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                               newdata = insight::get_data(model), --&gt;</span></span>
<span id="cb42-1649"><a href="#cb42-1649" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                               vcov = NULL, --&gt;</span></span>
<span id="cb42-1650"><a href="#cb42-1650" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                               conf_level = 0.95, --&gt;</span></span>
<span id="cb42-1651"><a href="#cb42-1651" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                               type = "response", --&gt;</span></span>
<span id="cb42-1652"><a href="#cb42-1652" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                                ...) { --&gt;</span></span>
<span id="cb42-1653"><a href="#cb42-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1654"><a href="#cb42-1654" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     out &lt;- stats::predict(model, what = type, newdata = newdata) --&gt;</span></span>
<span id="cb42-1655"><a href="#cb42-1655" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     out &lt;- data.frame(rowid = seq_len(length(out)), predicted = out) --&gt;</span></span>
<span id="cb42-1656"><a href="#cb42-1656" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     return(out) --&gt;</span></span>
<span id="cb42-1657"><a href="#cb42-1657" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- } --&gt;</span></span>
<span id="cb42-1658"><a href="#cb42-1658" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb42-1659"><a href="#cb42-1659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1660"><a href="#cb42-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1661"><a href="#cb42-1661" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ordered models {#sec-ordered}</span></span>
<span id="cb42-1662"><a href="#cb42-1662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1663"><a href="#cb42-1663" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{ordered model|(}</span>
<span id="cb42-1664"><a href="#cb42-1664" aria-hidden="true" tabindex="-1"></a>An ordered model is a model for which the response can take $J$</span>
<span id="cb42-1665"><a href="#cb42-1665" aria-hidden="true" tabindex="-1"></a>distinct values (with $J&gt;2$). The construction of the model is very</span>
<span id="cb42-1666"><a href="#cb42-1666" aria-hidden="true" tabindex="-1"></a>similar to the one of the binomial model. We consider, as in @sec-latent_variable, a latent</span>
<span id="cb42-1667"><a href="#cb42-1667" aria-hidden="true" tabindex="-1"></a>variable equal to the sum of a linear combination of the</span>
<span id="cb42-1668"><a href="#cb42-1668" aria-hidden="true" tabindex="-1"></a>covariates and an error:\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{latent variable!ordered model}</span>
<span id="cb42-1669"><a href="#cb42-1669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1670"><a href="#cb42-1670" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1671"><a href="#cb42-1671" aria-hidden="true" tabindex="-1"></a>y^* = \alpha + \beta^\top x + \epsilon</span>
<span id="cb42-1672"><a href="#cb42-1672" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1673"><a href="#cb42-1673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1674"><a href="#cb42-1674" aria-hidden="true" tabindex="-1"></a>Denoting $\mu = (\mu_0, \mu_1, \mu_1, \ldots, \mu_{J})$ a vector of</span>
<span id="cb42-1675"><a href="#cb42-1675" aria-hidden="true" tabindex="-1"></a>parameters, with $\mu_0 = -\infty$ and $\mu_{J}= +\infty$, the rule of</span>
<span id="cb42-1676"><a href="#cb42-1676" aria-hidden="true" tabindex="-1"></a>observation for the different values of $y$ is then:</span>
<span id="cb42-1677"><a href="#cb42-1677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1678"><a href="#cb42-1678" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1679"><a href="#cb42-1679" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span></span>
<span id="cb42-1680"><a href="#cb42-1680" aria-hidden="true" tabindex="-1"></a>\begin{array}{rclcclccc}</span>
<span id="cb42-1681"><a href="#cb42-1681" aria-hidden="true" tabindex="-1"></a>y &amp;=&amp; 1 &amp;  \Leftrightarrow &amp; \mu_0 &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_1 <span class="sc">\\</span></span>
<span id="cb42-1682"><a href="#cb42-1682" aria-hidden="true" tabindex="-1"></a>y &amp;=&amp; 2 &amp;  \Leftrightarrow &amp; \mu_1 &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_2 <span class="sc">\\</span></span>
<span id="cb42-1683"><a href="#cb42-1683" aria-hidden="true" tabindex="-1"></a>&amp;\vdots &amp;  &amp; \vdots &amp;&amp; \vdots &amp; &amp; \vdots<span class="sc">\\</span></span>
<span id="cb42-1684"><a href="#cb42-1684" aria-hidden="true" tabindex="-1"></a>y &amp;=&amp; J-1 &amp;  \Leftrightarrow &amp; \mu_{J-2} &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_{J-1} <span class="sc">\\</span></span>
<span id="cb42-1685"><a href="#cb42-1685" aria-hidden="true" tabindex="-1"></a>y &amp;=&amp; J &amp;  \Leftrightarrow &amp; \mu_{J-1} &amp;\leq&amp; \alpha + \beta^\top x + \epsilon &amp;\leq&amp; \mu_{J}<span class="sc">\\</span></span>
<span id="cb42-1686"><a href="#cb42-1686" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb42-1687"><a href="#cb42-1687" aria-hidden="true" tabindex="-1"></a>\right.</span>
<span id="cb42-1688"><a href="#cb42-1688" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1689"><a href="#cb42-1689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1690"><a href="#cb42-1690" aria-hidden="true" tabindex="-1"></a>For $y = 1$, subtracting $\alpha$ from the three terms of the inequality, we get:</span>
<span id="cb42-1691"><a href="#cb42-1691" aria-hidden="true" tabindex="-1"></a>$\mu_0 - \alpha \leq \beta ^ \top x + \epsilon \leq \mu_1 - \alpha$. Therefore, the observation rule doesn't depend on $\mu_0$, $\mu_1$ and $\alpha$, but on $\mu_0-\alpha$ and $\mu_1 - \alpha$. Therefore, $\mu_0$, $\mu_1$ and $\alpha$ are not identified and, for example, $\alpha$ can be set to 0. The same reasoning applies to the other values of $y$. </span>
<span id="cb42-1692"><a href="#cb42-1692" aria-hidden="true" tabindex="-1"></a>Denoting $F$ the cumulative density of $\epsilon$, the probability for a</span>
<span id="cb42-1693"><a href="#cb42-1693" aria-hidden="true" tabindex="-1"></a>given value $j$ of $y$ is:</span>
<span id="cb42-1694"><a href="#cb42-1694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1695"><a href="#cb42-1695" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1696"><a href="#cb42-1696" aria-hidden="true" tabindex="-1"></a>\mbox{P}(y_n=j)=F(\mu_{j} - \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)</span>
<span id="cb42-1697"><a href="#cb42-1697" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1698"><a href="#cb42-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1699"><a href="#cb42-1699" aria-hidden="true" tabindex="-1"></a>The probabilities are represented in @fig-ordered1 for $J</span>
<span id="cb42-1700"><a href="#cb42-1700" aria-hidden="true" tabindex="-1"></a>= 3$ by the areas under the density curve of $\epsilon$ between</span>
<span id="cb42-1701"><a href="#cb42-1701" aria-hidden="true" tabindex="-1"></a>two consecutive values of $\mu_j - \beta ^ \top x$ (with $\mu_0 =</span>
<span id="cb42-1702"><a href="#cb42-1702" aria-hidden="true" tabindex="-1"></a>-\infty$ and $\mu_3 = + \infty$).</span>
<span id="cb42-1703"><a href="#cb42-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1704"><a href="#cb42-1704" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1705"><a href="#cb42-1705" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ordered1</span></span>
<span id="cb42-1706"><a href="#cb42-1706" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Probabilities for an ordered model"</span></span>
<span id="cb42-1707"><a href="#cb42-1707" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1708"><a href="#cb42-1708" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/ordered1.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-1709"><a href="#cb42-1709" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1710"><a href="#cb42-1710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1711"><a href="#cb42-1711" aria-hidden="true" tabindex="-1"></a>Consider now an increase of a covariate $x_k$ and suppose that the</span>
<span id="cb42-1712"><a href="#cb42-1712" aria-hidden="true" tabindex="-1"></a>associated coefficient $\beta_k$ is positive. Then, all the values of $\mu_j -</span>
<span id="cb42-1713"><a href="#cb42-1713" aria-hidden="true" tabindex="-1"></a>\beta^ \top x$ decrease by the same amount $-\beta_k  \Delta</span>
<span id="cb42-1714"><a href="#cb42-1714" aria-hidden="true" tabindex="-1"></a>x_k$. The new probabilities are represented in @fig-ordered2.</span>
<span id="cb42-1715"><a href="#cb42-1715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1716"><a href="#cb42-1716" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1717"><a href="#cb42-1717" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ordered2</span></span>
<span id="cb42-1718"><a href="#cb42-1718" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Marginal effects for an ordered model"</span></span>
<span id="cb42-1719"><a href="#cb42-1719" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1720"><a href="#cb42-1720" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"./tikz/fig/ordered2.png"</span>, <span class="at">auto_pdf =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-1721"><a href="#cb42-1721" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1722"><a href="#cb42-1722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1723"><a href="#cb42-1723" aria-hidden="true" tabindex="-1"></a>The dashed area represents an increase of the probability that $y = 2$ and a</span>
<span id="cb42-1724"><a href="#cb42-1724" aria-hidden="true" tabindex="-1"></a>reduction of the probability that $y = 1$, and the dotted area a</span>
<span id="cb42-1725"><a href="#cb42-1725" aria-hidden="true" tabindex="-1"></a>reduction of the probability that $y = 2$ and an increase of the</span>
<span id="cb42-1726"><a href="#cb42-1726" aria-hidden="true" tabindex="-1"></a>probability that $y = 3$. Therefore, the marginal effect of $x_k$ is positive for $\mbox{P}(y = 3)$, negative for $\mbox{P}(y = 1)$  and ambiguous for $\mbox{P}(y = 2)$. For small changes of $x_k$ the dashed and dotted areas are</span>
<span id="cb42-1727"><a href="#cb42-1727" aria-hidden="true" tabindex="-1"></a>proportional to the densities for the two limits of the range of</span>
<span id="cb42-1728"><a href="#cb42-1728" aria-hidden="true" tabindex="-1"></a>$\epsilon$ for which $y = 2$. Therefore $\mbox{P}(y = 2)$ increases if</span>
<span id="cb42-1729"><a href="#cb42-1729" aria-hidden="true" tabindex="-1"></a>the density for the lower limit ($\mu_1 - \beta ^ \top x$) is greater</span>
<span id="cb42-1730"><a href="#cb42-1730" aria-hidden="true" tabindex="-1"></a>than the density for the upper limit ($\mu_2 - \beta ^ \top x$), which</span>
<span id="cb42-1731"><a href="#cb42-1731" aria-hidden="true" tabindex="-1"></a>is the case here, and decrease otherwise.</span>
<span id="cb42-1732"><a href="#cb42-1732" aria-hidden="true" tabindex="-1"></a>More generally, when $y$ takes $J$ values, the effect on the</span>
<span id="cb42-1733"><a href="#cb42-1733" aria-hidden="true" tabindex="-1"></a>probabilities is unambiguous only for $\mbox{P}(y = 1)$ and $\mbox{P}(y = J)$.</span>
<span id="cb42-1734"><a href="#cb42-1734" aria-hidden="true" tabindex="-1"></a>The probability of the outcome can be written compactly using the $\mathbf{1}(x)$ function which equals 1 if $x$ is true and 0 otherwise:</span>
<span id="cb42-1735"><a href="#cb42-1735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1736"><a href="#cb42-1736" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb42-1737"><a href="#cb42-1737" aria-hidden="true" tabindex="-1"></a>  \mbox{P}(y_n)=\sum_{j=1}^J \mathbf{1}(y_n = j)\left<span class="co">[</span><span class="ot">F(\mu_{j} - \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)\right</span><span class="co">]</span></span>
<span id="cb42-1738"><a href="#cb42-1738" aria-hidden="true" tabindex="-1"></a>$$ {#eq-probord}</span>
<span id="cb42-1739"><a href="#cb42-1739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1740"><a href="#cb42-1740" aria-hidden="true" tabindex="-1"></a>For a sample of size $N$, the log-likelihood function is obtained by</span>
<span id="cb42-1741"><a href="#cb42-1741" aria-hidden="true" tabindex="-1"></a>  summing the logarithms of @eq-probord for all the</span>
<span id="cb42-1742"><a href="#cb42-1742" aria-hidden="true" tabindex="-1"></a>  observations:</span>
<span id="cb42-1743"><a href="#cb42-1743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1744"><a href="#cb42-1744" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1745"><a href="#cb42-1745" aria-hidden="true" tabindex="-1"></a>\ln L = \sum_{n=1}^{N} \sum_{j = 1}^J\mathbf{1}(y_n = j)\ln \left[F(\mu_j -</span>
<span id="cb42-1746"><a href="#cb42-1746" aria-hidden="true" tabindex="-1"></a>  \beta^\top x_n) - F(\mu_{j-1} - \beta^\top x_n)\right]</span>
<span id="cb42-1747"><a href="#cb42-1747" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1748"><a href="#cb42-1748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1749"><a href="#cb42-1749" aria-hidden="true" tabindex="-1"></a>As for the binomial model, the most common choices for the</span>
<span id="cb42-1750"><a href="#cb42-1750" aria-hidden="true" tabindex="-1"></a>distribution of $\epsilon$ are the normal and the logistic</span>
<span id="cb42-1751"><a href="#cb42-1751" aria-hidden="true" tabindex="-1"></a>distributions, which lead respectively to the ordered probit and logit</span>
<span id="cb42-1752"><a href="#cb42-1752" aria-hidden="true" tabindex="-1"></a>models.</span>
<span id="cb42-1753"><a href="#cb42-1753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1754"><a href="#cb42-1754" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">(</span><span class="co">]</span>{fin<span class="sc">\_</span>reform}{micsr}</span>
<span id="cb42-1755"><a href="#cb42-1755" aria-hidden="true" tabindex="-1"></a>As an example, we consider the article of @ABIA:MODY:05\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Abiad}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Mody} who study</span>
<span id="cb42-1756"><a href="#cb42-1756" aria-hidden="true" tabindex="-1"></a>the determinants of financial reform. The data set, called <span class="in">`fin_reform`</span>, is a panel of 35 countries for 24 years (from 1973 to 1996). The variable of interest <span class="in">`fli`</span></span>
<span id="cb42-1757"><a href="#cb42-1757" aria-hidden="true" tabindex="-1"></a>is an index of financial liberalization, which takes integer values from</span>
<span id="cb42-1758"><a href="#cb42-1758" aria-hidden="true" tabindex="-1"></a>0 to 18. Denote $I_{nt}$ the value of this variable for country $n$ on year $t$ divided by 18, so that $I_{nt}$ equal to 0 or to 1 indicates respectively no and perfect financial liberalization. It is assumed that the yearly variation of the index is given by the following equation, denoting $I^*_{nt}$ the desired value of $I_{nt}$:</span>
<span id="cb42-1759"><a href="#cb42-1759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1760"><a href="#cb42-1760" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1761"><a href="#cb42-1761" aria-hidden="true" tabindex="-1"></a>\Delta I_{nt} = \alpha(I ^ *_{nt} - I_{n(t-1)}) + \epsilon_{nt}</span>
<span id="cb42-1762"><a href="#cb42-1762" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1763"><a href="#cb42-1763" aria-hidden="true" tabindex="-1"></a>$I^*$ is unobserved and is supposed to be equal to 1, so that the target  is perfect financial liberalization. $\alpha$ is an adjustment factor and is supposed to be equal to $\alpha = \theta I_{n(t-1)}$, so that the resistance to reform is a function of the state of liberalization. We then have:</span>
<span id="cb42-1764"><a href="#cb42-1764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1765"><a href="#cb42-1765" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1766"><a href="#cb42-1766" aria-hidden="true" tabindex="-1"></a>\Delta I_{nt} = \theta I_{n(t-1)}(1 - I_{n(t-1)}) + \epsilon_{nt}</span>
<span id="cb42-1767"><a href="#cb42-1767" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1768"><a href="#cb42-1768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1769"><a href="#cb42-1769" aria-hidden="true" tabindex="-1"></a>The response is therefore the change in the index and the main</span>
<span id="cb42-1770"><a href="#cb42-1770" aria-hidden="true" tabindex="-1"></a>covariate is <span class="in">`indxl`</span> $\times$ <span class="in">`(1 - indxl)`</span> where <span class="in">`indxl`</span> is the lagged value of</span>
<span id="cb42-1771"><a href="#cb42-1771" aria-hidden="true" tabindex="-1"></a>the index on the 0-1 scale. The computation of these variables are</span>
<span id="cb42-1772"><a href="#cb42-1772" aria-hidden="true" tabindex="-1"></a>presented below; note the use of the <span class="in">`lag`</span> function on the data frame</span>
<span id="cb42-1773"><a href="#cb42-1773" aria-hidden="true" tabindex="-1"></a>grouped by <span class="in">`country`</span>. This ensures that the lag value for the</span>
<span id="cb42-1774"><a href="#cb42-1774" aria-hidden="true" tabindex="-1"></a>first year (1973) for the second country (Australia) is <span class="in">`NA`</span> and not</span>
<span id="cb42-1775"><a href="#cb42-1775" aria-hidden="true" tabindex="-1"></a>the value of the first country (Argentina) for the last year (1996).</span>
<span id="cb42-1776"><a href="#cb42-1776" aria-hidden="true" tabindex="-1"></a>\idxfun{group<span class="sc">\_</span>by}{dplyr}\idxfun{mutate}{dplyr}\idxfun{ungroup}{dplyr}\idxfun{lag}{dplyr}</span>
<span id="cb42-1777"><a href="#cb42-1777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1778"><a href="#cb42-1778" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1779"><a href="#cb42-1779" aria-hidden="true" tabindex="-1"></a>fin_reform <span class="ot">&lt;-</span> fin_reform <span class="sc">%&gt;%</span></span>
<span id="cb42-1780"><a href="#cb42-1780" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(country) <span class="sc">%&gt;%</span></span>
<span id="cb42-1781"><a href="#cb42-1781" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">dindx =</span> fli <span class="sc">-</span> <span class="fu">lag</span>(fli),</span>
<span id="cb42-1782"><a href="#cb42-1782" aria-hidden="true" tabindex="-1"></a>           <span class="at">indx =</span> fli <span class="sc">/</span> <span class="dv">18</span>,</span>
<span id="cb42-1783"><a href="#cb42-1783" aria-hidden="true" tabindex="-1"></a>           <span class="at">indxl =</span> <span class="fu">lag</span>(indx),</span>
<span id="cb42-1784"><a href="#cb42-1784" aria-hidden="true" tabindex="-1"></a>           <span class="at">rhs1 =</span> indxl <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> indxl)) <span class="sc">%&gt;%</span></span>
<span id="cb42-1785"><a href="#cb42-1785" aria-hidden="true" tabindex="-1"></a>    ungroup</span>
<span id="cb42-1786"><a href="#cb42-1786" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1787"><a href="#cb42-1787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1790"><a href="#cb42-1790" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1791"><a href="#cb42-1791" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb42-1792"><a href="#cb42-1792" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-1793"><a href="#cb42-1793" aria-hidden="true" tabindex="-1"></a>fin_reform <span class="ot">&lt;-</span> fin_reform <span class="sc">%&gt;%</span> </span>
<span id="cb42-1794"><a href="#cb42-1794" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cls =</span> <span class="fu">case_when</span>(dindx <span class="sc">&lt;=</span> <span class="sc">-</span><span class="dv">3</span> <span class="sc">~</span> <span class="st">"large_reversal"</span>,</span>
<span id="cb42-1795"><a href="#cb42-1795" aria-hidden="true" tabindex="-1"></a>                         dindx <span class="sc">%in%</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>) <span class="sc">~</span> <span class="st">"reversal"</span>,</span>
<span id="cb42-1796"><a href="#cb42-1796" aria-hidden="true" tabindex="-1"></a>                         dindx <span class="sc">==</span> <span class="dv">0</span> <span class="sc">~</span> <span class="st">"status_quo"</span>,</span>
<span id="cb42-1797"><a href="#cb42-1797" aria-hidden="true" tabindex="-1"></a>                         dindx <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>) <span class="sc">~</span> <span class="st">"reform"</span>,</span>
<span id="cb42-1798"><a href="#cb42-1798" aria-hidden="true" tabindex="-1"></a>                         dindx <span class="sc">&gt;=</span> <span class="dv">3</span> <span class="sc">~</span> <span class="st">"large_reform"</span>))</span>
<span id="cb42-1799"><a href="#cb42-1799" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1800"><a href="#cb42-1800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1801"><a href="#cb42-1801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1802"><a href="#cb42-1802" aria-hidden="true" tabindex="-1"></a>The authors test the possibility of regional diffusion: countries within a region would then be induced to catch up with the highest level of liberalization observed within the region. Therefore, they introduce a covariate which is equal</span>
<span id="cb42-1803"><a href="#cb42-1803" aria-hidden="true" tabindex="-1"></a>to the difference between the previous value of the index and the</span>
<span id="cb42-1804"><a href="#cb42-1804" aria-hidden="true" tabindex="-1"></a>maximum value in the group of country:</span>
<span id="cb42-1805"><a href="#cb42-1805" aria-hidden="true" tabindex="-1"></a>\idxfun{group<span class="sc">\_</span>by}{dplyr}\idxfun{summarise}{dplyr}\idxfun{left<span class="sc">\_</span>join}{dplyr}\idxfun{mutate}{dplyr}</span>
<span id="cb42-1806"><a href="#cb42-1806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1807"><a href="#cb42-1807" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1808"><a href="#cb42-1808" aria-hidden="true" tabindex="-1"></a>g <span class="ot">&lt;-</span> fin_reform <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(region, year) <span class="sc">%&gt;%</span> </span>
<span id="cb42-1809"><a href="#cb42-1809" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">max_indxl =</span> <span class="fu">max</span>(indxl))</span>
<span id="cb42-1810"><a href="#cb42-1810" aria-hidden="true" tabindex="-1"></a>fin_reform <span class="ot">&lt;-</span> fin_reform <span class="sc">%&gt;%</span> <span class="fu">left_join</span>(g) <span class="sc">%&gt;%</span> </span>
<span id="cb42-1811"><a href="#cb42-1811" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">catchup =</span> max_indxl <span class="sc">-</span> indxl)</span>
<span id="cb42-1812"><a href="#cb42-1812" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1813"><a href="#cb42-1813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1814"><a href="#cb42-1814" aria-hidden="true" tabindex="-1"></a>Other covariates are the political orientation of the government</span>
<span id="cb42-1815"><a href="#cb42-1815" aria-hidden="true" tabindex="-1"></a>(<span class="in">`pol`</span>, a factor with levels <span class="in">`center`</span>, <span class="in">`left`</span> and <span class="in">`right`</span>) and dummies</span>
<span id="cb42-1816"><a href="#cb42-1816" aria-hidden="true" tabindex="-1"></a>for first year of office (<span class="in">`dum_1yofc`</span>), for balance of payments and</span>
<span id="cb42-1817"><a href="#cb42-1817" aria-hidden="true" tabindex="-1"></a>bank crises in the first two previous years (<span class="in">`dum_bop`</span> and <span class="in">`dum_bank`</span>)</span>
<span id="cb42-1818"><a href="#cb42-1818" aria-hidden="true" tabindex="-1"></a>and for recession <span class="in">`recession`</span> (growth rate <span class="in">`gdpg`</span> negative) and high</span>
<span id="cb42-1819"><a href="#cb42-1819" aria-hidden="true" tabindex="-1"></a>inflation <span class="in">`hinfl`</span> (inflation rate <span class="in">`infl`</span> greater than 50%). The relevant dummies are computed below:            </span>
<span id="cb42-1820"><a href="#cb42-1820" aria-hidden="true" tabindex="-1"></a>\idxfun{mutate}{dplyr}\idxfun{is.na}{base}\idxfun{ifelse}{base}\idxfun{lag}{dplyr}</span>
<span id="cb42-1821"><a href="#cb42-1821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1822"><a href="#cb42-1822" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1823"><a href="#cb42-1823" aria-hidden="true" tabindex="-1"></a>fin_reform <span class="ot">&lt;-</span> fin_reform <span class="sc">%&gt;%</span></span>
<span id="cb42-1824"><a href="#cb42-1824" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">dum_bop =</span> <span class="fu">ifelse</span>(bop <span class="sc">|</span> <span class="fu">lag</span>(bop) <span class="sc">|</span> (<span class="sc">!</span> <span class="fu">is.na</span>(<span class="fu">lag</span>(bop, <span class="dv">2</span>)) <span class="sc">&amp;</span> </span>
<span id="cb42-1825"><a href="#cb42-1825" aria-hidden="true" tabindex="-1"></a>                                                <span class="fu">lag</span>(bop, <span class="dv">2</span>)), <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb42-1826"><a href="#cb42-1826" aria-hidden="true" tabindex="-1"></a>           <span class="at">dum_bank =</span> <span class="fu">ifelse</span>(bank <span class="sc">|</span> <span class="fu">lag</span>(bank) <span class="sc">|</span> (<span class="sc">!</span> <span class="fu">is.na</span>(<span class="fu">lag</span>(bank, <span class="dv">2</span>)) <span class="sc">&amp;</span> </span>
<span id="cb42-1827"><a href="#cb42-1827" aria-hidden="true" tabindex="-1"></a>                                                   <span class="fu">lag</span>(bank, <span class="dv">2</span>)), <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb42-1828"><a href="#cb42-1828" aria-hidden="true" tabindex="-1"></a>           <span class="at">dum_1yofc =</span> <span class="fu">ifelse</span>(<span class="sc">!</span><span class="fu">is.na</span>(yofc) <span class="sc">&amp;</span> yofc <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb42-1829"><a href="#cb42-1829" aria-hidden="true" tabindex="-1"></a>           <span class="at">recession =</span> <span class="fu">ifelse</span>(gdpg <span class="sc">&lt;=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb42-1830"><a href="#cb42-1830" aria-hidden="true" tabindex="-1"></a>           <span class="at">hinfl =</span> <span class="fu">ifelse</span>(infl <span class="sc">&gt;</span> <span class="dv">50</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb42-1831"><a href="#cb42-1831" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1832"><a href="#cb42-1832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1833"><a href="#cb42-1833" aria-hidden="true" tabindex="-1"></a>Ordered models can be fitted using <span class="in">`MASS::polr`</span>, which has a <span class="in">`method`</span></span>
<span id="cb42-1834"><a href="#cb42-1834" aria-hidden="true" tabindex="-1"></a>argument similar to the <span class="in">`link`</span> argument of the <span class="in">`binomial`</span> function</span>
<span id="cb42-1835"><a href="#cb42-1835" aria-hidden="true" tabindex="-1"></a>used as a <span class="in">`family`</span> argument in <span class="in">`glm`</span>. It can be set to <span class="in">`logistic`</span></span>
<span id="cb42-1836"><a href="#cb42-1836" aria-hidden="true" tabindex="-1"></a>(called <span class="in">`logit`</span> for binomial) , <span class="in">`probit`</span>, <span class="in">`loglog`</span>, <span class="in">`cloglog`</span> and</span>
<span id="cb42-1837"><a href="#cb42-1837" aria-hidden="true" tabindex="-1"></a><span class="in">`cauchy`</span>. As for binomial models, <span class="in">`probit`</span> and <span class="in">`logit`</span> are by far the</span>
<span id="cb42-1838"><a href="#cb42-1838" aria-hidden="true" tabindex="-1"></a>most used links.</span>
<span id="cb42-1839"><a href="#cb42-1839" aria-hidden="true" tabindex="-1"></a>Another implementation of the ordered model is <span class="in">`micsr::ordreg`</span>. </span>
<span id="cb42-1840"><a href="#cb42-1840" aria-hidden="true" tabindex="-1"></a>@tbl-ordfinreform presents the three specifications presented</span>
<span id="cb42-1841"><a href="#cb42-1841" aria-hidden="true" tabindex="-1"></a>by @ABIA:MODY:05, table 7, page 78.\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Abiad}\index<span class="co">[</span><span class="ot">author</span><span class="co">]</span>{Mody}</span>
<span id="cb42-1842"><a href="#cb42-1842" aria-hidden="true" tabindex="-1"></a>\idxfun{polr}{MASS}\idxfun{ordreg}{micsr}\idxfun{update}{stats}</span>
<span id="cb42-1843"><a href="#cb42-1843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1846"><a href="#cb42-1846" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1847"><a href="#cb42-1847" aria-hidden="true" tabindex="-1"></a>mass1 <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">polr</span>(<span class="fu">factor</span>(dindx) <span class="sc">~</span> rhs1 <span class="sc">+</span> catchup, fin_reform, </span>
<span id="cb42-1848"><a href="#cb42-1848" aria-hidden="true" tabindex="-1"></a>                    <span class="at">method =</span> <span class="st">"logistic"</span>)</span>
<span id="cb42-1849"><a href="#cb42-1849" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">ordreg</span>(<span class="fu">factor</span>(dindx) <span class="sc">~</span> rhs1 <span class="sc">+</span> catchup, fin_reform, </span>
<span id="cb42-1850"><a href="#cb42-1850" aria-hidden="true" tabindex="-1"></a>               <span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb42-1851"><a href="#cb42-1851" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">update</span>(mod1, . <span class="sc">~</span> . <span class="sc">+</span> dum_bop <span class="sc">+</span> dum_bank <span class="sc">+</span> recession <span class="sc">+</span> hinfl)</span>
<span id="cb42-1852"><a href="#cb42-1852" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">update</span>(mod2, . <span class="sc">~</span> . <span class="sc">+</span> dum_1yofc <span class="sc">+</span> imf <span class="sc">+</span> usint <span class="sc">+</span> pol <span class="sc">+</span> open)</span>
<span id="cb42-1853"><a href="#cb42-1853" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1854"><a href="#cb42-1854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1855"><a href="#cb42-1855" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb42-1856"><a href="#cb42-1856" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-ordfinreform</span></span>
<span id="cb42-1857"><a href="#cb42-1857" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-1858"><a href="#cb42-1858" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Ordered logit models for the financial reform data set"</span></span>
<span id="cb42-1859"><a href="#cb42-1859" aria-hidden="true" tabindex="-1"></a>modelsummary<span class="sc">::</span><span class="fu">msummary</span>(<span class="fu">list</span>(mod1, mod2, mod3), <span class="at">stars  =</span> <span class="cn">TRUE</span>, <span class="at">output =</span> <span class="st">"kableExtra"</span>)</span>
<span id="cb42-1860"><a href="#cb42-1860" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1861"><a href="#cb42-1861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1862"><a href="#cb42-1862" aria-hidden="true" tabindex="-1"></a>The first column presents the result of the model with the resistance to reform and the diffusion covariates which have both of the expected signs and are significant. In the second column, the shocks covariates are added, and only the balance of payments and the bank crisis dummies are significant. Finally, in the third column, the political and economic structure  covariates are added, but none of them are significant. </span>
<span id="cb42-1863"><a href="#cb42-1863" aria-hidden="true" tabindex="-1"></a>\idxdata<span class="co">[</span><span class="ot">)</span><span class="co">]</span>{fin<span class="sc">\_</span>reform}{micsr}</span>
<span id="cb42-1864"><a href="#cb42-1864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1865"><a href="#cb42-1865" aria-hidden="true" tabindex="-1"></a>\index<span class="co">[</span><span class="ot">general</span><span class="co">]</span>{ordered model|)}</span>
<span id="cb42-1866"><a href="#cb42-1866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1867"><a href="#cb42-1867" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Bivariate probit --&gt;</span></span>
<span id="cb42-1868"><a href="#cb42-1868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1869"><a href="#cb42-1869" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The methods previously described rest on the hypothesis that the --&gt;</span></span>
<span id="cb42-1870"><a href="#cb42-1870" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- endogenous variables are normally distributed. They are therefore --&gt;</span></span>
<span id="cb42-1871"><a href="#cb42-1871" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- irrelevant in the common case where the endogenous variable is --&gt;</span></span>
<span id="cb42-1872"><a href="#cb42-1872" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- binary. In this situation, the bivariate probit model is --&gt;</span></span>
<span id="cb42-1873"><a href="#cb42-1873" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- appropriate. Denote $y_j$ and $x_j$ the two responses and the two sets --&gt;</span></span>
<span id="cb42-1874"><a href="#cb42-1874" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- of covariates. For the two responses, define $y_j^* = \beta_j ^ \top --&gt;</span></span>
<span id="cb42-1875"><a href="#cb42-1875" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- x_j + \epsilon_j$ a latent variable. $(y_1 = 0, y_2 = 0)$ is then --&gt;</span></span>
<span id="cb42-1876"><a href="#cb42-1876" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- observed if $(y_1 ^ * &lt; 0, y_2 ^ * &lt; 0)$ or $(\epsilon_1 &lt; - \beta_1 ^ --&gt;</span></span>
<span id="cb42-1877"><a href="#cb42-1877" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \top x_1, \epsilon_2 &lt; - \beta_2 ^ \top x_2)$. Assuming that the joint --&gt;</span></span>
<span id="cb42-1878"><a href="#cb42-1878" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- distribution of $(\epsilon_1, \epsilon_2)$ is normal with a --&gt;</span></span>
<span id="cb42-1879"><a href="#cb42-1879" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- coefficient of correlation $\rho$, the probability that $(y_1 = 0, y_2 --&gt;</span></span>
<span id="cb42-1880"><a href="#cb42-1880" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- = 0)$ is given by the cummulative bivariate density function: --&gt;</span></span>
<span id="cb42-1881"><a href="#cb42-1881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1882"><a href="#cb42-1882" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1883"><a href="#cb42-1883" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \mbox{P}(y_1 = 1, y_2 = 1) = \Phi_b(\beta_1 ^ \top x_1, \beta_2 ^ \top x_2, \rho) --&gt;</span></span>
<span id="cb42-1884"><a href="#cb42-1884" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1885"><a href="#cb42-1885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1886"><a href="#cb42-1886" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- @GREE:18 showed that the general formula for the probability is: --&gt;</span></span>
<span id="cb42-1887"><a href="#cb42-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1888"><a href="#cb42-1888" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1889"><a href="#cb42-1889" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \Phi_b(q_1 \beta_1 ^ \top x_1, q_2 \beta_2 ^ \top x_2, q_1 q_2 \rho) --&gt;</span></span>
<span id="cb42-1890"><a href="#cb42-1890" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1891"><a href="#cb42-1891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1892"><a href="#cb42-1892" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The log-likelihood function is then: --&gt;</span></span>
<span id="cb42-1893"><a href="#cb42-1893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1894"><a href="#cb42-1894" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1895"><a href="#cb42-1895" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \ln L = \sum_{n=1} ^ N \ln \Phi_b(q_{n1} \beta_1 ^ \top x_{n1}, q_{n2} \beta_2 ^ \top x_{n2}, q_{n1} q_{n2} \rho) --&gt;</span></span>
<span id="cb42-1896"><a href="#cb42-1896" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- $$ --&gt;</span></span>
<span id="cb42-1897"><a href="#cb42-1897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1898"><a href="#cb42-1898" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- This general model can deal with the case of endogenous dependant --&gt;</span></span>
<span id="cb42-1899"><a href="#cb42-1899" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- variable if, for example, $y_1$ is one element of $x_2$. --&gt;</span></span>
<span id="cb42-1900"><a href="#cb42-1900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1901"><a href="#cb42-1901" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r } --&gt;</span></span>
<span id="cb42-1902"><a href="#cb42-1902" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- pins &lt;- bivprobit(doctor | privateins ~ size + smsa + age + sex + educ + log(wage) | --&gt;</span></span>
<span id="cb42-1903"><a href="#cb42-1903" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                       . -privateins + pluriloc + nbemp, private_ins) --&gt;</span></span>
<span id="cb42-1904"><a href="#cb42-1904" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #pins &lt;- bivprobit(doctor | privateins ~ privateins + size + smsa + age + sex + educ + log(wage) | --&gt;</span></span>
<span id="cb42-1905"><a href="#cb42-1905" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- #                      . - privateins + pluriloc + nbemp, private_ins) --&gt;</span></span>
<span id="cb42-1906"><a href="#cb42-1906" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>